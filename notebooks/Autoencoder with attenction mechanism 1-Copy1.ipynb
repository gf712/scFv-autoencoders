{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0417 16:32:09.905183 140154006140736 deprecation_wrapper.py:76] From /home/gil/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:360: The name name_scope is deprecated. Please use compat.v1.name_scope instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"..\")\n",
    "from IPython.display import SVG\n",
    "import keras\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from models.attention_model1 import attentionmodel1\n",
    "from utils.data_preprocessing import encode_sequences, MinMaxScaler3D, shuffle_array\n",
    "from utils.parsers import parse_bulkiness, parse_hydrophobicity, parse_csv, load_kabat, aa_order, aa3_aa1\n",
    "from utils.defines import VL_LENGTH, VH_LENGTH\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AminoAcidEncoder:\n",
    "    def __init__(self, max_length, copy=True):\n",
    "        \"\"\"\n",
    "        3D matrix scaling for RNN preparation with mask\n",
    "        \"\"\"\n",
    "        self.copy = copy\n",
    "        self.aa_order = list(map(lambda x: aa3_aa1[x], aa_order))\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        result = np.zeros((len(X), self.max_length, len(aa_order)+1))\n",
    "        for i in range(len(X)):\n",
    "            for j in range(len(X[i])):\n",
    "                try:\n",
    "                    result[i, j, self.aa_order.index(X[i][j])] = 1\n",
    "                except:\n",
    "                    result[i, j, len(aa_order)] = 1\n",
    "        return result\n",
    "\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        result = list()\n",
    "        for i in range(X.shape[0]):\n",
    "            result_i=list()\n",
    "            for j in range(self.max_length):\n",
    "                idx = np.where(X[i,j]==1)[0]\n",
    "                if idx.size != 0:\n",
    "                    idx = int(idx)\n",
    "                    if idx < len(self.aa_order):\n",
    "                        result_i.append(self.aa_order[idx])\n",
    "                    else:\n",
    "                        result_i.append('')\n",
    "            print(i, ''.join(result_i))\n",
    "            result.append(''.join(result_i))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VL_sequences, VH_sequences, names_mask, animals_mask = \\\n",
    "    parse_csv(VH_LENGTH, VL_LENGTH,\n",
    "              \"../data/abysis_data_201801/abysis_data/emblig-20180125-7578.csv\",\n",
    "              \"../data/abysis_data_201801/abysis_data/kabat-20180117-10288.csv\")\n",
    "\n",
    "VH_encoded = AminoAcidEncoder(max_length=VH_LENGTH).transform(VH_sequences)\n",
    "VL_encoded = AminoAcidEncoder(max_length=VL_LENGTH).transform(VL_sequences)\n",
    "\n",
    "VH_encoded_shuffled, VL_encoded_shuffled = shuffle_array(VH_encoded, VL_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0417 16:32:17.841340 140154006140736 deprecation_wrapper.py:76] From ../models/attention_model1.py:25: The name ConfigProto is deprecated. Please use compat.v1.ConfigProto instead.\n",
      "\n",
      "W0417 16:32:17.853082 140154006140736 deprecation_wrapper.py:76] From ../models/attention_model1.py:26: The name Session is deprecated. Please use compat.v1.Session instead.\n",
      "\n",
      "W0417 16:32:18.026561 140154006140736 deprecation_wrapper.py:76] From /home/gil/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name placeholder is deprecated. Please use compat.v1.placeholder instead.\n",
      "\n",
      "W0417 16:32:18.028460 140154006140736 deprecation_wrapper.py:76] From /home/gil/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name get_default_graph is deprecated. Please use compat.v1.get_default_graph instead.\n",
      "\n",
      "W0417 16:32:21.255429 140154006140736 deprecation_wrapper.py:76] From /home/gil/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name train.Optimizer is deprecated. Please use compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"VL_output/add:0\", shape=(?, 200, 21), dtype=float32) Tensor(\"VL_INPUT:0\", shape=(?, 200, 21), dtype=float32)\n",
      "Tensor(\"VH_output/add:0\", shape=(?, 250, 21), dtype=float32) Tensor(\"VH_INPUT:0\", shape=(?, 250, 21), dtype=float32)\n",
      "[<tf.Tensor 'VL_attention_linear_output/add:0' shape=(?, 200, 21) dtype=float32>, <tf.Tensor 'VH_attention_linear_output/add:0' shape=(?, 250, 21) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "encoder, autoencoder, sess = attentionmodel1(21, latent_dim=50, RNN_cell='LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"1466pt\" viewBox=\"0.00 0.00 1827.00 1466.00\" width=\"1827pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1462)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-1462 1823,-1462 1823,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140152322856832 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140152322856832</title>\n",
       "<polygon fill=\"none\" points=\"399.5,-1411.5 399.5,-1457.5 707.5,-1457.5 707.5,-1411.5 399.5,-1411.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"474\" y=\"-1430.8\">VL_INPUT: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"548.5,-1411.5 548.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"576\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"548.5,-1434.5 603.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"576\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"603.5,-1411.5 603.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655.5\" y=\"-1442.3\">(None, 200, 21)</text>\n",
       "<polyline fill=\"none\" points=\"603.5,-1434.5 707.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655.5\" y=\"-1419.3\">(None, 200, 21)</text>\n",
       "</g>\n",
       "<!-- 140152322858288 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140152322858288</title>\n",
       "<polygon fill=\"none\" points=\"428,-1328.5 428,-1374.5 987,-1374.5 987,-1328.5 428,-1328.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"628\" y=\"-1347.8\">VL_bidirectional_RNN(cu_dnnlstm_1): Bidirectional(CuDNNLSTM)</text>\n",
       "<polyline fill=\"none\" points=\"828,-1328.5 828,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"855.5\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"828,-1351.5 883,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"855.5\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"883,-1328.5 883,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"935\" y=\"-1359.3\">(None, 200, 21)</text>\n",
       "<polyline fill=\"none\" points=\"883,-1351.5 987,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"935\" y=\"-1336.3\">(None, 16)</text>\n",
       "</g>\n",
       "<!-- 140152322856832&#45;&gt;140152322858288 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140152322856832-&gt;140152322858288</title>\n",
       "<path d=\"M596.3976,-1411.3799C614.7602,-1401.4832 636.3653,-1389.8388 655.6178,-1379.4625\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"657.4233,-1382.4654 664.5656,-1374.6399 654.1022,-1376.3034 657.4233,-1382.4654\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148946256504 -->\n",
       "<g class=\"node\" id=\"node20\">\n",
       "<title>140148946256504</title>\n",
       "<polygon fill=\"none\" points=\"0,-415.5 0,-461.5 337,-461.5 337,-415.5 0,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"37.5\" y=\"-434.8\">dot_1: Dot</text>\n",
       "<polyline fill=\"none\" points=\"75,-415.5 75,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"102.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"75,-438.5 130,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"102.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"130,-415.5 130,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-446.3\">[(None, 200, 21), (None, 200, 21)]</text>\n",
       "<polyline fill=\"none\" points=\"130,-438.5 337,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-423.3\">(None, 200, 200)</text>\n",
       "</g>\n",
       "<!-- 140152322856832&#45;&gt;140148946256504 -->\n",
       "<g class=\"edge\" id=\"edge20\">\n",
       "<title>140152322856832-&gt;140148946256504</title>\n",
       "<path d=\"M476.4553,-1411.3643C455.8525,-1402.4556 434.8051,-1390.5618 418.5,-1375 380.2532,-1338.4967 365.5,-1321.3707 365.5,-1268.5 365.5,-1268.5 365.5,-1268.5 365.5,-687.5 365.5,-613.7222 396.6105,-588.3977 365.5,-521.5\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<path d=\"M365.5,-521.5C354.18,-500.8366 305.6291,-480.2531 259.563,-464.7533\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"260.3781,-461.3366 249.7849,-461.5247 258.1833,-467.9836 260.3781,-461.3366\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945794104 -->\n",
       "<g class=\"node\" id=\"node24\">\n",
       "<title>140148945794104</title>\n",
       "<polygon fill=\"none\" points=\"176.5,-249.5 176.5,-295.5 520.5,-295.5 520.5,-249.5 176.5,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214\" y=\"-268.8\">dot_2: Dot</text>\n",
       "<polyline fill=\"none\" points=\"251.5,-249.5 251.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"251.5,-272.5 306.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"306.5,-249.5 306.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"413.5\" y=\"-280.3\">[(None, 200, 200), (None, 200, 21)]</text>\n",
       "<polyline fill=\"none\" points=\"306.5,-272.5 520.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"413.5\" y=\"-257.3\">(None, 200, 21)</text>\n",
       "</g>\n",
       "<!-- 140152322856832&#45;&gt;140148945794104 -->\n",
       "<g class=\"edge\" id=\"edge26\">\n",
       "<title>140152322856832-&gt;140148945794104</title>\n",
       "<path d=\"M365.5,-521.5C345.6567,-485.2784 345.9397,-364.9252 347.3779,-305.8263\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"350.8844,-305.6289 347.6553,-295.5382 343.887,-305.4402 350.8844,-305.6289\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140152322858344 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140152322858344</title>\n",
       "<polygon fill=\"none\" points=\"1322,-1411.5 1322,-1457.5 1631,-1457.5 1631,-1411.5 1322,-1411.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1397\" y=\"-1430.8\">VH_INPUT: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"1472,-1411.5 1472,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1499.5\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1472,-1434.5 1527,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1499.5\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1527,-1411.5 1527,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1579\" y=\"-1442.3\">(None, 250, 21)</text>\n",
       "<polyline fill=\"none\" points=\"1527,-1434.5 1631,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1579\" y=\"-1419.3\">(None, 250, 21)</text>\n",
       "</g>\n",
       "<!-- 140148954948440 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140148954948440</title>\n",
       "<polygon fill=\"none\" points=\"1022.5,-1328.5 1022.5,-1374.5 1582.5,-1374.5 1582.5,-1328.5 1022.5,-1328.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1223\" y=\"-1347.8\">VH_bidirectional_RNN(cu_dnnlstm_2): Bidirectional(CuDNNLSTM)</text>\n",
       "<polyline fill=\"none\" points=\"1423.5,-1328.5 1423.5,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1451\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1423.5,-1351.5 1478.5,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1451\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1478.5,-1328.5 1478.5,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1530.5\" y=\"-1359.3\">(None, 250, 21)</text>\n",
       "<polyline fill=\"none\" points=\"1478.5,-1351.5 1582.5,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1530.5\" y=\"-1336.3\">(None, 16)</text>\n",
       "</g>\n",
       "<!-- 140152322858344&#45;&gt;140148954948440 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140152322858344-&gt;140148954948440</title>\n",
       "<path d=\"M1428.0313,-1411.3799C1407.0023,-1401.3488 1382.2095,-1389.5224 1360.2358,-1379.0406\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1361.5429,-1375.7864 1351.0103,-1374.6399 1358.5291,-1382.1044 1361.5429,-1375.7864\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945709376 -->\n",
       "<g class=\"node\" id=\"node21\">\n",
       "<title>140148945709376</title>\n",
       "<polygon fill=\"none\" points=\"1482,-415.5 1482,-461.5 1819,-461.5 1819,-415.5 1482,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1519.5\" y=\"-434.8\">dot_3: Dot</text>\n",
       "<polyline fill=\"none\" points=\"1557,-415.5 1557,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1584.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1557,-438.5 1612,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1584.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1612,-415.5 1612,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1715.5\" y=\"-446.3\">[(None, 250, 21), (None, 250, 21)]</text>\n",
       "<polyline fill=\"none\" points=\"1612,-438.5 1819,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1715.5\" y=\"-423.3\">(None, 250, 250)</text>\n",
       "</g>\n",
       "<!-- 140152322858344&#45;&gt;140148945709376 -->\n",
       "<g class=\"edge\" id=\"edge22\">\n",
       "<title>140152322858344-&gt;140148945709376</title>\n",
       "<path d=\"M1650.5,-521.5C1643.4401,-506.319 1642.7886,-487.8211 1644.1827,-472.1443\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1647.7055,-472.1628 1645.4211,-461.8171 1640.7553,-471.3293 1647.7055,-472.1628\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945378440 -->\n",
       "<g class=\"node\" id=\"node25\">\n",
       "<title>140148945378440</title>\n",
       "<polygon fill=\"none\" points=\"1395.5,-249.5 1395.5,-295.5 1739.5,-295.5 1739.5,-249.5 1395.5,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1433\" y=\"-268.8\">dot_4: Dot</text>\n",
       "<polyline fill=\"none\" points=\"1470.5,-249.5 1470.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1470.5,-272.5 1525.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1525.5,-249.5 1525.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1632.5\" y=\"-280.3\">[(None, 250, 250), (None, 250, 21)]</text>\n",
       "<polyline fill=\"none\" points=\"1525.5,-272.5 1739.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1632.5\" y=\"-257.3\">(None, 250, 21)</text>\n",
       "</g>\n",
       "<!-- 140152322858344&#45;&gt;140148945378440 -->\n",
       "<g class=\"edge\" id=\"edge28\">\n",
       "<title>140152322858344-&gt;140148945378440</title>\n",
       "<path d=\"M1536.9787,-1411.4523C1555.9845,-1402.1684 1576.0251,-1390.0409 1591.5,-1375 1630.3027,-1337.2853 1650.5,-1322.6115 1650.5,-1268.5 1650.5,-1268.5 1650.5,-1268.5 1650.5,-687.5 1650.5,-613.7222 1681.6105,-588.3977 1650.5,-521.5\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<path d=\"M1650.5,-521.5C1611.0579,-448.479 1521.941,-529.3886 1473.5,-462 1462.3913,-446.5462 1469.3375,-349.5769 1479.5,-332 1486.5566,-319.7949 1497.2459,-309.5734 1508.7689,-301.2392\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1510.9368,-303.9986 1517.2669,-295.5027 1507.0203,-298.1968 1510.9368,-303.9986\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148954844576 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140148954844576</title>\n",
       "<polygon fill=\"none\" points=\"621,-1245.5 621,-1291.5 928,-1291.5 928,-1245.5 621,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"709\" y=\"-1264.8\">VL_encoder_dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"797,-1245.5 797,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"824.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"797,-1268.5 852,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"824.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"852,-1245.5 852,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890\" y=\"-1276.3\">(None, 16)</text>\n",
       "<polyline fill=\"none\" points=\"852,-1268.5 928,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890\" y=\"-1253.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 140152322858288&#45;&gt;140148954844576 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140152322858288-&gt;140148954844576</title>\n",
       "<path d=\"M726.1632,-1328.3799C733.3628,-1319.461 741.708,-1309.1229 749.4173,-1299.5725\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"752.1467,-1301.7636 755.7045,-1291.784 746.6998,-1297.3668 752.1467,-1301.7636\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148952428440 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140148952428440</title>\n",
       "<polygon fill=\"none\" points=\"1014,-1245.5 1014,-1291.5 1323,-1291.5 1323,-1245.5 1014,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1103\" y=\"-1264.8\">VH_encoder_dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1192,-1245.5 1192,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1219.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1192,-1268.5 1247,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1219.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1247,-1245.5 1247,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1285\" y=\"-1276.3\">(None, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1247,-1268.5 1323,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1285\" y=\"-1253.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 140148954948440&#45;&gt;140148952428440 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140148954948440-&gt;140148952428440</title>\n",
       "<path d=\"M1265.1735,-1328.3799C1249.6225,-1318.7475 1231.3988,-1307.4597 1214.9911,-1297.2967\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1216.4354,-1294.0743 1206.091,-1291.784 1212.7493,-1300.0252 1216.4354,-1294.0743\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148952018000 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140148952018000</title>\n",
       "<polygon fill=\"none\" points=\"755.5,-1162.5 755.5,-1208.5 1121.5,-1208.5 1121.5,-1162.5 755.5,-1162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"835\" y=\"-1181.8\">merge_layer: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"914.5,-1162.5 914.5,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"942\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"914.5,-1185.5 969.5,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"942\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"969.5,-1162.5 969.5,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1045.5\" y=\"-1193.3\">[(None, 32), (None, 32)]</text>\n",
       "<polyline fill=\"none\" points=\"969.5,-1185.5 1121.5,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1045.5\" y=\"-1170.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 140148954844576&#45;&gt;140148952018000 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140148954844576-&gt;140148952018000</title>\n",
       "<path d=\"M820.1831,-1245.3799C839.9151,-1235.3936 863.1629,-1223.6279 883.8048,-1213.1811\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"885.4358,-1216.2785 892.7777,-1208.6399 882.2748,-1210.0328 885.4358,-1216.2785\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148952428440&#45;&gt;140148952018000 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140148952428440-&gt;140148952018000</title>\n",
       "<path d=\"M1104.7376,-1245.4901C1075.9469,-1235.1004 1041.7706,-1222.7672 1011.9155,-1211.9934\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1012.9808,-1208.657 1002.3864,-1208.5547 1010.6046,-1215.2414 1012.9808,-1208.657\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148952108784 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140148952108784</title>\n",
       "<polygon fill=\"none\" points=\"773,-1079.5 773,-1125.5 1104,-1125.5 1104,-1079.5 773,-1079.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"873\" y=\"-1098.8\">merged_encoder_dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"973,-1079.5 973,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1000.5\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"973,-1102.5 1028,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1000.5\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1028,-1079.5 1028,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1066\" y=\"-1110.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1028,-1102.5 1104,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1066\" y=\"-1087.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 140148952018000&#45;&gt;140148952108784 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140148952018000-&gt;140148952108784</title>\n",
       "<path d=\"M938.5,-1162.3799C938.5,-1154.1745 938.5,-1144.7679 938.5,-1135.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"942.0001,-1135.784 938.5,-1125.784 935.0001,-1135.784 942.0001,-1135.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148952219544 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>140148952219544</title>\n",
       "<polygon fill=\"none\" points=\"816,-996.5 816,-1042.5 1061,-1042.5 1061,-996.5 816,-996.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"873\" y=\"-1015.8\">bottleneck: Dense</text>\n",
       "<polyline fill=\"none\" points=\"930,-996.5 930,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957.5\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"930,-1019.5 985,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957.5\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"985,-996.5 985,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023\" y=\"-1027.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"985,-1019.5 1061,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1023\" y=\"-1004.3\">(None, 50)</text>\n",
       "</g>\n",
       "<!-- 140148952108784&#45;&gt;140148952219544 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>140148952108784-&gt;140148952219544</title>\n",
       "<path d=\"M938.5,-1079.3799C938.5,-1071.1745 938.5,-1061.7679 938.5,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"942.0001,-1052.784 938.5,-1042.784 935.0001,-1052.784 942.0001,-1052.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148951792440 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>140148951792440</title>\n",
       "<polygon fill=\"none\" points=\"776.5,-913.5 776.5,-959.5 1100.5,-959.5 1100.5,-913.5 776.5,-913.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"873\" y=\"-932.8\">merged_decoder_dense1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"969.5,-913.5 969.5,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"997\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"969.5,-936.5 1024.5,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"997\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1024.5,-913.5 1024.5,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1062.5\" y=\"-944.3\">(None, 50)</text>\n",
       "<polyline fill=\"none\" points=\"1024.5,-936.5 1100.5,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1062.5\" y=\"-921.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 140148952219544&#45;&gt;140148951792440 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>140148952219544-&gt;140148951792440</title>\n",
       "<path d=\"M938.5,-996.3799C938.5,-988.1745 938.5,-978.7679 938.5,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"942.0001,-969.784 938.5,-959.784 935.0001,-969.784 942.0001,-969.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148951899328 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>140148951899328</title>\n",
       "<polygon fill=\"none\" points=\"776.5,-830.5 776.5,-876.5 1100.5,-876.5 1100.5,-830.5 776.5,-830.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"873\" y=\"-849.8\">merged_decoder_dense2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"969.5,-830.5 969.5,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"997\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"969.5,-853.5 1024.5,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"997\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1024.5,-830.5 1024.5,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1062.5\" y=\"-861.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1024.5,-853.5 1100.5,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1062.5\" y=\"-838.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 140148951792440&#45;&gt;140148951899328 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>140148951792440-&gt;140148951899328</title>\n",
       "<path d=\"M938.5,-913.3799C938.5,-905.1745 938.5,-895.7679 938.5,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"942.0001,-886.784 938.5,-876.784 935.0001,-886.784 942.0001,-886.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148951593312 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>140148951593312</title>\n",
       "<polygon fill=\"none\" points=\"688,-747.5 688,-793.5 989,-793.5 989,-747.5 688,-747.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"773\" y=\"-766.8\">VL_decoder_dense1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"858,-747.5 858,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"885.5\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"858,-770.5 913,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"885.5\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"913,-747.5 913,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"951\" y=\"-778.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"913,-770.5 989,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"951\" y=\"-755.3\">(None, 16)</text>\n",
       "</g>\n",
       "<!-- 140148951899328&#45;&gt;140148951593312 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>140148951899328-&gt;140148951593312</title>\n",
       "<path d=\"M910.6444,-830.3799C899.469,-821.1043 886.444,-810.2936 874.5608,-800.4304\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"876.4832,-797.4775 866.553,-793.784 872.0125,-802.8639 876.4832,-797.4775\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148948639872 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>140148948639872</title>\n",
       "<polygon fill=\"none\" points=\"1055.5,-747.5 1055.5,-793.5 1357.5,-793.5 1357.5,-747.5 1055.5,-747.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1141\" y=\"-766.8\">VH_decoder_dense1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1226.5,-747.5 1226.5,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1254\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1226.5,-770.5 1281.5,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1254\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1281.5,-747.5 1281.5,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1319.5\" y=\"-778.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"1281.5,-770.5 1357.5,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1319.5\" y=\"-755.3\">(None, 16)</text>\n",
       "</g>\n",
       "<!-- 140148951899328&#45;&gt;140148948639872 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>140148951899328-&gt;140148948639872</title>\n",
       "<path d=\"M1012.797,-830.4901C1046.7801,-819.9655 1087.2027,-807.4466 1122.3078,-796.5745\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1123.5415,-799.8565 1132.0584,-793.5547 1121.4706,-793.1698 1123.5415,-799.8565\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148951686728 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>140148951686728</title>\n",
       "<polygon fill=\"none\" points=\"541,-664.5 541,-710.5 946,-710.5 946,-664.5 541,-664.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664\" y=\"-683.8\">VL_decoder_repeatvector1: RepeatVector</text>\n",
       "<polyline fill=\"none\" points=\"787,-664.5 787,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"814.5\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"787,-687.5 842,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"814.5\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"842,-664.5 842,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"894\" y=\"-695.3\">(None, 16)</text>\n",
       "<polyline fill=\"none\" points=\"842,-687.5 946,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"894\" y=\"-672.3\">(None, 200, 16)</text>\n",
       "</g>\n",
       "<!-- 140148951593312&#45;&gt;140148951686728 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>140148951593312-&gt;140148951686728</title>\n",
       "<path d=\"M812.0372,-747.3799C801.4206,-738.1043 789.0468,-727.2936 777.7577,-717.4304\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"779.9839,-714.7277 770.1504,-710.784 775.3783,-719.9992 779.9839,-714.7277\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148948725320 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>140148948725320</title>\n",
       "<polygon fill=\"none\" points=\"1078,-664.5 1078,-710.5 1485,-710.5 1485,-664.5 1078,-664.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1202\" y=\"-683.8\">VH_decoder_repeatvector1: RepeatVector</text>\n",
       "<polyline fill=\"none\" points=\"1326,-664.5 1326,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1353.5\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1326,-687.5 1381,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1353.5\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1381,-664.5 1381,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1433\" y=\"-695.3\">(None, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1381,-687.5 1485,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1433\" y=\"-672.3\">(None, 250, 16)</text>\n",
       "</g>\n",
       "<!-- 140148948639872&#45;&gt;140148948725320 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>140148948639872-&gt;140148948725320</title>\n",
       "<path d=\"M1227.3917,-747.3799C1235.5315,-738.3718 1244.9795,-727.916 1253.6811,-718.2863\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1256.3526,-720.5502 1260.4602,-710.784 1251.1589,-715.8571 1256.3526,-720.5502\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148951395296 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>140148951395296</title>\n",
       "<polygon fill=\"none\" points=\"393,-581.5 393,-627.5 998,-627.5 998,-581.5 393,-581.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"616\" y=\"-600.8\">VL_decoder_bidirectional_rnn1(cu_dnnlstm_3): Bidirectional(CuDNNLSTM)</text>\n",
       "<polyline fill=\"none\" points=\"839,-581.5 839,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"866.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"839,-604.5 894,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"866.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"894,-581.5 894,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"946\" y=\"-612.3\">(None, 200, 16)</text>\n",
       "<polyline fill=\"none\" points=\"894,-604.5 998,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"946\" y=\"-589.3\">(None, 200, 16)</text>\n",
       "</g>\n",
       "<!-- 140148951686728&#45;&gt;140148951395296 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>140148951686728-&gt;140148951395296</title>\n",
       "<path d=\"M730.1293,-664.3799C725.1778,-655.8178 719.4697,-645.9477 714.1345,-636.7222\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"717.0016,-634.6885 708.9654,-627.784 710.9419,-638.1929 717.0016,-634.6885\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148948450328 -->\n",
       "<g class=\"node\" id=\"node17\">\n",
       "<title>140148948450328</title>\n",
       "<polygon fill=\"none\" points=\"1016.5,-581.5 1016.5,-627.5 1622.5,-627.5 1622.5,-581.5 1016.5,-581.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1240\" y=\"-600.8\">VH_decoder_bidirectional_rnn1(cu_dnnlstm_4): Bidirectional(CuDNNLSTM)</text>\n",
       "<polyline fill=\"none\" points=\"1463.5,-581.5 1463.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1491\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1463.5,-604.5 1518.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1491\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1518.5,-581.5 1518.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1570.5\" y=\"-612.3\">(None, 250, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1518.5,-604.5 1622.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1570.5\" y=\"-589.3\">(None, 250, 16)</text>\n",
       "</g>\n",
       "<!-- 140148948725320&#45;&gt;140148948450328 -->\n",
       "<g class=\"edge\" id=\"edge16\">\n",
       "<title>140148948725320-&gt;140148948450328</title>\n",
       "<path d=\"M1292.0851,-664.3799C1295.9643,-655.907 1300.4299,-646.1531 1304.6156,-637.0107\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1307.8594,-638.3334 1308.8399,-627.784 1301.4947,-635.4194 1307.8594,-638.3334\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148950996080 -->\n",
       "<g class=\"node\" id=\"node18\">\n",
       "<title>140148950996080</title>\n",
       "<polygon fill=\"none\" points=\"410.5,-498.5 410.5,-544.5 686.5,-544.5 686.5,-498.5 410.5,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"469\" y=\"-517.8\">VL_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"527.5,-498.5 527.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"527.5,-521.5 582.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"582.5,-498.5 582.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"634.5\" y=\"-529.3\">(None, 200, 16)</text>\n",
       "<polyline fill=\"none\" points=\"582.5,-521.5 686.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"634.5\" y=\"-506.3\">(None, 200, 21)</text>\n",
       "</g>\n",
       "<!-- 140148951395296&#45;&gt;140148950996080 -->\n",
       "<g class=\"edge\" id=\"edge17\">\n",
       "<title>140148951395296-&gt;140148950996080</title>\n",
       "<path d=\"M654.5523,-581.3799C637.1037,-571.5279 616.5878,-559.9442 598.2735,-549.6034\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"599.9115,-546.5089 589.4828,-544.6399 596.4698,-552.6044 599.9115,-546.5089\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148948546728 -->\n",
       "<g class=\"node\" id=\"node19\">\n",
       "<title>140148948546728</title>\n",
       "<polygon fill=\"none\" points=\"1228.5,-498.5 1228.5,-544.5 1506.5,-544.5 1506.5,-498.5 1228.5,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1288\" y=\"-517.8\">VH_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1347.5,-498.5 1347.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1375\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1347.5,-521.5 1402.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1375\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1402.5,-498.5 1402.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1454.5\" y=\"-529.3\">(None, 250, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1402.5,-521.5 1506.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1454.5\" y=\"-506.3\">(None, 250, 21)</text>\n",
       "</g>\n",
       "<!-- 140148948450328&#45;&gt;140148948546728 -->\n",
       "<g class=\"edge\" id=\"edge18\">\n",
       "<title>140148948450328-&gt;140148948546728</title>\n",
       "<path d=\"M1332.8707,-581.3799C1337.8222,-572.8178 1343.5303,-562.9477 1348.8655,-553.7222\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1352.0581,-555.1929 1354.0346,-544.784 1345.9984,-551.6885 1352.0581,-555.1929\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148950996080&#45;&gt;140148946256504 -->\n",
       "<g class=\"edge\" id=\"edge19\">\n",
       "<title>140148950996080-&gt;140148946256504</title>\n",
       "<path d=\"M443.1534,-498.4901C393.733,-487.6956 334.7077,-474.8033 284.0633,-463.7415\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"284.568,-460.2693 274.0515,-461.5547 283.0743,-467.108 284.568,-460.2693\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945796344 -->\n",
       "<g class=\"node\" id=\"node26\">\n",
       "<title>140148945796344</title>\n",
       "<polygon fill=\"none\" points=\"177.5,-166.5 177.5,-212.5 719.5,-212.5 719.5,-166.5 177.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-185.8\">merge_context_decoder_layer_VL: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"457.5,-166.5 457.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"457.5,-189.5 512.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"512.5,-166.5 512.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"616\" y=\"-197.3\">[(None, 200, 21), (None, 200, 21)]</text>\n",
       "<polyline fill=\"none\" points=\"512.5,-189.5 719.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"616\" y=\"-174.3\">(None, 200, 42)</text>\n",
       "</g>\n",
       "<!-- 140148950996080&#45;&gt;140148945796344 -->\n",
       "<g class=\"edge\" id=\"edge30\">\n",
       "<title>140148950996080-&gt;140148945796344</title>\n",
       "<path d=\"M553.0556,-498.1666C561.4598,-448.6845 574.6856,-331.0418 529.5,-249 522.9933,-237.186 513.0312,-227.0817 502.2936,-218.7318\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"504.1234,-215.735 493.9757,-212.6892 500.0092,-221.3983 504.1234,-215.735\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148948546728&#45;&gt;140148945709376 -->\n",
       "<g class=\"edge\" id=\"edge21\">\n",
       "<title>140148948546728-&gt;140148945709376</title>\n",
       "<path d=\"M1445.9555,-498.4901C1481.9939,-487.9205 1524.8905,-475.3395 1562.0705,-464.4352\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1563.2811,-467.7276 1571.8919,-461.5547 1561.3111,-461.0105 1563.2811,-467.7276\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945375864 -->\n",
       "<g class=\"node\" id=\"node27\">\n",
       "<title>140148945375864</title>\n",
       "<polygon fill=\"none\" points=\"1196,-166.5 1196,-212.5 1739,-212.5 1739,-166.5 1196,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1336.5\" y=\"-185.8\">merge_context_decoder_layer_VH: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"1477,-166.5 1477,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1504.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1477,-189.5 1532,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1504.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1532,-166.5 1532,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1635.5\" y=\"-197.3\">[(None, 250, 21), (None, 250, 21)]</text>\n",
       "<polyline fill=\"none\" points=\"1532,-189.5 1739,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1635.5\" y=\"-174.3\">(None, 250, 42)</text>\n",
       "</g>\n",
       "<!-- 140148948546728&#45;&gt;140148945375864 -->\n",
       "<g class=\"edge\" id=\"edge32\">\n",
       "<title>140148948546728-&gt;140148945375864</title>\n",
       "<path d=\"M1362.9444,-498.1666C1354.5402,-448.6845 1341.3144,-331.0418 1386.5,-249 1393.0067,-237.186 1402.9688,-227.0817 1413.7064,-218.7318\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1415.9908,-221.3983 1422.0243,-212.6892 1411.8766,-215.735 1415.9908,-221.3983\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945794440 -->\n",
       "<g class=\"node\" id=\"node22\">\n",
       "<title>140148945794440</title>\n",
       "<polygon fill=\"none\" points=\"18,-332.5 18,-378.5 331,-378.5 331,-332.5 18,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92\" y=\"-351.8\">activation_1: Activation</text>\n",
       "<polyline fill=\"none\" points=\"166,-332.5 166,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"166,-355.5 221,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"221,-332.5 221,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-363.3\">(None, 200, 200)</text>\n",
       "<polyline fill=\"none\" points=\"221,-355.5 331,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276\" y=\"-340.3\">(None, 200, 200)</text>\n",
       "</g>\n",
       "<!-- 140148946256504&#45;&gt;140148945794440 -->\n",
       "<g class=\"edge\" id=\"edge23\">\n",
       "<title>140148946256504-&gt;140148945794440</title>\n",
       "<path d=\"M170.1713,-415.3799C170.7645,-407.1745 171.4445,-397.7679 172.0871,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"175.5866,-389.0104 172.8168,-378.784 168.6048,-388.5056 175.5866,-389.0104\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945378496 -->\n",
       "<g class=\"node\" id=\"node23\">\n",
       "<title>140148945378496</title>\n",
       "<polygon fill=\"none\" points=\"1488,-332.5 1488,-378.5 1801,-378.5 1801,-332.5 1488,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1562\" y=\"-351.8\">activation_2: Activation</text>\n",
       "<polyline fill=\"none\" points=\"1636,-332.5 1636,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1663.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1636,-355.5 1691,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1663.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1691,-332.5 1691,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1746\" y=\"-363.3\">(None, 250, 250)</text>\n",
       "<polyline fill=\"none\" points=\"1691,-355.5 1801,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1746\" y=\"-340.3\">(None, 250, 250)</text>\n",
       "</g>\n",
       "<!-- 140148945709376&#45;&gt;140148945378496 -->\n",
       "<g class=\"edge\" id=\"edge24\">\n",
       "<title>140148945709376-&gt;140148945378496</title>\n",
       "<path d=\"M1648.8287,-415.3799C1648.2355,-407.1745 1647.5555,-397.7679 1646.9129,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1650.3952,-388.5056 1646.1832,-378.784 1643.4134,-389.0104 1650.3952,-388.5056\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945794440&#45;&gt;140148945794104 -->\n",
       "<g class=\"edge\" id=\"edge25\">\n",
       "<title>140148945794440-&gt;140148945794104</title>\n",
       "<path d=\"M222.9687,-332.3799C243.9977,-322.3488 268.7905,-310.5224 290.7642,-300.0406\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"292.4709,-303.1044 299.9897,-295.6399 289.4571,-296.7864 292.4709,-303.1044\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945378496&#45;&gt;140148945378440 -->\n",
       "<g class=\"edge\" id=\"edge27\">\n",
       "<title>140148945378496-&gt;140148945378440</title>\n",
       "<path d=\"M1623.0512,-332.3799C1614.6944,-323.3718 1604.9943,-312.916 1596.0608,-303.2863\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1598.4679,-300.7347 1589.1008,-295.784 1593.3361,-305.4955 1598.4679,-300.7347\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945794104&#45;&gt;140148945796344 -->\n",
       "<g class=\"edge\" id=\"edge29\">\n",
       "<title>140148945794104-&gt;140148945796344</title>\n",
       "<path d=\"M376.3556,-249.3799C387.531,-240.1043 400.556,-229.2936 412.4392,-219.4304\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"414.9875,-221.8639 420.447,-212.784 410.5168,-216.4775 414.9875,-221.8639\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945378440&#45;&gt;140148945375864 -->\n",
       "<g class=\"edge\" id=\"edge31\">\n",
       "<title>140148945378440-&gt;140148945375864</title>\n",
       "<path d=\"M1539.6444,-249.3799C1528.469,-240.1043 1515.444,-229.2936 1503.5608,-219.4304\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1505.4832,-216.4775 1495.553,-212.784 1501.0125,-221.8639 1505.4832,-216.4775\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945793376 -->\n",
       "<g class=\"node\" id=\"node28\">\n",
       "<title>140148945793376</title>\n",
       "<polygon fill=\"none\" points=\"268.5,-83.5 268.5,-129.5 628.5,-129.5 628.5,-83.5 268.5,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369\" y=\"-102.8\">VL_attention_tanh_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"469.5,-83.5 469.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"469.5,-106.5 524.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"524.5,-83.5 524.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"576.5\" y=\"-114.3\">(None, 200, 42)</text>\n",
       "<polyline fill=\"none\" points=\"524.5,-106.5 628.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"576.5\" y=\"-91.3\">(None, 200, 16)</text>\n",
       "</g>\n",
       "<!-- 140148945796344&#45;&gt;140148945793376 -->\n",
       "<g class=\"edge\" id=\"edge33\">\n",
       "<title>140148945796344-&gt;140148945793376</title>\n",
       "<path d=\"M448.5,-166.3799C448.5,-158.1745 448.5,-148.7679 448.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"452.0001,-139.784 448.5,-129.784 445.0001,-139.784 452.0001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945378216 -->\n",
       "<g class=\"node\" id=\"node29\">\n",
       "<title>140148945378216</title>\n",
       "<polygon fill=\"none\" points=\"1286.5,-83.5 1286.5,-129.5 1648.5,-129.5 1648.5,-83.5 1286.5,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1388\" y=\"-102.8\">VH_attention_tanh_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1489.5,-83.5 1489.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1517\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1489.5,-106.5 1544.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1517\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1544.5,-83.5 1544.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1596.5\" y=\"-114.3\">(None, 250, 42)</text>\n",
       "<polyline fill=\"none\" points=\"1544.5,-106.5 1648.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1596.5\" y=\"-91.3\">(None, 250, 16)</text>\n",
       "</g>\n",
       "<!-- 140148945375864&#45;&gt;140148945378216 -->\n",
       "<g class=\"edge\" id=\"edge34\">\n",
       "<title>140148945375864-&gt;140148945378216</title>\n",
       "<path d=\"M1467.5,-166.3799C1467.5,-158.1745 1467.5,-148.7679 1467.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1471.0001,-139.784 1467.5,-129.784 1464.0001,-139.784 1471.0001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945504072 -->\n",
       "<g class=\"node\" id=\"node30\">\n",
       "<title>140148945504072</title>\n",
       "<polygon fill=\"none\" points=\"264.5,-.5 264.5,-46.5 632.5,-46.5 632.5,-.5 264.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369\" y=\"-19.8\">VL_attention_linear_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"473.5,-.5 473.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"473.5,-23.5 528.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"501\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"528.5,-.5 528.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"580.5\" y=\"-31.3\">(None, 200, 16)</text>\n",
       "<polyline fill=\"none\" points=\"528.5,-23.5 632.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"580.5\" y=\"-8.3\">(None, 200, 21)</text>\n",
       "</g>\n",
       "<!-- 140148945793376&#45;&gt;140148945504072 -->\n",
       "<g class=\"edge\" id=\"edge35\">\n",
       "<title>140148945793376-&gt;140148945504072</title>\n",
       "<path d=\"M448.5,-83.3799C448.5,-75.1745 448.5,-65.7679 448.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"452.0001,-56.784 448.5,-46.784 445.0001,-56.784 452.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140148945098232 -->\n",
       "<g class=\"node\" id=\"node31\">\n",
       "<title>140148945098232</title>\n",
       "<polygon fill=\"none\" points=\"1283,-.5 1283,-46.5 1652,-46.5 1652,-.5 1283,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1388\" y=\"-19.8\">VH_attention_linear_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1493,-.5 1493,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1520.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1493,-23.5 1548,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1520.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1548,-.5 1548,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1600\" y=\"-31.3\">(None, 250, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1548,-23.5 1652,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1600\" y=\"-8.3\">(None, 250, 21)</text>\n",
       "</g>\n",
       "<!-- 140148945378216&#45;&gt;140148945098232 -->\n",
       "<g class=\"edge\" id=\"edge36\">\n",
       "<title>140148945378216-&gt;140148945098232</title>\n",
       "<path d=\"M1467.5,-83.3799C1467.5,-75.1745 1467.5,-65.7679 1467.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1471.0001,-56.784 1467.5,-46.784 1464.0001,-56.784 1471.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(autoencoder, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "VL_INPUT (InputLayer)           (None, 200, 21)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VH_INPUT (InputLayer)           (None, 250, 21)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_bidirectional_RNN (Bidirecti (None, 16)           4992        VL_INPUT[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "VH_bidirectional_RNN (Bidirecti (None, 16)           4992        VH_INPUT[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "VL_encoder_dense_1 (Dense)      (None, 32)           544         VL_bidirectional_RNN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "VH_encoder_dense_1 (Dense)      (None, 32)           544         VH_bidirectional_RNN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "merge_layer (Concatenate)       (None, 64)           0           VL_encoder_dense_1[0][0]         \n",
      "                                                                 VH_encoder_dense_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "merged_encoder_dense_1 (Dense)  (None, 32)           2080        merge_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bottleneck (Dense)              (None, 50)           1650        merged_encoder_dense_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "merged_decoder_dense1 (Dense)   (None, 32)           1632        bottleneck[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merged_decoder_dense2 (Dense)   (None, 64)           2112        merged_decoder_dense1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "VL_decoder_dense1 (Dense)       (None, 16)           1040        merged_decoder_dense2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "VH_decoder_dense1 (Dense)       (None, 16)           1040        merged_decoder_dense2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "VL_decoder_repeatvector1 (Repea (None, 200, 16)      0           VL_decoder_dense1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "VH_decoder_repeatvector1 (Repea (None, 250, 16)      0           VH_decoder_dense1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "VL_decoder_bidirectional_rnn1 ( (None, 200, 16)      4352        VL_decoder_repeatvector1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "VH_decoder_bidirectional_rnn1 ( (None, 250, 16)      4352        VH_decoder_repeatvector1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "VL_output (Dense)               (None, 200, 21)      357         VL_decoder_bidirectional_rnn1[0][\n",
      "__________________________________________________________________________________________________\n",
      "VH_output (Dense)               (None, 250, 21)      357         VH_decoder_bidirectional_rnn1[0][\n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 200, 200)     0           VL_output[0][0]                  \n",
      "                                                                 VL_INPUT[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 250, 250)     0           VH_output[0][0]                  \n",
      "                                                                 VH_INPUT[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 200, 200)     0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 250, 250)     0           dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 200, 21)      0           activation_1[0][0]               \n",
      "                                                                 VL_INPUT[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 250, 21)      0           activation_2[0][0]               \n",
      "                                                                 VH_INPUT[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merge_context_decoder_layer_VL  (None, 200, 42)      0           dot_2[0][0]                      \n",
      "                                                                 VL_output[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_context_decoder_layer_VH  (None, 250, 42)      0           dot_4[0][0]                      \n",
      "                                                                 VH_output[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "VL_attention_tanh_output (Dense (None, 200, 16)      688         merge_context_decoder_layer_VL[0]\n",
      "__________________________________________________________________________________________________\n",
      "VH_attention_tanh_output (Dense (None, 250, 16)      688         merge_context_decoder_layer_VH[0]\n",
      "__________________________________________________________________________________________________\n",
      "VL_attention_linear_output (Den (None, 200, 21)      357         VL_attention_tanh_output[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "VH_attention_linear_output (Den (None, 250, 21)      357         VH_attention_tanh_output[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 32,134\n",
      "Trainable params: 32,134\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME= 'attention_autoencoder1_raw_lstm'\n",
    "RUN = 'run2'\n",
    "\n",
    "weight_path = '../model_weights/{}/{}/{}.hdf5'.format(NAME,RUN,NAME)\n",
    "log_path = '../logs/{}/{}'.format(NAME, RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../model_weights/{}/{}/'.format(NAME,RUN)):\n",
    "    if not os.path.exists('../model_weights/{}'.format(NAME)):\n",
    "        os.mkdir('../model_weights/{}'.format(NAME))\n",
    "    os.mkdir('../model_weights/{}/{}'.format(NAME,RUN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(mask_value):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    :param mask_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    mask_value = K.constant(mask_value, dtype=K.floatx())\n",
    "\n",
    "    def masked_entropy(y_true, y_pred):\n",
    "        # find out which timesteps in `y_true` are not the padding character\n",
    "        mask = K.all(K.equal(y_true, mask_value), axis=-1)\n",
    "        mask = 1 - K.cast(mask, K.floatx())\n",
    "        mask_sum = K.sum(mask)\n",
    "        l=K.tf.contrib.seq2seq.sequence_loss(targets=K.argmax(y_true), logits=y_pred, weights=mask,\n",
    "                                     average_across_batch=False, average_across_timesteps=False)\n",
    "        return K.sum(l) / mask_sum\n",
    "    return masked_entropy\n",
    "    \n",
    "lhs=K.placeholder((None,200,21))\n",
    "rhs=K.placeholder((None,200,21))\n",
    "\n",
    "func=get_loss(0)(lhs, rhs)\n",
    "r=sess.run(func, feed_dict={lhs: VL_encoded_shuffled[:1], rhs: VL_encoded_shuffled[:1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_pred):\n",
    "    mask = K.all(K.equal(y_true, 0), axis=-1)\n",
    "    mask = 1 - K.cast(mask, K.floatx())\n",
    "    mask_sum = K.sum(mask)\n",
    "    acc = K.cast(K.equal(K.argmax(y_true), K.argmax(K.softmax(y_pred))), dtype=K.floatx()) * mask\n",
    "    return K.sum(acc) / mask_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=keras.optimizers.Adamax(), loss=get_loss(0), metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4144 samples, validate on 1036 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0417 16:32:31.039015 140154006140736 deprecation_wrapper.py:76] From /home/gil/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name summary.merge_all is deprecated. Please use compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0417 16:32:31.039512 140154006140736 deprecation_wrapper.py:76] From /home/gil/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name summary.FileWriter is deprecated. Please use compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4144/4144 [==============================] - 11s 3ms/step - loss: 5.6941 - VL_attention_linear_output_loss: 2.8271 - VH_attention_linear_output_loss: 2.8671 - VL_attention_linear_output_acc: 0.1395 - VH_attention_linear_output_acc: 0.1159 - val_loss: 5.6149 - val_VL_attention_linear_output_loss: 2.7906 - val_VH_attention_linear_output_loss: 2.8243 - val_VL_attention_linear_output_acc: 0.1474 - val_VH_attention_linear_output_acc: 0.1237\n",
      "Epoch 2/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.5886 - VL_attention_linear_output_loss: 2.7780 - VH_attention_linear_output_loss: 2.8107 - VL_attention_linear_output_acc: 0.1497 - VH_attention_linear_output_acc: 0.1275 - val_loss: 5.5566 - val_VL_attention_linear_output_loss: 2.7628 - val_VH_attention_linear_output_loss: 2.7938 - val_VL_attention_linear_output_acc: 0.1571 - val_VH_attention_linear_output_acc: 0.1302\n",
      "Epoch 3/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.5419 - VL_attention_linear_output_loss: 2.7531 - VH_attention_linear_output_loss: 2.7888 - VL_attention_linear_output_acc: 0.1543 - VH_attention_linear_output_acc: 0.1300 - val_loss: 5.5192 - val_VL_attention_linear_output_loss: 2.7391 - val_VH_attention_linear_output_loss: 2.7801 - val_VL_attention_linear_output_acc: 0.1490 - val_VH_attention_linear_output_acc: 0.1377\n",
      "Epoch 4/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.5070 - VL_attention_linear_output_loss: 2.7291 - VH_attention_linear_output_loss: 2.7779 - VL_attention_linear_output_acc: 0.1604 - VH_attention_linear_output_acc: 0.1327 - val_loss: 5.4975 - val_VL_attention_linear_output_loss: 2.7256 - val_VH_attention_linear_output_loss: 2.7719 - val_VL_attention_linear_output_acc: 0.1622 - val_VH_attention_linear_output_acc: 0.1386\n",
      "Epoch 5/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.4803 - VL_attention_linear_output_loss: 2.7089 - VH_attention_linear_output_loss: 2.7714 - VL_attention_linear_output_acc: 0.1664 - VH_attention_linear_output_acc: 0.1341 - val_loss: 5.4597 - val_VL_attention_linear_output_loss: 2.6968 - val_VH_attention_linear_output_loss: 2.7629 - val_VL_attention_linear_output_acc: 0.1630 - val_VH_attention_linear_output_acc: 0.1345\n",
      "Epoch 6/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.4508 - VL_attention_linear_output_loss: 2.6874 - VH_attention_linear_output_loss: 2.7634 - VL_attention_linear_output_acc: 0.1664 - VH_attention_linear_output_acc: 0.1349 - val_loss: 5.4332 - val_VL_attention_linear_output_loss: 2.6785 - val_VH_attention_linear_output_loss: 2.7547 - val_VL_attention_linear_output_acc: 0.1511 - val_VH_attention_linear_output_acc: 0.1335\n",
      "Epoch 7/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.4227 - VL_attention_linear_output_loss: 2.6689 - VH_attention_linear_output_loss: 2.7538 - VL_attention_linear_output_acc: 0.1638 - VH_attention_linear_output_acc: 0.1336 - val_loss: 5.4014 - val_VL_attention_linear_output_loss: 2.6561 - val_VH_attention_linear_output_loss: 2.7453 - val_VL_attention_linear_output_acc: 0.1735 - val_VH_attention_linear_output_acc: 0.1376\n",
      "Epoch 8/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.3935 - VL_attention_linear_output_loss: 2.6483 - VH_attention_linear_output_loss: 2.7452 - VL_attention_linear_output_acc: 0.1713 - VH_attention_linear_output_acc: 0.1421 - val_loss: 5.3691 - val_VL_attention_linear_output_loss: 2.6334 - val_VH_attention_linear_output_loss: 2.7357 - val_VL_attention_linear_output_acc: 0.1781 - val_VH_attention_linear_output_acc: 0.1538\n",
      "Epoch 9/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.3643 - VL_attention_linear_output_loss: 2.6277 - VH_attention_linear_output_loss: 2.7366 - VL_attention_linear_output_acc: 0.1745 - VH_attention_linear_output_acc: 0.1504 - val_loss: 5.3397 - val_VL_attention_linear_output_loss: 2.6130 - val_VH_attention_linear_output_loss: 2.7267 - val_VL_attention_linear_output_acc: 0.1793 - val_VH_attention_linear_output_acc: 0.1513\n",
      "Epoch 10/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.3321 - VL_attention_linear_output_loss: 2.6044 - VH_attention_linear_output_loss: 2.7278 - VL_attention_linear_output_acc: 0.1775 - VH_attention_linear_output_acc: 0.1504 - val_loss: 5.3125 - val_VL_attention_linear_output_loss: 2.5914 - val_VH_attention_linear_output_loss: 2.7211 - val_VL_attention_linear_output_acc: 0.1788 - val_VH_attention_linear_output_acc: 0.1499\n",
      "Epoch 11/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.3034 - VL_attention_linear_output_loss: 2.5842 - VH_attention_linear_output_loss: 2.7193 - VL_attention_linear_output_acc: 0.1823 - VH_attention_linear_output_acc: 0.1512 - val_loss: 5.2750 - val_VL_attention_linear_output_loss: 2.5628 - val_VH_attention_linear_output_loss: 2.7122 - val_VL_attention_linear_output_acc: 0.1935 - val_VH_attention_linear_output_acc: 0.1525\n",
      "Epoch 12/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.2661 - VL_attention_linear_output_loss: 2.5546 - VH_attention_linear_output_loss: 2.7115 - VL_attention_linear_output_acc: 0.1972 - VH_attention_linear_output_acc: 0.1515 - val_loss: 5.2599 - val_VL_attention_linear_output_loss: 2.5553 - val_VH_attention_linear_output_loss: 2.7047 - val_VL_attention_linear_output_acc: 0.1919 - val_VH_attention_linear_output_acc: 0.1513\n",
      "Epoch 13/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.2313 - VL_attention_linear_output_loss: 2.5244 - VH_attention_linear_output_loss: 2.7069 - VL_attention_linear_output_acc: 0.2119 - VH_attention_linear_output_acc: 0.1512 - val_loss: 5.2088 - val_VL_attention_linear_output_loss: 2.5153 - val_VH_attention_linear_output_loss: 2.6936 - val_VL_attention_linear_output_acc: 0.2080 - val_VH_attention_linear_output_acc: 0.1558\n",
      "Epoch 14/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.1905 - VL_attention_linear_output_loss: 2.4915 - VH_attention_linear_output_loss: 2.6990 - VL_attention_linear_output_acc: 0.2223 - VH_attention_linear_output_acc: 0.1522 - val_loss: 5.1531 - val_VL_attention_linear_output_loss: 2.4598 - val_VH_attention_linear_output_loss: 2.6932 - val_VL_attention_linear_output_acc: 0.2336 - val_VH_attention_linear_output_acc: 0.1508\n",
      "Epoch 15/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.1545 - VL_attention_linear_output_loss: 2.4636 - VH_attention_linear_output_loss: 2.6909 - VL_attention_linear_output_acc: 0.2288 - VH_attention_linear_output_acc: 0.1531 - val_loss: 5.1238 - val_VL_attention_linear_output_loss: 2.4423 - val_VH_attention_linear_output_loss: 2.6814 - val_VL_attention_linear_output_acc: 0.2335 - val_VH_attention_linear_output_acc: 0.1546\n",
      "Epoch 16/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.1303 - VL_attention_linear_output_loss: 2.4435 - VH_attention_linear_output_loss: 2.6867 - VL_attention_linear_output_acc: 0.2331 - VH_attention_linear_output_acc: 0.1534 - val_loss: 5.0874 - val_VL_attention_linear_output_loss: 2.4133 - val_VH_attention_linear_output_loss: 2.6740 - val_VL_attention_linear_output_acc: 0.2387 - val_VH_attention_linear_output_acc: 0.1562\n",
      "Epoch 17/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.1013 - VL_attention_linear_output_loss: 2.4235 - VH_attention_linear_output_loss: 2.6778 - VL_attention_linear_output_acc: 0.2358 - VH_attention_linear_output_acc: 0.1541 - val_loss: 5.0748 - val_VL_attention_linear_output_loss: 2.4080 - val_VH_attention_linear_output_loss: 2.6667 - val_VL_attention_linear_output_acc: 0.2389 - val_VH_attention_linear_output_acc: 0.1566\n",
      "Epoch 18/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.0893 - VL_attention_linear_output_loss: 2.4150 - VH_attention_linear_output_loss: 2.6743 - VL_attention_linear_output_acc: 0.2374 - VH_attention_linear_output_acc: 0.1547 - val_loss: 5.0568 - val_VL_attention_linear_output_loss: 2.3827 - val_VH_attention_linear_output_loss: 2.6742 - val_VL_attention_linear_output_acc: 0.2399 - val_VH_attention_linear_output_acc: 0.1540\n",
      "Epoch 19/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.0533 - VL_attention_linear_output_loss: 2.3898 - VH_attention_linear_output_loss: 2.6635 - VL_attention_linear_output_acc: 0.2418 - VH_attention_linear_output_acc: 0.1569 - val_loss: 5.0222 - val_VL_attention_linear_output_loss: 2.3677 - val_VH_attention_linear_output_loss: 2.6545 - val_VL_attention_linear_output_acc: 0.2452 - val_VH_attention_linear_output_acc: 0.1599\n",
      "Epoch 20/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.0361 - VL_attention_linear_output_loss: 2.3773 - VH_attention_linear_output_loss: 2.6588 - VL_attention_linear_output_acc: 0.2432 - VH_attention_linear_output_acc: 0.1584 - val_loss: 5.0136 - val_VL_attention_linear_output_loss: 2.3549 - val_VH_attention_linear_output_loss: 2.6587 - val_VL_attention_linear_output_acc: 0.2485 - val_VH_attention_linear_output_acc: 0.1553\n",
      "Epoch 21/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.0207 - VL_attention_linear_output_loss: 2.3674 - VH_attention_linear_output_loss: 2.6533 - VL_attention_linear_output_acc: 0.2450 - VH_attention_linear_output_acc: 0.1596 - val_loss: 4.9961 - val_VL_attention_linear_output_loss: 2.3426 - val_VH_attention_linear_output_loss: 2.6535 - val_VL_attention_linear_output_acc: 0.2538 - val_VH_attention_linear_output_acc: 0.1568\n",
      "Epoch 22/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 5.0105 - VL_attention_linear_output_loss: 2.3605 - VH_attention_linear_output_loss: 2.6500 - VL_attention_linear_output_acc: 0.2497 - VH_attention_linear_output_acc: 0.1601 - val_loss: 4.9747 - val_VL_attention_linear_output_loss: 2.3381 - val_VH_attention_linear_output_loss: 2.6366 - val_VL_attention_linear_output_acc: 0.2524 - val_VH_attention_linear_output_acc: 0.1661\n",
      "Epoch 23/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.9860 - VL_attention_linear_output_loss: 2.3451 - VH_attention_linear_output_loss: 2.6408 - VL_attention_linear_output_acc: 0.2548 - VH_attention_linear_output_acc: 0.1622 - val_loss: 4.9709 - val_VL_attention_linear_output_loss: 2.3392 - val_VH_attention_linear_output_loss: 2.6317 - val_VL_attention_linear_output_acc: 0.2555 - val_VH_attention_linear_output_acc: 0.1641\n",
      "Epoch 24/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.9683 - VL_attention_linear_output_loss: 2.3329 - VH_attention_linear_output_loss: 2.6354 - VL_attention_linear_output_acc: 0.2585 - VH_attention_linear_output_acc: 0.1626 - val_loss: 4.9509 - val_VL_attention_linear_output_loss: 2.3086 - val_VH_attention_linear_output_loss: 2.6422 - val_VL_attention_linear_output_acc: 0.2618 - val_VH_attention_linear_output_acc: 0.1568\n",
      "Epoch 25/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.9502 - VL_attention_linear_output_loss: 2.3179 - VH_attention_linear_output_loss: 2.6323 - VL_attention_linear_output_acc: 0.2625 - VH_attention_linear_output_acc: 0.1629 - val_loss: 4.9546 - val_VL_attention_linear_output_loss: 2.3336 - val_VH_attention_linear_output_loss: 2.6210 - val_VL_attention_linear_output_acc: 0.2492 - val_VH_attention_linear_output_acc: 0.1649\n",
      "Epoch 26/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.9377 - VL_attention_linear_output_loss: 2.3097 - VH_attention_linear_output_loss: 2.6280 - VL_attention_linear_output_acc: 0.2640 - VH_attention_linear_output_acc: 0.1631 - val_loss: 4.9255 - val_VL_attention_linear_output_loss: 2.3019 - val_VH_attention_linear_output_loss: 2.6236 - val_VL_attention_linear_output_acc: 0.2648 - val_VH_attention_linear_output_acc: 0.1635\n",
      "Epoch 27/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.9192 - VL_attention_linear_output_loss: 2.2991 - VH_attention_linear_output_loss: 2.6201 - VL_attention_linear_output_acc: 0.2672 - VH_attention_linear_output_acc: 0.1651 - val_loss: 5.0524 - val_VL_attention_linear_output_loss: 2.4451 - val_VH_attention_linear_output_loss: 2.6073 - val_VL_attention_linear_output_acc: 0.2106 - val_VH_attention_linear_output_acc: 0.1701\n",
      "Epoch 28/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.9145 - VL_attention_linear_output_loss: 2.2967 - VH_attention_linear_output_loss: 2.6178 - VL_attention_linear_output_acc: 0.2667 - VH_attention_linear_output_acc: 0.1644 - val_loss: 4.8817 - val_VL_attention_linear_output_loss: 2.2777 - val_VH_attention_linear_output_loss: 2.6039 - val_VL_attention_linear_output_acc: 0.2697 - val_VH_attention_linear_output_acc: 0.1711\n",
      "Epoch 29/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.8939 - VL_attention_linear_output_loss: 2.2839 - VH_attention_linear_output_loss: 2.6100 - VL_attention_linear_output_acc: 0.2702 - VH_attention_linear_output_acc: 0.1673 - val_loss: 4.8908 - val_VL_attention_linear_output_loss: 2.2904 - val_VH_attention_linear_output_loss: 2.6004 - val_VL_attention_linear_output_acc: 0.2775 - val_VH_attention_linear_output_acc: 0.1703\n",
      "Epoch 30/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.8871 - VL_attention_linear_output_loss: 2.2802 - VH_attention_linear_output_loss: 2.6069 - VL_attention_linear_output_acc: 0.2707 - VH_attention_linear_output_acc: 0.1671 - val_loss: 4.8629 - val_VL_attention_linear_output_loss: 2.2551 - val_VH_attention_linear_output_loss: 2.6078 - val_VL_attention_linear_output_acc: 0.2735 - val_VH_attention_linear_output_acc: 0.1644\n",
      "Epoch 31/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.8706 - VL_attention_linear_output_loss: 2.2714 - VH_attention_linear_output_loss: 2.5992 - VL_attention_linear_output_acc: 0.2722 - VH_attention_linear_output_acc: 0.1696 - val_loss: 4.8402 - val_VL_attention_linear_output_loss: 2.2516 - val_VH_attention_linear_output_loss: 2.5887 - val_VL_attention_linear_output_acc: 0.2810 - val_VH_attention_linear_output_acc: 0.1752\n",
      "Epoch 32/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.8586 - VL_attention_linear_output_loss: 2.2641 - VH_attention_linear_output_loss: 2.5945 - VL_attention_linear_output_acc: 0.2741 - VH_attention_linear_output_acc: 0.1707 - val_loss: 4.8687 - val_VL_attention_linear_output_loss: 2.2647 - val_VH_attention_linear_output_loss: 2.6040 - val_VL_attention_linear_output_acc: 0.2761 - val_VH_attention_linear_output_acc: 0.1655\n",
      "Epoch 33/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.8502 - VL_attention_linear_output_loss: 2.2573 - VH_attention_linear_output_loss: 2.5929 - VL_attention_linear_output_acc: 0.2764 - VH_attention_linear_output_acc: 0.1712 - val_loss: 4.8288 - val_VL_attention_linear_output_loss: 2.2253 - val_VH_attention_linear_output_loss: 2.6036 - val_VL_attention_linear_output_acc: 0.2886 - val_VH_attention_linear_output_acc: 0.1647\n",
      "Epoch 34/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.8480 - VL_attention_linear_output_loss: 2.2603 - VH_attention_linear_output_loss: 2.5877 - VL_attention_linear_output_acc: 0.2759 - VH_attention_linear_output_acc: 0.1740 - val_loss: 4.8029 - val_VL_attention_linear_output_loss: 2.2266 - val_VH_attention_linear_output_loss: 2.5763 - val_VL_attention_linear_output_acc: 0.2828 - val_VH_attention_linear_output_acc: 0.1751\n",
      "Epoch 35/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.8285 - VL_attention_linear_output_loss: 2.2473 - VH_attention_linear_output_loss: 2.5812 - VL_attention_linear_output_acc: 0.2821 - VH_attention_linear_output_acc: 0.1777 - val_loss: 4.7995 - val_VL_attention_linear_output_loss: 2.2197 - val_VH_attention_linear_output_loss: 2.5798 - val_VL_attention_linear_output_acc: 0.2882 - val_VH_attention_linear_output_acc: 0.1802\n",
      "Epoch 36/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.8183 - VL_attention_linear_output_loss: 2.2369 - VH_attention_linear_output_loss: 2.5814 - VL_attention_linear_output_acc: 0.2872 - VH_attention_linear_output_acc: 0.1782 - val_loss: 4.7777 - val_VL_attention_linear_output_loss: 2.2102 - val_VH_attention_linear_output_loss: 2.5675 - val_VL_attention_linear_output_acc: 0.2932 - val_VH_attention_linear_output_acc: 0.1859\n",
      "Epoch 37/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.7934 - VL_attention_linear_output_loss: 2.2200 - VH_attention_linear_output_loss: 2.5734 - VL_attention_linear_output_acc: 0.2945 - VH_attention_linear_output_acc: 0.1820 - val_loss: 4.7924 - val_VL_attention_linear_output_loss: 2.2290 - val_VH_attention_linear_output_loss: 2.5635 - val_VL_attention_linear_output_acc: 0.2800 - val_VH_attention_linear_output_acc: 0.1843\n",
      "Epoch 38/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.7909 - VL_attention_linear_output_loss: 2.2238 - VH_attention_linear_output_loss: 2.5671 - VL_attention_linear_output_acc: 0.2945 - VH_attention_linear_output_acc: 0.1852 - val_loss: 4.7539 - val_VL_attention_linear_output_loss: 2.1968 - val_VH_attention_linear_output_loss: 2.5572 - val_VL_attention_linear_output_acc: 0.3076 - val_VH_attention_linear_output_acc: 0.1908\n",
      "Epoch 39/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.7905 - VL_attention_linear_output_loss: 2.2242 - VH_attention_linear_output_loss: 2.5663 - VL_attention_linear_output_acc: 0.2964 - VH_attention_linear_output_acc: 0.1845 - val_loss: 4.7838 - val_VL_attention_linear_output_loss: 2.2276 - val_VH_attention_linear_output_loss: 2.5562 - val_VL_attention_linear_output_acc: 0.3010 - val_VH_attention_linear_output_acc: 0.1882\n",
      "Epoch 40/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.7761 - VL_attention_linear_output_loss: 2.2175 - VH_attention_linear_output_loss: 2.5586 - VL_attention_linear_output_acc: 0.2986 - VH_attention_linear_output_acc: 0.1893 - val_loss: 4.7347 - val_VL_attention_linear_output_loss: 2.1867 - val_VH_attention_linear_output_loss: 2.5480 - val_VL_attention_linear_output_acc: 0.3099 - val_VH_attention_linear_output_acc: 0.1986\n",
      "Epoch 41/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.7679 - VL_attention_linear_output_loss: 2.2156 - VH_attention_linear_output_loss: 2.5523 - VL_attention_linear_output_acc: 0.2999 - VH_attention_linear_output_acc: 0.1911 - val_loss: 4.7309 - val_VL_attention_linear_output_loss: 2.1931 - val_VH_attention_linear_output_loss: 2.5378 - val_VL_attention_linear_output_acc: 0.3079 - val_VH_attention_linear_output_acc: 0.1993\n",
      "Epoch 42/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.7514 - VL_attention_linear_output_loss: 2.2070 - VH_attention_linear_output_loss: 2.5444 - VL_attention_linear_output_acc: 0.3031 - VH_attention_linear_output_acc: 0.1913 - val_loss: 4.7264 - val_VL_attention_linear_output_loss: 2.1914 - val_VH_attention_linear_output_loss: 2.5350 - val_VL_attention_linear_output_acc: 0.3061 - val_VH_attention_linear_output_acc: 0.1892\n",
      "Epoch 43/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.7250 - VL_attention_linear_output_loss: 2.1911 - VH_attention_linear_output_loss: 2.5339 - VL_attention_linear_output_acc: 0.3106 - VH_attention_linear_output_acc: 0.1942 - val_loss: 4.7169 - val_VL_attention_linear_output_loss: 2.1900 - val_VH_attention_linear_output_loss: 2.5269 - val_VL_attention_linear_output_acc: 0.3059 - val_VH_attention_linear_output_acc: 0.1918\n",
      "Epoch 44/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.7285 - VL_attention_linear_output_loss: 2.2003 - VH_attention_linear_output_loss: 2.5281 - VL_attention_linear_output_acc: 0.3057 - VH_attention_linear_output_acc: 0.1936 - val_loss: 4.7562 - val_VL_attention_linear_output_loss: 2.1984 - val_VH_attention_linear_output_loss: 2.5578 - val_VL_attention_linear_output_acc: 0.3014 - val_VH_attention_linear_output_acc: 0.1684\n",
      "Epoch 45/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6989 - VL_attention_linear_output_loss: 2.1808 - VH_attention_linear_output_loss: 2.5180 - VL_attention_linear_output_acc: 0.3141 - VH_attention_linear_output_acc: 0.2015 - val_loss: 4.6941 - val_VL_attention_linear_output_loss: 2.1685 - val_VH_attention_linear_output_loss: 2.5256 - val_VL_attention_linear_output_acc: 0.3200 - val_VH_attention_linear_output_acc: 0.1875\n",
      "Epoch 46/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.7101 - VL_attention_linear_output_loss: 2.1893 - VH_attention_linear_output_loss: 2.5208 - VL_attention_linear_output_acc: 0.3097 - VH_attention_linear_output_acc: 0.1970 - val_loss: 4.7507 - val_VL_attention_linear_output_loss: 2.2376 - val_VH_attention_linear_output_loss: 2.5130 - val_VL_attention_linear_output_acc: 0.2814 - val_VH_attention_linear_output_acc: 0.1956\n",
      "Epoch 47/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.7007 - VL_attention_linear_output_loss: 2.1930 - VH_attention_linear_output_loss: 2.5077 - VL_attention_linear_output_acc: 0.3078 - VH_attention_linear_output_acc: 0.2050 - val_loss: 4.6792 - val_VL_attention_linear_output_loss: 2.1806 - val_VH_attention_linear_output_loss: 2.4986 - val_VL_attention_linear_output_acc: 0.3177 - val_VH_attention_linear_output_acc: 0.2112\n",
      "Epoch 48/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6760 - VL_attention_linear_output_loss: 2.1749 - VH_attention_linear_output_loss: 2.5012 - VL_attention_linear_output_acc: 0.3149 - VH_attention_linear_output_acc: 0.2091 - val_loss: 4.6461 - val_VL_attention_linear_output_loss: 2.1536 - val_VH_attention_linear_output_loss: 2.4925 - val_VL_attention_linear_output_acc: 0.3175 - val_VH_attention_linear_output_acc: 0.2150\n",
      "Epoch 49/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6900 - VL_attention_linear_output_loss: 2.1932 - VH_attention_linear_output_loss: 2.4969 - VL_attention_linear_output_acc: 0.3073 - VH_attention_linear_output_acc: 0.2121 - val_loss: 4.6468 - val_VL_attention_linear_output_loss: 2.1597 - val_VH_attention_linear_output_loss: 2.4870 - val_VL_attention_linear_output_acc: 0.3174 - val_VH_attention_linear_output_acc: 0.2200\n",
      "Epoch 50/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6583 - VL_attention_linear_output_loss: 2.1651 - VH_attention_linear_output_loss: 2.4932 - VL_attention_linear_output_acc: 0.3193 - VH_attention_linear_output_acc: 0.2134 - val_loss: 4.6455 - val_VL_attention_linear_output_loss: 2.1571 - val_VH_attention_linear_output_loss: 2.4884 - val_VL_attention_linear_output_acc: 0.3261 - val_VH_attention_linear_output_acc: 0.2180\n",
      "Epoch 51/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6669 - VL_attention_linear_output_loss: 2.1770 - VH_attention_linear_output_loss: 2.4898 - VL_attention_linear_output_acc: 0.3146 - VH_attention_linear_output_acc: 0.2154 - val_loss: 4.6277 - val_VL_attention_linear_output_loss: 2.1454 - val_VH_attention_linear_output_loss: 2.4823 - val_VL_attention_linear_output_acc: 0.3239 - val_VH_attention_linear_output_acc: 0.2157\n",
      "Epoch 52/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6458 - VL_attention_linear_output_loss: 2.1580 - VH_attention_linear_output_loss: 2.4879 - VL_attention_linear_output_acc: 0.3227 - VH_attention_linear_output_acc: 0.2151 - val_loss: 4.7639 - val_VL_attention_linear_output_loss: 2.2759 - val_VH_attention_linear_output_loss: 2.4880 - val_VL_attention_linear_output_acc: 0.2628 - val_VH_attention_linear_output_acc: 0.2118\n",
      "Epoch 53/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6507 - VL_attention_linear_output_loss: 2.1659 - VH_attention_linear_output_loss: 2.4847 - VL_attention_linear_output_acc: 0.3185 - VH_attention_linear_output_acc: 0.2159 - val_loss: 4.6443 - val_VL_attention_linear_output_loss: 2.1685 - val_VH_attention_linear_output_loss: 2.4758 - val_VL_attention_linear_output_acc: 0.3152 - val_VH_attention_linear_output_acc: 0.2247\n",
      "Epoch 54/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6352 - VL_attention_linear_output_loss: 2.1541 - VH_attention_linear_output_loss: 2.4811 - VL_attention_linear_output_acc: 0.3241 - VH_attention_linear_output_acc: 0.2181 - val_loss: 4.5992 - val_VL_attention_linear_output_loss: 2.1261 - val_VH_attention_linear_output_loss: 2.4731 - val_VL_attention_linear_output_acc: 0.3424 - val_VH_attention_linear_output_acc: 0.2227\n",
      "Epoch 55/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6349 - VL_attention_linear_output_loss: 2.1551 - VH_attention_linear_output_loss: 2.4799 - VL_attention_linear_output_acc: 0.3223 - VH_attention_linear_output_acc: 0.2180 - val_loss: 4.6746 - val_VL_attention_linear_output_loss: 2.1829 - val_VH_attention_linear_output_loss: 2.4916 - val_VL_attention_linear_output_acc: 0.3026 - val_VH_attention_linear_output_acc: 0.2071\n",
      "Epoch 56/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6383 - VL_attention_linear_output_loss: 2.1617 - VH_attention_linear_output_loss: 2.4766 - VL_attention_linear_output_acc: 0.3194 - VH_attention_linear_output_acc: 0.2183 - val_loss: 4.5910 - val_VL_attention_linear_output_loss: 2.1231 - val_VH_attention_linear_output_loss: 2.4679 - val_VL_attention_linear_output_acc: 0.3324 - val_VH_attention_linear_output_acc: 0.2286\n",
      "Epoch 57/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6163 - VL_attention_linear_output_loss: 2.1435 - VH_attention_linear_output_loss: 2.4729 - VL_attention_linear_output_acc: 0.3271 - VH_attention_linear_output_acc: 0.2202 - val_loss: 4.5807 - val_VL_attention_linear_output_loss: 2.1164 - val_VH_attention_linear_output_loss: 2.4643 - val_VL_attention_linear_output_acc: 0.3406 - val_VH_attention_linear_output_acc: 0.2221\n",
      "Epoch 58/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6157 - VL_attention_linear_output_loss: 2.1459 - VH_attention_linear_output_loss: 2.4698 - VL_attention_linear_output_acc: 0.3254 - VH_attention_linear_output_acc: 0.2214 - val_loss: 4.7527 - val_VL_attention_linear_output_loss: 2.2889 - val_VH_attention_linear_output_loss: 2.4639 - val_VL_attention_linear_output_acc: 0.2638 - val_VH_attention_linear_output_acc: 0.2238\n",
      "Epoch 59/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6163 - VL_attention_linear_output_loss: 2.1439 - VH_attention_linear_output_loss: 2.4724 - VL_attention_linear_output_acc: 0.3260 - VH_attention_linear_output_acc: 0.2164 - val_loss: 4.5807 - val_VL_attention_linear_output_loss: 2.1131 - val_VH_attention_linear_output_loss: 2.4676 - val_VL_attention_linear_output_acc: 0.3462 - val_VH_attention_linear_output_acc: 0.2199\n",
      "Epoch 60/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5981 - VL_attention_linear_output_loss: 2.1325 - VH_attention_linear_output_loss: 2.4656 - VL_attention_linear_output_acc: 0.3311 - VH_attention_linear_output_acc: 0.2200 - val_loss: 4.5962 - val_VL_attention_linear_output_loss: 2.1389 - val_VH_attention_linear_output_loss: 2.4573 - val_VL_attention_linear_output_acc: 0.3307 - val_VH_attention_linear_output_acc: 0.2220\n",
      "Epoch 61/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.6094 - VL_attention_linear_output_loss: 2.1453 - VH_attention_linear_output_loss: 2.4642 - VL_attention_linear_output_acc: 0.3259 - VH_attention_linear_output_acc: 0.2206 - val_loss: 4.5878 - val_VL_attention_linear_output_loss: 2.1351 - val_VH_attention_linear_output_loss: 2.4527 - val_VL_attention_linear_output_acc: 0.3269 - val_VH_attention_linear_output_acc: 0.2317\n",
      "Epoch 62/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5932 - VL_attention_linear_output_loss: 2.1334 - VH_attention_linear_output_loss: 2.4597 - VL_attention_linear_output_acc: 0.3313 - VH_attention_linear_output_acc: 0.2221 - val_loss: 4.5792 - val_VL_attention_linear_output_loss: 2.1278 - val_VH_attention_linear_output_loss: 2.4515 - val_VL_attention_linear_output_acc: 0.3378 - val_VH_attention_linear_output_acc: 0.2265\n",
      "Epoch 63/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5921 - VL_attention_linear_output_loss: 2.1340 - VH_attention_linear_output_loss: 2.4581 - VL_attention_linear_output_acc: 0.3306 - VH_attention_linear_output_acc: 0.2204 - val_loss: 4.5661 - val_VL_attention_linear_output_loss: 2.0975 - val_VH_attention_linear_output_loss: 2.4686 - val_VL_attention_linear_output_acc: 0.3540 - val_VH_attention_linear_output_acc: 0.2087\n",
      "Epoch 64/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5941 - VL_attention_linear_output_loss: 2.1354 - VH_attention_linear_output_loss: 2.4587 - VL_attention_linear_output_acc: 0.3290 - VH_attention_linear_output_acc: 0.2187 - val_loss: 4.5595 - val_VL_attention_linear_output_loss: 2.1131 - val_VH_attention_linear_output_loss: 2.4464 - val_VL_attention_linear_output_acc: 0.3243 - val_VH_attention_linear_output_acc: 0.2268\n",
      "Epoch 65/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5780 - VL_attention_linear_output_loss: 2.1249 - VH_attention_linear_output_loss: 2.4531 - VL_attention_linear_output_acc: 0.3349 - VH_attention_linear_output_acc: 0.2231 - val_loss: 4.5483 - val_VL_attention_linear_output_loss: 2.0999 - val_VH_attention_linear_output_loss: 2.4483 - val_VL_attention_linear_output_acc: 0.3494 - val_VH_attention_linear_output_acc: 0.2245\n",
      "Epoch 66/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5618 - VL_attention_linear_output_loss: 2.1153 - VH_attention_linear_output_loss: 2.4465 - VL_attention_linear_output_acc: 0.3392 - VH_attention_linear_output_acc: 0.2271 - val_loss: 4.5490 - val_VL_attention_linear_output_loss: 2.1061 - val_VH_attention_linear_output_loss: 2.4429 - val_VL_attention_linear_output_acc: 0.3329 - val_VH_attention_linear_output_acc: 0.2258\n",
      "Epoch 67/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5637 - VL_attention_linear_output_loss: 2.1163 - VH_attention_linear_output_loss: 2.4474 - VL_attention_linear_output_acc: 0.3397 - VH_attention_linear_output_acc: 0.2238 - val_loss: 4.5468 - val_VL_attention_linear_output_loss: 2.1098 - val_VH_attention_linear_output_loss: 2.4369 - val_VL_attention_linear_output_acc: 0.3408 - val_VH_attention_linear_output_acc: 0.2330\n",
      "Epoch 68/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5533 - VL_attention_linear_output_loss: 2.1097 - VH_attention_linear_output_loss: 2.4436 - VL_attention_linear_output_acc: 0.3426 - VH_attention_linear_output_acc: 0.2244 - val_loss: 4.6322 - val_VL_attention_linear_output_loss: 2.1896 - val_VH_attention_linear_output_loss: 2.4426 - val_VL_attention_linear_output_acc: 0.2897 - val_VH_attention_linear_output_acc: 0.2240\n",
      "Epoch 69/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5965 - VL_attention_linear_output_loss: 2.1514 - VH_attention_linear_output_loss: 2.4451 - VL_attention_linear_output_acc: 0.3227 - VH_attention_linear_output_acc: 0.2204 - val_loss: 4.5493 - val_VL_attention_linear_output_loss: 2.1199 - val_VH_attention_linear_output_loss: 2.4295 - val_VL_attention_linear_output_acc: 0.3282 - val_VH_attention_linear_output_acc: 0.2319\n",
      "Epoch 70/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5448 - VL_attention_linear_output_loss: 2.1078 - VH_attention_linear_output_loss: 2.4370 - VL_attention_linear_output_acc: 0.3442 - VH_attention_linear_output_acc: 0.2258 - val_loss: 4.6213 - val_VL_attention_linear_output_loss: 2.1705 - val_VH_attention_linear_output_loss: 2.4508 - val_VL_attention_linear_output_acc: 0.3122 - val_VH_attention_linear_output_acc: 0.2086\n",
      "Epoch 71/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5529 - VL_attention_linear_output_loss: 2.1134 - VH_attention_linear_output_loss: 2.4395 - VL_attention_linear_output_acc: 0.3421 - VH_attention_linear_output_acc: 0.2225 - val_loss: 4.5511 - val_VL_attention_linear_output_loss: 2.1228 - val_VH_attention_linear_output_loss: 2.4283 - val_VL_attention_linear_output_acc: 0.3312 - val_VH_attention_linear_output_acc: 0.2260\n",
      "Epoch 72/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5570 - VL_attention_linear_output_loss: 2.1185 - VH_attention_linear_output_loss: 2.4385 - VL_attention_linear_output_acc: 0.3398 - VH_attention_linear_output_acc: 0.2202 - val_loss: 4.5397 - val_VL_attention_linear_output_loss: 2.0768 - val_VH_attention_linear_output_loss: 2.4629 - val_VL_attention_linear_output_acc: 0.3618 - val_VH_attention_linear_output_acc: 0.1966\n",
      "Epoch 73/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5519 - VL_attention_linear_output_loss: 2.1209 - VH_attention_linear_output_loss: 2.4310 - VL_attention_linear_output_acc: 0.3381 - VH_attention_linear_output_acc: 0.2238 - val_loss: 4.6162 - val_VL_attention_linear_output_loss: 2.1926 - val_VH_attention_linear_output_loss: 2.4236 - val_VL_attention_linear_output_acc: 0.2980 - val_VH_attention_linear_output_acc: 0.2251\n",
      "Epoch 74/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5431 - VL_attention_linear_output_loss: 2.1144 - VH_attention_linear_output_loss: 2.4287 - VL_attention_linear_output_acc: 0.3410 - VH_attention_linear_output_acc: 0.2237 - val_loss: 4.5032 - val_VL_attention_linear_output_loss: 2.0833 - val_VH_attention_linear_output_loss: 2.4198 - val_VL_attention_linear_output_acc: 0.3570 - val_VH_attention_linear_output_acc: 0.2270\n",
      "Epoch 75/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5601 - VL_attention_linear_output_loss: 2.1308 - VH_attention_linear_output_loss: 2.4293 - VL_attention_linear_output_acc: 0.3338 - VH_attention_linear_output_acc: 0.2201 - val_loss: 4.5652 - val_VL_attention_linear_output_loss: 2.1145 - val_VH_attention_linear_output_loss: 2.4507 - val_VL_attention_linear_output_acc: 0.3528 - val_VH_attention_linear_output_acc: 0.2014\n",
      "Epoch 76/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5268 - VL_attention_linear_output_loss: 2.1023 - VH_attention_linear_output_loss: 2.4245 - VL_attention_linear_output_acc: 0.3477 - VH_attention_linear_output_acc: 0.2226 - val_loss: 4.5319 - val_VL_attention_linear_output_loss: 2.1185 - val_VH_attention_linear_output_loss: 2.4134 - val_VL_attention_linear_output_acc: 0.3394 - val_VH_attention_linear_output_acc: 0.2318\n",
      "Epoch 77/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5273 - VL_attention_linear_output_loss: 2.1057 - VH_attention_linear_output_loss: 2.4217 - VL_attention_linear_output_acc: 0.3461 - VH_attention_linear_output_acc: 0.2233 - val_loss: 4.4981 - val_VL_attention_linear_output_loss: 2.0750 - val_VH_attention_linear_output_loss: 2.4231 - val_VL_attention_linear_output_acc: 0.3595 - val_VH_attention_linear_output_acc: 0.2144\n",
      "Epoch 78/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5344 - VL_attention_linear_output_loss: 2.1116 - VH_attention_linear_output_loss: 2.4228 - VL_attention_linear_output_acc: 0.3425 - VH_attention_linear_output_acc: 0.2194 - val_loss: 4.5379 - val_VL_attention_linear_output_loss: 2.1148 - val_VH_attention_linear_output_loss: 2.4231 - val_VL_attention_linear_output_acc: 0.3289 - val_VH_attention_linear_output_acc: 0.2182\n",
      "Epoch 79/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5166 - VL_attention_linear_output_loss: 2.1002 - VH_attention_linear_output_loss: 2.4164 - VL_attention_linear_output_acc: 0.3488 - VH_attention_linear_output_acc: 0.2243 - val_loss: 4.5692 - val_VL_attention_linear_output_loss: 2.1612 - val_VH_attention_linear_output_loss: 2.4080 - val_VL_attention_linear_output_acc: 0.3107 - val_VH_attention_linear_output_acc: 0.2251\n",
      "Epoch 80/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5219 - VL_attention_linear_output_loss: 2.1062 - VH_attention_linear_output_loss: 2.4157 - VL_attention_linear_output_acc: 0.3446 - VH_attention_linear_output_acc: 0.2235 - val_loss: 4.5689 - val_VL_attention_linear_output_loss: 2.1314 - val_VH_attention_linear_output_loss: 2.4375 - val_VL_attention_linear_output_acc: 0.3238 - val_VH_attention_linear_output_acc: 0.2008\n",
      "Epoch 81/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5072 - VL_attention_linear_output_loss: 2.0950 - VH_attention_linear_output_loss: 2.4122 - VL_attention_linear_output_acc: 0.3529 - VH_attention_linear_output_acc: 0.2230 - val_loss: 4.4923 - val_VL_attention_linear_output_loss: 2.0573 - val_VH_attention_linear_output_loss: 2.4350 - val_VL_attention_linear_output_acc: 0.3731 - val_VH_attention_linear_output_acc: 0.2086\n",
      "Epoch 82/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5089 - VL_attention_linear_output_loss: 2.0899 - VH_attention_linear_output_loss: 2.4189 - VL_attention_linear_output_acc: 0.3545 - VH_attention_linear_output_acc: 0.2198 - val_loss: 4.4910 - val_VL_attention_linear_output_loss: 2.0807 - val_VH_attention_linear_output_loss: 2.4102 - val_VL_attention_linear_output_acc: 0.3653 - val_VH_attention_linear_output_acc: 0.2322\n",
      "Epoch 83/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5014 - VL_attention_linear_output_loss: 2.0906 - VH_attention_linear_output_loss: 2.4109 - VL_attention_linear_output_acc: 0.3541 - VH_attention_linear_output_acc: 0.2236 - val_loss: 4.7101 - val_VL_attention_linear_output_loss: 2.2447 - val_VH_attention_linear_output_loss: 2.4654 - val_VL_attention_linear_output_acc: 0.2875 - val_VH_attention_linear_output_acc: 0.1862\n",
      "Epoch 84/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5243 - VL_attention_linear_output_loss: 2.1139 - VH_attention_linear_output_loss: 2.4104 - VL_attention_linear_output_acc: 0.3439 - VH_attention_linear_output_acc: 0.2215 - val_loss: 4.4692 - val_VL_attention_linear_output_loss: 2.0672 - val_VH_attention_linear_output_loss: 2.4020 - val_VL_attention_linear_output_acc: 0.3612 - val_VH_attention_linear_output_acc: 0.2284\n",
      "Epoch 85/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4906 - VL_attention_linear_output_loss: 2.0865 - VH_attention_linear_output_loss: 2.4041 - VL_attention_linear_output_acc: 0.3559 - VH_attention_linear_output_acc: 0.2257 - val_loss: 4.6057 - val_VL_attention_linear_output_loss: 2.2121 - val_VH_attention_linear_output_loss: 2.3936 - val_VL_attention_linear_output_acc: 0.2847 - val_VH_attention_linear_output_acc: 0.2348\n",
      "Epoch 86/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.5055 - VL_attention_linear_output_loss: 2.0969 - VH_attention_linear_output_loss: 2.4086 - VL_attention_linear_output_acc: 0.3506 - VH_attention_linear_output_acc: 0.2226 - val_loss: 4.5251 - val_VL_attention_linear_output_loss: 2.1270 - val_VH_attention_linear_output_loss: 2.3981 - val_VL_attention_linear_output_acc: 0.3209 - val_VH_attention_linear_output_acc: 0.2316\n",
      "Epoch 87/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4887 - VL_attention_linear_output_loss: 2.0851 - VH_attention_linear_output_loss: 2.4036 - VL_attention_linear_output_acc: 0.3573 - VH_attention_linear_output_acc: 0.2274 - val_loss: 4.4944 - val_VL_attention_linear_output_loss: 2.0871 - val_VH_attention_linear_output_loss: 2.4073 - val_VL_attention_linear_output_acc: 0.3570 - val_VH_attention_linear_output_acc: 0.2185\n",
      "Epoch 88/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4749 - VL_attention_linear_output_loss: 2.0760 - VH_attention_linear_output_loss: 2.3989 - VL_attention_linear_output_acc: 0.3622 - VH_attention_linear_output_acc: 0.2283 - val_loss: 4.4873 - val_VL_attention_linear_output_loss: 2.0943 - val_VH_attention_linear_output_loss: 2.3930 - val_VL_attention_linear_output_acc: 0.3369 - val_VH_attention_linear_output_acc: 0.2356\n",
      "Epoch 89/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4642 - VL_attention_linear_output_loss: 2.0705 - VH_attention_linear_output_loss: 2.3937 - VL_attention_linear_output_acc: 0.3658 - VH_attention_linear_output_acc: 0.2324 - val_loss: 4.4376 - val_VL_attention_linear_output_loss: 2.0457 - val_VH_attention_linear_output_loss: 2.3919 - val_VL_attention_linear_output_acc: 0.3796 - val_VH_attention_linear_output_acc: 0.2353\n",
      "Epoch 90/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4677 - VL_attention_linear_output_loss: 2.0729 - VH_attention_linear_output_loss: 2.3948 - VL_attention_linear_output_acc: 0.3644 - VH_attention_linear_output_acc: 0.2293 - val_loss: 4.4831 - val_VL_attention_linear_output_loss: 2.0955 - val_VH_attention_linear_output_loss: 2.3875 - val_VL_attention_linear_output_acc: 0.3469 - val_VH_attention_linear_output_acc: 0.2358\n",
      "Epoch 91/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4675 - VL_attention_linear_output_loss: 2.0763 - VH_attention_linear_output_loss: 2.3913 - VL_attention_linear_output_acc: 0.3628 - VH_attention_linear_output_acc: 0.2306 - val_loss: 4.4749 - val_VL_attention_linear_output_loss: 2.0896 - val_VH_attention_linear_output_loss: 2.3853 - val_VL_attention_linear_output_acc: 0.3431 - val_VH_attention_linear_output_acc: 0.2307\n",
      "Epoch 92/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4802 - VL_attention_linear_output_loss: 2.0877 - VH_attention_linear_output_loss: 2.3925 - VL_attention_linear_output_acc: 0.3563 - VH_attention_linear_output_acc: 0.2292 - val_loss: 4.4336 - val_VL_attention_linear_output_loss: 2.0531 - val_VH_attention_linear_output_loss: 2.3805 - val_VL_attention_linear_output_acc: 0.3717 - val_VH_attention_linear_output_acc: 0.2354\n",
      "Epoch 93/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4645 - VL_attention_linear_output_loss: 2.0810 - VH_attention_linear_output_loss: 2.3835 - VL_attention_linear_output_acc: 0.3606 - VH_attention_linear_output_acc: 0.2368 - val_loss: 4.5096 - val_VL_attention_linear_output_loss: 2.1372 - val_VH_attention_linear_output_loss: 2.3724 - val_VL_attention_linear_output_acc: 0.3132 - val_VH_attention_linear_output_acc: 0.2412\n",
      "Epoch 94/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4752 - VL_attention_linear_output_loss: 2.0981 - VH_attention_linear_output_loss: 2.3771 - VL_attention_linear_output_acc: 0.3514 - VH_attention_linear_output_acc: 0.2393 - val_loss: 4.4209 - val_VL_attention_linear_output_loss: 2.0537 - val_VH_attention_linear_output_loss: 2.3673 - val_VL_attention_linear_output_acc: 0.3680 - val_VH_attention_linear_output_acc: 0.2433\n",
      "Epoch 95/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4393 - VL_attention_linear_output_loss: 2.0700 - VH_attention_linear_output_loss: 2.3693 - VL_attention_linear_output_acc: 0.3663 - VH_attention_linear_output_acc: 0.2420 - val_loss: 4.4274 - val_VL_attention_linear_output_loss: 2.0591 - val_VH_attention_linear_output_loss: 2.3683 - val_VL_attention_linear_output_acc: 0.3737 - val_VH_attention_linear_output_acc: 0.2379\n",
      "Epoch 96/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4380 - VL_attention_linear_output_loss: 2.0780 - VH_attention_linear_output_loss: 2.3600 - VL_attention_linear_output_acc: 0.3625 - VH_attention_linear_output_acc: 0.2465 - val_loss: 4.4062 - val_VL_attention_linear_output_loss: 2.0518 - val_VH_attention_linear_output_loss: 2.3544 - val_VL_attention_linear_output_acc: 0.3803 - val_VH_attention_linear_output_acc: 0.2483\n",
      "Epoch 97/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4253 - VL_attention_linear_output_loss: 2.0654 - VH_attention_linear_output_loss: 2.3599 - VL_attention_linear_output_acc: 0.3692 - VH_attention_linear_output_acc: 0.2443 - val_loss: 4.3918 - val_VL_attention_linear_output_loss: 2.0437 - val_VH_attention_linear_output_loss: 2.3481 - val_VL_attention_linear_output_acc: 0.3909 - val_VH_attention_linear_output_acc: 0.2540\n",
      "Epoch 98/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4310 - VL_attention_linear_output_loss: 2.0763 - VH_attention_linear_output_loss: 2.3547 - VL_attention_linear_output_acc: 0.3627 - VH_attention_linear_output_acc: 0.2463 - val_loss: 4.4255 - val_VL_attention_linear_output_loss: 2.0761 - val_VH_attention_linear_output_loss: 2.3494 - val_VL_attention_linear_output_acc: 0.3573 - val_VH_attention_linear_output_acc: 0.2458\n",
      "Epoch 99/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4173 - VL_attention_linear_output_loss: 2.0652 - VH_attention_linear_output_loss: 2.3521 - VL_attention_linear_output_acc: 0.3693 - VH_attention_linear_output_acc: 0.2467 - val_loss: 4.4857 - val_VL_attention_linear_output_loss: 2.0981 - val_VH_attention_linear_output_loss: 2.3875 - val_VL_attention_linear_output_acc: 0.3466 - val_VH_attention_linear_output_acc: 0.2282\n",
      "Epoch 100/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4212 - VL_attention_linear_output_loss: 2.0737 - VH_attention_linear_output_loss: 2.3475 - VL_attention_linear_output_acc: 0.3640 - VH_attention_linear_output_acc: 0.2486 - val_loss: 4.4206 - val_VL_attention_linear_output_loss: 2.0680 - val_VH_attention_linear_output_loss: 2.3525 - val_VL_attention_linear_output_acc: 0.3580 - val_VH_attention_linear_output_acc: 0.2412\n",
      "Epoch 101/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4074 - VL_attention_linear_output_loss: 2.0620 - VH_attention_linear_output_loss: 2.3453 - VL_attention_linear_output_acc: 0.3713 - VH_attention_linear_output_acc: 0.2505 - val_loss: 4.3720 - val_VL_attention_linear_output_loss: 2.0338 - val_VH_attention_linear_output_loss: 2.3382 - val_VL_attention_linear_output_acc: 0.3881 - val_VH_attention_linear_output_acc: 0.2538- VL_attention_linear_output_loss: 2.0688 - VH_attention_linear_output_loss: 2.3422 - VL_attention_l\n",
      "Epoch 102/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4113 - VL_attention_linear_output_loss: 2.0681 - VH_attention_linear_output_loss: 2.3432 - VL_attention_linear_output_acc: 0.3681 - VH_attention_linear_output_acc: 0.2496 - val_loss: 4.3782 - val_VL_attention_linear_output_loss: 2.0399 - val_VH_attention_linear_output_loss: 2.3383 - val_VL_attention_linear_output_acc: 0.3822 - val_VH_attention_linear_output_acc: 0.2468\n",
      "Epoch 103/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4022 - VL_attention_linear_output_loss: 2.0602 - VH_attention_linear_output_loss: 2.3420 - VL_attention_linear_output_acc: 0.3742 - VH_attention_linear_output_acc: 0.2506 - val_loss: 4.5107 - val_VL_attention_linear_output_loss: 2.1727 - val_VH_attention_linear_output_loss: 2.3380 - val_VL_attention_linear_output_acc: 0.2995 - val_VH_attention_linear_output_acc: 0.2531\n",
      "Epoch 104/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3936 - VL_attention_linear_output_loss: 2.0561 - VH_attention_linear_output_loss: 2.3375 - VL_attention_linear_output_acc: 0.3762 - VH_attention_linear_output_acc: 0.2532 - val_loss: 4.4141 - val_VL_attention_linear_output_loss: 2.0857 - val_VH_attention_linear_output_loss: 2.3285 - val_VL_attention_linear_output_acc: 0.3485 - val_VH_attention_linear_output_acc: 0.2602\n",
      "Epoch 105/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3952 - VL_attention_linear_output_loss: 2.0579 - VH_attention_linear_output_loss: 2.3373 - VL_attention_linear_output_acc: 0.3742 - VH_attention_linear_output_acc: 0.2516 - val_loss: 4.4170 - val_VL_attention_linear_output_loss: 2.0911 - val_VH_attention_linear_output_loss: 2.3259 - val_VL_attention_linear_output_acc: 0.3459 - val_VH_attention_linear_output_acc: 0.2613\n",
      "Epoch 106/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3973 - VL_attention_linear_output_loss: 2.0611 - VH_attention_linear_output_loss: 2.3362 - VL_attention_linear_output_acc: 0.3726 - VH_attention_linear_output_acc: 0.2517 - val_loss: 4.3761 - val_VL_attention_linear_output_loss: 2.0422 - val_VH_attention_linear_output_loss: 2.3339 - val_VL_attention_linear_output_acc: 0.3838 - val_VH_attention_linear_output_acc: 0.2555\n",
      "Epoch 107/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3970 - VL_attention_linear_output_loss: 2.0575 - VH_attention_linear_output_loss: 2.3395 - VL_attention_linear_output_acc: 0.3744 - VH_attention_linear_output_acc: 0.2481 - val_loss: 4.3841 - val_VL_attention_linear_output_loss: 2.0567 - val_VH_attention_linear_output_loss: 2.3273 - val_VL_attention_linear_output_acc: 0.3770 - val_VH_attention_linear_output_acc: 0.2571\n",
      "Epoch 108/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4062 - VL_attention_linear_output_loss: 2.0750 - VH_attention_linear_output_loss: 2.3312 - VL_attention_linear_output_acc: 0.3635 - VH_attention_linear_output_acc: 0.2546 - val_loss: 4.3866 - val_VL_attention_linear_output_loss: 2.0325 - val_VH_attention_linear_output_loss: 2.3541 - val_VL_attention_linear_output_acc: 0.3922 - val_VH_attention_linear_output_acc: 0.2475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3868 - VL_attention_linear_output_loss: 2.0543 - VH_attention_linear_output_loss: 2.3325 - VL_attention_linear_output_acc: 0.3763 - VH_attention_linear_output_acc: 0.2530 - val_loss: 4.3503 - val_VL_attention_linear_output_loss: 2.0269 - val_VH_attention_linear_output_loss: 2.3234 - val_VL_attention_linear_output_acc: 0.3959 - val_VH_attention_linear_output_acc: 0.2559\n",
      "Epoch 110/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4084 - VL_attention_linear_output_loss: 2.0743 - VH_attention_linear_output_loss: 2.3341 - VL_attention_linear_output_acc: 0.3647 - VH_attention_linear_output_acc: 0.2525 - val_loss: 4.3500 - val_VL_attention_linear_output_loss: 2.0324 - val_VH_attention_linear_output_loss: 2.3175 - val_VL_attention_linear_output_acc: 0.3866 - val_VH_attention_linear_output_acc: 0.2648\n",
      "Epoch 111/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3802 - VL_attention_linear_output_loss: 2.0568 - VH_attention_linear_output_loss: 2.3234 - VL_attention_linear_output_acc: 0.3749 - VH_attention_linear_output_acc: 0.2593 - val_loss: 4.4180 - val_VL_attention_linear_output_loss: 2.0903 - val_VH_attention_linear_output_loss: 2.3276 - val_VL_attention_linear_output_acc: 0.3518 - val_VH_attention_linear_output_acc: 0.2612\n",
      "Epoch 112/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3761 - VL_attention_linear_output_loss: 2.0493 - VH_attention_linear_output_loss: 2.3268 - VL_attention_linear_output_acc: 0.3791 - VH_attention_linear_output_acc: 0.2575 - val_loss: 4.4031 - val_VL_attention_linear_output_loss: 2.0460 - val_VH_attention_linear_output_loss: 2.3571 - val_VL_attention_linear_output_acc: 0.3717 - val_VH_attention_linear_output_acc: 0.2303\n",
      "Epoch 113/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3701 - VL_attention_linear_output_loss: 2.0444 - VH_attention_linear_output_loss: 2.3257 - VL_attention_linear_output_acc: 0.3823 - VH_attention_linear_output_acc: 0.2576 - val_loss: 4.3575 - val_VL_attention_linear_output_loss: 2.0397 - val_VH_attention_linear_output_loss: 2.3178 - val_VL_attention_linear_output_acc: 0.3823 - val_VH_attention_linear_output_acc: 0.2652\n",
      "Epoch 114/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4119 - VL_attention_linear_output_loss: 2.0811 - VH_attention_linear_output_loss: 2.3308 - VL_attention_linear_output_acc: 0.3597 - VH_attention_linear_output_acc: 0.2550 - val_loss: 4.3517 - val_VL_attention_linear_output_loss: 2.0340 - val_VH_attention_linear_output_loss: 2.3177 - val_VL_attention_linear_output_acc: 0.3906 - val_VH_attention_linear_output_acc: 0.2665\n",
      "Epoch 115/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3615 - VL_attention_linear_output_loss: 2.0410 - VH_attention_linear_output_loss: 2.3205 - VL_attention_linear_output_acc: 0.3841 - VH_attention_linear_output_acc: 0.2634 - val_loss: 4.3541 - val_VL_attention_linear_output_loss: 2.0440 - val_VH_attention_linear_output_loss: 2.3101 - val_VL_attention_linear_output_acc: 0.3812 - val_VH_attention_linear_output_acc: 0.2694\n",
      "Epoch 116/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3613 - VL_attention_linear_output_loss: 2.0418 - VH_attention_linear_output_loss: 2.3195 - VL_attention_linear_output_acc: 0.3831 - VH_attention_linear_output_acc: 0.2625 - val_loss: 4.3761 - val_VL_attention_linear_output_loss: 2.0606 - val_VH_attention_linear_output_loss: 2.3155 - val_VL_attention_linear_output_acc: 0.3660 - val_VH_attention_linear_output_acc: 0.2652\n",
      "Epoch 117/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3631 - VL_attention_linear_output_loss: 2.0458 - VH_attention_linear_output_loss: 2.3173 - VL_attention_linear_output_acc: 0.3792 - VH_attention_linear_output_acc: 0.2631 - val_loss: 4.3407 - val_VL_attention_linear_output_loss: 2.0225 - val_VH_attention_linear_output_loss: 2.3182 - val_VL_attention_linear_output_acc: 0.3960 - val_VH_attention_linear_output_acc: 0.2595\n",
      "Epoch 118/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3584 - VL_attention_linear_output_loss: 2.0439 - VH_attention_linear_output_loss: 2.3144 - VL_attention_linear_output_acc: 0.3810 - VH_attention_linear_output_acc: 0.2652 - val_loss: 4.3268 - val_VL_attention_linear_output_loss: 2.0164 - val_VH_attention_linear_output_loss: 2.3104 - val_VL_attention_linear_output_acc: 0.4034 - val_VH_attention_linear_output_acc: 0.2697\n",
      "Epoch 119/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3586 - VL_attention_linear_output_loss: 2.0480 - VH_attention_linear_output_loss: 2.3106 - VL_attention_linear_output_acc: 0.3801 - VH_attention_linear_output_acc: 0.2672 - val_loss: 4.3858 - val_VL_attention_linear_output_loss: 2.0830 - val_VH_attention_linear_output_loss: 2.3028 - val_VL_attention_linear_output_acc: 0.3483 - val_VH_attention_linear_output_acc: 0.2753\n",
      "Epoch 120/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3581 - VL_attention_linear_output_loss: 2.0464 - VH_attention_linear_output_loss: 2.3117 - VL_attention_linear_output_acc: 0.3790 - VH_attention_linear_output_acc: 0.2670 - val_loss: 4.3711 - val_VL_attention_linear_output_loss: 2.0379 - val_VH_attention_linear_output_loss: 2.3333 - val_VL_attention_linear_output_acc: 0.3788 - val_VH_attention_linear_output_acc: 0.2520\n",
      "Epoch 121/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3784 - VL_attention_linear_output_loss: 2.0641 - VH_attention_linear_output_loss: 2.3143 - VL_attention_linear_output_acc: 0.3693 - VH_attention_linear_output_acc: 0.2643 - val_loss: 4.3873 - val_VL_attention_linear_output_loss: 2.0869 - val_VH_attention_linear_output_loss: 2.3004 - val_VL_attention_linear_output_acc: 0.3717 - val_VH_attention_linear_output_acc: 0.2780\n",
      "Epoch 122/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3499 - VL_attention_linear_output_loss: 2.0396 - VH_attention_linear_output_loss: 2.3103 - VL_attention_linear_output_acc: 0.3830 - VH_attention_linear_output_acc: 0.2672 - val_loss: 4.3807 - val_VL_attention_linear_output_loss: 2.0809 - val_VH_attention_linear_output_loss: 2.2998 - val_VL_attention_linear_output_acc: 0.3612 - val_VH_attention_linear_output_acc: 0.2800\n",
      "Epoch 123/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3438 - VL_attention_linear_output_loss: 2.0362 - VH_attention_linear_output_loss: 2.3076 - VL_attention_linear_output_acc: 0.3865 - VH_attention_linear_output_acc: 0.2700 - val_loss: 4.5023 - val_VL_attention_linear_output_loss: 2.2017 - val_VH_attention_linear_output_loss: 2.3006 - val_VL_attention_linear_output_acc: 0.2986 - val_VH_attention_linear_output_acc: 0.2752\n",
      "Epoch 124/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3561 - VL_attention_linear_output_loss: 2.0480 - VH_attention_linear_output_loss: 2.3081 - VL_attention_linear_output_acc: 0.3776 - VH_attention_linear_output_acc: 0.2684 - val_loss: 4.4100 - val_VL_attention_linear_output_loss: 2.0702 - val_VH_attention_linear_output_loss: 2.3398 - val_VL_attention_linear_output_acc: 0.3635 - val_VH_attention_linear_output_acc: 0.2333\n",
      "Epoch 125/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3560 - VL_attention_linear_output_loss: 2.0460 - VH_attention_linear_output_loss: 2.3100 - VL_attention_linear_output_acc: 0.3795 - VH_attention_linear_output_acc: 0.2672 - val_loss: 4.3161 - val_VL_attention_linear_output_loss: 2.0134 - val_VH_attention_linear_output_loss: 2.3027 - val_VL_attention_linear_output_acc: 0.3995 - val_VH_attention_linear_output_acc: 0.2729\n",
      "Epoch 126/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3488 - VL_attention_linear_output_loss: 2.0432 - VH_attention_linear_output_loss: 2.3056 - VL_attention_linear_output_acc: 0.3791 - VH_attention_linear_output_acc: 0.2693 - val_loss: 4.3350 - val_VL_attention_linear_output_loss: 2.0300 - val_VH_attention_linear_output_loss: 2.3051 - val_VL_attention_linear_output_acc: 0.3882 - val_VH_attention_linear_output_acc: 0.2738\n",
      "Epoch 127/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3475 - VL_attention_linear_output_loss: 2.0406 - VH_attention_linear_output_loss: 2.3069 - VL_attention_linear_output_acc: 0.3824 - VH_attention_linear_output_acc: 0.2682 - val_loss: 4.3280 - val_VL_attention_linear_output_loss: 2.0152 - val_VH_attention_linear_output_loss: 2.3128 - val_VL_attention_linear_output_acc: 0.4006 - val_VH_attention_linear_output_acc: 0.2664\n",
      "Epoch 128/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3422 - VL_attention_linear_output_loss: 2.0367 - VH_attention_linear_output_loss: 2.3055 - VL_attention_linear_output_acc: 0.3840 - VH_attention_linear_output_acc: 0.2688 - val_loss: 4.3164 - val_VL_attention_linear_output_loss: 2.0148 - val_VH_attention_linear_output_loss: 2.3015 - val_VL_attention_linear_output_acc: 0.3936 - val_VH_attention_linear_output_acc: 0.2752\n",
      "Epoch 129/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3243 - VL_attention_linear_output_loss: 2.0221 - VH_attention_linear_output_loss: 2.3023 - VL_attention_linear_output_acc: 0.3935 - VH_attention_linear_output_acc: 0.2724 - val_loss: 4.3124 - val_VL_attention_linear_output_loss: 2.0111 - val_VH_attention_linear_output_loss: 2.3013 - val_VL_attention_linear_output_acc: 0.4009 - val_VH_attention_linear_output_acc: 0.2749\n",
      "Epoch 130/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3313 - VL_attention_linear_output_loss: 2.0246 - VH_attention_linear_output_loss: 2.3067 - VL_attention_linear_output_acc: 0.3911 - VH_attention_linear_output_acc: 0.2696 - val_loss: 4.3448 - val_VL_attention_linear_output_loss: 2.0324 - val_VH_attention_linear_output_loss: 2.3124 - val_VL_attention_linear_output_acc: 0.3814 - val_VH_attention_linear_output_acc: 0.2574\n",
      "Epoch 131/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3380 - VL_attention_linear_output_loss: 2.0347 - VH_attention_linear_output_loss: 2.3033 - VL_attention_linear_output_acc: 0.3841 - VH_attention_linear_output_acc: 0.2703 - val_loss: 4.3335 - val_VL_attention_linear_output_loss: 2.0162 - val_VH_attention_linear_output_loss: 2.3173 - val_VL_attention_linear_output_acc: 0.3986 - val_VH_attention_linear_output_acc: 0.2619\n",
      "Epoch 132/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3452 - VL_attention_linear_output_loss: 2.0427 - VH_attention_linear_output_loss: 2.3025 - VL_attention_linear_output_acc: 0.3783 - VH_attention_linear_output_acc: 0.2703 - val_loss: 4.3400 - val_VL_attention_linear_output_loss: 2.0340 - val_VH_attention_linear_output_loss: 2.3060 - val_VL_attention_linear_output_acc: 0.3734 - val_VH_attention_linear_output_acc: 0.2656\n",
      "Epoch 133/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3184 - VL_attention_linear_output_loss: 2.0199 - VH_attention_linear_output_loss: 2.2985 - VL_attention_linear_output_acc: 0.3933 - VH_attention_linear_output_acc: 0.2737 - val_loss: 4.3448 - val_VL_attention_linear_output_loss: 2.0556 - val_VH_attention_linear_output_loss: 2.2892 - val_VL_attention_linear_output_acc: 0.3648 - val_VH_attention_linear_output_acc: 0.2803\n",
      "Epoch 134/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3233 - VL_attention_linear_output_loss: 2.0240 - VH_attention_linear_output_loss: 2.2993 - VL_attention_linear_output_acc: 0.3907 - VH_attention_linear_output_acc: 0.2727 - val_loss: 4.3327 - val_VL_attention_linear_output_loss: 2.0078 - val_VH_attention_linear_output_loss: 2.3249 - val_VL_attention_linear_output_acc: 0.4036 - val_VH_attention_linear_output_acc: 0.2482\n",
      "Epoch 135/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3302 - VL_attention_linear_output_loss: 2.0299 - VH_attention_linear_output_loss: 2.3003 - VL_attention_linear_output_acc: 0.3864 - VH_attention_linear_output_acc: 0.2714 - val_loss: 4.3140 - val_VL_attention_linear_output_loss: 2.0035 - val_VH_attention_linear_output_loss: 2.3105 - val_VL_attention_linear_output_acc: 0.4026 - val_VH_attention_linear_output_acc: 0.2523\n",
      "Epoch 136/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3139 - VL_attention_linear_output_loss: 2.0189 - VH_attention_linear_output_loss: 2.2950 - VL_attention_linear_output_acc: 0.3940 - VH_attention_linear_output_acc: 0.2743 - val_loss: 4.3277 - val_VL_attention_linear_output_loss: 2.0266 - val_VH_attention_linear_output_loss: 2.3012 - val_VL_attention_linear_output_acc: 0.3817 - val_VH_attention_linear_output_acc: 0.2590\n",
      "Epoch 137/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3154 - VL_attention_linear_output_loss: 2.0197 - VH_attention_linear_output_loss: 2.2956 - VL_attention_linear_output_acc: 0.3923 - VH_attention_linear_output_acc: 0.2739 - val_loss: 4.3051 - val_VL_attention_linear_output_loss: 2.0068 - val_VH_attention_linear_output_loss: 2.2983 - val_VL_attention_linear_output_acc: 0.3989 - val_VH_attention_linear_output_acc: 0.2688\n",
      "Epoch 138/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3260 - VL_attention_linear_output_loss: 2.0293 - VH_attention_linear_output_loss: 2.2967 - VL_attention_linear_output_acc: 0.3865 - VH_attention_linear_output_acc: 0.2727 - val_loss: 4.3570 - val_VL_attention_linear_output_loss: 2.0507 - val_VH_attention_linear_output_loss: 2.3063 - val_VL_attention_linear_output_acc: 0.3655 - val_VH_attention_linear_output_acc: 0.2694\n",
      "Epoch 139/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3382 - VL_attention_linear_output_loss: 2.0386 - VH_attention_linear_output_loss: 2.2996 - VL_attention_linear_output_acc: 0.3797 - VH_attention_linear_output_acc: 0.2702 - val_loss: 4.3285 - val_VL_attention_linear_output_loss: 2.0357 - val_VH_attention_linear_output_loss: 2.2928 - val_VL_attention_linear_output_acc: 0.3798 - val_VH_attention_linear_output_acc: 0.2780\n",
      "Epoch 140/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3187 - VL_attention_linear_output_loss: 2.0231 - VH_attention_linear_output_loss: 2.2955 - VL_attention_linear_output_acc: 0.3897 - VH_attention_linear_output_acc: 0.2731 - val_loss: 4.3031 - val_VL_attention_linear_output_loss: 2.0165 - val_VH_attention_linear_output_loss: 2.2866 - val_VL_attention_linear_output_acc: 0.3916 - val_VH_attention_linear_output_acc: 0.2827\n",
      "Epoch 141/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3134 - VL_attention_linear_output_loss: 2.0216 - VH_attention_linear_output_loss: 2.2919 - VL_attention_linear_output_acc: 0.3903 - VH_attention_linear_output_acc: 0.2772 - val_loss: 4.3039 - val_VL_attention_linear_output_loss: 2.0211 - val_VH_attention_linear_output_loss: 2.2828 - val_VL_attention_linear_output_acc: 0.3877 - val_VH_attention_linear_output_acc: 0.2793\n",
      "Epoch 142/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3157 - VL_attention_linear_output_loss: 2.0246 - VH_attention_linear_output_loss: 2.2911 - VL_attention_linear_output_acc: 0.3877 - VH_attention_linear_output_acc: 0.2746 - val_loss: 4.3431 - val_VL_attention_linear_output_loss: 2.0433 - val_VH_attention_linear_output_loss: 2.2998 - val_VL_attention_linear_output_acc: 0.3653 - val_VH_attention_linear_output_acc: 0.2697\n",
      "Epoch 143/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3184 - VL_attention_linear_output_loss: 2.0257 - VH_attention_linear_output_loss: 2.2927 - VL_attention_linear_output_acc: 0.3886 - VH_attention_linear_output_acc: 0.2749 - val_loss: 4.3443 - val_VL_attention_linear_output_loss: 2.0543 - val_VH_attention_linear_output_loss: 2.2900 - val_VL_attention_linear_output_acc: 0.3654 - val_VH_attention_linear_output_acc: 0.2708\n",
      "Epoch 144/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3245 - VL_attention_linear_output_loss: 2.0314 - VH_attention_linear_output_loss: 2.2931 - VL_attention_linear_output_acc: 0.3832 - VH_attention_linear_output_acc: 0.2744 - val_loss: 4.2961 - val_VL_attention_linear_output_loss: 2.0138 - val_VH_attention_linear_output_loss: 2.2824 - val_VL_attention_linear_output_acc: 0.3919 - val_VH_attention_linear_output_acc: 0.2802\n",
      "Epoch 145/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3067 - VL_attention_linear_output_loss: 2.0084 - VH_attention_linear_output_loss: 2.2983 - VL_attention_linear_output_acc: 0.3995 - VH_attention_linear_output_acc: 0.2716 - val_loss: 4.2785 - val_VL_attention_linear_output_loss: 1.9950 - val_VH_attention_linear_output_loss: 2.2834 - val_VL_attention_linear_output_acc: 0.4053 - val_VH_attention_linear_output_acc: 0.2797\n",
      "Epoch 146/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2859 - VL_attention_linear_output_loss: 2.0019 - VH_attention_linear_output_loss: 2.2840 - VL_attention_linear_output_acc: 0.4021 - VH_attention_linear_output_acc: 0.2791 - val_loss: 4.2842 - val_VL_attention_linear_output_loss: 2.0036 - val_VH_attention_linear_output_loss: 2.2806 - val_VL_attention_linear_output_acc: 0.4039 - val_VH_attention_linear_output_acc: 0.2808\n",
      "Epoch 147/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2845 - VL_attention_linear_output_loss: 2.0019 - VH_attention_linear_output_loss: 2.2826 - VL_attention_linear_output_acc: 0.4013 - VH_attention_linear_output_acc: 0.2805 - val_loss: 4.2800 - val_VL_attention_linear_output_loss: 1.9938 - val_VH_attention_linear_output_loss: 2.2862 - val_VL_attention_linear_output_acc: 0.4132 - val_VH_attention_linear_output_acc: 0.2799\n",
      "Epoch 148/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2852 - VL_attention_linear_output_loss: 2.0034 - VH_attention_linear_output_loss: 2.2818 - VL_attention_linear_output_acc: 0.4003 - VH_attention_linear_output_acc: 0.2805 - val_loss: 4.3416 - val_VL_attention_linear_output_loss: 2.0645 - val_VH_attention_linear_output_loss: 2.2771 - val_VL_attention_linear_output_acc: 0.3575 - val_VH_attention_linear_output_acc: 0.2851\n",
      "Epoch 149/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2884 - VL_attention_linear_output_loss: 2.0074 - VH_attention_linear_output_loss: 2.2809 - VL_attention_linear_output_acc: 0.3967 - VH_attention_linear_output_acc: 0.2810 - val_loss: 4.2664 - val_VL_attention_linear_output_loss: 1.9877 - val_VH_attention_linear_output_loss: 2.2787 - val_VL_attention_linear_output_acc: 0.4084 - val_VH_attention_linear_output_acc: 0.2827\n",
      "Epoch 150/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2909 - VL_attention_linear_output_loss: 2.0077 - VH_attention_linear_output_loss: 2.2832 - VL_attention_linear_output_acc: 0.3965 - VH_attention_linear_output_acc: 0.2781 - val_loss: 4.3138 - val_VL_attention_linear_output_loss: 1.9964 - val_VH_attention_linear_output_loss: 2.3174 - val_VL_attention_linear_output_acc: 0.4066 - val_VH_attention_linear_output_acc: 0.2437\n",
      "Epoch 151/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2958 - VL_attention_linear_output_loss: 2.0143 - VH_attention_linear_output_loss: 2.2816 - VL_attention_linear_output_acc: 0.3912 - VH_attention_linear_output_acc: 0.2795 - val_loss: 4.2951 - val_VL_attention_linear_output_loss: 2.0145 - val_VH_attention_linear_output_loss: 2.2807 - val_VL_attention_linear_output_acc: 0.3979 - val_VH_attention_linear_output_acc: 0.2790\n",
      "Epoch 152/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2936 - VL_attention_linear_output_loss: 2.0136 - VH_attention_linear_output_loss: 2.2800 - VL_attention_linear_output_acc: 0.3920 - VH_attention_linear_output_acc: 0.2813 - val_loss: 4.2681 - val_VL_attention_linear_output_loss: 1.9878 - val_VH_attention_linear_output_loss: 2.2803 - val_VL_attention_linear_output_acc: 0.4143 - val_VH_attention_linear_output_acc: 0.2779\n",
      "Epoch 153/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2786 - VL_attention_linear_output_loss: 1.9994 - VH_attention_linear_output_loss: 2.2792 - VL_attention_linear_output_acc: 0.4011 - VH_attention_linear_output_acc: 0.2818 - val_loss: 4.3186 - val_VL_attention_linear_output_loss: 2.0414 - val_VH_attention_linear_output_loss: 2.2773 - val_VL_attention_linear_output_acc: 0.3720 - val_VH_attention_linear_output_acc: 0.2818\n",
      "Epoch 154/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3155 - VL_attention_linear_output_loss: 2.0332 - VH_attention_linear_output_loss: 2.2823 - VL_attention_linear_output_acc: 0.3800 - VH_attention_linear_output_acc: 0.2785 - val_loss: 4.2989 - val_VL_attention_linear_output_loss: 2.0105 - val_VH_attention_linear_output_loss: 2.2884 - val_VL_attention_linear_output_acc: 0.3914 - val_VH_attention_linear_output_acc: 0.2736\n",
      "Epoch 155/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2868 - VL_attention_linear_output_loss: 2.0035 - VH_attention_linear_output_loss: 2.2833 - VL_attention_linear_output_acc: 0.3975 - VH_attention_linear_output_acc: 0.2778 - val_loss: 4.2692 - val_VL_attention_linear_output_loss: 1.9926 - val_VH_attention_linear_output_loss: 2.2766 - val_VL_attention_linear_output_acc: 0.4051 - val_VH_attention_linear_output_acc: 0.2762\n",
      "Epoch 156/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2835 - VL_attention_linear_output_loss: 2.0022 - VH_attention_linear_output_loss: 2.2813 - VL_attention_linear_output_acc: 0.3990 - VH_attention_linear_output_acc: 0.2795 - val_loss: 4.2661 - val_VL_attention_linear_output_loss: 1.9891 - val_VH_attention_linear_output_loss: 2.2770 - val_VL_attention_linear_output_acc: 0.4034 - val_VH_attention_linear_output_acc: 0.2815\n",
      "Epoch 157/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2914 - VL_attention_linear_output_loss: 2.0125 - VH_attention_linear_output_loss: 2.2789 - VL_attention_linear_output_acc: 0.3908 - VH_attention_linear_output_acc: 0.2803 - val_loss: 4.2933 - val_VL_attention_linear_output_loss: 2.0088 - val_VH_attention_linear_output_loss: 2.2845 - val_VL_attention_linear_output_acc: 0.3938 - val_VH_attention_linear_output_acc: 0.2792\n",
      "Epoch 158/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2968 - VL_attention_linear_output_loss: 2.0156 - VH_attention_linear_output_loss: 2.2812 - VL_attention_linear_output_acc: 0.3894 - VH_attention_linear_output_acc: 0.2788 - val_loss: 4.3533 - val_VL_attention_linear_output_loss: 2.0657 - val_VH_attention_linear_output_loss: 2.2875 - val_VL_attention_linear_output_acc: 0.3612 - val_VH_attention_linear_output_acc: 0.2645\n",
      "Epoch 159/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2743 - VL_attention_linear_output_loss: 1.9989 - VH_attention_linear_output_loss: 2.2754 - VL_attention_linear_output_acc: 0.3996 - VH_attention_linear_output_acc: 0.2826 - val_loss: 4.2720 - val_VL_attention_linear_output_loss: 1.9984 - val_VH_attention_linear_output_loss: 2.2737 - val_VL_attention_linear_output_acc: 0.4022 - val_VH_attention_linear_output_acc: 0.2833\n",
      "Epoch 160/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2905 - VL_attention_linear_output_loss: 2.0134 - VH_attention_linear_output_loss: 2.2772 - VL_attention_linear_output_acc: 0.3901 - VH_attention_linear_output_acc: 0.2810 - val_loss: 4.3440 - val_VL_attention_linear_output_loss: 2.0620 - val_VH_attention_linear_output_loss: 2.2820 - val_VL_attention_linear_output_acc: 0.3610 - val_VH_attention_linear_output_acc: 0.2769\n",
      "Epoch 161/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2851 - VL_attention_linear_output_loss: 2.0089 - VH_attention_linear_output_loss: 2.2762 - VL_attention_linear_output_acc: 0.3922 - VH_attention_linear_output_acc: 0.2821 - val_loss: 4.5424 - val_VL_attention_linear_output_loss: 2.2037 - val_VH_attention_linear_output_loss: 2.3387 - val_VL_attention_linear_output_acc: 0.2952 - val_VH_attention_linear_output_acc: 0.2348\n",
      "Epoch 162/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3189 - VL_attention_linear_output_loss: 2.0331 - VH_attention_linear_output_loss: 2.2858 - VL_attention_linear_output_acc: 0.3812 - VH_attention_linear_output_acc: 0.2754 - val_loss: 4.2810 - val_VL_attention_linear_output_loss: 2.0109 - val_VH_attention_linear_output_loss: 2.2701 - val_VL_attention_linear_output_acc: 0.3888 - val_VH_attention_linear_output_acc: 0.2873\n",
      "Epoch 163/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2650 - VL_attention_linear_output_loss: 1.9901 - VH_attention_linear_output_loss: 2.2749 - VL_attention_linear_output_acc: 0.4041 - VH_attention_linear_output_acc: 0.2823 - val_loss: 4.2472 - val_VL_attention_linear_output_loss: 1.9758 - val_VH_attention_linear_output_loss: 2.2714 - val_VL_attention_linear_output_acc: 0.4138 - val_VH_attention_linear_output_acc: 0.2784\n",
      "Epoch 164/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2757 - VL_attention_linear_output_loss: 1.9991 - VH_attention_linear_output_loss: 2.2766 - VL_attention_linear_output_acc: 0.3989 - VH_attention_linear_output_acc: 0.2806 - val_loss: 4.2757 - val_VL_attention_linear_output_loss: 1.9852 - val_VH_attention_linear_output_loss: 2.2906 - val_VL_attention_linear_output_acc: 0.4093 - val_VH_attention_linear_output_acc: 0.2728\n",
      "Epoch 165/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2722 - VL_attention_linear_output_loss: 1.9997 - VH_attention_linear_output_loss: 2.2725 - VL_attention_linear_output_acc: 0.3978 - VH_attention_linear_output_acc: 0.2833 - val_loss: 4.2552 - val_VL_attention_linear_output_loss: 1.9859 - val_VH_attention_linear_output_loss: 2.2692 - val_VL_attention_linear_output_acc: 0.4123 - val_VH_attention_linear_output_acc: 0.2857\n",
      "Epoch 166/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2754 - VL_attention_linear_output_loss: 1.9974 - VH_attention_linear_output_loss: 2.2780 - VL_attention_linear_output_acc: 0.3980 - VH_attention_linear_output_acc: 0.2779 - val_loss: 4.2597 - val_VL_attention_linear_output_loss: 1.9901 - val_VH_attention_linear_output_loss: 2.2696 - val_VL_attention_linear_output_acc: 0.4036 - val_VH_attention_linear_output_acc: 0.2832\n",
      "Epoch 167/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2947 - VL_attention_linear_output_loss: 2.0172 - VH_attention_linear_output_loss: 2.2775 - VL_attention_linear_output_acc: 0.3875 - VH_attention_linear_output_acc: 0.2791 - val_loss: 4.3784 - val_VL_attention_linear_output_loss: 2.1027 - val_VH_attention_linear_output_loss: 2.2757 - val_VL_attention_linear_output_acc: 0.3346 - val_VH_attention_linear_output_acc: 0.2761\n",
      "Epoch 168/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2819 - VL_attention_linear_output_loss: 2.0049 - VH_attention_linear_output_loss: 2.2770 - VL_attention_linear_output_acc: 0.3941 - VH_attention_linear_output_acc: 0.2791 - val_loss: 4.3116 - val_VL_attention_linear_output_loss: 2.0486 - val_VH_attention_linear_output_loss: 2.2631 - val_VL_attention_linear_output_acc: 0.3653 - val_VH_attention_linear_output_acc: 0.2914\n",
      "Epoch 169/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2896 - VL_attention_linear_output_loss: 2.0133 - VH_attention_linear_output_loss: 2.2763 - VL_attention_linear_output_acc: 0.3876 - VH_attention_linear_output_acc: 0.2812 - val_loss: 4.2896 - val_VL_attention_linear_output_loss: 2.0250 - val_VH_attention_linear_output_loss: 2.2646 - val_VL_attention_linear_output_acc: 0.3820 - val_VH_attention_linear_output_acc: 0.2860\n",
      "Epoch 170/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2908 - VL_attention_linear_output_loss: 2.0137 - VH_attention_linear_output_loss: 2.2771 - VL_attention_linear_output_acc: 0.3877 - VH_attention_linear_output_acc: 0.2786 - val_loss: 4.2659 - val_VL_attention_linear_output_loss: 1.9894 - val_VH_attention_linear_output_loss: 2.2765 - val_VL_attention_linear_output_acc: 0.4111 - val_VH_attention_linear_output_acc: 0.2720\n",
      "Epoch 171/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2621 - VL_attention_linear_output_loss: 1.9937 - VH_attention_linear_output_loss: 2.2684 - VL_attention_linear_output_acc: 0.4000 - VH_attention_linear_output_acc: 0.2851 - val_loss: 4.2627 - val_VL_attention_linear_output_loss: 1.9963 - val_VH_attention_linear_output_loss: 2.2664 - val_VL_attention_linear_output_acc: 0.3978 - val_VH_attention_linear_output_acc: 0.2858\n",
      "Epoch 172/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2696 - VL_attention_linear_output_loss: 1.9968 - VH_attention_linear_output_loss: 2.2728 - VL_attention_linear_output_acc: 0.3980 - VH_attention_linear_output_acc: 0.2826 - val_loss: 4.2502 - val_VL_attention_linear_output_loss: 1.9832 - val_VH_attention_linear_output_loss: 2.2670 - val_VL_attention_linear_output_acc: 0.4118 - val_VH_attention_linear_output_acc: 0.2849\n",
      "Epoch 173/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2615 - VL_attention_linear_output_loss: 1.9929 - VH_attention_linear_output_loss: 2.2687 - VL_attention_linear_output_acc: 0.3996 - VH_attention_linear_output_acc: 0.2852 - val_loss: 4.2538 - val_VL_attention_linear_output_loss: 1.9834 - val_VH_attention_linear_output_loss: 2.2704 - val_VL_attention_linear_output_acc: 0.4101 - val_VH_attention_linear_output_acc: 0.2772\n",
      "Epoch 174/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2661 - VL_attention_linear_output_loss: 1.9942 - VH_attention_linear_output_loss: 2.2719 - VL_attention_linear_output_acc: 0.3989 - VH_attention_linear_output_acc: 0.2826 - val_loss: 4.2742 - val_VL_attention_linear_output_loss: 1.9754 - val_VH_attention_linear_output_loss: 2.2989 - val_VL_attention_linear_output_acc: 0.4132 - val_VH_attention_linear_output_acc: 0.2607\n",
      "Epoch 175/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2550 - VL_attention_linear_output_loss: 1.9867 - VH_attention_linear_output_loss: 2.2684 - VL_attention_linear_output_acc: 0.4031 - VH_attention_linear_output_acc: 0.2845 - val_loss: 4.2491 - val_VL_attention_linear_output_loss: 1.9864 - val_VH_attention_linear_output_loss: 2.2626 - val_VL_attention_linear_output_acc: 0.3971 - val_VH_attention_linear_output_acc: 0.2869\n",
      "Epoch 176/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2616 - VL_attention_linear_output_loss: 1.9935 - VH_attention_linear_output_loss: 2.2681 - VL_attention_linear_output_acc: 0.3987 - VH_attention_linear_output_acc: 0.2855 - val_loss: 4.2533 - val_VL_attention_linear_output_loss: 1.9718 - val_VH_attention_linear_output_loss: 2.2814 - val_VL_attention_linear_output_acc: 0.4100 - val_VH_attention_linear_output_acc: 0.2759\n",
      "Epoch 177/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2738 - VL_attention_linear_output_loss: 2.0000 - VH_attention_linear_output_loss: 2.2738 - VL_attention_linear_output_acc: 0.3936 - VH_attention_linear_output_acc: 0.2801 - val_loss: 4.2403 - val_VL_attention_linear_output_loss: 1.9782 - val_VH_attention_linear_output_loss: 2.2621 - val_VL_attention_linear_output_acc: 0.4116 - val_VH_attention_linear_output_acc: 0.2909\n",
      "Epoch 178/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2591 - VL_attention_linear_output_loss: 1.9922 - VH_attention_linear_output_loss: 2.2669 - VL_attention_linear_output_acc: 0.3980 - VH_attention_linear_output_acc: 0.2848 - val_loss: 4.2952 - val_VL_attention_linear_output_loss: 2.0319 - val_VH_attention_linear_output_loss: 2.2633 - val_VL_attention_linear_output_acc: 0.3741 - val_VH_attention_linear_output_acc: 0.2860\n",
      "Epoch 179/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2826 - VL_attention_linear_output_loss: 2.0145 - VH_attention_linear_output_loss: 2.2681 - VL_attention_linear_output_acc: 0.3859 - VH_attention_linear_output_acc: 0.2830 - val_loss: 4.2465 - val_VL_attention_linear_output_loss: 1.9787 - val_VH_attention_linear_output_loss: 2.2678 - val_VL_attention_linear_output_acc: 0.4005 - val_VH_attention_linear_output_acc: 0.2810\n",
      "Epoch 180/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2446 - VL_attention_linear_output_loss: 1.9795 - VH_attention_linear_output_loss: 2.2650 - VL_attention_linear_output_acc: 0.4058 - VH_attention_linear_output_acc: 0.2868 - val_loss: 4.2327 - val_VL_attention_linear_output_loss: 1.9747 - val_VH_attention_linear_output_loss: 2.2580 - val_VL_attention_linear_output_acc: 0.4073 - val_VH_attention_linear_output_acc: 0.2885\n",
      "Epoch 181/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2651 - VL_attention_linear_output_loss: 1.9966 - VH_attention_linear_output_loss: 2.2685 - VL_attention_linear_output_acc: 0.3950 - VH_attention_linear_output_acc: 0.2825 - val_loss: 4.2352 - val_VL_attention_linear_output_loss: 1.9782 - val_VH_attention_linear_output_loss: 2.2571 - val_VL_attention_linear_output_acc: 0.4107 - val_VH_attention_linear_output_acc: 0.2908\n",
      "Epoch 182/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2535 - VL_attention_linear_output_loss: 1.9889 - VH_attention_linear_output_loss: 2.2646 - VL_attention_linear_output_acc: 0.4008 - VH_attention_linear_output_acc: 0.2864 - val_loss: 4.4618 - val_VL_attention_linear_output_loss: 2.1926 - val_VH_attention_linear_output_loss: 2.2692 - val_VL_attention_linear_output_acc: 0.3037 - val_VH_attention_linear_output_acc: 0.2831\n",
      "Epoch 183/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2559 - VL_attention_linear_output_loss: 1.9922 - VH_attention_linear_output_loss: 2.2638 - VL_attention_linear_output_acc: 0.3973 - VH_attention_linear_output_acc: 0.2868 - val_loss: 4.2695 - val_VL_attention_linear_output_loss: 2.0083 - val_VH_attention_linear_output_loss: 2.2612 - val_VL_attention_linear_output_acc: 0.3788 - val_VH_attention_linear_output_acc: 0.2890\n",
      "Epoch 184/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2593 - VL_attention_linear_output_loss: 1.9966 - VH_attention_linear_output_loss: 2.2627 - VL_attention_linear_output_acc: 0.3945 - VH_attention_linear_output_acc: 0.2874 - val_loss: 4.2760 - val_VL_attention_linear_output_loss: 1.9921 - val_VH_attention_linear_output_loss: 2.2839 - val_VL_attention_linear_output_acc: 0.3897 - val_VH_attention_linear_output_acc: 0.2705\n",
      "Epoch 185/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2440 - VL_attention_linear_output_loss: 1.9840 - VH_attention_linear_output_loss: 2.2600 - VL_attention_linear_output_acc: 0.4010 - VH_attention_linear_output_acc: 0.2892 - val_loss: 4.2474 - val_VL_attention_linear_output_loss: 1.9641 - val_VH_attention_linear_output_loss: 2.2832 - val_VL_attention_linear_output_acc: 0.4139 - val_VH_attention_linear_output_acc: 0.2669\n",
      "Epoch 186/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2612 - VL_attention_linear_output_loss: 1.9927 - VH_attention_linear_output_loss: 2.2685 - VL_attention_linear_output_acc: 0.3955 - VH_attention_linear_output_acc: 0.2810 - val_loss: 4.2515 - val_VL_attention_linear_output_loss: 1.9904 - val_VH_attention_linear_output_loss: 2.2611 - val_VL_attention_linear_output_acc: 0.3941 - val_VH_attention_linear_output_acc: 0.2834\n",
      "Epoch 187/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2471 - VL_attention_linear_output_loss: 1.9849 - VH_attention_linear_output_loss: 2.2622 - VL_attention_linear_output_acc: 0.4001 - VH_attention_linear_output_acc: 0.2869 - val_loss: 4.2235 - val_VL_attention_linear_output_loss: 1.9713 - val_VH_attention_linear_output_loss: 2.2521 - val_VL_attention_linear_output_acc: 0.4094 - val_VH_attention_linear_output_acc: 0.2946\n",
      "Epoch 188/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2562 - VL_attention_linear_output_loss: 1.9876 - VH_attention_linear_output_loss: 2.2687 - VL_attention_linear_output_acc: 0.3983 - VH_attention_linear_output_acc: 0.2814 - val_loss: 4.2312 - val_VL_attention_linear_output_loss: 1.9716 - val_VH_attention_linear_output_loss: 2.2596 - val_VL_attention_linear_output_acc: 0.4083 - val_VH_attention_linear_output_acc: 0.2841\n",
      "Epoch 189/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2704 - VL_attention_linear_output_loss: 1.9867 - VH_attention_linear_output_loss: 2.2837 - VL_attention_linear_output_acc: 0.3987 - VH_attention_linear_output_acc: 0.2835 - val_loss: 4.2736 - val_VL_attention_linear_output_loss: 1.9920 - val_VH_attention_linear_output_loss: 2.2816 - val_VL_attention_linear_output_acc: 0.3988 - val_VH_attention_linear_output_acc: 0.2906\n",
      "Epoch 190/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2751 - VL_attention_linear_output_loss: 1.9905 - VH_attention_linear_output_loss: 2.2845 - VL_attention_linear_output_acc: 0.3962 - VH_attention_linear_output_acc: 0.2857 - val_loss: 4.2444 - val_VL_attention_linear_output_loss: 1.9789 - val_VH_attention_linear_output_loss: 2.2655 - val_VL_attention_linear_output_acc: 0.4042 - val_VH_attention_linear_output_acc: 0.2949\n",
      "Epoch 191/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2641 - VL_attention_linear_output_loss: 1.9868 - VH_attention_linear_output_loss: 2.2773 - VL_attention_linear_output_acc: 0.3997 - VH_attention_linear_output_acc: 0.2876 - val_loss: 4.3387 - val_VL_attention_linear_output_loss: 2.0171 - val_VH_attention_linear_output_loss: 2.3216 - val_VL_attention_linear_output_acc: 0.3775 - val_VH_attention_linear_output_acc: 0.2658\n",
      "Epoch 192/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2760 - VL_attention_linear_output_loss: 1.9759 - VH_attention_linear_output_loss: 2.3002 - VL_attention_linear_output_acc: 0.4046 - VH_attention_linear_output_acc: 0.2862 - val_loss: 4.2949 - val_VL_attention_linear_output_loss: 2.0161 - val_VH_attention_linear_output_loss: 2.2788 - val_VL_attention_linear_output_acc: 0.3756 - val_VH_attention_linear_output_acc: 0.2918\n",
      "Epoch 193/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2604 - VL_attention_linear_output_loss: 1.9759 - VH_attention_linear_output_loss: 2.2845 - VL_attention_linear_output_acc: 0.4034 - VH_attention_linear_output_acc: 0.2919 - val_loss: 4.2741 - val_VL_attention_linear_output_loss: 1.9896 - val_VH_attention_linear_output_loss: 2.2845 - val_VL_attention_linear_output_acc: 0.3999 - val_VH_attention_linear_output_acc: 0.2818\n",
      "Epoch 194/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2570 - VL_attention_linear_output_loss: 1.9732 - VH_attention_linear_output_loss: 2.2838 - VL_attention_linear_output_acc: 0.4052 - VH_attention_linear_output_acc: 0.2913 - val_loss: 4.3239 - val_VL_attention_linear_output_loss: 2.0377 - val_VH_attention_linear_output_loss: 2.2861 - val_VL_attention_linear_output_acc: 0.3663 - val_VH_attention_linear_output_acc: 0.2773\n",
      "Epoch 195/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2662 - VL_attention_linear_output_loss: 1.9687 - VH_attention_linear_output_loss: 2.2975 - VL_attention_linear_output_acc: 0.4069 - VH_attention_linear_output_acc: 0.2739 - val_loss: 4.2147 - val_VL_attention_linear_output_loss: 1.9585 - val_VH_attention_linear_output_loss: 2.2562 - val_VL_attention_linear_output_acc: 0.4149 - val_VH_attention_linear_output_acc: 0.2922\n",
      "Epoch 196/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2198 - VL_attention_linear_output_loss: 1.9642 - VH_attention_linear_output_loss: 2.2556 - VL_attention_linear_output_acc: 0.4105 - VH_attention_linear_output_acc: 0.2933 - val_loss: 4.2184 - val_VL_attention_linear_output_loss: 1.9624 - val_VH_attention_linear_output_loss: 2.2560 - val_VL_attention_linear_output_acc: 0.4110 - val_VH_attention_linear_output_acc: 0.2870\n",
      "Epoch 197/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2195 - VL_attention_linear_output_loss: 1.9679 - VH_attention_linear_output_loss: 2.2516 - VL_attention_linear_output_acc: 0.4066 - VH_attention_linear_output_acc: 0.2937 - val_loss: 4.2206 - val_VL_attention_linear_output_loss: 1.9715 - val_VH_attention_linear_output_loss: 2.2491 - val_VL_attention_linear_output_acc: 0.4029 - val_VH_attention_linear_output_acc: 0.2931\n",
      "Epoch 198/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2248 - VL_attention_linear_output_loss: 1.9747 - VH_attention_linear_output_loss: 2.2501 - VL_attention_linear_output_acc: 0.4033 - VH_attention_linear_output_acc: 0.2943 - val_loss: 4.2083 - val_VL_attention_linear_output_loss: 1.9579 - val_VH_attention_linear_output_loss: 2.2504 - val_VL_attention_linear_output_acc: 0.4159 - val_VH_attention_linear_output_acc: 0.2952\n",
      "Epoch 199/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2207 - VL_attention_linear_output_loss: 1.9707 - VH_attention_linear_output_loss: 2.2500 - VL_attention_linear_output_acc: 0.4055 - VH_attention_linear_output_acc: 0.2948 - val_loss: 4.2113 - val_VL_attention_linear_output_loss: 1.9591 - val_VH_attention_linear_output_loss: 2.2522 - val_VL_attention_linear_output_acc: 0.4131 - val_VH_attention_linear_output_acc: 0.2926\n",
      "Epoch 200/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2250 - VL_attention_linear_output_loss: 1.9749 - VH_attention_linear_output_loss: 2.2500 - VL_attention_linear_output_acc: 0.4023 - VH_attention_linear_output_acc: 0.2937 - val_loss: 4.2195 - val_VL_attention_linear_output_loss: 1.9674 - val_VH_attention_linear_output_loss: 2.2521 - val_VL_attention_linear_output_acc: 0.4089 - val_VH_attention_linear_output_acc: 0.2966\n",
      "Epoch 201/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2208 - VL_attention_linear_output_loss: 1.9720 - VH_attention_linear_output_loss: 2.2488 - VL_attention_linear_output_acc: 0.4034 - VH_attention_linear_output_acc: 0.2949 - val_loss: 4.2094 - val_VL_attention_linear_output_loss: 1.9621 - val_VH_attention_linear_output_loss: 2.2473 - val_VL_attention_linear_output_acc: 0.4062 - val_VH_attention_linear_output_acc: 0.2968\n",
      "Epoch 202/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2110 - VL_attention_linear_output_loss: 1.9634 - VH_attention_linear_output_loss: 2.2476 - VL_attention_linear_output_acc: 0.4081 - VH_attention_linear_output_acc: 0.2958 - val_loss: 4.2849 - val_VL_attention_linear_output_loss: 2.0355 - val_VH_attention_linear_output_loss: 2.2494 - val_VL_attention_linear_output_acc: 0.3662 - val_VH_attention_linear_output_acc: 0.2948\n",
      "Epoch 203/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2261 - VL_attention_linear_output_loss: 1.9764 - VH_attention_linear_output_loss: 2.2496 - VL_attention_linear_output_acc: 0.4011 - VH_attention_linear_output_acc: 0.2948 - val_loss: 4.2277 - val_VL_attention_linear_output_loss: 1.9784 - val_VH_attention_linear_output_loss: 2.2493 - val_VL_attention_linear_output_acc: 0.3992 - val_VH_attention_linear_output_acc: 0.2943\n",
      "Epoch 204/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2239 - VL_attention_linear_output_loss: 1.9741 - VH_attention_linear_output_loss: 2.2498 - VL_attention_linear_output_acc: 0.4004 - VH_attention_linear_output_acc: 0.2928 - val_loss: 4.2295 - val_VL_attention_linear_output_loss: 1.9609 - val_VH_attention_linear_output_loss: 2.2686 - val_VL_attention_linear_output_acc: 0.4125 - val_VH_attention_linear_output_acc: 0.2741\n",
      "Epoch 205/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2131 - VL_attention_linear_output_loss: 1.9638 - VH_attention_linear_output_loss: 2.2493 - VL_attention_linear_output_acc: 0.4073 - VH_attention_linear_output_acc: 0.2935 - val_loss: 4.2200 - val_VL_attention_linear_output_loss: 1.9715 - val_VH_attention_linear_output_loss: 2.2485 - val_VL_attention_linear_output_acc: 0.3991 - val_VH_attention_linear_output_acc: 0.2899\n",
      "Epoch 206/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2187 - VL_attention_linear_output_loss: 1.9715 - VH_attention_linear_output_loss: 2.2472 - VL_attention_linear_output_acc: 0.4024 - VH_attention_linear_output_acc: 0.2947 - val_loss: 4.2376 - val_VL_attention_linear_output_loss: 1.9950 - val_VH_attention_linear_output_loss: 2.2427 - val_VL_attention_linear_output_acc: 0.3968 - val_VH_attention_linear_output_acc: 0.2952\n",
      "Epoch 207/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2108 - VL_attention_linear_output_loss: 1.9647 - VH_attention_linear_output_loss: 2.2461 - VL_attention_linear_output_acc: 0.4054 - VH_attention_linear_output_acc: 0.2956 - val_loss: 4.2155 - val_VL_attention_linear_output_loss: 1.9609 - val_VH_attention_linear_output_loss: 2.2546 - val_VL_attention_linear_output_acc: 0.4075 - val_VH_attention_linear_output_acc: 0.2827\n",
      "Epoch 208/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2068 - VL_attention_linear_output_loss: 1.9618 - VH_attention_linear_output_loss: 2.2450 - VL_attention_linear_output_acc: 0.4075 - VH_attention_linear_output_acc: 0.2957 - val_loss: 4.2087 - val_VL_attention_linear_output_loss: 1.9599 - val_VH_attention_linear_output_loss: 2.2488 - val_VL_attention_linear_output_acc: 0.4026 - val_VH_attention_linear_output_acc: 0.2918\n",
      "Epoch 209/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2319 - VL_attention_linear_output_loss: 1.9851 - VH_attention_linear_output_loss: 2.2468 - VL_attention_linear_output_acc: 0.3938 - VH_attention_linear_output_acc: 0.2944 - val_loss: 4.2252 - val_VL_attention_linear_output_loss: 1.9819 - val_VH_attention_linear_output_loss: 2.2433 - val_VL_attention_linear_output_acc: 0.3968 - val_VH_attention_linear_output_acc: 0.2947\n",
      "Epoch 210/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2296 - VL_attention_linear_output_loss: 1.9833 - VH_attention_linear_output_loss: 2.2463 - VL_attention_linear_output_acc: 0.3940 - VH_attention_linear_output_acc: 0.2945 - val_loss: 4.2225 - val_VL_attention_linear_output_loss: 1.9790 - val_VH_attention_linear_output_loss: 2.2435 - val_VL_attention_linear_output_acc: 0.3953 - val_VH_attention_linear_output_acc: 0.2974\n",
      "Epoch 211/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1979 - VL_attention_linear_output_loss: 1.9536 - VH_attention_linear_output_loss: 2.2443 - VL_attention_linear_output_acc: 0.4104 - VH_attention_linear_output_acc: 0.2967 - val_loss: 4.2343 - val_VL_attention_linear_output_loss: 1.9602 - val_VH_attention_linear_output_loss: 2.2741 - val_VL_attention_linear_output_acc: 0.4040 - val_VH_attention_linear_output_acc: 0.2811\n",
      "Epoch 212/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2285 - VL_attention_linear_output_loss: 1.9778 - VH_attention_linear_output_loss: 2.2507 - VL_attention_linear_output_acc: 0.3979 - VH_attention_linear_output_acc: 0.2950 - val_loss: 4.2040 - val_VL_attention_linear_output_loss: 1.9637 - val_VH_attention_linear_output_loss: 2.2403 - val_VL_attention_linear_output_acc: 0.4018 - val_VH_attention_linear_output_acc: 0.2975\n",
      "Epoch 213/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2167 - VL_attention_linear_output_loss: 1.9708 - VH_attention_linear_output_loss: 2.2459 - VL_attention_linear_output_acc: 0.4013 - VH_attention_linear_output_acc: 0.2954 - val_loss: 4.1941 - val_VL_attention_linear_output_loss: 1.9509 - val_VH_attention_linear_output_loss: 2.2432 - val_VL_attention_linear_output_acc: 0.4147 - val_VH_attention_linear_output_acc: 0.2942\n",
      "Epoch 214/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2031 - VL_attention_linear_output_loss: 1.9597 - VH_attention_linear_output_loss: 2.2433 - VL_attention_linear_output_acc: 0.4059 - VH_attention_linear_output_acc: 0.2958 - val_loss: 4.2311 - val_VL_attention_linear_output_loss: 1.9909 - val_VH_attention_linear_output_loss: 2.2402 - val_VL_attention_linear_output_acc: 0.3792 - val_VH_attention_linear_output_acc: 0.2976\n",
      "Epoch 215/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2183 - VL_attention_linear_output_loss: 1.9702 - VH_attention_linear_output_loss: 2.2481 - VL_attention_linear_output_acc: 0.4007 - VH_attention_linear_output_acc: 0.2920 - val_loss: 4.1976 - val_VL_attention_linear_output_loss: 1.9442 - val_VH_attention_linear_output_loss: 2.2534 - val_VL_attention_linear_output_acc: 0.4147 - val_VH_attention_linear_output_acc: 0.2846\n",
      "Epoch 216/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2178 - VL_attention_linear_output_loss: 1.9745 - VH_attention_linear_output_loss: 2.2433 - VL_attention_linear_output_acc: 0.3973 - VH_attention_linear_output_acc: 0.2953 - val_loss: 4.2212 - val_VL_attention_linear_output_loss: 1.9831 - val_VH_attention_linear_output_loss: 2.2381 - val_VL_attention_linear_output_acc: 0.3892 - val_VH_attention_linear_output_acc: 0.2986\n",
      "Epoch 217/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2048 - VL_attention_linear_output_loss: 1.9627 - VH_attention_linear_output_loss: 2.2421 - VL_attention_linear_output_acc: 0.4041 - VH_attention_linear_output_acc: 0.2958 - val_loss: 4.1889 - val_VL_attention_linear_output_loss: 1.9502 - val_VH_attention_linear_output_loss: 2.2387 - val_VL_attention_linear_output_acc: 0.4110 - val_VH_attention_linear_output_acc: 0.3010\n",
      "Epoch 218/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2123 - VL_attention_linear_output_loss: 1.9689 - VH_attention_linear_output_loss: 2.2435 - VL_attention_linear_output_acc: 0.4011 - VH_attention_linear_output_acc: 0.2954 - val_loss: 4.1854 - val_VL_attention_linear_output_loss: 1.9467 - val_VH_attention_linear_output_loss: 2.2388 - val_VL_attention_linear_output_acc: 0.4136 - val_VH_attention_linear_output_acc: 0.3011\n",
      "Epoch 219/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2111 - VL_attention_linear_output_loss: 1.9669 - VH_attention_linear_output_loss: 2.2442 - VL_attention_linear_output_acc: 0.4017 - VH_attention_linear_output_acc: 0.2944 - val_loss: 4.1924 - val_VL_attention_linear_output_loss: 1.9524 - val_VH_attention_linear_output_loss: 2.2399 - val_VL_attention_linear_output_acc: 0.4118 - val_VH_attention_linear_output_acc: 0.2993\n",
      "Epoch 220/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2194 - VL_attention_linear_output_loss: 1.9735 - VH_attention_linear_output_loss: 2.2460 - VL_attention_linear_output_acc: 0.3980 - VH_attention_linear_output_acc: 0.2928 - val_loss: 4.2067 - val_VL_attention_linear_output_loss: 1.9619 - val_VH_attention_linear_output_loss: 2.2449 - val_VL_attention_linear_output_acc: 0.4045 - val_VH_attention_linear_output_acc: 0.2913\n",
      "Epoch 221/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2113 - VL_attention_linear_output_loss: 1.9634 - VH_attention_linear_output_loss: 2.2479 - VL_attention_linear_output_acc: 0.4043 - VH_attention_linear_output_acc: 0.2909 - val_loss: 4.2224 - val_VL_attention_linear_output_loss: 1.9553 - val_VH_attention_linear_output_loss: 2.2671 - val_VL_attention_linear_output_acc: 0.4128 - val_VH_attention_linear_output_acc: 0.2712\n",
      "Epoch 222/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2081 - VL_attention_linear_output_loss: 1.9654 - VH_attention_linear_output_loss: 2.2427 - VL_attention_linear_output_acc: 0.4016 - VH_attention_linear_output_acc: 0.2948 - val_loss: 4.2022 - val_VL_attention_linear_output_loss: 1.9585 - val_VH_attention_linear_output_loss: 2.2438 - val_VL_attention_linear_output_acc: 0.4060 - val_VH_attention_linear_output_acc: 0.2929\n",
      "Epoch 223/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1989 - VL_attention_linear_output_loss: 1.9549 - VH_attention_linear_output_loss: 2.2440 - VL_attention_linear_output_acc: 0.4076 - VH_attention_linear_output_acc: 0.2936 - val_loss: 4.1859 - val_VL_attention_linear_output_loss: 1.9446 - val_VH_attention_linear_output_loss: 2.2413 - val_VL_attention_linear_output_acc: 0.4055 - val_VH_attention_linear_output_acc: 0.2961\n",
      "Epoch 224/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2028 - VL_attention_linear_output_loss: 1.9648 - VH_attention_linear_output_loss: 2.2380 - VL_attention_linear_output_acc: 0.4017 - VH_attention_linear_output_acc: 0.2973 - val_loss: 4.1990 - val_VL_attention_linear_output_loss: 1.9588 - val_VH_attention_linear_output_loss: 2.2401 - val_VL_attention_linear_output_acc: 0.3983 - val_VH_attention_linear_output_acc: 0.2963\n",
      "Epoch 225/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2067 - VL_attention_linear_output_loss: 1.9620 - VH_attention_linear_output_loss: 2.2447 - VL_attention_linear_output_acc: 0.4028 - VH_attention_linear_output_acc: 0.2930 - val_loss: 4.2122 - val_VL_attention_linear_output_loss: 1.9721 - val_VH_attention_linear_output_loss: 2.2401 - val_VL_attention_linear_output_acc: 0.4016 - val_VH_attention_linear_output_acc: 0.2968\n",
      "Epoch 226/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2037 - VL_attention_linear_output_loss: 1.9633 - VH_attention_linear_output_loss: 2.2404 - VL_attention_linear_output_acc: 0.4034 - VH_attention_linear_output_acc: 0.2960 - val_loss: 4.1963 - val_VL_attention_linear_output_loss: 1.9597 - val_VH_attention_linear_output_loss: 2.2366 - val_VL_attention_linear_output_acc: 0.4109 - val_VH_attention_linear_output_acc: 0.3007\n",
      "Epoch 227/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2065 - VL_attention_linear_output_loss: 1.9629 - VH_attention_linear_output_loss: 2.2436 - VL_attention_linear_output_acc: 0.4029 - VH_attention_linear_output_acc: 0.2941 - val_loss: 4.2475 - val_VL_attention_linear_output_loss: 1.9986 - val_VH_attention_linear_output_loss: 2.2488 - val_VL_attention_linear_output_acc: 0.3779 - val_VH_attention_linear_output_acc: 0.2804\n",
      "Epoch 228/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2093 - VL_attention_linear_output_loss: 1.9664 - VH_attention_linear_output_loss: 2.2428 - VL_attention_linear_output_acc: 0.4006 - VH_attention_linear_output_acc: 0.2930 - val_loss: 4.1934 - val_VL_attention_linear_output_loss: 1.9486 - val_VH_attention_linear_output_loss: 2.2448 - val_VL_attention_linear_output_acc: 0.4133 - val_VH_attention_linear_output_acc: 0.2916\n",
      "Epoch 229/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2165 - VL_attention_linear_output_loss: 1.9713 - VH_attention_linear_output_loss: 2.2451 - VL_attention_linear_output_acc: 0.3985 - VH_attention_linear_output_acc: 0.2918 - val_loss: 4.2009 - val_VL_attention_linear_output_loss: 1.9636 - val_VH_attention_linear_output_loss: 2.2373 - val_VL_attention_linear_output_acc: 0.4048 - val_VH_attention_linear_output_acc: 0.2957\n",
      "Epoch 230/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1998 - VL_attention_linear_output_loss: 1.9595 - VH_attention_linear_output_loss: 2.2403 - VL_attention_linear_output_acc: 0.4042 - VH_attention_linear_output_acc: 0.2956 - val_loss: 4.1851 - val_VL_attention_linear_output_loss: 1.9433 - val_VH_attention_linear_output_loss: 2.2417 - val_VL_attention_linear_output_acc: 0.4110 - val_VH_attention_linear_output_acc: 0.2918\n",
      "Epoch 231/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2019 - VL_attention_linear_output_loss: 1.9610 - VH_attention_linear_output_loss: 2.2409 - VL_attention_linear_output_acc: 0.4022 - VH_attention_linear_output_acc: 0.2940 - val_loss: 4.1763 - val_VL_attention_linear_output_loss: 1.9448 - val_VH_attention_linear_output_loss: 2.2316 - val_VL_attention_linear_output_acc: 0.4078 - val_VH_attention_linear_output_acc: 0.3009\n",
      "Epoch 232/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1783 - VL_attention_linear_output_loss: 1.9436 - VH_attention_linear_output_loss: 2.2348 - VL_attention_linear_output_acc: 0.4110 - VH_attention_linear_output_acc: 0.2991 - val_loss: 4.2229 - val_VL_attention_linear_output_loss: 1.9869 - val_VH_attention_linear_output_loss: 2.2360 - val_VL_attention_linear_output_acc: 0.3828 - val_VH_attention_linear_output_acc: 0.2962\n",
      "Epoch 233/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1858 - VL_attention_linear_output_loss: 1.9474 - VH_attention_linear_output_loss: 2.2384 - VL_attention_linear_output_acc: 0.4096 - VH_attention_linear_output_acc: 0.2950 - val_loss: 4.1721 - val_VL_attention_linear_output_loss: 1.9401 - val_VH_attention_linear_output_loss: 2.2320 - val_VL_attention_linear_output_acc: 0.4168 - val_VH_attention_linear_output_acc: 0.2975\n",
      "Epoch 234/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1913 - VL_attention_linear_output_loss: 1.9577 - VH_attention_linear_output_loss: 2.2336 - VL_attention_linear_output_acc: 0.4040 - VH_attention_linear_output_acc: 0.2995 - val_loss: 4.2245 - val_VL_attention_linear_output_loss: 1.9735 - val_VH_attention_linear_output_loss: 2.2510 - val_VL_attention_linear_output_acc: 0.3926 - val_VH_attention_linear_output_acc: 0.2889\n",
      "Epoch 235/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2068 - VL_attention_linear_output_loss: 1.9708 - VH_attention_linear_output_loss: 2.2360 - VL_attention_linear_output_acc: 0.3967 - VH_attention_linear_output_acc: 0.2975 - val_loss: 4.1695 - val_VL_attention_linear_output_loss: 1.9414 - val_VH_attention_linear_output_loss: 2.2281 - val_VL_attention_linear_output_acc: 0.4144 - val_VH_attention_linear_output_acc: 0.3029\n",
      "Epoch 236/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1906 - VL_attention_linear_output_loss: 1.9545 - VH_attention_linear_output_loss: 2.2361 - VL_attention_linear_output_acc: 0.4061 - VH_attention_linear_output_acc: 0.2971 - val_loss: 4.2383 - val_VL_attention_linear_output_loss: 2.0078 - val_VH_attention_linear_output_loss: 2.2305 - val_VL_attention_linear_output_acc: 0.3689 - val_VH_attention_linear_output_acc: 0.2986\n",
      "Epoch 237/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1863 - VL_attention_linear_output_loss: 1.9510 - VH_attention_linear_output_loss: 2.2353 - VL_attention_linear_output_acc: 0.4065 - VH_attention_linear_output_acc: 0.2976 - val_loss: 4.1740 - val_VL_attention_linear_output_loss: 1.9414 - val_VH_attention_linear_output_loss: 2.2326 - val_VL_attention_linear_output_acc: 0.4100 - val_VH_attention_linear_output_acc: 0.2996\n",
      "Epoch 238/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2002 - VL_attention_linear_output_loss: 1.9673 - VH_attention_linear_output_loss: 2.2329 - VL_attention_linear_output_acc: 0.3984 - VH_attention_linear_output_acc: 0.2993 - val_loss: 4.1811 - val_VL_attention_linear_output_loss: 1.9495 - val_VH_attention_linear_output_loss: 2.2316 - val_VL_attention_linear_output_acc: 0.4108 - val_VH_attention_linear_output_acc: 0.3018\n",
      "Epoch 239/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1841 - VL_attention_linear_output_loss: 1.9517 - VH_attention_linear_output_loss: 2.2325 - VL_attention_linear_output_acc: 0.4064 - VH_attention_linear_output_acc: 0.2994 - val_loss: 4.1797 - val_VL_attention_linear_output_loss: 1.9367 - val_VH_attention_linear_output_loss: 2.2430 - val_VL_attention_linear_output_acc: 0.4189 - val_VH_attention_linear_output_acc: 0.2817\n",
      "Epoch 240/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1965 - VL_attention_linear_output_loss: 1.9633 - VH_attention_linear_output_loss: 2.2331 - VL_attention_linear_output_acc: 0.4010 - VH_attention_linear_output_acc: 0.2984 - val_loss: 4.1751 - val_VL_attention_linear_output_loss: 1.9452 - val_VH_attention_linear_output_loss: 2.2299 - val_VL_attention_linear_output_acc: 0.4140 - val_VH_attention_linear_output_acc: 0.3006\n",
      "Epoch 241/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1873 - VL_attention_linear_output_loss: 1.9512 - VH_attention_linear_output_loss: 2.2361 - VL_attention_linear_output_acc: 0.4067 - VH_attention_linear_output_acc: 0.2956 - val_loss: 4.1660 - val_VL_attention_linear_output_loss: 1.9354 - val_VH_attention_linear_output_loss: 2.2307 - val_VL_attention_linear_output_acc: 0.4165 - val_VH_attention_linear_output_acc: 0.2995\n",
      "Epoch 242/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1834 - VL_attention_linear_output_loss: 1.9550 - VH_attention_linear_output_loss: 2.2284 - VL_attention_linear_output_acc: 0.4044 - VH_attention_linear_output_acc: 0.3021 - val_loss: 4.2037 - val_VL_attention_linear_output_loss: 1.9780 - val_VH_attention_linear_output_loss: 2.2257 - val_VL_attention_linear_output_acc: 0.4043 - val_VH_attention_linear_output_acc: 0.3024\n",
      "Epoch 243/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1804 - VL_attention_linear_output_loss: 1.9530 - VH_attention_linear_output_loss: 2.2274 - VL_attention_linear_output_acc: 0.4055 - VH_attention_linear_output_acc: 0.3019 - val_loss: 4.1809 - val_VL_attention_linear_output_loss: 1.9579 - val_VH_attention_linear_output_loss: 2.2230 - val_VL_attention_linear_output_acc: 0.4132 - val_VH_attention_linear_output_acc: 0.3047\n",
      "Epoch 244/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1814 - VL_attention_linear_output_loss: 1.9552 - VH_attention_linear_output_loss: 2.2263 - VL_attention_linear_output_acc: 0.4041 - VH_attention_linear_output_acc: 0.3025 - val_loss: 4.2814 - val_VL_attention_linear_output_loss: 2.0557 - val_VH_attention_linear_output_loss: 2.2257 - val_VL_attention_linear_output_acc: 0.3522 - val_VH_attention_linear_output_acc: 0.3049\n",
      "Epoch 245/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1798 - VL_attention_linear_output_loss: 1.9504 - VH_attention_linear_output_loss: 2.2295 - VL_attention_linear_output_acc: 0.4066 - VH_attention_linear_output_acc: 0.3010 - val_loss: 4.1673 - val_VL_attention_linear_output_loss: 1.9446 - val_VH_attention_linear_output_loss: 2.2227 - val_VL_attention_linear_output_acc: 0.4042 - val_VH_attention_linear_output_acc: 0.3056\n",
      "Epoch 246/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1798 - VL_attention_linear_output_loss: 1.9513 - VH_attention_linear_output_loss: 2.2285 - VL_attention_linear_output_acc: 0.4054 - VH_attention_linear_output_acc: 0.3012 - val_loss: 4.1649 - val_VL_attention_linear_output_loss: 1.9332 - val_VH_attention_linear_output_loss: 2.2317 - val_VL_attention_linear_output_acc: 0.4129 - val_VH_attention_linear_output_acc: 0.2947\n",
      "Epoch 247/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1852 - VL_attention_linear_output_loss: 1.9554 - VH_attention_linear_output_loss: 2.2298 - VL_attention_linear_output_acc: 0.4032 - VH_attention_linear_output_acc: 0.2992 - val_loss: 4.2405 - val_VL_attention_linear_output_loss: 2.0105 - val_VH_attention_linear_output_loss: 2.2301 - val_VL_attention_linear_output_acc: 0.3813 - val_VH_attention_linear_output_acc: 0.3003\n",
      "Epoch 248/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1761 - VL_attention_linear_output_loss: 1.9454 - VH_attention_linear_output_loss: 2.2307 - VL_attention_linear_output_acc: 0.4085 - VH_attention_linear_output_acc: 0.2998 - val_loss: 4.1668 - val_VL_attention_linear_output_loss: 1.9496 - val_VH_attention_linear_output_loss: 2.2172 - val_VL_attention_linear_output_acc: 0.4128 - val_VH_attention_linear_output_acc: 0.3080\n",
      "Epoch 249/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1669 - VL_attention_linear_output_loss: 1.9429 - VH_attention_linear_output_loss: 2.2240 - VL_attention_linear_output_acc: 0.4096 - VH_attention_linear_output_acc: 0.3031 - val_loss: 4.1917 - val_VL_attention_linear_output_loss: 1.9570 - val_VH_attention_linear_output_loss: 2.2347 - val_VL_attention_linear_output_acc: 0.4086 - val_VH_attention_linear_output_acc: 0.2974\n",
      "Epoch 250/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1702 - VL_attention_linear_output_loss: 1.9486 - VH_attention_linear_output_loss: 2.2217 - VL_attention_linear_output_acc: 0.4059 - VH_attention_linear_output_acc: 0.3051 - val_loss: 4.1585 - val_VL_attention_linear_output_loss: 1.9344 - val_VH_attention_linear_output_loss: 2.2240 - val_VL_attention_linear_output_acc: 0.4189 - val_VH_attention_linear_output_acc: 0.3018\n",
      "Epoch 251/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1726 - VL_attention_linear_output_loss: 1.9483 - VH_attention_linear_output_loss: 2.2244 - VL_attention_linear_output_acc: 0.4073 - VH_attention_linear_output_acc: 0.3018 - val_loss: 4.1987 - val_VL_attention_linear_output_loss: 1.9664 - val_VH_attention_linear_output_loss: 2.2324 - val_VL_attention_linear_output_acc: 0.4036 - val_VH_attention_linear_output_acc: 0.2952\n",
      "Epoch 252/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1923 - VL_attention_linear_output_loss: 1.9674 - VH_attention_linear_output_loss: 2.2249 - VL_attention_linear_output_acc: 0.3967 - VH_attention_linear_output_acc: 0.3017 - val_loss: 4.1695 - val_VL_attention_linear_output_loss: 1.9475 - val_VH_attention_linear_output_loss: 2.2221 - val_VL_attention_linear_output_acc: 0.4103 - val_VH_attention_linear_output_acc: 0.3073\n",
      "Epoch 253/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1768 - VL_attention_linear_output_loss: 1.9546 - VH_attention_linear_output_loss: 2.2222 - VL_attention_linear_output_acc: 0.4029 - VH_attention_linear_output_acc: 0.3048 - val_loss: 4.1578 - val_VL_attention_linear_output_loss: 1.9343 - val_VH_attention_linear_output_loss: 2.2235 - val_VL_attention_linear_output_acc: 0.4164 - val_VH_attention_linear_output_acc: 0.3039\n",
      "Epoch 254/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1587 - VL_attention_linear_output_loss: 1.9386 - VH_attention_linear_output_loss: 2.2201 - VL_attention_linear_output_acc: 0.4114 - VH_attention_linear_output_acc: 0.3053 - val_loss: 4.1857 - val_VL_attention_linear_output_loss: 1.9703 - val_VH_attention_linear_output_loss: 2.2154 - val_VL_attention_linear_output_acc: 0.3891 - val_VH_attention_linear_output_acc: 0.3074\n",
      "Epoch 255/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1782 - VL_attention_linear_output_loss: 1.9567 - VH_attention_linear_output_loss: 2.2214 - VL_attention_linear_output_acc: 0.4031 - VH_attention_linear_output_acc: 0.3034 - val_loss: 4.1721 - val_VL_attention_linear_output_loss: 1.9402 - val_VH_attention_linear_output_loss: 2.2319 - val_VL_attention_linear_output_acc: 0.4107 - val_VH_attention_linear_output_acc: 0.2962\n",
      "Epoch 256/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1587 - VL_attention_linear_output_loss: 1.9395 - VH_attention_linear_output_loss: 2.2191 - VL_attention_linear_output_acc: 0.4104 - VH_attention_linear_output_acc: 0.3055 - val_loss: 4.2257 - val_VL_attention_linear_output_loss: 2.0008 - val_VH_attention_linear_output_loss: 2.2250 - val_VL_attention_linear_output_acc: 0.3733 - val_VH_attention_linear_output_acc: 0.2993\n",
      "Epoch 257/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1869 - VL_attention_linear_output_loss: 1.9632 - VH_attention_linear_output_loss: 2.2237 - VL_attention_linear_output_acc: 0.3983 - VH_attention_linear_output_acc: 0.3027 - val_loss: 4.1523 - val_VL_attention_linear_output_loss: 1.9302 - val_VH_attention_linear_output_loss: 2.2221 - val_VL_attention_linear_output_acc: 0.4147 - val_VH_attention_linear_output_acc: 0.2951\n",
      "Epoch 258/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1516 - VL_attention_linear_output_loss: 1.9362 - VH_attention_linear_output_loss: 2.2154 - VL_attention_linear_output_acc: 0.4121 - VH_attention_linear_output_acc: 0.3084 - val_loss: 4.2798 - val_VL_attention_linear_output_loss: 2.0630 - val_VH_attention_linear_output_loss: 2.2168 - val_VL_attention_linear_output_acc: 0.3389 - val_VH_attention_linear_output_acc: 0.3113\n",
      "Epoch 259/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1747 - VL_attention_linear_output_loss: 1.9534 - VH_attention_linear_output_loss: 2.2214 - VL_attention_linear_output_acc: 0.4027 - VH_attention_linear_output_acc: 0.3039 - val_loss: 4.1782 - val_VL_attention_linear_output_loss: 1.9449 - val_VH_attention_linear_output_loss: 2.2333 - val_VL_attention_linear_output_acc: 0.4047 - val_VH_attention_linear_output_acc: 0.2908\n",
      "Epoch 260/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1644 - VL_attention_linear_output_loss: 1.9465 - VH_attention_linear_output_loss: 2.2178 - VL_attention_linear_output_acc: 0.4061 - VH_attention_linear_output_acc: 0.3061 - val_loss: 4.3060 - val_VL_attention_linear_output_loss: 2.0907 - val_VH_attention_linear_output_loss: 2.2153 - val_VL_attention_linear_output_acc: 0.3268 - val_VH_attention_linear_output_acc: 0.3041\n",
      "Epoch 261/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1702 - VL_attention_linear_output_loss: 1.9533 - VH_attention_linear_output_loss: 2.2170 - VL_attention_linear_output_acc: 0.4023 - VH_attention_linear_output_acc: 0.3065 - val_loss: 4.1996 - val_VL_attention_linear_output_loss: 1.9883 - val_VH_attention_linear_output_loss: 2.2113 - val_VL_attention_linear_output_acc: 0.3855 - val_VH_attention_linear_output_acc: 0.3140\n",
      "Epoch 262/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1616 - VL_attention_linear_output_loss: 1.9459 - VH_attention_linear_output_loss: 2.2157 - VL_attention_linear_output_acc: 0.4087 - VH_attention_linear_output_acc: 0.3078 - val_loss: 4.2207 - val_VL_attention_linear_output_loss: 1.9792 - val_VH_attention_linear_output_loss: 2.2416 - val_VL_attention_linear_output_acc: 0.3974 - val_VH_attention_linear_output_acc: 0.2940\n",
      "Epoch 263/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1639 - VL_attention_linear_output_loss: 1.9441 - VH_attention_linear_output_loss: 2.2198 - VL_attention_linear_output_acc: 0.4070 - VH_attention_linear_output_acc: 0.3042 - val_loss: 4.1691 - val_VL_attention_linear_output_loss: 1.9503 - val_VH_attention_linear_output_loss: 2.2187 - val_VL_attention_linear_output_acc: 0.4021 - val_VH_attention_linear_output_acc: 0.3028\n",
      "Epoch 264/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1468 - VL_attention_linear_output_loss: 1.9322 - VH_attention_linear_output_loss: 2.2145 - VL_attention_linear_output_acc: 0.4133 - VH_attention_linear_output_acc: 0.3078 - val_loss: 4.1461 - val_VL_attention_linear_output_loss: 1.9343 - val_VH_attention_linear_output_loss: 2.2118 - val_VL_attention_linear_output_acc: 0.4072 - val_VH_attention_linear_output_acc: 0.3135\n",
      "Epoch 265/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1603 - VL_attention_linear_output_loss: 1.9410 - VH_attention_linear_output_loss: 2.2193 - VL_attention_linear_output_acc: 0.4086 - VH_attention_linear_output_acc: 0.3037 - val_loss: 4.1697 - val_VL_attention_linear_output_loss: 1.9457 - val_VH_attention_linear_output_loss: 2.2240 - val_VL_attention_linear_output_acc: 0.4030 - val_VH_attention_linear_output_acc: 0.2922\n",
      "Epoch 266/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1778 - VL_attention_linear_output_loss: 1.9615 - VH_attention_linear_output_loss: 2.2164 - VL_attention_linear_output_acc: 0.3986 - VH_attention_linear_output_acc: 0.3061 - val_loss: 4.1767 - val_VL_attention_linear_output_loss: 1.9656 - val_VH_attention_linear_output_loss: 2.2111 - val_VL_attention_linear_output_acc: 0.3920 - val_VH_attention_linear_output_acc: 0.3078\n",
      "Epoch 267/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1513 - VL_attention_linear_output_loss: 1.9374 - VH_attention_linear_output_loss: 2.2139 - VL_attention_linear_output_acc: 0.4104 - VH_attention_linear_output_acc: 0.3077 - val_loss: 4.1463 - val_VL_attention_linear_output_loss: 1.9352 - val_VH_attention_linear_output_loss: 2.2111 - val_VL_attention_linear_output_acc: 0.4112 - val_VH_attention_linear_output_acc: 0.3066\n",
      "Epoch 268/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1624 - VL_attention_linear_output_loss: 1.9465 - VH_attention_linear_output_loss: 2.2159 - VL_attention_linear_output_acc: 0.4055 - VH_attention_linear_output_acc: 0.3058 - val_loss: 4.1498 - val_VL_attention_linear_output_loss: 1.9398 - val_VH_attention_linear_output_loss: 2.2100 - val_VL_attention_linear_output_acc: 0.4053 - val_VH_attention_linear_output_acc: 0.3143\n",
      "Epoch 269/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1461 - VL_attention_linear_output_loss: 1.9347 - VH_attention_linear_output_loss: 2.2114 - VL_attention_linear_output_acc: 0.4109 - VH_attention_linear_output_acc: 0.3101 - val_loss: 4.1880 - val_VL_attention_linear_output_loss: 1.9298 - val_VH_attention_linear_output_loss: 2.2582 - val_VL_attention_linear_output_acc: 0.4151 - val_VH_attention_linear_output_acc: 0.2819\n",
      "Epoch 270/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1629 - VL_attention_linear_output_loss: 1.9471 - VH_attention_linear_output_loss: 2.2158 - VL_attention_linear_output_acc: 0.4046 - VH_attention_linear_output_acc: 0.3061 - val_loss: 4.1351 - val_VL_attention_linear_output_loss: 1.9270 - val_VH_attention_linear_output_loss: 2.2081 - val_VL_attention_linear_output_acc: 0.4162 - val_VH_attention_linear_output_acc: 0.3084\n",
      "Epoch 271/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1411 - VL_attention_linear_output_loss: 1.9322 - VH_attention_linear_output_loss: 2.2089 - VL_attention_linear_output_acc: 0.4120 - VH_attention_linear_output_acc: 0.3115 - val_loss: 4.1324 - val_VL_attention_linear_output_loss: 1.9257 - val_VH_attention_linear_output_loss: 2.2067 - val_VL_attention_linear_output_acc: 0.4159 - val_VH_attention_linear_output_acc: 0.3139\n",
      "Epoch 272/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1847 - VL_attention_linear_output_loss: 1.9688 - VH_attention_linear_output_loss: 2.2159 - VL_attention_linear_output_acc: 0.3938 - VH_attention_linear_output_acc: 0.3055 - val_loss: 4.2368 - val_VL_attention_linear_output_loss: 2.0252 - val_VH_attention_linear_output_loss: 2.2117 - val_VL_attention_linear_output_acc: 0.3701 - val_VH_attention_linear_output_acc: 0.3081\n",
      "Epoch 273/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1430 - VL_attention_linear_output_loss: 1.9334 - VH_attention_linear_output_loss: 2.2095 - VL_attention_linear_output_acc: 0.4112 - VH_attention_linear_output_acc: 0.3097 - val_loss: 4.1321 - val_VL_attention_linear_output_loss: 1.9235 - val_VH_attention_linear_output_loss: 2.2087 - val_VL_attention_linear_output_acc: 0.4182 - val_VH_attention_linear_output_acc: 0.3102\n",
      "Epoch 274/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1434 - VL_attention_linear_output_loss: 1.9311 - VH_attention_linear_output_loss: 2.2123 - VL_attention_linear_output_acc: 0.4121 - VH_attention_linear_output_acc: 0.3078 - val_loss: 4.1904 - val_VL_attention_linear_output_loss: 1.9742 - val_VH_attention_linear_output_loss: 2.2162 - val_VL_attention_linear_output_acc: 0.3958 - val_VH_attention_linear_output_acc: 0.3083\n",
      "Epoch 275/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1673 - VL_attention_linear_output_loss: 1.9558 - VH_attention_linear_output_loss: 2.2115 - VL_attention_linear_output_acc: 0.3997 - VH_attention_linear_output_acc: 0.3088 - val_loss: 4.2254 - val_VL_attention_linear_output_loss: 2.0220 - val_VH_attention_linear_output_loss: 2.2034 - val_VL_attention_linear_output_acc: 0.3763 - val_VH_attention_linear_output_acc: 0.3150\n",
      "Epoch 276/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1494 - VL_attention_linear_output_loss: 1.9394 - VH_attention_linear_output_loss: 2.2100 - VL_attention_linear_output_acc: 0.4084 - VH_attention_linear_output_acc: 0.3096 - val_loss: 4.1592 - val_VL_attention_linear_output_loss: 1.9472 - val_VH_attention_linear_output_loss: 2.2120 - val_VL_attention_linear_output_acc: 0.4026 - val_VH_attention_linear_output_acc: 0.3031\n",
      "Epoch 277/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1397 - VL_attention_linear_output_loss: 1.9321 - VH_attention_linear_output_loss: 2.2075 - VL_attention_linear_output_acc: 0.4126 - VH_attention_linear_output_acc: 0.3114 - val_loss: 4.1451 - val_VL_attention_linear_output_loss: 1.9329 - val_VH_attention_linear_output_loss: 2.2122 - val_VL_attention_linear_output_acc: 0.4171 - val_VH_attention_linear_output_acc: 0.3116\n",
      "Epoch 278/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1504 - VL_attention_linear_output_loss: 1.9411 - VH_attention_linear_output_loss: 2.2093 - VL_attention_linear_output_acc: 0.4071 - VH_attention_linear_output_acc: 0.3092 - val_loss: 4.1483 - val_VL_attention_linear_output_loss: 1.9288 - val_VH_attention_linear_output_loss: 2.2195 - val_VL_attention_linear_output_acc: 0.4115 - val_VH_attention_linear_output_acc: 0.2966\n",
      "Epoch 279/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1422 - VL_attention_linear_output_loss: 1.9370 - VH_attention_linear_output_loss: 2.2053 - VL_attention_linear_output_acc: 0.4089 - VH_attention_linear_output_acc: 0.3122 - val_loss: 4.1741 - val_VL_attention_linear_output_loss: 1.9632 - val_VH_attention_linear_output_loss: 2.2109 - val_VL_attention_linear_output_acc: 0.4072 - val_VH_attention_linear_output_acc: 0.3121\n",
      "Epoch 280/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1415 - VL_attention_linear_output_loss: 1.9330 - VH_attention_linear_output_loss: 2.2085 - VL_attention_linear_output_acc: 0.4106 - VH_attention_linear_output_acc: 0.3093 - val_loss: 4.1456 - val_VL_attention_linear_output_loss: 1.9235 - val_VH_attention_linear_output_loss: 2.2222 - val_VL_attention_linear_output_acc: 0.4159 - val_VH_attention_linear_output_acc: 0.2949\n",
      "Epoch 281/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1383 - VL_attention_linear_output_loss: 1.9372 - VH_attention_linear_output_loss: 2.2010 - VL_attention_linear_output_acc: 0.4080 - VH_attention_linear_output_acc: 0.3146 - val_loss: 4.1344 - val_VL_attention_linear_output_loss: 1.9334 - val_VH_attention_linear_output_loss: 2.2010 - val_VL_attention_linear_output_acc: 0.4066 - val_VH_attention_linear_output_acc: 0.3148\n",
      "Epoch 282/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1414 - VL_attention_linear_output_loss: 1.9338 - VH_attention_linear_output_loss: 2.2076 - VL_attention_linear_output_acc: 0.4098 - VH_attention_linear_output_acc: 0.3104 - val_loss: 4.1460 - val_VL_attention_linear_output_loss: 1.9408 - val_VH_attention_linear_output_loss: 2.2051 - val_VL_attention_linear_output_acc: 0.4012 - val_VH_attention_linear_output_acc: 0.3118\n",
      "Epoch 283/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1552 - VL_attention_linear_output_loss: 1.9489 - VH_attention_linear_output_loss: 2.2063 - VL_attention_linear_output_acc: 0.4030 - VH_attention_linear_output_acc: 0.3100 - val_loss: 4.1406 - val_VL_attention_linear_output_loss: 1.9312 - val_VH_attention_linear_output_loss: 2.2093 - val_VL_attention_linear_output_acc: 0.4164 - val_VH_attention_linear_output_acc: 0.3115\n",
      "Epoch 284/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1392 - VL_attention_linear_output_loss: 1.9378 - VH_attention_linear_output_loss: 2.2014 - VL_attention_linear_output_acc: 0.4085 - VH_attention_linear_output_acc: 0.3150 - val_loss: 4.2136 - val_VL_attention_linear_output_loss: 2.0102 - val_VH_attention_linear_output_loss: 2.2034 - val_VL_attention_linear_output_acc: 0.3586 - val_VH_attention_linear_output_acc: 0.3113\n",
      "Epoch 285/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1500 - VL_attention_linear_output_loss: 1.9453 - VH_attention_linear_output_loss: 2.2047 - VL_attention_linear_output_acc: 0.4045 - VH_attention_linear_output_acc: 0.3119 - val_loss: 4.1457 - val_VL_attention_linear_output_loss: 1.9373 - val_VH_attention_linear_output_loss: 2.2084 - val_VL_attention_linear_output_acc: 0.4022 - val_VH_attention_linear_output_acc: 0.3089\n",
      "Epoch 286/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1414 - VL_attention_linear_output_loss: 1.9358 - VH_attention_linear_output_loss: 2.2056 - VL_attention_linear_output_acc: 0.4088 - VH_attention_linear_output_acc: 0.3103 - val_loss: 4.1552 - val_VL_attention_linear_output_loss: 1.9603 - val_VH_attention_linear_output_loss: 2.1949 - val_VL_attention_linear_output_acc: 0.4103 - val_VH_attention_linear_output_acc: 0.3202\n",
      "Epoch 287/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1390 - VL_attention_linear_output_loss: 1.9363 - VH_attention_linear_output_loss: 2.2027 - VL_attention_linear_output_acc: 0.4091 - VH_attention_linear_output_acc: 0.3130 - val_loss: 4.1253 - val_VL_attention_linear_output_loss: 1.9195 - val_VH_attention_linear_output_loss: 2.2058 - val_VL_attention_linear_output_acc: 0.4156 - val_VH_attention_linear_output_acc: 0.3161\n",
      "Epoch 288/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1272 - VL_attention_linear_output_loss: 1.9247 - VH_attention_linear_output_loss: 2.2024 - VL_attention_linear_output_acc: 0.4142 - VH_attention_linear_output_acc: 0.3127 - val_loss: 4.1316 - val_VL_attention_linear_output_loss: 1.9238 - val_VH_attention_linear_output_loss: 2.2078 - val_VL_attention_linear_output_acc: 0.4143 - val_VH_attention_linear_output_acc: 0.3021\n",
      "Epoch 289/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1275 - VL_attention_linear_output_loss: 1.9289 - VH_attention_linear_output_loss: 2.1987 - VL_attention_linear_output_acc: 0.4137 - VH_attention_linear_output_acc: 0.3159 - val_loss: 4.1459 - val_VL_attention_linear_output_loss: 1.9247 - val_VH_attention_linear_output_loss: 2.2212 - val_VL_attention_linear_output_acc: 0.4082 - val_VH_attention_linear_output_acc: 0.3009\n",
      "Epoch 290/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1257 - VL_attention_linear_output_loss: 1.9257 - VH_attention_linear_output_loss: 2.2000 - VL_attention_linear_output_acc: 0.4133 - VH_attention_linear_output_acc: 0.3146 - val_loss: 4.1898 - val_VL_attention_linear_output_loss: 1.9847 - val_VH_attention_linear_output_loss: 2.2051 - val_VL_attention_linear_output_acc: 0.3793 - val_VH_attention_linear_output_acc: 0.3190\n",
      "Epoch 291/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1325 - VL_attention_linear_output_loss: 1.9328 - VH_attention_linear_output_loss: 2.1996 - VL_attention_linear_output_acc: 0.4105 - VH_attention_linear_output_acc: 0.3150 - val_loss: 4.1740 - val_VL_attention_linear_output_loss: 1.9537 - val_VH_attention_linear_output_loss: 2.2204 - val_VL_attention_linear_output_acc: 0.4018 - val_VH_attention_linear_output_acc: 0.2999\n",
      "Epoch 292/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1507 - VL_attention_linear_output_loss: 1.9474 - VH_attention_linear_output_loss: 2.2033 - VL_attention_linear_output_acc: 0.4029 - VH_attention_linear_output_acc: 0.3116 - val_loss: 4.1453 - val_VL_attention_linear_output_loss: 1.9237 - val_VH_attention_linear_output_loss: 2.2216 - val_VL_attention_linear_output_acc: 0.4140 - val_VH_attention_linear_output_acc: 0.3018\n",
      "Epoch 293/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1215 - VL_attention_linear_output_loss: 1.9213 - VH_attention_linear_output_loss: 2.2002 - VL_attention_linear_output_acc: 0.4168 - VH_attention_linear_output_acc: 0.3137 - val_loss: 4.1451 - val_VL_attention_linear_output_loss: 1.9185 - val_VH_attention_linear_output_loss: 2.2266 - val_VL_attention_linear_output_acc: 0.4192 - val_VH_attention_linear_output_acc: 0.2983\n",
      "Epoch 294/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1345 - VL_attention_linear_output_loss: 1.9361 - VH_attention_linear_output_loss: 2.1984 - VL_attention_linear_output_acc: 0.4085 - VH_attention_linear_output_acc: 0.3155 - val_loss: 4.1455 - val_VL_attention_linear_output_loss: 1.9407 - val_VH_attention_linear_output_loss: 2.2048 - val_VL_attention_linear_output_acc: 0.4060 - val_VH_attention_linear_output_acc: 0.3027\n",
      "Epoch 295/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1354 - VL_attention_linear_output_loss: 1.9361 - VH_attention_linear_output_loss: 2.1993 - VL_attention_linear_output_acc: 0.4092 - VH_attention_linear_output_acc: 0.3149 - val_loss: 4.1071 - val_VL_attention_linear_output_loss: 1.9165 - val_VH_attention_linear_output_loss: 2.1906 - val_VL_attention_linear_output_acc: 0.4230 - val_VH_attention_linear_output_acc: 0.3197\n",
      "Epoch 296/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1160 - VL_attention_linear_output_loss: 1.9216 - VH_attention_linear_output_loss: 2.1944 - VL_attention_linear_output_acc: 0.4152 - VH_attention_linear_output_acc: 0.3172 - val_loss: 4.1168 - val_VL_attention_linear_output_loss: 1.9249 - val_VH_attention_linear_output_loss: 2.1920 - val_VL_attention_linear_output_acc: 0.4125 - val_VH_attention_linear_output_acc: 0.3184\n",
      "Epoch 297/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1214 - VL_attention_linear_output_loss: 1.9266 - VH_attention_linear_output_loss: 2.1948 - VL_attention_linear_output_acc: 0.4134 - VH_attention_linear_output_acc: 0.3168 - val_loss: 4.1404 - val_VL_attention_linear_output_loss: 1.9189 - val_VH_attention_linear_output_loss: 2.2215 - val_VL_attention_linear_output_acc: 0.4191 - val_VH_attention_linear_output_acc: 0.2883\n",
      "Epoch 298/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1305 - VL_attention_linear_output_loss: 1.9327 - VH_attention_linear_output_loss: 2.1978 - VL_attention_linear_output_acc: 0.4115 - VH_attention_linear_output_acc: 0.3135 - val_loss: 4.1314 - val_VL_attention_linear_output_loss: 1.9211 - val_VH_attention_linear_output_loss: 2.2103 - val_VL_attention_linear_output_acc: 0.4155 - val_VH_attention_linear_output_acc: 0.3050\n",
      "Epoch 299/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1410 - VL_attention_linear_output_loss: 1.9339 - VH_attention_linear_output_loss: 2.2071 - VL_attention_linear_output_acc: 0.4109 - VH_attention_linear_output_acc: 0.3162 - val_loss: 4.1815 - val_VL_attention_linear_output_loss: 1.9483 - val_VH_attention_linear_output_loss: 2.2332 - val_VL_attention_linear_output_acc: 0.3999 - val_VH_attention_linear_output_acc: 0.2989\n",
      "Epoch 300/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1519 - VL_attention_linear_output_loss: 1.9285 - VH_attention_linear_output_loss: 2.2235 - VL_attention_linear_output_acc: 0.4135 - VH_attention_linear_output_acc: 0.3123 - val_loss: 4.1179 - val_VL_attention_linear_output_loss: 1.9175 - val_VH_attention_linear_output_loss: 2.2004 - val_VL_attention_linear_output_acc: 0.4144 - val_VH_attention_linear_output_acc: 0.3165\n",
      "Epoch 301/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1256 - VL_attention_linear_output_loss: 1.9322 - VH_attention_linear_output_loss: 2.1935 - VL_attention_linear_output_acc: 0.4119 - VH_attention_linear_output_acc: 0.3179 - val_loss: 4.1091 - val_VL_attention_linear_output_loss: 1.9196 - val_VH_attention_linear_output_loss: 2.1895 - val_VL_attention_linear_output_acc: 0.4134 - val_VH_attention_linear_output_acc: 0.3212\n",
      "Epoch 302/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1028 - VL_attention_linear_output_loss: 1.9146 - VH_attention_linear_output_loss: 2.1881 - VL_attention_linear_output_acc: 0.4198 - VH_attention_linear_output_acc: 0.3210 - val_loss: 4.1275 - val_VL_attention_linear_output_loss: 1.9398 - val_VH_attention_linear_output_loss: 2.1877 - val_VL_attention_linear_output_acc: 0.4010 - val_VH_attention_linear_output_acc: 0.3202\n",
      "Epoch 303/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1265 - VL_attention_linear_output_loss: 1.9349 - VH_attention_linear_output_loss: 2.1916 - VL_attention_linear_output_acc: 0.4096 - VH_attention_linear_output_acc: 0.3170 - val_loss: 4.1083 - val_VL_attention_linear_output_loss: 1.9156 - val_VH_attention_linear_output_loss: 2.1927 - val_VL_attention_linear_output_acc: 0.4199 - val_VH_attention_linear_output_acc: 0.3190\n",
      "Epoch 304/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1316 - VL_attention_linear_output_loss: 1.9428 - VH_attention_linear_output_loss: 2.1888 - VL_attention_linear_output_acc: 0.4054 - VH_attention_linear_output_acc: 0.3188 - val_loss: 4.1579 - val_VL_attention_linear_output_loss: 1.9146 - val_VH_attention_linear_output_loss: 2.2433 - val_VL_attention_linear_output_acc: 0.4171 - val_VH_attention_linear_output_acc: 0.2802\n",
      "Epoch 305/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1143 - VL_attention_linear_output_loss: 1.9230 - VH_attention_linear_output_loss: 2.1913 - VL_attention_linear_output_acc: 0.4159 - VH_attention_linear_output_acc: 0.3172 - val_loss: 4.1120 - val_VL_attention_linear_output_loss: 1.9231 - val_VH_attention_linear_output_loss: 2.1889 - val_VL_attention_linear_output_acc: 0.4163 - val_VH_attention_linear_output_acc: 0.3181\n",
      "Epoch 306/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1071 - VL_attention_linear_output_loss: 1.9199 - VH_attention_linear_output_loss: 2.1872 - VL_attention_linear_output_acc: 0.4171 - VH_attention_linear_output_acc: 0.3207 - val_loss: 4.1141 - val_VL_attention_linear_output_loss: 1.9201 - val_VH_attention_linear_output_loss: 2.1940 - val_VL_attention_linear_output_acc: 0.4158 - val_VH_attention_linear_output_acc: 0.3130\n",
      "Epoch 307/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1356 - VL_attention_linear_output_loss: 1.9457 - VH_attention_linear_output_loss: 2.1899 - VL_attention_linear_output_acc: 0.4048 - VH_attention_linear_output_acc: 0.3187 - val_loss: 4.1098 - val_VL_attention_linear_output_loss: 1.9240 - val_VH_attention_linear_output_loss: 2.1858 - val_VL_attention_linear_output_acc: 0.4217 - val_VH_attention_linear_output_acc: 0.3243\n",
      "Epoch 308/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1095 - VL_attention_linear_output_loss: 1.9236 - VH_attention_linear_output_loss: 2.1858 - VL_attention_linear_output_acc: 0.4159 - VH_attention_linear_output_acc: 0.3218 - val_loss: 4.1053 - val_VL_attention_linear_output_loss: 1.9199 - val_VH_attention_linear_output_loss: 2.1853 - val_VL_attention_linear_output_acc: 0.4275 - val_VH_attention_linear_output_acc: 0.3255\n",
      "Epoch 309/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1354 - VL_attention_linear_output_loss: 1.9419 - VH_attention_linear_output_loss: 2.1935 - VL_attention_linear_output_acc: 0.4080 - VH_attention_linear_output_acc: 0.3179 - val_loss: 4.1048 - val_VL_attention_linear_output_loss: 1.9163 - val_VH_attention_linear_output_loss: 2.1885 - val_VL_attention_linear_output_acc: 0.4158 - val_VH_attention_linear_output_acc: 0.3193\n",
      "Epoch 310/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1105 - VL_attention_linear_output_loss: 1.9197 - VH_attention_linear_output_loss: 2.1908 - VL_attention_linear_output_acc: 0.4177 - VH_attention_linear_output_acc: 0.3195 - val_loss: 4.1020 - val_VL_attention_linear_output_loss: 1.9195 - val_VH_attention_linear_output_loss: 2.1826 - val_VL_attention_linear_output_acc: 0.4198 - val_VH_attention_linear_output_acc: 0.3265\n",
      "Epoch 311/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1053 - VL_attention_linear_output_loss: 1.9176 - VH_attention_linear_output_loss: 2.1877 - VL_attention_linear_output_acc: 0.4190 - VH_attention_linear_output_acc: 0.3209 - val_loss: 4.1081 - val_VL_attention_linear_output_loss: 1.9117 - val_VH_attention_linear_output_loss: 2.1964 - val_VL_attention_linear_output_acc: 0.4232 - val_VH_attention_linear_output_acc: 0.3136\n",
      "Epoch 312/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1061 - VL_attention_linear_output_loss: 1.9217 - VH_attention_linear_output_loss: 2.1844 - VL_attention_linear_output_acc: 0.4168 - VH_attention_linear_output_acc: 0.3211 - val_loss: 4.1209 - val_VL_attention_linear_output_loss: 1.9410 - val_VH_attention_linear_output_loss: 2.1800 - val_VL_attention_linear_output_acc: 0.4015 - val_VH_attention_linear_output_acc: 0.3254\n",
      "Epoch 313/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1101 - VL_attention_linear_output_loss: 1.9243 - VH_attention_linear_output_loss: 2.1858 - VL_attention_linear_output_acc: 0.4168 - VH_attention_linear_output_acc: 0.3196 - val_loss: 4.0994 - val_VL_attention_linear_output_loss: 1.9170 - val_VH_attention_linear_output_loss: 2.1824 - val_VL_attention_linear_output_acc: 0.4216 - val_VH_attention_linear_output_acc: 0.3218\n",
      "Epoch 314/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1033 - VL_attention_linear_output_loss: 1.9199 - VH_attention_linear_output_loss: 2.1835 - VL_attention_linear_output_acc: 0.4180 - VH_attention_linear_output_acc: 0.3215 - val_loss: 4.1149 - val_VL_attention_linear_output_loss: 1.9260 - val_VH_attention_linear_output_loss: 2.1889 - val_VL_attention_linear_output_acc: 0.4121 - val_VH_attention_linear_output_acc: 0.3178\n",
      "Epoch 315/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1118 - VL_attention_linear_output_loss: 1.9277 - VH_attention_linear_output_loss: 2.1841 - VL_attention_linear_output_acc: 0.4153 - VH_attention_linear_output_acc: 0.3211 - val_loss: 4.1078 - val_VL_attention_linear_output_loss: 1.9259 - val_VH_attention_linear_output_loss: 2.1819 - val_VL_attention_linear_output_acc: 0.4200 - val_VH_attention_linear_output_acc: 0.3254\n",
      "Epoch 316/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1091 - VL_attention_linear_output_loss: 1.9247 - VH_attention_linear_output_loss: 2.1844 - VL_attention_linear_output_acc: 0.4162 - VH_attention_linear_output_acc: 0.3222 - val_loss: 4.1021 - val_VL_attention_linear_output_loss: 1.9235 - val_VH_attention_linear_output_loss: 2.1786 - val_VL_attention_linear_output_acc: 0.4247 - val_VH_attention_linear_output_acc: 0.3242\n",
      "Epoch 317/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1066 - VL_attention_linear_output_loss: 1.9198 - VH_attention_linear_output_loss: 2.1868 - VL_attention_linear_output_acc: 0.4185 - VH_attention_linear_output_acc: 0.3184 - val_loss: 4.1199 - val_VL_attention_linear_output_loss: 1.9345 - val_VH_attention_linear_output_loss: 2.1854 - val_VL_attention_linear_output_acc: 0.4136 - val_VH_attention_linear_output_acc: 0.3166\n",
      "Epoch 318/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1142 - VL_attention_linear_output_loss: 1.9283 - VH_attention_linear_output_loss: 2.1859 - VL_attention_linear_output_acc: 0.4144 - VH_attention_linear_output_acc: 0.3190 - val_loss: 4.0997 - val_VL_attention_linear_output_loss: 1.9209 - val_VH_attention_linear_output_loss: 2.1788 - val_VL_attention_linear_output_acc: 0.4172 - val_VH_attention_linear_output_acc: 0.3216\n",
      "Epoch 319/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0976 - VL_attention_linear_output_loss: 1.9123 - VH_attention_linear_output_loss: 2.1853 - VL_attention_linear_output_acc: 0.4227 - VH_attention_linear_output_acc: 0.3194 - val_loss: 4.1035 - val_VL_attention_linear_output_loss: 1.9246 - val_VH_attention_linear_output_loss: 2.1788 - val_VL_attention_linear_output_acc: 0.4113 - val_VH_attention_linear_output_acc: 0.3229\n",
      "Epoch 320/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1147 - VL_attention_linear_output_loss: 1.9288 - VH_attention_linear_output_loss: 2.1859 - VL_attention_linear_output_acc: 0.4156 - VH_attention_linear_output_acc: 0.3185 - val_loss: 4.0930 - val_VL_attention_linear_output_loss: 1.9133 - val_VH_attention_linear_output_loss: 2.1796 - val_VL_attention_linear_output_acc: 0.4193 - val_VH_attention_linear_output_acc: 0.3212\n",
      "Epoch 321/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0946 - VL_attention_linear_output_loss: 1.9141 - VH_attention_linear_output_loss: 2.1804 - VL_attention_linear_output_acc: 0.4220 - VH_attention_linear_output_acc: 0.3226 - val_loss: 4.3660 - val_VL_attention_linear_output_loss: 2.1488 - val_VH_attention_linear_output_loss: 2.2172 - val_VL_attention_linear_output_acc: 0.3206 - val_VH_attention_linear_output_acc: 0.2966\n",
      "Epoch 322/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1125 - VL_attention_linear_output_loss: 1.9242 - VH_attention_linear_output_loss: 2.1883 - VL_attention_linear_output_acc: 0.4167 - VH_attention_linear_output_acc: 0.3150 - val_loss: 4.1141 - val_VL_attention_linear_output_loss: 1.9218 - val_VH_attention_linear_output_loss: 2.1922 - val_VL_attention_linear_output_acc: 0.4158 - val_VH_attention_linear_output_acc: 0.3098\n",
      "Epoch 323/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0932 - VL_attention_linear_output_loss: 1.9102 - VH_attention_linear_output_loss: 2.1830 - VL_attention_linear_output_acc: 0.4235 - VH_attention_linear_output_acc: 0.3201 - val_loss: 4.1060 - val_VL_attention_linear_output_loss: 1.9117 - val_VH_attention_linear_output_loss: 2.1944 - val_VL_attention_linear_output_acc: 0.4284 - val_VH_attention_linear_output_acc: 0.3117\n",
      "Epoch 324/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1004 - VL_attention_linear_output_loss: 1.9157 - VH_attention_linear_output_loss: 2.1848 - VL_attention_linear_output_acc: 0.4223 - VH_attention_linear_output_acc: 0.3185 - val_loss: 4.0992 - val_VL_attention_linear_output_loss: 1.9186 - val_VH_attention_linear_output_loss: 2.1806 - val_VL_attention_linear_output_acc: 0.4228 - val_VH_attention_linear_output_acc: 0.3252\n",
      "Epoch 325/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1074 - VL_attention_linear_output_loss: 1.9239 - VH_attention_linear_output_loss: 2.1835 - VL_attention_linear_output_acc: 0.4172 - VH_attention_linear_output_acc: 0.3191 - val_loss: 4.0937 - val_VL_attention_linear_output_loss: 1.9075 - val_VH_attention_linear_output_loss: 2.1862 - val_VL_attention_linear_output_acc: 0.4223 - val_VH_attention_linear_output_acc: 0.3128\n",
      "Epoch 326/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1107 - VL_attention_linear_output_loss: 1.9298 - VH_attention_linear_output_loss: 2.1808 - VL_attention_linear_output_acc: 0.4150 - VH_attention_linear_output_acc: 0.3208 - val_loss: 4.1125 - val_VL_attention_linear_output_loss: 1.9308 - val_VH_attention_linear_output_loss: 2.1817 - val_VL_attention_linear_output_acc: 0.4203 - val_VH_attention_linear_output_acc: 0.3149\n",
      "Epoch 327/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0927 - VL_attention_linear_output_loss: 1.9135 - VH_attention_linear_output_loss: 2.1792 - VL_attention_linear_output_acc: 0.4232 - VH_attention_linear_output_acc: 0.3221 - val_loss: 4.0847 - val_VL_attention_linear_output_loss: 1.9085 - val_VH_attention_linear_output_loss: 2.1762 - val_VL_attention_linear_output_acc: 0.4276 - val_VH_attention_linear_output_acc: 0.3190\n",
      "Epoch 328/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0916 - VL_attention_linear_output_loss: 1.9093 - VH_attention_linear_output_loss: 2.1823 - VL_attention_linear_output_acc: 0.4249 - VH_attention_linear_output_acc: 0.3197 - val_loss: 4.0901 - val_VL_attention_linear_output_loss: 1.9123 - val_VH_attention_linear_output_loss: 2.1778 - val_VL_attention_linear_output_acc: 0.4231 - val_VH_attention_linear_output_acc: 0.3231\n",
      "Epoch 329/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1274 - VL_attention_linear_output_loss: 1.9404 - VH_attention_linear_output_loss: 2.1870 - VL_attention_linear_output_acc: 0.4095 - VH_attention_linear_output_acc: 0.3151 - val_loss: 4.0929 - val_VL_attention_linear_output_loss: 1.9103 - val_VH_attention_linear_output_loss: 2.1826 - val_VL_attention_linear_output_acc: 0.4239 - val_VH_attention_linear_output_acc: 0.3174\n",
      "Epoch 330/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0850 - VL_attention_linear_output_loss: 1.9062 - VH_attention_linear_output_loss: 2.1788 - VL_attention_linear_output_acc: 0.4257 - VH_attention_linear_output_acc: 0.3226 - val_loss: 4.1064 - val_VL_attention_linear_output_loss: 1.9278 - val_VH_attention_linear_output_loss: 2.1787 - val_VL_attention_linear_output_acc: 0.4261 - val_VH_attention_linear_output_acc: 0.3245\n",
      "Epoch 331/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1167 - VL_attention_linear_output_loss: 1.9344 - VH_attention_linear_output_loss: 2.1824 - VL_attention_linear_output_acc: 0.4127 - VH_attention_linear_output_acc: 0.3193 - val_loss: 4.1034 - val_VL_attention_linear_output_loss: 1.9147 - val_VH_attention_linear_output_loss: 2.1887 - val_VL_attention_linear_output_acc: 0.4222 - val_VH_attention_linear_output_acc: 0.3094\n",
      "Epoch 332/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0945 - VL_attention_linear_output_loss: 1.9123 - VH_attention_linear_output_loss: 2.1822 - VL_attention_linear_output_acc: 0.4242 - VH_attention_linear_output_acc: 0.3190 - val_loss: 4.0891 - val_VL_attention_linear_output_loss: 1.9059 - val_VH_attention_linear_output_loss: 2.1831 - val_VL_attention_linear_output_acc: 0.4300 - val_VH_attention_linear_output_acc: 0.3140\n",
      "Epoch 333/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1071 - VL_attention_linear_output_loss: 1.9221 - VH_attention_linear_output_loss: 2.1850 - VL_attention_linear_output_acc: 0.4197 - VH_attention_linear_output_acc: 0.3165 - val_loss: 4.1058 - val_VL_attention_linear_output_loss: 1.9324 - val_VH_attention_linear_output_loss: 2.1735 - val_VL_attention_linear_output_acc: 0.4258 - val_VH_attention_linear_output_acc: 0.3202\n",
      "Epoch 334/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1374 - VL_attention_linear_output_loss: 1.9367 - VH_attention_linear_output_loss: 2.2007 - VL_attention_linear_output_acc: 0.4109 - VH_attention_linear_output_acc: 0.3161 - val_loss: 4.1431 - val_VL_attention_linear_output_loss: 1.9202 - val_VH_attention_linear_output_loss: 2.2229 - val_VL_attention_linear_output_acc: 0.4242 - val_VH_attention_linear_output_acc: 0.3195\n",
      "Epoch 335/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1414 - VL_attention_linear_output_loss: 1.9257 - VH_attention_linear_output_loss: 2.2157 - VL_attention_linear_output_acc: 0.4177 - VH_attention_linear_output_acc: 0.3183 - val_loss: 4.1247 - val_VL_attention_linear_output_loss: 1.9189 - val_VH_attention_linear_output_loss: 2.2057 - val_VL_attention_linear_output_acc: 0.4278 - val_VH_attention_linear_output_acc: 0.3218\n",
      "Epoch 336/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1164 - VL_attention_linear_output_loss: 1.9146 - VH_attention_linear_output_loss: 2.2018 - VL_attention_linear_output_acc: 0.4224 - VH_attention_linear_output_acc: 0.3223 - val_loss: 4.1685 - val_VL_attention_linear_output_loss: 1.9753 - val_VH_attention_linear_output_loss: 2.1932 - val_VL_attention_linear_output_acc: 0.4059 - val_VH_attention_linear_output_acc: 0.3215\n",
      "Epoch 337/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1094 - VL_attention_linear_output_loss: 1.9124 - VH_attention_linear_output_loss: 2.1970 - VL_attention_linear_output_acc: 0.4241 - VH_attention_linear_output_acc: 0.3222 - val_loss: 4.0998 - val_VL_attention_linear_output_loss: 1.9114 - val_VH_attention_linear_output_loss: 2.1884 - val_VL_attention_linear_output_acc: 0.4291 - val_VH_attention_linear_output_acc: 0.3270\n",
      "Epoch 338/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1096 - VL_attention_linear_output_loss: 1.9149 - VH_attention_linear_output_loss: 2.1948 - VL_attention_linear_output_acc: 0.4230 - VH_attention_linear_output_acc: 0.3219 - val_loss: 4.0875 - val_VL_attention_linear_output_loss: 1.9026 - val_VH_attention_linear_output_loss: 2.1849 - val_VL_attention_linear_output_acc: 0.4320 - val_VH_attention_linear_output_acc: 0.3242\n",
      "Epoch 339/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1075 - VL_attention_linear_output_loss: 1.9157 - VH_attention_linear_output_loss: 2.1918 - VL_attention_linear_output_acc: 0.4224 - VH_attention_linear_output_acc: 0.3228 - val_loss: 4.1181 - val_VL_attention_linear_output_loss: 1.9131 - val_VH_attention_linear_output_loss: 2.2050 - val_VL_attention_linear_output_acc: 0.4254 - val_VH_attention_linear_output_acc: 0.3012\n",
      "Epoch 340/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0956 - VL_attention_linear_output_loss: 1.9056 - VH_attention_linear_output_loss: 2.1900 - VL_attention_linear_output_acc: 0.4278 - VH_attention_linear_output_acc: 0.3223 - val_loss: 4.0966 - val_VL_attention_linear_output_loss: 1.9080 - val_VH_attention_linear_output_loss: 2.1886 - val_VL_attention_linear_output_acc: 0.4321 - val_VH_attention_linear_output_acc: 0.3247\n",
      "Epoch 341/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1163 - VL_attention_linear_output_loss: 1.9254 - VH_attention_linear_output_loss: 2.1909 - VL_attention_linear_output_acc: 0.4170 - VH_attention_linear_output_acc: 0.3222 - val_loss: 4.0983 - val_VL_attention_linear_output_loss: 1.9166 - val_VH_attention_linear_output_loss: 2.1817 - val_VL_attention_linear_output_acc: 0.4227 - val_VH_attention_linear_output_acc: 0.3227\n",
      "Epoch 342/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1009 - VL_attention_linear_output_loss: 1.9085 - VH_attention_linear_output_loss: 2.1924 - VL_attention_linear_output_acc: 0.4261 - VH_attention_linear_output_acc: 0.3207 - val_loss: 4.1241 - val_VL_attention_linear_output_loss: 1.9236 - val_VH_attention_linear_output_loss: 2.2005 - val_VL_attention_linear_output_acc: 0.4167 - val_VH_attention_linear_output_acc: 0.3174\n",
      "Epoch 343/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0953 - VL_attention_linear_output_loss: 1.9062 - VH_attention_linear_output_loss: 2.1892 - VL_attention_linear_output_acc: 0.4284 - VH_attention_linear_output_acc: 0.3232 - val_loss: 4.1086 - val_VL_attention_linear_output_loss: 1.9052 - val_VH_attention_linear_output_loss: 2.2034 - val_VL_attention_linear_output_acc: 0.4304 - val_VH_attention_linear_output_acc: 0.3049\n",
      "Epoch 344/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1044 - VL_attention_linear_output_loss: 1.9138 - VH_attention_linear_output_loss: 2.1906 - VL_attention_linear_output_acc: 0.4248 - VH_attention_linear_output_acc: 0.3220 - val_loss: 4.0901 - val_VL_attention_linear_output_loss: 1.9082 - val_VH_attention_linear_output_loss: 2.1819 - val_VL_attention_linear_output_acc: 0.4330 - val_VH_attention_linear_output_acc: 0.3242\n",
      "Epoch 345/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1069 - VL_attention_linear_output_loss: 1.9182 - VH_attention_linear_output_loss: 2.1888 - VL_attention_linear_output_acc: 0.4227 - VH_attention_linear_output_acc: 0.3220 - val_loss: 4.1315 - val_VL_attention_linear_output_loss: 1.9416 - val_VH_attention_linear_output_loss: 2.1899 - val_VL_attention_linear_output_acc: 0.4024 - val_VH_attention_linear_output_acc: 0.3215\n",
      "Epoch 346/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1036 - VL_attention_linear_output_loss: 1.9168 - VH_attention_linear_output_loss: 2.1867 - VL_attention_linear_output_acc: 0.4223 - VH_attention_linear_output_acc: 0.3229 - val_loss: 4.1595 - val_VL_attention_linear_output_loss: 1.9682 - val_VH_attention_linear_output_loss: 2.1914 - val_VL_attention_linear_output_acc: 0.3962 - val_VH_attention_linear_output_acc: 0.3119\n",
      "Epoch 347/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0974 - VL_attention_linear_output_loss: 1.9104 - VH_attention_linear_output_loss: 2.1870 - VL_attention_linear_output_acc: 0.4254 - VH_attention_linear_output_acc: 0.3218 - val_loss: 4.0934 - val_VL_attention_linear_output_loss: 1.9074 - val_VH_attention_linear_output_loss: 2.1860 - val_VL_attention_linear_output_acc: 0.4243 - val_VH_attention_linear_output_acc: 0.3215\n",
      "Epoch 348/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1150 - VL_attention_linear_output_loss: 1.9226 - VH_attention_linear_output_loss: 2.1924 - VL_attention_linear_output_acc: 0.4194 - VH_attention_linear_output_acc: 0.3184 - val_loss: 4.0993 - val_VL_attention_linear_output_loss: 1.9224 - val_VH_attention_linear_output_loss: 2.1769 - val_VL_attention_linear_output_acc: 0.4254 - val_VH_attention_linear_output_acc: 0.3286\n",
      "Epoch 349/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1021 - VL_attention_linear_output_loss: 1.9170 - VH_attention_linear_output_loss: 2.1851 - VL_attention_linear_output_acc: 0.4233 - VH_attention_linear_output_acc: 0.3235 - val_loss: 4.0846 - val_VL_attention_linear_output_loss: 1.9080 - val_VH_attention_linear_output_loss: 2.1766 - val_VL_attention_linear_output_acc: 0.4352 - val_VH_attention_linear_output_acc: 0.3279\n",
      "Epoch 350/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0942 - VL_attention_linear_output_loss: 1.9089 - VH_attention_linear_output_loss: 2.1853 - VL_attention_linear_output_acc: 0.4263 - VH_attention_linear_output_acc: 0.3231 - val_loss: 4.0947 - val_VL_attention_linear_output_loss: 1.9114 - val_VH_attention_linear_output_loss: 2.1833 - val_VL_attention_linear_output_acc: 0.4252 - val_VH_attention_linear_output_acc: 0.3277\n",
      "Epoch 351/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1024 - VL_attention_linear_output_loss: 1.9146 - VH_attention_linear_output_loss: 2.1878 - VL_attention_linear_output_acc: 0.4246 - VH_attention_linear_output_acc: 0.3205 - val_loss: 4.0985 - val_VL_attention_linear_output_loss: 1.9187 - val_VH_attention_linear_output_loss: 2.1798 - val_VL_attention_linear_output_acc: 0.4169 - val_VH_attention_linear_output_acc: 0.3249\n",
      "Epoch 352/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0963 - VL_attention_linear_output_loss: 1.9087 - VH_attention_linear_output_loss: 2.1876 - VL_attention_linear_output_acc: 0.4281 - VH_attention_linear_output_acc: 0.3202 - val_loss: 4.1492 - val_VL_attention_linear_output_loss: 1.9485 - val_VH_attention_linear_output_loss: 2.2007 - val_VL_attention_linear_output_acc: 0.4026 - val_VH_attention_linear_output_acc: 0.3059\n",
      "Epoch 353/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0952 - VL_attention_linear_output_loss: 1.9103 - VH_attention_linear_output_loss: 2.1848 - VL_attention_linear_output_acc: 0.4258 - VH_attention_linear_output_acc: 0.3210 - val_loss: 4.0815 - val_VL_attention_linear_output_loss: 1.9062 - val_VH_attention_linear_output_loss: 2.1753 - val_VL_attention_linear_output_acc: 0.4334 - val_VH_attention_linear_output_acc: 0.3255\n",
      "Epoch 354/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0967 - VL_attention_linear_output_loss: 1.9140 - VH_attention_linear_output_loss: 2.1827 - VL_attention_linear_output_acc: 0.4254 - VH_attention_linear_output_acc: 0.3228 - val_loss: 4.1251 - val_VL_attention_linear_output_loss: 1.9331 - val_VH_attention_linear_output_loss: 2.1920 - val_VL_attention_linear_output_acc: 0.4203 - val_VH_attention_linear_output_acc: 0.3168\n",
      "Epoch 355/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1013 - VL_attention_linear_output_loss: 1.9174 - VH_attention_linear_output_loss: 2.1839 - VL_attention_linear_output_acc: 0.4235 - VH_attention_linear_output_acc: 0.3216 - val_loss: 4.0896 - val_VL_attention_linear_output_loss: 1.9000 - val_VH_attention_linear_output_loss: 2.1896 - val_VL_attention_linear_output_acc: 0.4304 - val_VH_attention_linear_output_acc: 0.3179\n",
      "Epoch 356/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0787 - VL_attention_linear_output_loss: 1.9005 - VH_attention_linear_output_loss: 2.1783 - VL_attention_linear_output_acc: 0.4303 - VH_attention_linear_output_acc: 0.3252 - val_loss: 4.1016 - val_VL_attention_linear_output_loss: 1.9235 - val_VH_attention_linear_output_loss: 2.1781 - val_VL_attention_linear_output_acc: 0.4255 - val_VH_attention_linear_output_acc: 0.3201\n",
      "Epoch 357/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0921 - VL_attention_linear_output_loss: 1.9080 - VH_attention_linear_output_loss: 2.1841 - VL_attention_linear_output_acc: 0.4284 - VH_attention_linear_output_acc: 0.3199 - val_loss: 4.1083 - val_VL_attention_linear_output_loss: 1.9350 - val_VH_attention_linear_output_loss: 2.1732 - val_VL_attention_linear_output_acc: 0.4230 - val_VH_attention_linear_output_acc: 0.3296\n",
      "Epoch 358/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0784 - VL_attention_linear_output_loss: 1.9013 - VH_attention_linear_output_loss: 2.1771 - VL_attention_linear_output_acc: 0.4307 - VH_attention_linear_output_acc: 0.3259 - val_loss: 4.0753 - val_VL_attention_linear_output_loss: 1.8998 - val_VH_attention_linear_output_loss: 2.1755 - val_VL_attention_linear_output_acc: 0.4382 - val_VH_attention_linear_output_acc: 0.3243\n",
      "Epoch 359/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0859 - VL_attention_linear_output_loss: 1.9042 - VH_attention_linear_output_loss: 2.1817 - VL_attention_linear_output_acc: 0.4301 - VH_attention_linear_output_acc: 0.3223 - val_loss: 4.0847 - val_VL_attention_linear_output_loss: 1.9090 - val_VH_attention_linear_output_loss: 2.1757 - val_VL_attention_linear_output_acc: 0.4357 - val_VH_attention_linear_output_acc: 0.3256\n",
      "Epoch 360/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0955 - VL_attention_linear_output_loss: 1.9161 - VH_attention_linear_output_loss: 2.1794 - VL_attention_linear_output_acc: 0.4238 - VH_attention_linear_output_acc: 0.3238 - val_loss: 4.0833 - val_VL_attention_linear_output_loss: 1.9045 - val_VH_attention_linear_output_loss: 2.1788 - val_VL_attention_linear_output_acc: 0.4404 - val_VH_attention_linear_output_acc: 0.3247\n",
      "Epoch 361/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0855 - VL_attention_linear_output_loss: 1.9009 - VH_attention_linear_output_loss: 2.1847 - VL_attention_linear_output_acc: 0.4316 - VH_attention_linear_output_acc: 0.3211 - val_loss: 4.0856 - val_VL_attention_linear_output_loss: 1.9004 - val_VH_attention_linear_output_loss: 2.1852 - val_VL_attention_linear_output_acc: 0.4377 - val_VH_attention_linear_output_acc: 0.3201\n",
      "Epoch 362/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0914 - VL_attention_linear_output_loss: 1.9073 - VH_attention_linear_output_loss: 2.1840 - VL_attention_linear_output_acc: 0.4282 - VH_attention_linear_output_acc: 0.3200 - val_loss: 4.0962 - val_VL_attention_linear_output_loss: 1.9002 - val_VH_attention_linear_output_loss: 2.1960 - val_VL_attention_linear_output_acc: 0.4337 - val_VH_attention_linear_output_acc: 0.3134\n",
      "Epoch 363/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0733 - VL_attention_linear_output_loss: 1.8980 - VH_attention_linear_output_loss: 2.1754 - VL_attention_linear_output_acc: 0.4333 - VH_attention_linear_output_acc: 0.3252 - val_loss: 4.1030 - val_VL_attention_linear_output_loss: 1.9288 - val_VH_attention_linear_output_loss: 2.1742 - val_VL_attention_linear_output_acc: 0.4174 - val_VH_attention_linear_output_acc: 0.3243\n",
      "Epoch 364/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0843 - VL_attention_linear_output_loss: 1.9032 - VH_attention_linear_output_loss: 2.1811 - VL_attention_linear_output_acc: 0.4308 - VH_attention_linear_output_acc: 0.3210 - val_loss: 4.0885 - val_VL_attention_linear_output_loss: 1.9017 - val_VH_attention_linear_output_loss: 2.1867 - val_VL_attention_linear_output_acc: 0.4393 - val_VH_attention_linear_output_acc: 0.3148\n",
      "Epoch 365/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0699 - VL_attention_linear_output_loss: 1.8965 - VH_attention_linear_output_loss: 2.1734 - VL_attention_linear_output_acc: 0.4344 - VH_attention_linear_output_acc: 0.3262 - val_loss: 4.0717 - val_VL_attention_linear_output_loss: 1.8956 - val_VH_attention_linear_output_loss: 2.1761 - val_VL_attention_linear_output_acc: 0.4340 - val_VH_attention_linear_output_acc: 0.3285\n",
      "Epoch 366/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0899 - VL_attention_linear_output_loss: 1.9136 - VH_attention_linear_output_loss: 2.1763 - VL_attention_linear_output_acc: 0.4248 - VH_attention_linear_output_acc: 0.3245 - val_loss: 4.0836 - val_VL_attention_linear_output_loss: 1.8978 - val_VH_attention_linear_output_loss: 2.1858 - val_VL_attention_linear_output_acc: 0.4322 - val_VH_attention_linear_output_acc: 0.3209\n",
      "Epoch 367/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0927 - VL_attention_linear_output_loss: 1.9151 - VH_attention_linear_output_loss: 2.1776 - VL_attention_linear_output_acc: 0.4238 - VH_attention_linear_output_acc: 0.3224 - val_loss: 4.0853 - val_VL_attention_linear_output_loss: 1.9048 - val_VH_attention_linear_output_loss: 2.1805 - val_VL_attention_linear_output_acc: 0.4275 - val_VH_attention_linear_output_acc: 0.3149\n",
      "Epoch 368/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0719 - VL_attention_linear_output_loss: 1.8973 - VH_attention_linear_output_loss: 2.1746 - VL_attention_linear_output_acc: 0.4333 - VH_attention_linear_output_acc: 0.3251 - val_loss: 4.0666 - val_VL_attention_linear_output_loss: 1.8932 - val_VH_attention_linear_output_loss: 2.1734 - val_VL_attention_linear_output_acc: 0.4324 - val_VH_attention_linear_output_acc: 0.3289\n",
      "Epoch 369/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0895 - VL_attention_linear_output_loss: 1.9083 - VH_attention_linear_output_loss: 2.1812 - VL_attention_linear_output_acc: 0.4286 - VH_attention_linear_output_acc: 0.3216 - val_loss: 4.0955 - val_VL_attention_linear_output_loss: 1.9017 - val_VH_attention_linear_output_loss: 2.1939 - val_VL_attention_linear_output_acc: 0.4267 - val_VH_attention_linear_output_acc: 0.3068\n",
      "Epoch 370/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0763 - VL_attention_linear_output_loss: 1.9013 - VH_attention_linear_output_loss: 2.1750 - VL_attention_linear_output_acc: 0.4310 - VH_attention_linear_output_acc: 0.3246 - val_loss: 4.0792 - val_VL_attention_linear_output_loss: 1.8997 - val_VH_attention_linear_output_loss: 2.1794 - val_VL_attention_linear_output_acc: 0.4345 - val_VH_attention_linear_output_acc: 0.3204\n",
      "Epoch 371/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0848 - VL_attention_linear_output_loss: 1.9061 - VH_attention_linear_output_loss: 2.1787 - VL_attention_linear_output_acc: 0.4289 - VH_attention_linear_output_acc: 0.3227 - val_loss: 4.1694 - val_VL_attention_linear_output_loss: 1.9834 - val_VH_attention_linear_output_loss: 2.1860 - val_VL_attention_linear_output_acc: 0.3940 - val_VH_attention_linear_output_acc: 0.3159\n",
      "Epoch 372/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1006 - VL_attention_linear_output_loss: 1.9198 - VH_attention_linear_output_loss: 2.1808 - VL_attention_linear_output_acc: 0.4220 - VH_attention_linear_output_acc: 0.3196 - val_loss: 4.0829 - val_VL_attention_linear_output_loss: 1.9132 - val_VH_attention_linear_output_loss: 2.1697 - val_VL_attention_linear_output_acc: 0.4230 - val_VH_attention_linear_output_acc: 0.3297\n",
      "Epoch 373/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0792 - VL_attention_linear_output_loss: 1.8997 - VH_attention_linear_output_loss: 2.1795 - VL_attention_linear_output_acc: 0.4311 - VH_attention_linear_output_acc: 0.3207 - val_loss: 4.1024 - val_VL_attention_linear_output_loss: 1.9268 - val_VH_attention_linear_output_loss: 2.1757 - val_VL_attention_linear_output_acc: 0.4260 - val_VH_attention_linear_output_acc: 0.3296\n",
      "Epoch 374/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0871 - VL_attention_linear_output_loss: 1.9120 - VH_attention_linear_output_loss: 2.1751 - VL_attention_linear_output_acc: 0.4266 - VH_attention_linear_output_acc: 0.3256 - val_loss: 4.0680 - val_VL_attention_linear_output_loss: 1.9024 - val_VH_attention_linear_output_loss: 2.1655 - val_VL_attention_linear_output_acc: 0.4327 - val_VH_attention_linear_output_acc: 0.3326\n",
      "Epoch 375/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0833 - VL_attention_linear_output_loss: 1.9132 - VH_attention_linear_output_loss: 2.1701 - VL_attention_linear_output_acc: 0.4251 - VH_attention_linear_output_acc: 0.3270 - val_loss: 4.0641 - val_VL_attention_linear_output_loss: 1.8910 - val_VH_attention_linear_output_loss: 2.1731 - val_VL_attention_linear_output_acc: 0.4389 - val_VH_attention_linear_output_acc: 0.3245\n",
      "Epoch 376/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0691 - VL_attention_linear_output_loss: 1.8939 - VH_attention_linear_output_loss: 2.1752 - VL_attention_linear_output_acc: 0.4353 - VH_attention_linear_output_acc: 0.3227 - val_loss: 4.0739 - val_VL_attention_linear_output_loss: 1.9035 - val_VH_attention_linear_output_loss: 2.1704 - val_VL_attention_linear_output_acc: 0.4427 - val_VH_attention_linear_output_acc: 0.3222\n",
      "Epoch 377/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0809 - VL_attention_linear_output_loss: 1.9070 - VH_attention_linear_output_loss: 2.1739 - VL_attention_linear_output_acc: 0.4284 - VH_attention_linear_output_acc: 0.3238 - val_loss: 4.0640 - val_VL_attention_linear_output_loss: 1.8916 - val_VH_attention_linear_output_loss: 2.1723 - val_VL_attention_linear_output_acc: 0.4442 - val_VH_attention_linear_output_acc: 0.3240\n",
      "Epoch 378/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0838 - VL_attention_linear_output_loss: 1.9092 - VH_attention_linear_output_loss: 2.1746 - VL_attention_linear_output_acc: 0.4275 - VH_attention_linear_output_acc: 0.3227 - val_loss: 4.1855 - val_VL_attention_linear_output_loss: 2.0166 - val_VH_attention_linear_output_loss: 2.1689 - val_VL_attention_linear_output_acc: 0.3624 - val_VH_attention_linear_output_acc: 0.3274\n",
      "Epoch 379/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0670 - VL_attention_linear_output_loss: 1.8982 - VH_attention_linear_output_loss: 2.1688 - VL_attention_linear_output_acc: 0.4333 - VH_attention_linear_output_acc: 0.3266 - val_loss: 4.0752 - val_VL_attention_linear_output_loss: 1.9043 - val_VH_attention_linear_output_loss: 2.1709 - val_VL_attention_linear_output_acc: 0.4306 - val_VH_attention_linear_output_acc: 0.3254\n",
      "Epoch 380/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0722 - VL_attention_linear_output_loss: 1.8976 - VH_attention_linear_output_loss: 2.1746 - VL_attention_linear_output_acc: 0.4345 - VH_attention_linear_output_acc: 0.3221 - val_loss: 4.0989 - val_VL_attention_linear_output_loss: 1.9032 - val_VH_attention_linear_output_loss: 2.1957 - val_VL_attention_linear_output_acc: 0.4389 - val_VH_attention_linear_output_acc: 0.3035\n",
      "Epoch 381/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0703 - VL_attention_linear_output_loss: 1.8990 - VH_attention_linear_output_loss: 2.1713 - VL_attention_linear_output_acc: 0.4333 - VH_attention_linear_output_acc: 0.3250 - val_loss: 4.0898 - val_VL_attention_linear_output_loss: 1.9063 - val_VH_attention_linear_output_loss: 2.1835 - val_VL_attention_linear_output_acc: 0.4278 - val_VH_attention_linear_output_acc: 0.3173\n",
      "Epoch 382/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0918 - VL_attention_linear_output_loss: 1.9146 - VH_attention_linear_output_loss: 2.1772 - VL_attention_linear_output_acc: 0.4261 - VH_attention_linear_output_acc: 0.3242 - val_loss: 4.0682 - val_VL_attention_linear_output_loss: 1.9023 - val_VH_attention_linear_output_loss: 2.1659 - val_VL_attention_linear_output_acc: 0.4382 - val_VH_attention_linear_output_acc: 0.3273\n",
      "Epoch 383/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0712 - VL_attention_linear_output_loss: 1.8972 - VH_attention_linear_output_loss: 2.1741 - VL_attention_linear_output_acc: 0.4331 - VH_attention_linear_output_acc: 0.3251 - val_loss: 4.0784 - val_VL_attention_linear_output_loss: 1.9114 - val_VH_attention_linear_output_loss: 2.1670 - val_VL_attention_linear_output_acc: 0.4382 - val_VH_attention_linear_output_acc: 0.3298\n",
      "Epoch 384/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0971 - VL_attention_linear_output_loss: 1.9204 - VH_attention_linear_output_loss: 2.1767 - VL_attention_linear_output_acc: 0.4206 - VH_attention_linear_output_acc: 0.3220 - val_loss: 4.0929 - val_VL_attention_linear_output_loss: 1.9130 - val_VH_attention_linear_output_loss: 2.1799 - val_VL_attention_linear_output_acc: 0.4357 - val_VH_attention_linear_output_acc: 0.3227\n",
      "Epoch 385/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0834 - VL_attention_linear_output_loss: 1.9074 - VH_attention_linear_output_loss: 2.1760 - VL_attention_linear_output_acc: 0.4279 - VH_attention_linear_output_acc: 0.3224 - val_loss: 4.0680 - val_VL_attention_linear_output_loss: 1.9047 - val_VH_attention_linear_output_loss: 2.1633 - val_VL_attention_linear_output_acc: 0.4368 - val_VH_attention_linear_output_acc: 0.3329\n",
      "Epoch 386/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0737 - VL_attention_linear_output_loss: 1.9028 - VH_attention_linear_output_loss: 2.1709 - VL_attention_linear_output_acc: 0.4316 - VH_attention_linear_output_acc: 0.3268 - val_loss: 4.1023 - val_VL_attention_linear_output_loss: 1.9242 - val_VH_attention_linear_output_loss: 2.1781 - val_VL_attention_linear_output_acc: 0.4243 - val_VH_attention_linear_output_acc: 0.3181\n",
      "Epoch 387/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0840 - VL_attention_linear_output_loss: 1.9067 - VH_attention_linear_output_loss: 2.1773 - VL_attention_linear_output_acc: 0.4283 - VH_attention_linear_output_acc: 0.3218 - val_loss: 4.0513 - val_VL_attention_linear_output_loss: 1.8892 - val_VH_attention_linear_output_loss: 2.1621 - val_VL_attention_linear_output_acc: 0.4398 - val_VH_attention_linear_output_acc: 0.3282\n",
      "Epoch 388/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0561 - VL_attention_linear_output_loss: 1.8847 - VH_attention_linear_output_loss: 2.1714 - VL_attention_linear_output_acc: 0.4400 - VH_attention_linear_output_acc: 0.3262 - val_loss: 4.0908 - val_VL_attention_linear_output_loss: 1.9134 - val_VH_attention_linear_output_loss: 2.1774 - val_VL_attention_linear_output_acc: 0.4303 - val_VH_attention_linear_output_acc: 0.3236\n",
      "Epoch 389/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0723 - VL_attention_linear_output_loss: 1.8980 - VH_attention_linear_output_loss: 2.1743 - VL_attention_linear_output_acc: 0.4330 - VH_attention_linear_output_acc: 0.3231 - val_loss: 4.0810 - val_VL_attention_linear_output_loss: 1.8980 - val_VH_attention_linear_output_loss: 2.1830 - val_VL_attention_linear_output_acc: 0.4355 - val_VH_attention_linear_output_acc: 0.3149\n",
      "Epoch 390/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0715 - VL_attention_linear_output_loss: 1.8991 - VH_attention_linear_output_loss: 2.1724 - VL_attention_linear_output_acc: 0.4320 - VH_attention_linear_output_acc: 0.3253 - val_loss: 4.0602 - val_VL_attention_linear_output_loss: 1.8949 - val_VH_attention_linear_output_loss: 2.1654 - val_VL_attention_linear_output_acc: 0.4373 - val_VH_attention_linear_output_acc: 0.3286\n",
      "Epoch 391/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0944 - VL_attention_linear_output_loss: 1.9209 - VH_attention_linear_output_loss: 2.1736 - VL_attention_linear_output_acc: 0.4206 - VH_attention_linear_output_acc: 0.3237 - val_loss: 4.1283 - val_VL_attention_linear_output_loss: 1.9270 - val_VH_attention_linear_output_loss: 2.2013 - val_VL_attention_linear_output_acc: 0.4131 - val_VH_attention_linear_output_acc: 0.3024\n",
      "Epoch 392/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0581 - VL_attention_linear_output_loss: 1.8875 - VH_attention_linear_output_loss: 2.1706 - VL_attention_linear_output_acc: 0.4387 - VH_attention_linear_output_acc: 0.3236 - val_loss: 4.0891 - val_VL_attention_linear_output_loss: 1.9213 - val_VH_attention_linear_output_loss: 2.1678 - val_VL_attention_linear_output_acc: 0.4253 - val_VH_attention_linear_output_acc: 0.3258\n",
      "Epoch 393/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0544 - VL_attention_linear_output_loss: 1.8889 - VH_attention_linear_output_loss: 2.1654 - VL_attention_linear_output_acc: 0.4368 - VH_attention_linear_output_acc: 0.3274 - val_loss: 4.0538 - val_VL_attention_linear_output_loss: 1.8884 - val_VH_attention_linear_output_loss: 2.1654 - val_VL_attention_linear_output_acc: 0.4408 - val_VH_attention_linear_output_acc: 0.3271\n",
      "Epoch 394/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0547 - VL_attention_linear_output_loss: 1.8861 - VH_attention_linear_output_loss: 2.1686 - VL_attention_linear_output_acc: 0.4384 - VH_attention_linear_output_acc: 0.3255 - val_loss: 4.0621 - val_VL_attention_linear_output_loss: 1.8843 - val_VH_attention_linear_output_loss: 2.1779 - val_VL_attention_linear_output_acc: 0.4421 - val_VH_attention_linear_output_acc: 0.3130\n",
      "Epoch 395/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0588 - VL_attention_linear_output_loss: 1.8896 - VH_attention_linear_output_loss: 2.1692 - VL_attention_linear_output_acc: 0.4370 - VH_attention_linear_output_acc: 0.3247 - val_loss: 4.0495 - val_VL_attention_linear_output_loss: 1.8880 - val_VH_attention_linear_output_loss: 2.1615 - val_VL_attention_linear_output_acc: 0.4436 - val_VH_attention_linear_output_acc: 0.3253\n",
      "Epoch 396/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0683 - VL_attention_linear_output_loss: 1.9007 - VH_attention_linear_output_loss: 2.1675 - VL_attention_linear_output_acc: 0.4324 - VH_attention_linear_output_acc: 0.3253 - val_loss: 4.1506 - val_VL_attention_linear_output_loss: 1.9816 - val_VH_attention_linear_output_loss: 2.1690 - val_VL_attention_linear_output_acc: 0.3831 - val_VH_attention_linear_output_acc: 0.3212\n",
      "Epoch 397/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0758 - VL_attention_linear_output_loss: 1.8942 - VH_attention_linear_output_loss: 2.1817 - VL_attention_linear_output_acc: 0.4351 - VH_attention_linear_output_acc: 0.3208 - val_loss: 4.0670 - val_VL_attention_linear_output_loss: 1.9028 - val_VH_attention_linear_output_loss: 2.1642 - val_VL_attention_linear_output_acc: 0.4384 - val_VH_attention_linear_output_acc: 0.3279\n",
      "Epoch 398/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0509 - VL_attention_linear_output_loss: 1.8857 - VH_attention_linear_output_loss: 2.1652 - VL_attention_linear_output_acc: 0.4388 - VH_attention_linear_output_acc: 0.3284 - val_loss: 4.0577 - val_VL_attention_linear_output_loss: 1.8919 - val_VH_attention_linear_output_loss: 2.1658 - val_VL_attention_linear_output_acc: 0.4450 - val_VH_attention_linear_output_acc: 0.3243\n",
      "Epoch 399/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0461 - VL_attention_linear_output_loss: 1.8832 - VH_attention_linear_output_loss: 2.1628 - VL_attention_linear_output_acc: 0.4403 - VH_attention_linear_output_acc: 0.3291 - val_loss: 4.0647 - val_VL_attention_linear_output_loss: 1.9010 - val_VH_attention_linear_output_loss: 2.1637 - val_VL_attention_linear_output_acc: 0.4365 - val_VH_attention_linear_output_acc: 0.3301\n",
      "Epoch 400/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0529 - VL_attention_linear_output_loss: 1.8890 - VH_attention_linear_output_loss: 2.1639 - VL_attention_linear_output_acc: 0.4375 - VH_attention_linear_output_acc: 0.3289 - val_loss: 4.0556 - val_VL_attention_linear_output_loss: 1.8977 - val_VH_attention_linear_output_loss: 2.1578 - val_VL_attention_linear_output_acc: 0.4321 - val_VH_attention_linear_output_acc: 0.3294\n",
      "Epoch 401/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0672 - VL_attention_linear_output_loss: 1.8983 - VH_attention_linear_output_loss: 2.1689 - VL_attention_linear_output_acc: 0.4325 - VH_attention_linear_output_acc: 0.3258 - val_loss: 4.0533 - val_VL_attention_linear_output_loss: 1.8856 - val_VH_attention_linear_output_loss: 2.1677 - val_VL_attention_linear_output_acc: 0.4398 - val_VH_attention_linear_output_acc: 0.3268\n",
      "Epoch 402/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0743 - VL_attention_linear_output_loss: 1.9071 - VH_attention_linear_output_loss: 2.1673 - VL_attention_linear_output_acc: 0.4297 - VH_attention_linear_output_acc: 0.3278 - val_loss: 4.0741 - val_VL_attention_linear_output_loss: 1.9202 - val_VH_attention_linear_output_loss: 2.1540 - val_VL_attention_linear_output_acc: 0.4281 - val_VH_attention_linear_output_acc: 0.3299\n",
      "Epoch 403/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0482 - VL_attention_linear_output_loss: 1.8850 - VH_attention_linear_output_loss: 2.1632 - VL_attention_linear_output_acc: 0.4385 - VH_attention_linear_output_acc: 0.3280 - val_loss: 4.0748 - val_VL_attention_linear_output_loss: 1.8882 - val_VH_attention_linear_output_loss: 2.1867 - val_VL_attention_linear_output_acc: 0.4443 - val_VH_attention_linear_output_acc: 0.3099\n",
      "Epoch 404/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0526 - VL_attention_linear_output_loss: 1.8900 - VH_attention_linear_output_loss: 2.1625 - VL_attention_linear_output_acc: 0.4379 - VH_attention_linear_output_acc: 0.3288 - val_loss: 4.0565 - val_VL_attention_linear_output_loss: 1.8943 - val_VH_attention_linear_output_loss: 2.1622 - val_VL_attention_linear_output_acc: 0.4369 - val_VH_attention_linear_output_acc: 0.3253\n",
      "Epoch 405/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0603 - VL_attention_linear_output_loss: 1.8948 - VH_attention_linear_output_loss: 2.1655 - VL_attention_linear_output_acc: 0.4333 - VH_attention_linear_output_acc: 0.3257 - val_loss: 4.0395 - val_VL_attention_linear_output_loss: 1.8843 - val_VH_attention_linear_output_loss: 2.1551 - val_VL_attention_linear_output_acc: 0.4432 - val_VH_attention_linear_output_acc: 0.3281\n",
      "Epoch 406/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0547 - VL_attention_linear_output_loss: 1.8901 - VH_attention_linear_output_loss: 2.1646 - VL_attention_linear_output_acc: 0.4355 - VH_attention_linear_output_acc: 0.3260 - val_loss: 4.0461 - val_VL_attention_linear_output_loss: 1.8836 - val_VH_attention_linear_output_loss: 2.1625 - val_VL_attention_linear_output_acc: 0.4409 - val_VH_attention_linear_output_acc: 0.3304\n",
      "Epoch 407/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0407 - VL_attention_linear_output_loss: 1.8809 - VH_attention_linear_output_loss: 2.1597 - VL_attention_linear_output_acc: 0.4419 - VH_attention_linear_output_acc: 0.3306 - val_loss: 4.0369 - val_VL_attention_linear_output_loss: 1.8805 - val_VH_attention_linear_output_loss: 2.1564 - val_VL_attention_linear_output_acc: 0.4439 - val_VH_attention_linear_output_acc: 0.3313\n",
      "Epoch 408/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0538 - VL_attention_linear_output_loss: 1.8923 - VH_attention_linear_output_loss: 2.1615 - VL_attention_linear_output_acc: 0.4360 - VH_attention_linear_output_acc: 0.3280 - val_loss: 4.0532 - val_VL_attention_linear_output_loss: 1.8942 - val_VH_attention_linear_output_loss: 2.1590 - val_VL_attention_linear_output_acc: 0.4440 - val_VH_attention_linear_output_acc: 0.3287\n",
      "Epoch 409/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0508 - VL_attention_linear_output_loss: 1.8898 - VH_attention_linear_output_loss: 2.1610 - VL_attention_linear_output_acc: 0.4376 - VH_attention_linear_output_acc: 0.3275 - val_loss: 4.0519 - val_VL_attention_linear_output_loss: 1.8870 - val_VH_attention_linear_output_loss: 2.1649 - val_VL_attention_linear_output_acc: 0.4354 - val_VH_attention_linear_output_acc: 0.3270\n",
      "Epoch 410/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0415 - VL_attention_linear_output_loss: 1.8775 - VH_attention_linear_output_loss: 2.1640 - VL_attention_linear_output_acc: 0.4439 - VH_attention_linear_output_acc: 0.3262 - val_loss: 4.0406 - val_VL_attention_linear_output_loss: 1.8820 - val_VH_attention_linear_output_loss: 2.1586 - val_VL_attention_linear_output_acc: 0.4419 - val_VH_attention_linear_output_acc: 0.3273\n",
      "Epoch 411/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0568 - VL_attention_linear_output_loss: 1.8935 - VH_attention_linear_output_loss: 2.1633 - VL_attention_linear_output_acc: 0.4357 - VH_attention_linear_output_acc: 0.3281 - val_loss: 4.0486 - val_VL_attention_linear_output_loss: 1.8936 - val_VH_attention_linear_output_loss: 2.1550 - val_VL_attention_linear_output_acc: 0.4427 - val_VH_attention_linear_output_acc: 0.3320\n",
      "Epoch 412/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0347 - VL_attention_linear_output_loss: 1.8777 - VH_attention_linear_output_loss: 2.1571 - VL_attention_linear_output_acc: 0.4441 - VH_attention_linear_output_acc: 0.3309 - val_loss: 4.0614 - val_VL_attention_linear_output_loss: 1.8845 - val_VH_attention_linear_output_loss: 2.1769 - val_VL_attention_linear_output_acc: 0.4495 - val_VH_attention_linear_output_acc: 0.3111\n",
      "Epoch 413/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0558 - VL_attention_linear_output_loss: 1.8937 - VH_attention_linear_output_loss: 2.1621 - VL_attention_linear_output_acc: 0.4356 - VH_attention_linear_output_acc: 0.3264 - val_loss: 4.0492 - val_VL_attention_linear_output_loss: 1.8918 - val_VH_attention_linear_output_loss: 2.1574 - val_VL_attention_linear_output_acc: 0.4451 - val_VH_attention_linear_output_acc: 0.3278\n",
      "Epoch 414/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0307 - VL_attention_linear_output_loss: 1.8731 - VH_attention_linear_output_loss: 2.1576 - VL_attention_linear_output_acc: 0.4472 - VH_attention_linear_output_acc: 0.3287 - val_loss: 4.0309 - val_VL_attention_linear_output_loss: 1.8789 - val_VH_attention_linear_output_loss: 2.1519 - val_VL_attention_linear_output_acc: 0.4462 - val_VH_attention_linear_output_acc: 0.3295\n",
      "Epoch 415/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0365 - VL_attention_linear_output_loss: 1.8802 - VH_attention_linear_output_loss: 2.1563 - VL_attention_linear_output_acc: 0.4427 - VH_attention_linear_output_acc: 0.3304 - val_loss: 4.0362 - val_VL_attention_linear_output_loss: 1.8806 - val_VH_attention_linear_output_loss: 2.1557 - val_VL_attention_linear_output_acc: 0.4469 - val_VH_attention_linear_output_acc: 0.3265\n",
      "Epoch 416/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0401 - VL_attention_linear_output_loss: 1.8792 - VH_attention_linear_output_loss: 2.1610 - VL_attention_linear_output_acc: 0.4445 - VH_attention_linear_output_acc: 0.3264 - val_loss: 4.0433 - val_VL_attention_linear_output_loss: 1.8843 - val_VH_attention_linear_output_loss: 2.1589 - val_VL_attention_linear_output_acc: 0.4432 - val_VH_attention_linear_output_acc: 0.3287\n",
      "Epoch 417/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0454 - VL_attention_linear_output_loss: 1.8857 - VH_attention_linear_output_loss: 2.1597 - VL_attention_linear_output_acc: 0.4415 - VH_attention_linear_output_acc: 0.3264 - val_loss: 4.0443 - val_VL_attention_linear_output_loss: 1.8890 - val_VH_attention_linear_output_loss: 2.1552 - val_VL_attention_linear_output_acc: 0.4420 - val_VH_attention_linear_output_acc: 0.3290\n",
      "Epoch 418/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0378 - VL_attention_linear_output_loss: 1.8803 - VH_attention_linear_output_loss: 2.1575 - VL_attention_linear_output_acc: 0.4441 - VH_attention_linear_output_acc: 0.3295 - val_loss: 4.0439 - val_VL_attention_linear_output_loss: 1.8834 - val_VH_attention_linear_output_loss: 2.1605 - val_VL_attention_linear_output_acc: 0.4389 - val_VH_attention_linear_output_acc: 0.3249\n",
      "Epoch 419/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0551 - VL_attention_linear_output_loss: 1.8962 - VH_attention_linear_output_loss: 2.1589 - VL_attention_linear_output_acc: 0.4359 - VH_attention_linear_output_acc: 0.3281 - val_loss: 4.0672 - val_VL_attention_linear_output_loss: 1.8816 - val_VH_attention_linear_output_loss: 2.1857 - val_VL_attention_linear_output_acc: 0.4456 - val_VH_attention_linear_output_acc: 0.3011\n",
      "Epoch 420/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0254 - VL_attention_linear_output_loss: 1.8689 - VH_attention_linear_output_loss: 2.1565 - VL_attention_linear_output_acc: 0.4488 - VH_attention_linear_output_acc: 0.3288 - val_loss: 4.0867 - val_VL_attention_linear_output_loss: 1.8859 - val_VH_attention_linear_output_loss: 2.2007 - val_VL_attention_linear_output_acc: 0.4481 - val_VH_attention_linear_output_acc: 0.3026\n",
      "Epoch 421/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0568 - VL_attention_linear_output_loss: 1.8948 - VH_attention_linear_output_loss: 2.1619 - VL_attention_linear_output_acc: 0.4375 - VH_attention_linear_output_acc: 0.3259 - val_loss: 4.0542 - val_VL_attention_linear_output_loss: 1.8995 - val_VH_attention_linear_output_loss: 2.1546 - val_VL_attention_linear_output_acc: 0.4339 - val_VH_attention_linear_output_acc: 0.3296\n",
      "Epoch 422/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0288 - VL_attention_linear_output_loss: 1.8714 - VH_attention_linear_output_loss: 2.1574 - VL_attention_linear_output_acc: 0.4487 - VH_attention_linear_output_acc: 0.3278 - val_loss: 4.0359 - val_VL_attention_linear_output_loss: 1.8768 - val_VH_attention_linear_output_loss: 2.1591 - val_VL_attention_linear_output_acc: 0.4452 - val_VH_attention_linear_output_acc: 0.3255\n",
      "Epoch 423/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0357 - VL_attention_linear_output_loss: 1.8741 - VH_attention_linear_output_loss: 2.1616 - VL_attention_linear_output_acc: 0.4484 - VH_attention_linear_output_acc: 0.3244 - val_loss: 4.0862 - val_VL_attention_linear_output_loss: 1.9216 - val_VH_attention_linear_output_loss: 2.1646 - val_VL_attention_linear_output_acc: 0.4133 - val_VH_attention_linear_output_acc: 0.3194\n",
      "Epoch 424/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0465 - VL_attention_linear_output_loss: 1.8867 - VH_attention_linear_output_loss: 2.1598 - VL_attention_linear_output_acc: 0.4408 - VH_attention_linear_output_acc: 0.3267 - val_loss: 4.0326 - val_VL_attention_linear_output_loss: 1.8759 - val_VH_attention_linear_output_loss: 2.1567 - val_VL_attention_linear_output_acc: 0.4551 - val_VH_attention_linear_output_acc: 0.3256\n",
      "Epoch 425/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0368 - VL_attention_linear_output_loss: 1.8780 - VH_attention_linear_output_loss: 2.1588 - VL_attention_linear_output_acc: 0.4456 - VH_attention_linear_output_acc: 0.3268 - val_loss: 4.0405 - val_VL_attention_linear_output_loss: 1.8882 - val_VH_attention_linear_output_loss: 2.1523 - val_VL_attention_linear_output_acc: 0.4473 - val_VH_attention_linear_output_acc: 0.3301\n",
      "Epoch 426/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0445 - VL_attention_linear_output_loss: 1.8850 - VH_attention_linear_output_loss: 2.1596 - VL_attention_linear_output_acc: 0.4427 - VH_attention_linear_output_acc: 0.3266 - val_loss: 4.0692 - val_VL_attention_linear_output_loss: 1.8792 - val_VH_attention_linear_output_loss: 2.1900 - val_VL_attention_linear_output_acc: 0.4521 - val_VH_attention_linear_output_acc: 0.3000\n",
      "Epoch 427/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0519 - VL_attention_linear_output_loss: 1.8854 - VH_attention_linear_output_loss: 2.1666 - VL_attention_linear_output_acc: 0.4405 - VH_attention_linear_output_acc: 0.3227 - val_loss: 4.0442 - val_VL_attention_linear_output_loss: 1.8877 - val_VH_attention_linear_output_loss: 2.1565 - val_VL_attention_linear_output_acc: 0.4356 - val_VH_attention_linear_output_acc: 0.3228\n",
      "Epoch 428/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0261 - VL_attention_linear_output_loss: 1.8698 - VH_attention_linear_output_loss: 2.1563 - VL_attention_linear_output_acc: 0.4496 - VH_attention_linear_output_acc: 0.3281 - val_loss: 4.0323 - val_VL_attention_linear_output_loss: 1.8716 - val_VH_attention_linear_output_loss: 2.1607 - val_VL_attention_linear_output_acc: 0.4544 - val_VH_attention_linear_output_acc: 0.3249\n",
      "Epoch 429/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0346 - VL_attention_linear_output_loss: 1.8719 - VH_attention_linear_output_loss: 2.1627 - VL_attention_linear_output_acc: 0.4490 - VH_attention_linear_output_acc: 0.3246 - val_loss: 4.0698 - val_VL_attention_linear_output_loss: 1.8799 - val_VH_attention_linear_output_loss: 2.1899 - val_VL_attention_linear_output_acc: 0.4502 - val_VH_attention_linear_output_acc: 0.3027\n",
      "Epoch 430/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0376 - VL_attention_linear_output_loss: 1.8791 - VH_attention_linear_output_loss: 2.1585 - VL_attention_linear_output_acc: 0.4451 - VH_attention_linear_output_acc: 0.3264 - val_loss: 4.0480 - val_VL_attention_linear_output_loss: 1.8739 - val_VH_attention_linear_output_loss: 2.1741 - val_VL_attention_linear_output_acc: 0.4489 - val_VH_attention_linear_output_acc: 0.3080\n",
      "Epoch 431/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0596 - VL_attention_linear_output_loss: 1.8910 - VH_attention_linear_output_loss: 2.1686 - VL_attention_linear_output_acc: 0.4392 - VH_attention_linear_output_acc: 0.3207 - val_loss: 4.0385 - val_VL_attention_linear_output_loss: 1.8791 - val_VH_attention_linear_output_loss: 2.1594 - val_VL_attention_linear_output_acc: 0.4522 - val_VH_attention_linear_output_acc: 0.3258\n",
      "Epoch 432/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0253 - VL_attention_linear_output_loss: 1.8649 - VH_attention_linear_output_loss: 2.1604 - VL_attention_linear_output_acc: 0.4534 - VH_attention_linear_output_acc: 0.3260 - val_loss: 4.0261 - val_VL_attention_linear_output_loss: 1.8682 - val_VH_attention_linear_output_loss: 2.1579 - val_VL_attention_linear_output_acc: 0.4563 - val_VH_attention_linear_output_acc: 0.3217\n",
      "Epoch 433/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0379 - VL_attention_linear_output_loss: 1.8845 - VH_attention_linear_output_loss: 2.1534 - VL_attention_linear_output_acc: 0.4412 - VH_attention_linear_output_acc: 0.3297 - val_loss: 4.0508 - val_VL_attention_linear_output_loss: 1.8730 - val_VH_attention_linear_output_loss: 2.1777 - val_VL_attention_linear_output_acc: 0.4524 - val_VH_attention_linear_output_acc: 0.3094\n",
      "Epoch 434/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0247 - VL_attention_linear_output_loss: 1.8698 - VH_attention_linear_output_loss: 2.1549 - VL_attention_linear_output_acc: 0.4499 - VH_attention_linear_output_acc: 0.3288 - val_loss: 4.0300 - val_VL_attention_linear_output_loss: 1.8773 - val_VH_attention_linear_output_loss: 2.1527 - val_VL_attention_linear_output_acc: 0.4558 - val_VH_attention_linear_output_acc: 0.3238\n",
      "Epoch 435/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0326 - VL_attention_linear_output_loss: 1.8759 - VH_attention_linear_output_loss: 2.1568 - VL_attention_linear_output_acc: 0.4471 - VH_attention_linear_output_acc: 0.3267 - val_loss: 4.0762 - val_VL_attention_linear_output_loss: 1.8795 - val_VH_attention_linear_output_loss: 2.1967 - val_VL_attention_linear_output_acc: 0.4565 - val_VH_attention_linear_output_acc: 0.2925\n",
      "Epoch 436/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0503 - VL_attention_linear_output_loss: 1.8867 - VH_attention_linear_output_loss: 2.1636 - VL_attention_linear_output_acc: 0.4409 - VH_attention_linear_output_acc: 0.3232 - val_loss: 4.0427 - val_VL_attention_linear_output_loss: 1.8916 - val_VH_attention_linear_output_loss: 2.1511 - val_VL_attention_linear_output_acc: 0.4384 - val_VH_attention_linear_output_acc: 0.3249\n",
      "Epoch 437/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0282 - VL_attention_linear_output_loss: 1.8762 - VH_attention_linear_output_loss: 2.1520 - VL_attention_linear_output_acc: 0.4473 - VH_attention_linear_output_acc: 0.3302 - val_loss: 4.0430 - val_VL_attention_linear_output_loss: 1.8828 - val_VH_attention_linear_output_loss: 2.1602 - val_VL_attention_linear_output_acc: 0.4407 - val_VH_attention_linear_output_acc: 0.3240\n",
      "Epoch 438/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0245 - VL_attention_linear_output_loss: 1.8703 - VH_attention_linear_output_loss: 2.1542 - VL_attention_linear_output_acc: 0.4495 - VH_attention_linear_output_acc: 0.3278 - val_loss: 4.0312 - val_VL_attention_linear_output_loss: 1.8830 - val_VH_attention_linear_output_loss: 2.1482 - val_VL_attention_linear_output_acc: 0.4467 - val_VH_attention_linear_output_acc: 0.3252\n",
      "Epoch 439/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0156 - VL_attention_linear_output_loss: 1.8631 - VH_attention_linear_output_loss: 2.1525 - VL_attention_linear_output_acc: 0.4545 - VH_attention_linear_output_acc: 0.3292 - val_loss: 4.0324 - val_VL_attention_linear_output_loss: 1.8736 - val_VH_attention_linear_output_loss: 2.1588 - val_VL_attention_linear_output_acc: 0.4608 - val_VH_attention_linear_output_acc: 0.3200\n",
      "Epoch 440/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0389 - VL_attention_linear_output_loss: 1.8823 - VH_attention_linear_output_loss: 2.1566 - VL_attention_linear_output_acc: 0.4414 - VH_attention_linear_output_acc: 0.3270 - val_loss: 4.0555 - val_VL_attention_linear_output_loss: 1.8916 - val_VH_attention_linear_output_loss: 2.1638 - val_VL_attention_linear_output_acc: 0.4522 - val_VH_attention_linear_output_acc: 0.3300\n",
      "Epoch 441/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0372 - VL_attention_linear_output_loss: 1.8769 - VH_attention_linear_output_loss: 2.1603 - VL_attention_linear_output_acc: 0.4452 - VH_attention_linear_output_acc: 0.3263 - val_loss: 4.0194 - val_VL_attention_linear_output_loss: 1.8696 - val_VH_attention_linear_output_loss: 2.1497 - val_VL_attention_linear_output_acc: 0.4502 - val_VH_attention_linear_output_acc: 0.3265\n",
      "Epoch 442/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0262 - VL_attention_linear_output_loss: 1.8637 - VH_attention_linear_output_loss: 2.1625 - VL_attention_linear_output_acc: 0.4545 - VH_attention_linear_output_acc: 0.3235 - val_loss: 4.0486 - val_VL_attention_linear_output_loss: 1.9008 - val_VH_attention_linear_output_loss: 2.1477 - val_VL_attention_linear_output_acc: 0.4406 - val_VH_attention_linear_output_acc: 0.3282\n",
      "Epoch 443/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0248 - VL_attention_linear_output_loss: 1.8727 - VH_attention_linear_output_loss: 2.1521 - VL_attention_linear_output_acc: 0.4483 - VH_attention_linear_output_acc: 0.3294 - val_loss: 4.0715 - val_VL_attention_linear_output_loss: 1.9197 - val_VH_attention_linear_output_loss: 2.1518 - val_VL_attention_linear_output_acc: 0.4205 - val_VH_attention_linear_output_acc: 0.3255\n",
      "Epoch 444/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0344 - VL_attention_linear_output_loss: 1.8832 - VH_attention_linear_output_loss: 2.1512 - VL_attention_linear_output_acc: 0.4418 - VH_attention_linear_output_acc: 0.3292 - val_loss: 4.0421 - val_VL_attention_linear_output_loss: 1.8794 - val_VH_attention_linear_output_loss: 2.1627 - val_VL_attention_linear_output_acc: 0.4477 - val_VH_attention_linear_output_acc: 0.3171\n",
      "Epoch 445/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0221 - VL_attention_linear_output_loss: 1.8680 - VH_attention_linear_output_loss: 2.1541 - VL_attention_linear_output_acc: 0.4504 - VH_attention_linear_output_acc: 0.3282 - val_loss: 4.0164 - val_VL_attention_linear_output_loss: 1.8674 - val_VH_attention_linear_output_loss: 2.1490 - val_VL_attention_linear_output_acc: 0.4582 - val_VH_attention_linear_output_acc: 0.3314\n",
      "Epoch 446/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0409 - VL_attention_linear_output_loss: 1.8808 - VH_attention_linear_output_loss: 2.1602 - VL_attention_linear_output_acc: 0.4441 - VH_attention_linear_output_acc: 0.3240 - val_loss: 4.1410 - val_VL_attention_linear_output_loss: 1.9755 - val_VH_attention_linear_output_loss: 2.1655 - val_VL_attention_linear_output_acc: 0.3879 - val_VH_attention_linear_output_acc: 0.3197\n",
      "Epoch 447/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0341 - VL_attention_linear_output_loss: 1.8777 - VH_attention_linear_output_loss: 2.1563 - VL_attention_linear_output_acc: 0.4452 - VH_attention_linear_output_acc: 0.3273 - val_loss: 4.0367 - val_VL_attention_linear_output_loss: 1.8743 - val_VH_attention_linear_output_loss: 2.1624 - val_VL_attention_linear_output_acc: 0.4543 - val_VH_attention_linear_output_acc: 0.3189\n",
      "Epoch 448/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0232 - VL_attention_linear_output_loss: 1.8696 - VH_attention_linear_output_loss: 2.1535 - VL_attention_linear_output_acc: 0.4497 - VH_attention_linear_output_acc: 0.3282 - val_loss: 4.0155 - val_VL_attention_linear_output_loss: 1.8687 - val_VH_attention_linear_output_loss: 2.1468 - val_VL_attention_linear_output_acc: 0.4572 - val_VH_attention_linear_output_acc: 0.3291\n",
      "Epoch 449/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0327 - VL_attention_linear_output_loss: 1.8746 - VH_attention_linear_output_loss: 2.1581 - VL_attention_linear_output_acc: 0.4475 - VH_attention_linear_output_acc: 0.3252 - val_loss: 4.0713 - val_VL_attention_linear_output_loss: 1.9247 - val_VH_attention_linear_output_loss: 2.1466 - val_VL_attention_linear_output_acc: 0.4166 - val_VH_attention_linear_output_acc: 0.3271\n",
      "Epoch 450/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0129 - VL_attention_linear_output_loss: 1.8615 - VH_attention_linear_output_loss: 2.1514 - VL_attention_linear_output_acc: 0.4536 - VH_attention_linear_output_acc: 0.3287 - val_loss: 4.0346 - val_VL_attention_linear_output_loss: 1.8913 - val_VH_attention_linear_output_loss: 2.1433 - val_VL_attention_linear_output_acc: 0.4345 - val_VH_attention_linear_output_acc: 0.3318\n",
      "Epoch 451/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0275 - VL_attention_linear_output_loss: 1.8785 - VH_attention_linear_output_loss: 2.1490 - VL_attention_linear_output_acc: 0.4447 - VH_attention_linear_output_acc: 0.3310 - val_loss: 4.0334 - val_VL_attention_linear_output_loss: 1.8848 - val_VH_attention_linear_output_loss: 2.1486 - val_VL_attention_linear_output_acc: 0.4516 - val_VH_attention_linear_output_acc: 0.3297\n",
      "Epoch 452/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0194 - VL_attention_linear_output_loss: 1.8669 - VH_attention_linear_output_loss: 2.1524 - VL_attention_linear_output_acc: 0.4518 - VH_attention_linear_output_acc: 0.3272 - val_loss: 4.0337 - val_VL_attention_linear_output_loss: 1.8679 - val_VH_attention_linear_output_loss: 2.1658 - val_VL_attention_linear_output_acc: 0.4505 - val_VH_attention_linear_output_acc: 0.3201\n",
      "Epoch 453/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0220 - VL_attention_linear_output_loss: 1.8733 - VH_attention_linear_output_loss: 2.1487 - VL_attention_linear_output_acc: 0.4483 - VH_attention_linear_output_acc: 0.3302 - val_loss: 4.0158 - val_VL_attention_linear_output_loss: 1.8637 - val_VH_attention_linear_output_loss: 2.1520 - val_VL_attention_linear_output_acc: 0.4578 - val_VH_attention_linear_output_acc: 0.3285\n",
      "Epoch 454/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0297 - VL_attention_linear_output_loss: 1.8771 - VH_attention_linear_output_loss: 2.1527 - VL_attention_linear_output_acc: 0.4462 - VH_attention_linear_output_acc: 0.3284 - val_loss: 4.0265 - val_VL_attention_linear_output_loss: 1.8734 - val_VH_attention_linear_output_loss: 2.1531 - val_VL_attention_linear_output_acc: 0.4601 - val_VH_attention_linear_output_acc: 0.3254\n",
      "Epoch 455/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0090 - VL_attention_linear_output_loss: 1.8613 - VH_attention_linear_output_loss: 2.1477 - VL_attention_linear_output_acc: 0.4541 - VH_attention_linear_output_acc: 0.3317 - val_loss: 4.0025 - val_VL_attention_linear_output_loss: 1.8614 - val_VH_attention_linear_output_loss: 2.1411 - val_VL_attention_linear_output_acc: 0.4589 - val_VH_attention_linear_output_acc: 0.3348\n",
      "Epoch 456/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0420 - VL_attention_linear_output_loss: 1.8807 - VH_attention_linear_output_loss: 2.1612 - VL_attention_linear_output_acc: 0.4435 - VH_attention_linear_output_acc: 0.3225 - val_loss: 4.0298 - val_VL_attention_linear_output_loss: 1.8850 - val_VH_attention_linear_output_loss: 2.1448 - val_VL_attention_linear_output_acc: 0.4515 - val_VH_attention_linear_output_acc: 0.3330\n",
      "Epoch 457/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0082 - VL_attention_linear_output_loss: 1.8617 - VH_attention_linear_output_loss: 2.1465 - VL_attention_linear_output_acc: 0.4538 - VH_attention_linear_output_acc: 0.3322 - val_loss: 4.0451 - val_VL_attention_linear_output_loss: 1.8856 - val_VH_attention_linear_output_loss: 2.1595 - val_VL_attention_linear_output_acc: 0.4356 - val_VH_attention_linear_output_acc: 0.3208\n",
      "Epoch 458/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0355 - VL_attention_linear_output_loss: 1.8772 - VH_attention_linear_output_loss: 2.1583 - VL_attention_linear_output_acc: 0.4454 - VH_attention_linear_output_acc: 0.3277 - val_loss: 4.0095 - val_VL_attention_linear_output_loss: 1.8639 - val_VH_attention_linear_output_loss: 2.1456 - val_VL_attention_linear_output_acc: 0.4507 - val_VH_attention_linear_output_acc: 0.3306\n",
      "Epoch 459/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9976 - VL_attention_linear_output_loss: 1.8531 - VH_attention_linear_output_loss: 2.1445 - VL_attention_linear_output_acc: 0.4595 - VH_attention_linear_output_acc: 0.3326 - val_loss: 4.0050 - val_VL_attention_linear_output_loss: 1.8614 - val_VH_attention_linear_output_loss: 2.1436 - val_VL_attention_linear_output_acc: 0.4568 - val_VH_attention_linear_output_acc: 0.3323\n",
      "Epoch 460/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0013 - VL_attention_linear_output_loss: 1.8583 - VH_attention_linear_output_loss: 2.1431 - VL_attention_linear_output_acc: 0.4552 - VH_attention_linear_output_acc: 0.3338 - val_loss: 4.0360 - val_VL_attention_linear_output_loss: 1.8782 - val_VH_attention_linear_output_loss: 2.1578 - val_VL_attention_linear_output_acc: 0.4461 - val_VH_attention_linear_output_acc: 0.3181\n",
      "Epoch 461/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0039 - VL_attention_linear_output_loss: 1.8597 - VH_attention_linear_output_loss: 2.1442 - VL_attention_linear_output_acc: 0.4536 - VH_attention_linear_output_acc: 0.3327 - val_loss: 4.0104 - val_VL_attention_linear_output_loss: 1.8637 - val_VH_attention_linear_output_loss: 2.1468 - val_VL_attention_linear_output_acc: 0.4595 - val_VH_attention_linear_output_acc: 0.3301\n",
      "Epoch 462/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0052 - VL_attention_linear_output_loss: 1.8604 - VH_attention_linear_output_loss: 2.1448 - VL_attention_linear_output_acc: 0.4543 - VH_attention_linear_output_acc: 0.3323 - val_loss: 4.0105 - val_VL_attention_linear_output_loss: 1.8686 - val_VH_attention_linear_output_loss: 2.1419 - val_VL_attention_linear_output_acc: 0.4539 - val_VH_attention_linear_output_acc: 0.3363\n",
      "Epoch 463/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0344 - VL_attention_linear_output_loss: 1.8875 - VH_attention_linear_output_loss: 2.1469 - VL_attention_linear_output_acc: 0.4387 - VH_attention_linear_output_acc: 0.3315 - val_loss: 4.0394 - val_VL_attention_linear_output_loss: 1.8690 - val_VH_attention_linear_output_loss: 2.1704 - val_VL_attention_linear_output_acc: 0.4513 - val_VH_attention_linear_output_acc: 0.3119\n",
      "Epoch 464/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0031 - VL_attention_linear_output_loss: 1.8519 - VH_attention_linear_output_loss: 2.1511 - VL_attention_linear_output_acc: 0.4587 - VH_attention_linear_output_acc: 0.3273 - val_loss: 4.0134 - val_VL_attention_linear_output_loss: 1.8591 - val_VH_attention_linear_output_loss: 2.1543 - val_VL_attention_linear_output_acc: 0.4622 - val_VH_attention_linear_output_acc: 0.3197\n",
      "Epoch 465/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9980 - VL_attention_linear_output_loss: 1.8532 - VH_attention_linear_output_loss: 2.1448 - VL_attention_linear_output_acc: 0.4584 - VH_attention_linear_output_acc: 0.3321 - val_loss: 3.9965 - val_VL_attention_linear_output_loss: 1.8585 - val_VH_attention_linear_output_loss: 2.1380 - val_VL_attention_linear_output_acc: 0.4593 - val_VH_attention_linear_output_acc: 0.3374\n",
      "Epoch 466/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0172 - VL_attention_linear_output_loss: 1.8676 - VH_attention_linear_output_loss: 2.1495 - VL_attention_linear_output_acc: 0.4513 - VH_attention_linear_output_acc: 0.3291 - val_loss: 4.0147 - val_VL_attention_linear_output_loss: 1.8722 - val_VH_attention_linear_output_loss: 2.1424 - val_VL_attention_linear_output_acc: 0.4483 - val_VH_attention_linear_output_acc: 0.3356\n",
      "Epoch 467/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0070 - VL_attention_linear_output_loss: 1.8596 - VH_attention_linear_output_loss: 2.1474 - VL_attention_linear_output_acc: 0.4548 - VH_attention_linear_output_acc: 0.3304 - val_loss: 4.0053 - val_VL_attention_linear_output_loss: 1.8639 - val_VH_attention_linear_output_loss: 2.1414 - val_VL_attention_linear_output_acc: 0.4510 - val_VH_attention_linear_output_acc: 0.3365\n",
      "Epoch 468/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0019 - VL_attention_linear_output_loss: 1.8521 - VH_attention_linear_output_loss: 2.1498 - VL_attention_linear_output_acc: 0.4588 - VH_attention_linear_output_acc: 0.3295 - val_loss: 4.0061 - val_VL_attention_linear_output_loss: 1.8572 - val_VH_attention_linear_output_loss: 2.1489 - val_VL_attention_linear_output_acc: 0.4595 - val_VH_attention_linear_output_acc: 0.3274\n",
      "Epoch 469/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2049 - VL_attention_linear_output_loss: 1.8690 - VH_attention_linear_output_loss: 2.3359 - VL_attention_linear_output_acc: 0.4509 - VH_attention_linear_output_acc: 0.2924 - val_loss: 4.6194 - val_VL_attention_linear_output_loss: 1.8998 - val_VH_attention_linear_output_loss: 2.7196 - val_VL_attention_linear_output_acc: 0.4518 - val_VH_attention_linear_output_acc: 0.2282\n",
      "Epoch 470/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.4051 - VL_attention_linear_output_loss: 1.8811 - VH_attention_linear_output_loss: 2.5239 - VL_attention_linear_output_acc: 0.4461 - VH_attention_linear_output_acc: 0.2545 - val_loss: 4.3072 - val_VL_attention_linear_output_loss: 1.8621 - val_VH_attention_linear_output_loss: 2.4451 - val_VL_attention_linear_output_acc: 0.4562 - val_VH_attention_linear_output_acc: 0.2628\n",
      "Epoch 471/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2849 - VL_attention_linear_output_loss: 1.8600 - VH_attention_linear_output_loss: 2.4249 - VL_attention_linear_output_acc: 0.4564 - VH_attention_linear_output_acc: 0.2719 - val_loss: 4.3255 - val_VL_attention_linear_output_loss: 1.8922 - val_VH_attention_linear_output_loss: 2.4334 - val_VL_attention_linear_output_acc: 0.4386 - val_VH_attention_linear_output_acc: 0.2620\n",
      "Epoch 472/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2398 - VL_attention_linear_output_loss: 1.8529 - VH_attention_linear_output_loss: 2.3868 - VL_attention_linear_output_acc: 0.4587 - VH_attention_linear_output_acc: 0.2787 - val_loss: 4.2203 - val_VL_attention_linear_output_loss: 1.8598 - val_VH_attention_linear_output_loss: 2.3605 - val_VL_attention_linear_output_acc: 0.4622 - val_VH_attention_linear_output_acc: 0.2831\n",
      "Epoch 473/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2166 - VL_attention_linear_output_loss: 1.8623 - VH_attention_linear_output_loss: 2.3542 - VL_attention_linear_output_acc: 0.4542 - VH_attention_linear_output_acc: 0.2856 - val_loss: 4.2182 - val_VL_attention_linear_output_loss: 1.8824 - val_VH_attention_linear_output_loss: 2.3357 - val_VL_attention_linear_output_acc: 0.4469 - val_VH_attention_linear_output_acc: 0.2859\n",
      "Epoch 474/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1972 - VL_attention_linear_output_loss: 1.8543 - VH_attention_linear_output_loss: 2.3430 - VL_attention_linear_output_acc: 0.4584 - VH_attention_linear_output_acc: 0.2844 - val_loss: 4.2155 - val_VL_attention_linear_output_loss: 1.8950 - val_VH_attention_linear_output_loss: 2.3205 - val_VL_attention_linear_output_acc: 0.4306 - val_VH_attention_linear_output_acc: 0.2941\n",
      "Epoch 475/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1917 - VL_attention_linear_output_loss: 1.8677 - VH_attention_linear_output_loss: 2.3240 - VL_attention_linear_output_acc: 0.4510 - VH_attention_linear_output_acc: 0.2883 - val_loss: 4.2035 - val_VL_attention_linear_output_loss: 1.8980 - val_VH_attention_linear_output_loss: 2.3055 - val_VL_attention_linear_output_acc: 0.4495 - val_VH_attention_linear_output_acc: 0.2910\n",
      "Epoch 476/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1746 - VL_attention_linear_output_loss: 1.8620 - VH_attention_linear_output_loss: 2.3126 - VL_attention_linear_output_acc: 0.4544 - VH_attention_linear_output_acc: 0.2893 - val_loss: 4.1739 - val_VL_attention_linear_output_loss: 1.8779 - val_VH_attention_linear_output_loss: 2.2959 - val_VL_attention_linear_output_acc: 0.4444 - val_VH_attention_linear_output_acc: 0.2909\n",
      "Epoch 477/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2425 - VL_attention_linear_output_loss: 1.8702 - VH_attention_linear_output_loss: 2.3723 - VL_attention_linear_output_acc: 0.4506 - VH_attention_linear_output_acc: 0.2626 - val_loss: 4.1277 - val_VL_attention_linear_output_loss: 1.8654 - val_VH_attention_linear_output_loss: 2.2623 - val_VL_attention_linear_output_acc: 0.4633 - val_VH_attention_linear_output_acc: 0.2829\n",
      "Epoch 478/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0897 - VL_attention_linear_output_loss: 1.8560 - VH_attention_linear_output_loss: 2.2336 - VL_attention_linear_output_acc: 0.4570 - VH_attention_linear_output_acc: 0.3019 - val_loss: 4.0662 - val_VL_attention_linear_output_loss: 1.8584 - val_VH_attention_linear_output_loss: 2.2078 - val_VL_attention_linear_output_acc: 0.4631 - val_VH_attention_linear_output_acc: 0.3101\n",
      "Epoch 479/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0571 - VL_attention_linear_output_loss: 1.8521 - VH_attention_linear_output_loss: 2.2050 - VL_attention_linear_output_acc: 0.4601 - VH_attention_linear_output_acc: 0.3125 - val_loss: 4.0531 - val_VL_attention_linear_output_loss: 1.8579 - val_VH_attention_linear_output_loss: 2.1952 - val_VL_attention_linear_output_acc: 0.4595 - val_VH_attention_linear_output_acc: 0.3126\n",
      "Epoch 480/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0627 - VL_attention_linear_output_loss: 1.8662 - VH_attention_linear_output_loss: 2.1965 - VL_attention_linear_output_acc: 0.4516 - VH_attention_linear_output_acc: 0.3148 - val_loss: 4.0519 - val_VL_attention_linear_output_loss: 1.8617 - val_VH_attention_linear_output_loss: 2.1902 - val_VL_attention_linear_output_acc: 0.4545 - val_VH_attention_linear_output_acc: 0.3175\n",
      "Epoch 481/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0418 - VL_attention_linear_output_loss: 1.8491 - VH_attention_linear_output_loss: 2.1926 - VL_attention_linear_output_acc: 0.4606 - VH_attention_linear_output_acc: 0.3166 - val_loss: 4.0840 - val_VL_attention_linear_output_loss: 1.8928 - val_VH_attention_linear_output_loss: 2.1912 - val_VL_attention_linear_output_acc: 0.4479 - val_VH_attention_linear_output_acc: 0.3166\n",
      "Epoch 482/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0415 - VL_attention_linear_output_loss: 1.8562 - VH_attention_linear_output_loss: 2.1853 - VL_attention_linear_output_acc: 0.4564 - VH_attention_linear_output_acc: 0.3199 - val_loss: 4.0708 - val_VL_attention_linear_output_loss: 1.8890 - val_VH_attention_linear_output_loss: 2.1818 - val_VL_attention_linear_output_acc: 0.4461 - val_VH_attention_linear_output_acc: 0.3198\n",
      "Epoch 483/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0434 - VL_attention_linear_output_loss: 1.8633 - VH_attention_linear_output_loss: 2.1801 - VL_attention_linear_output_acc: 0.4527 - VH_attention_linear_output_acc: 0.3213 - val_loss: 4.0319 - val_VL_attention_linear_output_loss: 1.8494 - val_VH_attention_linear_output_loss: 2.1825 - val_VL_attention_linear_output_acc: 0.4605 - val_VH_attention_linear_output_acc: 0.3176\n",
      "Epoch 484/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0220 - VL_attention_linear_output_loss: 1.8450 - VH_attention_linear_output_loss: 2.1770 - VL_attention_linear_output_acc: 0.4623 - VH_attention_linear_output_acc: 0.3226 - val_loss: 4.0405 - val_VL_attention_linear_output_loss: 1.8682 - val_VH_attention_linear_output_loss: 2.1723 - val_VL_attention_linear_output_acc: 0.4510 - val_VH_attention_linear_output_acc: 0.3222\n",
      "Epoch 485/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0174 - VL_attention_linear_output_loss: 1.8449 - VH_attention_linear_output_loss: 2.1724 - VL_attention_linear_output_acc: 0.4638 - VH_attention_linear_output_acc: 0.3243 - val_loss: 4.0188 - val_VL_attention_linear_output_loss: 1.8487 - val_VH_attention_linear_output_loss: 2.1701 - val_VL_attention_linear_output_acc: 0.4656 - val_VH_attention_linear_output_acc: 0.3210\n",
      "Epoch 486/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0291 - VL_attention_linear_output_loss: 1.8595 - VH_attention_linear_output_loss: 2.1695 - VL_attention_linear_output_acc: 0.4554 - VH_attention_linear_output_acc: 0.3239 - val_loss: 4.0167 - val_VL_attention_linear_output_loss: 1.8496 - val_VH_attention_linear_output_loss: 2.1671 - val_VL_attention_linear_output_acc: 0.4642 - val_VH_attention_linear_output_acc: 0.3201\n",
      "Epoch 487/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0130 - VL_attention_linear_output_loss: 1.8455 - VH_attention_linear_output_loss: 2.1675 - VL_attention_linear_output_acc: 0.4621 - VH_attention_linear_output_acc: 0.3232 - val_loss: 4.0278 - val_VL_attention_linear_output_loss: 1.8595 - val_VH_attention_linear_output_loss: 2.1683 - val_VL_attention_linear_output_acc: 0.4604 - val_VH_attention_linear_output_acc: 0.3220\n",
      "Epoch 488/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0161 - VL_attention_linear_output_loss: 1.8515 - VH_attention_linear_output_loss: 2.1646 - VL_attention_linear_output_acc: 0.4583 - VH_attention_linear_output_acc: 0.3241 - val_loss: 4.0147 - val_VL_attention_linear_output_loss: 1.8532 - val_VH_attention_linear_output_loss: 2.1615 - val_VL_attention_linear_output_acc: 0.4646 - val_VH_attention_linear_output_acc: 0.3249\n",
      "Epoch 489/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0222 - VL_attention_linear_output_loss: 1.8585 - VH_attention_linear_output_loss: 2.1637 - VL_attention_linear_output_acc: 0.4559 - VH_attention_linear_output_acc: 0.3243 - val_loss: 4.0540 - val_VL_attention_linear_output_loss: 1.8785 - val_VH_attention_linear_output_loss: 2.1755 - val_VL_attention_linear_output_acc: 0.4531 - val_VH_attention_linear_output_acc: 0.3109\n",
      "Epoch 490/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0234 - VL_attention_linear_output_loss: 1.8610 - VH_attention_linear_output_loss: 2.1624 - VL_attention_linear_output_acc: 0.4543 - VH_attention_linear_output_acc: 0.3244 - val_loss: 4.0483 - val_VL_attention_linear_output_loss: 1.8892 - val_VH_attention_linear_output_loss: 2.1592 - val_VL_attention_linear_output_acc: 0.4438 - val_VH_attention_linear_output_acc: 0.3231\n",
      "Epoch 491/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0102 - VL_attention_linear_output_loss: 1.8495 - VH_attention_linear_output_loss: 2.1607 - VL_attention_linear_output_acc: 0.4601 - VH_attention_linear_output_acc: 0.3250 - val_loss: 4.0074 - val_VL_attention_linear_output_loss: 1.8504 - val_VH_attention_linear_output_loss: 2.1570 - val_VL_attention_linear_output_acc: 0.4697 - val_VH_attention_linear_output_acc: 0.3264\n",
      "Epoch 492/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0101 - VL_attention_linear_output_loss: 1.8508 - VH_attention_linear_output_loss: 2.1593 - VL_attention_linear_output_acc: 0.4583 - VH_attention_linear_output_acc: 0.3250 - val_loss: 4.0422 - val_VL_attention_linear_output_loss: 1.8835 - val_VH_attention_linear_output_loss: 2.1587 - val_VL_attention_linear_output_acc: 0.4443 - val_VH_attention_linear_output_acc: 0.3235\n",
      "Epoch 493/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0080 - VL_attention_linear_output_loss: 1.8499 - VH_attention_linear_output_loss: 2.1581 - VL_attention_linear_output_acc: 0.4595 - VH_attention_linear_output_acc: 0.3255 - val_loss: 4.0152 - val_VL_attention_linear_output_loss: 1.8550 - val_VH_attention_linear_output_loss: 2.1602 - val_VL_attention_linear_output_acc: 0.4548 - val_VH_attention_linear_output_acc: 0.3235\n",
      "Epoch 494/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0060 - VL_attention_linear_output_loss: 1.8499 - VH_attention_linear_output_loss: 2.1562 - VL_attention_linear_output_acc: 0.4594 - VH_attention_linear_output_acc: 0.3270 - val_loss: 4.0098 - val_VL_attention_linear_output_loss: 1.8548 - val_VH_attention_linear_output_loss: 2.1550 - val_VL_attention_linear_output_acc: 0.4583 - val_VH_attention_linear_output_acc: 0.3226\n",
      "Epoch 495/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0189 - VL_attention_linear_output_loss: 1.8634 - VH_attention_linear_output_loss: 2.1555 - VL_attention_linear_output_acc: 0.4516 - VH_attention_linear_output_acc: 0.3262 - val_loss: 4.0156 - val_VL_attention_linear_output_loss: 1.8602 - val_VH_attention_linear_output_loss: 2.1554 - val_VL_attention_linear_output_acc: 0.4596 - val_VH_attention_linear_output_acc: 0.3262\n",
      "Epoch 496/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0097 - VL_attention_linear_output_loss: 1.8521 - VH_attention_linear_output_loss: 2.1576 - VL_attention_linear_output_acc: 0.4597 - VH_attention_linear_output_acc: 0.3246 - val_loss: 4.0077 - val_VL_attention_linear_output_loss: 1.8462 - val_VH_attention_linear_output_loss: 2.1614 - val_VL_attention_linear_output_acc: 0.4658 - val_VH_attention_linear_output_acc: 0.3188\n",
      "Epoch 497/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0248 - VL_attention_linear_output_loss: 1.8666 - VH_attention_linear_output_loss: 2.1582 - VL_attention_linear_output_acc: 0.4504 - VH_attention_linear_output_acc: 0.3244 - val_loss: 4.0383 - val_VL_attention_linear_output_loss: 1.8771 - val_VH_attention_linear_output_loss: 2.1612 - val_VL_attention_linear_output_acc: 0.4486 - val_VH_attention_linear_output_acc: 0.3241\n",
      "Epoch 498/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0208 - VL_attention_linear_output_loss: 1.8600 - VH_attention_linear_output_loss: 2.1608 - VL_attention_linear_output_acc: 0.4550 - VH_attention_linear_output_acc: 0.3235 - val_loss: 4.0157 - val_VL_attention_linear_output_loss: 1.8589 - val_VH_attention_linear_output_loss: 2.1568 - val_VL_attention_linear_output_acc: 0.4573 - val_VH_attention_linear_output_acc: 0.3243\n",
      "Epoch 499/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0080 - VL_attention_linear_output_loss: 1.8503 - VH_attention_linear_output_loss: 2.1577 - VL_attention_linear_output_acc: 0.4610 - VH_attention_linear_output_acc: 0.3256 - val_loss: 4.0399 - val_VL_attention_linear_output_loss: 1.8718 - val_VH_attention_linear_output_loss: 2.1681 - val_VL_attention_linear_output_acc: 0.4595 - val_VH_attention_linear_output_acc: 0.3157\n",
      "Epoch 500/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0152 - VL_attention_linear_output_loss: 1.8553 - VH_attention_linear_output_loss: 2.1599 - VL_attention_linear_output_acc: 0.4567 - VH_attention_linear_output_acc: 0.3234 - val_loss: 4.0157 - val_VL_attention_linear_output_loss: 1.8546 - val_VH_attention_linear_output_loss: 2.1610 - val_VL_attention_linear_output_acc: 0.4579 - val_VH_attention_linear_output_acc: 0.3206\n",
      "Epoch 501/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9926 - VL_attention_linear_output_loss: 1.8401 - VH_attention_linear_output_loss: 2.1524 - VL_attention_linear_output_acc: 0.4640 - VH_attention_linear_output_acc: 0.3274 - val_loss: 4.0148 - val_VL_attention_linear_output_loss: 1.8562 - val_VH_attention_linear_output_loss: 2.1586 - val_VL_attention_linear_output_acc: 0.4594 - val_VH_attention_linear_output_acc: 0.3225\n",
      "Epoch 502/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0059 - VL_attention_linear_output_loss: 1.8524 - VH_attention_linear_output_loss: 2.1535 - VL_attention_linear_output_acc: 0.4581 - VH_attention_linear_output_acc: 0.3260 - val_loss: 4.0043 - val_VL_attention_linear_output_loss: 1.8525 - val_VH_attention_linear_output_loss: 2.1518 - val_VL_attention_linear_output_acc: 0.4700 - val_VH_attention_linear_output_acc: 0.3256\n",
      "Epoch 503/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0052 - VL_attention_linear_output_loss: 1.8520 - VH_attention_linear_output_loss: 2.1532 - VL_attention_linear_output_acc: 0.4596 - VH_attention_linear_output_acc: 0.3246 - val_loss: 4.0310 - val_VL_attention_linear_output_loss: 1.8764 - val_VH_attention_linear_output_loss: 2.1546 - val_VL_attention_linear_output_acc: 0.4535 - val_VH_attention_linear_output_acc: 0.3207\n",
      "Epoch 504/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0091 - VL_attention_linear_output_loss: 1.8544 - VH_attention_linear_output_loss: 2.1547 - VL_attention_linear_output_acc: 0.4568 - VH_attention_linear_output_acc: 0.3247 - val_loss: 4.0173 - val_VL_attention_linear_output_loss: 1.8594 - val_VH_attention_linear_output_loss: 2.1579 - val_VL_attention_linear_output_acc: 0.4595 - val_VH_attention_linear_output_acc: 0.3181\n",
      "Epoch 505/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0050 - VL_attention_linear_output_loss: 1.8531 - VH_attention_linear_output_loss: 2.1518 - VL_attention_linear_output_acc: 0.4581 - VH_attention_linear_output_acc: 0.3259 - val_loss: 3.9968 - val_VL_attention_linear_output_loss: 1.8486 - val_VH_attention_linear_output_loss: 2.1482 - val_VL_attention_linear_output_acc: 0.4708 - val_VH_attention_linear_output_acc: 0.3250\n",
      "Epoch 506/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0039 - VL_attention_linear_output_loss: 1.8539 - VH_attention_linear_output_loss: 2.1500 - VL_attention_linear_output_acc: 0.4585 - VH_attention_linear_output_acc: 0.3269 - val_loss: 4.0261 - val_VL_attention_linear_output_loss: 1.8771 - val_VH_attention_linear_output_loss: 2.1490 - val_VL_attention_linear_output_acc: 0.4469 - val_VH_attention_linear_output_acc: 0.3256\n",
      "Epoch 507/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0113 - VL_attention_linear_output_loss: 1.8550 - VH_attention_linear_output_loss: 2.1563 - VL_attention_linear_output_acc: 0.4572 - VH_attention_linear_output_acc: 0.3228 - val_loss: 4.0176 - val_VL_attention_linear_output_loss: 1.8608 - val_VH_attention_linear_output_loss: 2.1568 - val_VL_attention_linear_output_acc: 0.4542 - val_VH_attention_linear_output_acc: 0.3273\n",
      "Epoch 508/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0161 - VL_attention_linear_output_loss: 1.8621 - VH_attention_linear_output_loss: 2.1540 - VL_attention_linear_output_acc: 0.4527 - VH_attention_linear_output_acc: 0.3260 - val_loss: 4.0062 - val_VL_attention_linear_output_loss: 1.8512 - val_VH_attention_linear_output_loss: 2.1550 - val_VL_attention_linear_output_acc: 0.4618 - val_VH_attention_linear_output_acc: 0.3244\n",
      "Epoch 509/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0010 - VL_attention_linear_output_loss: 1.8474 - VH_attention_linear_output_loss: 2.1536 - VL_attention_linear_output_acc: 0.4613 - VH_attention_linear_output_acc: 0.3243 - val_loss: 4.0263 - val_VL_attention_linear_output_loss: 1.8544 - val_VH_attention_linear_output_loss: 2.1720 - val_VL_attention_linear_output_acc: 0.4633 - val_VH_attention_linear_output_acc: 0.3152\n",
      "Epoch 510/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0193 - VL_attention_linear_output_loss: 1.8677 - VH_attention_linear_output_loss: 2.1517 - VL_attention_linear_output_acc: 0.4509 - VH_attention_linear_output_acc: 0.3269 - val_loss: 4.0192 - val_VL_attention_linear_output_loss: 1.8635 - val_VH_attention_linear_output_loss: 2.1557 - val_VL_attention_linear_output_acc: 0.4533 - val_VH_attention_linear_output_acc: 0.3251\n",
      "Epoch 511/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3196 - VL_attention_linear_output_loss: 1.8530 - VH_attention_linear_output_loss: 2.4666 - VL_attention_linear_output_acc: 0.4589 - VH_attention_linear_output_acc: 0.2697 - val_loss: 4.3250 - val_VL_attention_linear_output_loss: 1.8502 - val_VH_attention_linear_output_loss: 2.4747 - val_VL_attention_linear_output_acc: 0.4643 - val_VH_attention_linear_output_acc: 0.2547\n",
      "Epoch 512/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.2612 - VL_attention_linear_output_loss: 1.8591 - VH_attention_linear_output_loss: 2.4021 - VL_attention_linear_output_acc: 0.4555 - VH_attention_linear_output_acc: 0.2785 - val_loss: 4.2431 - val_VL_attention_linear_output_loss: 1.8572 - val_VH_attention_linear_output_loss: 2.3859 - val_VL_attention_linear_output_acc: 0.4605 - val_VH_attention_linear_output_acc: 0.2854\n",
      "Epoch 513/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1884 - VL_attention_linear_output_loss: 1.8405 - VH_attention_linear_output_loss: 2.3479 - VL_attention_linear_output_acc: 0.4650 - VH_attention_linear_output_acc: 0.2921 - val_loss: 4.1609 - val_VL_attention_linear_output_loss: 1.8591 - val_VH_attention_linear_output_loss: 2.3018 - val_VL_attention_linear_output_acc: 0.4599 - val_VH_attention_linear_output_acc: 0.3029\n",
      "Epoch 514/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1252 - VL_attention_linear_output_loss: 1.8521 - VH_attention_linear_output_loss: 2.2731 - VL_attention_linear_output_acc: 0.4586 - VH_attention_linear_output_acc: 0.2886 - val_loss: 4.0227 - val_VL_attention_linear_output_loss: 1.8512 - val_VH_attention_linear_output_loss: 2.1715 - val_VL_attention_linear_output_acc: 0.4634 - val_VH_attention_linear_output_acc: 0.3210\n",
      "Epoch 515/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9997 - VL_attention_linear_output_loss: 1.8382 - VH_attention_linear_output_loss: 2.1615 - VL_attention_linear_output_acc: 0.4646 - VH_attention_linear_output_acc: 0.3257 - val_loss: 4.0008 - val_VL_attention_linear_output_loss: 1.8504 - val_VH_attention_linear_output_loss: 2.1505 - val_VL_attention_linear_output_acc: 0.4619 - val_VH_attention_linear_output_acc: 0.3294\n",
      "Epoch 516/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9994 - VL_attention_linear_output_loss: 1.8484 - VH_attention_linear_output_loss: 2.1509 - VL_attention_linear_output_acc: 0.4596 - VH_attention_linear_output_acc: 0.3292 - val_loss: 4.0424 - val_VL_attention_linear_output_loss: 1.8822 - val_VH_attention_linear_output_loss: 2.1602 - val_VL_attention_linear_output_acc: 0.4589 - val_VH_attention_linear_output_acc: 0.3211\n",
      "Epoch 517/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9969 - VL_attention_linear_output_loss: 1.8451 - VH_attention_linear_output_loss: 2.1519 - VL_attention_linear_output_acc: 0.4620 - VH_attention_linear_output_acc: 0.3287 - val_loss: 4.0933 - val_VL_attention_linear_output_loss: 1.9340 - val_VH_attention_linear_output_loss: 2.1593 - val_VL_attention_linear_output_acc: 0.4139 - val_VH_attention_linear_output_acc: 0.3149\n",
      "Epoch 518/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0072 - VL_attention_linear_output_loss: 1.8555 - VH_attention_linear_output_loss: 2.1517 - VL_attention_linear_output_acc: 0.4558 - VH_attention_linear_output_acc: 0.3276 - val_loss: 4.0614 - val_VL_attention_linear_output_loss: 1.8889 - val_VH_attention_linear_output_loss: 2.1725 - val_VL_attention_linear_output_acc: 0.4504 - val_VH_attention_linear_output_acc: 0.3199\n",
      "Epoch 519/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0000 - VL_attention_linear_output_loss: 1.8482 - VH_attention_linear_output_loss: 2.1518 - VL_attention_linear_output_acc: 0.4611 - VH_attention_linear_output_acc: 0.3272 - val_loss: 3.9913 - val_VL_attention_linear_output_loss: 1.8464 - val_VH_attention_linear_output_loss: 2.1449 - val_VL_attention_linear_output_acc: 0.4674 - val_VH_attention_linear_output_acc: 0.3299\n",
      "Epoch 520/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0004 - VL_attention_linear_output_loss: 1.8543 - VH_attention_linear_output_loss: 2.1460 - VL_attention_linear_output_acc: 0.4565 - VH_attention_linear_output_acc: 0.3296 - val_loss: 3.9884 - val_VL_attention_linear_output_loss: 1.8456 - val_VH_attention_linear_output_loss: 2.1428 - val_VL_attention_linear_output_acc: 0.4666 - val_VH_attention_linear_output_acc: 0.3272\n",
      "Epoch 521/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9760 - VL_attention_linear_output_loss: 1.8348 - VH_attention_linear_output_loss: 2.1412 - VL_attention_linear_output_acc: 0.4669 - VH_attention_linear_output_acc: 0.3318 - val_loss: 3.9866 - val_VL_attention_linear_output_loss: 1.8459 - val_VH_attention_linear_output_loss: 2.1406 - val_VL_attention_linear_output_acc: 0.4625 - val_VH_attention_linear_output_acc: 0.3303\n",
      "Epoch 522/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0042 - VL_attention_linear_output_loss: 1.8489 - VH_attention_linear_output_loss: 2.1553 - VL_attention_linear_output_acc: 0.4594 - VH_attention_linear_output_acc: 0.3250 - val_loss: 4.0802 - val_VL_attention_linear_output_loss: 1.9403 - val_VH_attention_linear_output_loss: 2.1398 - val_VL_attention_linear_output_acc: 0.3962 - val_VH_attention_linear_output_acc: 0.3309\n",
      "Epoch 523/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0066 - VL_attention_linear_output_loss: 1.8659 - VH_attention_linear_output_loss: 2.1408 - VL_attention_linear_output_acc: 0.4501 - VH_attention_linear_output_acc: 0.3317 - val_loss: 3.9861 - val_VL_attention_linear_output_loss: 1.8466 - val_VH_attention_linear_output_loss: 2.1394 - val_VL_attention_linear_output_acc: 0.4636 - val_VH_attention_linear_output_acc: 0.3266\n",
      "Epoch 524/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9822 - VL_attention_linear_output_loss: 1.8444 - VH_attention_linear_output_loss: 2.1377 - VL_attention_linear_output_acc: 0.4615 - VH_attention_linear_output_acc: 0.3331 - val_loss: 3.9931 - val_VL_attention_linear_output_loss: 1.8509 - val_VH_attention_linear_output_loss: 2.1422 - val_VL_attention_linear_output_acc: 0.4625 - val_VH_attention_linear_output_acc: 0.3256\n",
      "Epoch 525/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9880 - VL_attention_linear_output_loss: 1.8461 - VH_attention_linear_output_loss: 2.1419 - VL_attention_linear_output_acc: 0.4609 - VH_attention_linear_output_acc: 0.3298 - val_loss: 3.9815 - val_VL_attention_linear_output_loss: 1.8456 - val_VH_attention_linear_output_loss: 2.1359 - val_VL_attention_linear_output_acc: 0.4643 - val_VH_attention_linear_output_acc: 0.3340\n",
      "Epoch 526/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9996 - VL_attention_linear_output_loss: 1.8456 - VH_attention_linear_output_loss: 2.1540 - VL_attention_linear_output_acc: 0.4609 - VH_attention_linear_output_acc: 0.3247 - val_loss: 4.0000 - val_VL_attention_linear_output_loss: 1.8549 - val_VH_attention_linear_output_loss: 2.1451 - val_VL_attention_linear_output_acc: 0.4611 - val_VH_attention_linear_output_acc: 0.3305\n",
      "Epoch 527/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9861 - VL_attention_linear_output_loss: 1.8455 - VH_attention_linear_output_loss: 2.1406 - VL_attention_linear_output_acc: 0.4608 - VH_attention_linear_output_acc: 0.3329 - val_loss: 3.9842 - val_VL_attention_linear_output_loss: 1.8455 - val_VH_attention_linear_output_loss: 2.1387 - val_VL_attention_linear_output_acc: 0.4660 - val_VH_attention_linear_output_acc: 0.3330\n",
      "Epoch 528/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9756 - VL_attention_linear_output_loss: 1.8381 - VH_attention_linear_output_loss: 2.1374 - VL_attention_linear_output_acc: 0.4642 - VH_attention_linear_output_acc: 0.3330 - val_loss: 3.9842 - val_VL_attention_linear_output_loss: 1.8465 - val_VH_attention_linear_output_loss: 2.1377 - val_VL_attention_linear_output_acc: 0.4660 - val_VH_attention_linear_output_acc: 0.3319\n",
      "Epoch 529/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9774 - VL_attention_linear_output_loss: 1.8401 - VH_attention_linear_output_loss: 2.1373 - VL_attention_linear_output_acc: 0.4635 - VH_attention_linear_output_acc: 0.3325 - val_loss: 3.9928 - val_VL_attention_linear_output_loss: 1.8535 - val_VH_attention_linear_output_loss: 2.1393 - val_VL_attention_linear_output_acc: 0.4673 - val_VH_attention_linear_output_acc: 0.3297\n",
      "Epoch 530/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9947 - VL_attention_linear_output_loss: 1.8592 - VH_attention_linear_output_loss: 2.1355 - VL_attention_linear_output_acc: 0.4539 - VH_attention_linear_output_acc: 0.3328 - val_loss: 3.9785 - val_VL_attention_linear_output_loss: 1.8414 - val_VH_attention_linear_output_loss: 2.1371 - val_VL_attention_linear_output_acc: 0.4655 - val_VH_attention_linear_output_acc: 0.3320\n",
      "Epoch 531/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9697 - VL_attention_linear_output_loss: 1.8338 - VH_attention_linear_output_loss: 2.1359 - VL_attention_linear_output_acc: 0.4662 - VH_attention_linear_output_acc: 0.3323 - val_loss: 3.9836 - val_VL_attention_linear_output_loss: 1.8429 - val_VH_attention_linear_output_loss: 2.1407 - val_VL_attention_linear_output_acc: 0.4672 - val_VH_attention_linear_output_acc: 0.3269\n",
      "Epoch 532/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9706 - VL_attention_linear_output_loss: 1.8327 - VH_attention_linear_output_loss: 2.1378 - VL_attention_linear_output_acc: 0.4661 - VH_attention_linear_output_acc: 0.3298 - val_loss: 3.9803 - val_VL_attention_linear_output_loss: 1.8502 - val_VH_attention_linear_output_loss: 2.1301 - val_VL_attention_linear_output_acc: 0.4643 - val_VH_attention_linear_output_acc: 0.3330\n",
      "Epoch 533/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9994 - VL_attention_linear_output_loss: 1.8631 - VH_attention_linear_output_loss: 2.1363 - VL_attention_linear_output_acc: 0.4518 - VH_attention_linear_output_acc: 0.3314 - val_loss: 3.9815 - val_VL_attention_linear_output_loss: 1.8467 - val_VH_attention_linear_output_loss: 2.1348 - val_VL_attention_linear_output_acc: 0.4617 - val_VH_attention_linear_output_acc: 0.3315\n",
      "Epoch 534/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9785 - VL_attention_linear_output_loss: 1.8428 - VH_attention_linear_output_loss: 2.1356 - VL_attention_linear_output_acc: 0.4619 - VH_attention_linear_output_acc: 0.3309 - val_loss: 3.9813 - val_VL_attention_linear_output_loss: 1.8490 - val_VH_attention_linear_output_loss: 2.1323 - val_VL_attention_linear_output_acc: 0.4673 - val_VH_attention_linear_output_acc: 0.3324\n",
      "Epoch 535/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9753 - VL_attention_linear_output_loss: 1.8403 - VH_attention_linear_output_loss: 2.1350 - VL_attention_linear_output_acc: 0.4642 - VH_attention_linear_output_acc: 0.3309 - val_loss: 3.9788 - val_VL_attention_linear_output_loss: 1.8469 - val_VH_attention_linear_output_loss: 2.1319 - val_VL_attention_linear_output_acc: 0.4634 - val_VH_attention_linear_output_acc: 0.3360\n",
      "Epoch 536/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9770 - VL_attention_linear_output_loss: 1.8429 - VH_attention_linear_output_loss: 2.1341 - VL_attention_linear_output_acc: 0.4629 - VH_attention_linear_output_acc: 0.3314 - val_loss: 4.0055 - val_VL_attention_linear_output_loss: 1.8625 - val_VH_attention_linear_output_loss: 2.1430 - val_VL_attention_linear_output_acc: 0.4621 - val_VH_attention_linear_output_acc: 0.3251\n",
      "Epoch 537/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0000 - VL_attention_linear_output_loss: 1.8643 - VH_attention_linear_output_loss: 2.1357 - VL_attention_linear_output_acc: 0.4502 - VH_attention_linear_output_acc: 0.3312 - val_loss: 3.9853 - val_VL_attention_linear_output_loss: 1.8512 - val_VH_attention_linear_output_loss: 2.1341 - val_VL_attention_linear_output_acc: 0.4574 - val_VH_attention_linear_output_acc: 0.3341\n",
      "Epoch 538/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9696 - VL_attention_linear_output_loss: 1.8326 - VH_attention_linear_output_loss: 2.1370 - VL_attention_linear_output_acc: 0.4671 - VH_attention_linear_output_acc: 0.3295 - val_loss: 3.9947 - val_VL_attention_linear_output_loss: 1.8558 - val_VH_attention_linear_output_loss: 2.1389 - val_VL_attention_linear_output_acc: 0.4659 - val_VH_attention_linear_output_acc: 0.3288\n",
      "Epoch 539/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9931 - VL_attention_linear_output_loss: 1.8557 - VH_attention_linear_output_loss: 2.1374 - VL_attention_linear_output_acc: 0.4555 - VH_attention_linear_output_acc: 0.3292 - val_loss: 3.9910 - val_VL_attention_linear_output_loss: 1.8547 - val_VH_attention_linear_output_loss: 2.1363 - val_VL_attention_linear_output_acc: 0.4604 - val_VH_attention_linear_output_acc: 0.3303\n",
      "Epoch 540/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9938 - VL_attention_linear_output_loss: 1.8546 - VH_attention_linear_output_loss: 2.1392 - VL_attention_linear_output_acc: 0.4564 - VH_attention_linear_output_acc: 0.3296 - val_loss: 4.0079 - val_VL_attention_linear_output_loss: 1.8619 - val_VH_attention_linear_output_loss: 2.1460 - val_VL_attention_linear_output_acc: 0.4642 - val_VH_attention_linear_output_acc: 0.3250\n",
      "Epoch 541/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9836 - VL_attention_linear_output_loss: 1.8486 - VH_attention_linear_output_loss: 2.1351 - VL_attention_linear_output_acc: 0.4593 - VH_attention_linear_output_acc: 0.3313 - val_loss: 4.0190 - val_VL_attention_linear_output_loss: 1.8697 - val_VH_attention_linear_output_loss: 2.1493 - val_VL_attention_linear_output_acc: 0.4467 - val_VH_attention_linear_output_acc: 0.3209\n",
      "Epoch 542/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9721 - VL_attention_linear_output_loss: 1.8360 - VH_attention_linear_output_loss: 2.1361 - VL_attention_linear_output_acc: 0.4653 - VH_attention_linear_output_acc: 0.3302 - val_loss: 4.0071 - val_VL_attention_linear_output_loss: 1.8500 - val_VH_attention_linear_output_loss: 2.1570 - val_VL_attention_linear_output_acc: 0.4638 - val_VH_attention_linear_output_acc: 0.3131\n",
      "Epoch 543/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9686 - VL_attention_linear_output_loss: 1.8334 - VH_attention_linear_output_loss: 2.1351 - VL_attention_linear_output_acc: 0.4669 - VH_attention_linear_output_acc: 0.3299 - val_loss: 4.0142 - val_VL_attention_linear_output_loss: 1.8723 - val_VH_attention_linear_output_loss: 2.1419 - val_VL_attention_linear_output_acc: 0.4554 - val_VH_attention_linear_output_acc: 0.3284\n",
      "Epoch 544/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9872 - VL_attention_linear_output_loss: 1.8489 - VH_attention_linear_output_loss: 2.1384 - VL_attention_linear_output_acc: 0.4587 - VH_attention_linear_output_acc: 0.3286 - val_loss: 4.0084 - val_VL_attention_linear_output_loss: 1.8717 - val_VH_attention_linear_output_loss: 2.1367 - val_VL_attention_linear_output_acc: 0.4388 - val_VH_attention_linear_output_acc: 0.3287\n",
      "Epoch 545/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9812 - VL_attention_linear_output_loss: 1.8471 - VH_attention_linear_output_loss: 2.1340 - VL_attention_linear_output_acc: 0.4591 - VH_attention_linear_output_acc: 0.3310 - val_loss: 3.9835 - val_VL_attention_linear_output_loss: 1.8456 - val_VH_attention_linear_output_loss: 2.1379 - val_VL_attention_linear_output_acc: 0.4630 - val_VH_attention_linear_output_acc: 0.3235\n",
      "Epoch 546/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9856 - VL_attention_linear_output_loss: 1.8508 - VH_attention_linear_output_loss: 2.1348 - VL_attention_linear_output_acc: 0.4587 - VH_attention_linear_output_acc: 0.3307 - val_loss: 4.0144 - val_VL_attention_linear_output_loss: 1.8866 - val_VH_attention_linear_output_loss: 2.1278 - val_VL_attention_linear_output_acc: 0.4360 - val_VH_attention_linear_output_acc: 0.3345\n",
      "Epoch 547/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9693 - VL_attention_linear_output_loss: 1.8377 - VH_attention_linear_output_loss: 2.1316 - VL_attention_linear_output_acc: 0.4658 - VH_attention_linear_output_acc: 0.3330 - val_loss: 4.0084 - val_VL_attention_linear_output_loss: 1.8802 - val_VH_attention_linear_output_loss: 2.1282 - val_VL_attention_linear_output_acc: 0.4470 - val_VH_attention_linear_output_acc: 0.3353\n",
      "Epoch 548/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9759 - VL_attention_linear_output_loss: 1.8377 - VH_attention_linear_output_loss: 2.1382 - VL_attention_linear_output_acc: 0.4650 - VH_attention_linear_output_acc: 0.3316 - val_loss: 3.9704 - val_VL_attention_linear_output_loss: 1.8404 - val_VH_attention_linear_output_loss: 2.1300 - val_VL_attention_linear_output_acc: 0.4662 - val_VH_attention_linear_output_acc: 0.3371\n",
      "Epoch 549/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9973 - VL_attention_linear_output_loss: 1.8616 - VH_attention_linear_output_loss: 2.1357 - VL_attention_linear_output_acc: 0.4506 - VH_attention_linear_output_acc: 0.3307 - val_loss: 4.0339 - val_VL_attention_linear_output_loss: 1.8841 - val_VH_attention_linear_output_loss: 2.1498 - val_VL_attention_linear_output_acc: 0.4567 - val_VH_attention_linear_output_acc: 0.3233\n",
      "Epoch 550/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9628 - VL_attention_linear_output_loss: 1.8336 - VH_attention_linear_output_loss: 2.1292 - VL_attention_linear_output_acc: 0.4664 - VH_attention_linear_output_acc: 0.3343 - val_loss: 3.9707 - val_VL_attention_linear_output_loss: 1.8393 - val_VH_attention_linear_output_loss: 2.1314 - val_VL_attention_linear_output_acc: 0.4676 - val_VH_attention_linear_output_acc: 0.3334\n",
      "Epoch 551/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9637 - VL_attention_linear_output_loss: 1.8334 - VH_attention_linear_output_loss: 2.1303 - VL_attention_linear_output_acc: 0.4666 - VH_attention_linear_output_acc: 0.3326 - val_loss: 3.9725 - val_VL_attention_linear_output_loss: 1.8388 - val_VH_attention_linear_output_loss: 2.1338 - val_VL_attention_linear_output_acc: 0.4677 - val_VH_attention_linear_output_acc: 0.3294\n",
      "Epoch 552/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9613 - VL_attention_linear_output_loss: 1.8304 - VH_attention_linear_output_loss: 2.1310 - VL_attention_linear_output_acc: 0.4680 - VH_attention_linear_output_acc: 0.3322 - val_loss: 4.0223 - val_VL_attention_linear_output_loss: 1.8904 - val_VH_attention_linear_output_loss: 2.1319 - val_VL_attention_linear_output_acc: 0.4347 - val_VH_attention_linear_output_acc: 0.3300\n",
      "Epoch 553/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9827 - VL_attention_linear_output_loss: 1.8471 - VH_attention_linear_output_loss: 2.1355 - VL_attention_linear_output_acc: 0.4581 - VH_attention_linear_output_acc: 0.3298 - val_loss: 3.9882 - val_VL_attention_linear_output_loss: 1.8577 - val_VH_attention_linear_output_loss: 2.1306 - val_VL_attention_linear_output_acc: 0.4586 - val_VH_attention_linear_output_acc: 0.3325\n",
      "Epoch 554/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9993 - VL_attention_linear_output_loss: 1.8636 - VH_attention_linear_output_loss: 2.1358 - VL_attention_linear_output_acc: 0.4508 - VH_attention_linear_output_acc: 0.3291 - val_loss: 3.9861 - val_VL_attention_linear_output_loss: 1.8494 - val_VH_attention_linear_output_loss: 2.1366 - val_VL_attention_linear_output_acc: 0.4663 - val_VH_attention_linear_output_acc: 0.3303\n",
      "Epoch 555/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9770 - VL_attention_linear_output_loss: 1.8409 - VH_attention_linear_output_loss: 2.1360 - VL_attention_linear_output_acc: 0.4631 - VH_attention_linear_output_acc: 0.3294 - val_loss: 3.9685 - val_VL_attention_linear_output_loss: 1.8430 - val_VH_attention_linear_output_loss: 2.1255 - val_VL_attention_linear_output_acc: 0.4648 - val_VH_attention_linear_output_acc: 0.3404\n",
      "Epoch 556/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9641 - VL_attention_linear_output_loss: 1.8337 - VH_attention_linear_output_loss: 2.1304 - VL_attention_linear_output_acc: 0.4657 - VH_attention_linear_output_acc: 0.3334 - val_loss: 3.9880 - val_VL_attention_linear_output_loss: 1.8453 - val_VH_attention_linear_output_loss: 2.1427 - val_VL_attention_linear_output_acc: 0.4586 - val_VH_attention_linear_output_acc: 0.3270\n",
      "Epoch 557/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9696 - VL_attention_linear_output_loss: 1.8356 - VH_attention_linear_output_loss: 2.1339 - VL_attention_linear_output_acc: 0.4644 - VH_attention_linear_output_acc: 0.3304 - val_loss: 3.9944 - val_VL_attention_linear_output_loss: 1.8579 - val_VH_attention_linear_output_loss: 2.1365 - val_VL_attention_linear_output_acc: 0.4606 - val_VH_attention_linear_output_acc: 0.3264\n",
      "Epoch 558/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9878 - VL_attention_linear_output_loss: 1.8507 - VH_attention_linear_output_loss: 2.1371 - VL_attention_linear_output_acc: 0.4573 - VH_attention_linear_output_acc: 0.3317 - val_loss: 3.9842 - val_VL_attention_linear_output_loss: 1.8426 - val_VH_attention_linear_output_loss: 2.1415 - val_VL_attention_linear_output_acc: 0.4645 - val_VH_attention_linear_output_acc: 0.3284\n",
      "Epoch 559/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9658 - VL_attention_linear_output_loss: 1.8334 - VH_attention_linear_output_loss: 2.1324 - VL_attention_linear_output_acc: 0.4656 - VH_attention_linear_output_acc: 0.3331 - val_loss: 4.0346 - val_VL_attention_linear_output_loss: 1.9141 - val_VH_attention_linear_output_loss: 2.1205 - val_VL_attention_linear_output_acc: 0.4220 - val_VH_attention_linear_output_acc: 0.3371\n",
      "Epoch 560/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9609 - VL_attention_linear_output_loss: 1.8354 - VH_attention_linear_output_loss: 2.1254 - VL_attention_linear_output_acc: 0.4652 - VH_attention_linear_output_acc: 0.3362 - val_loss: 3.9692 - val_VL_attention_linear_output_loss: 1.8379 - val_VH_attention_linear_output_loss: 2.1313 - val_VL_attention_linear_output_acc: 0.4735 - val_VH_attention_linear_output_acc: 0.3306\n",
      "Epoch 561/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9630 - VL_attention_linear_output_loss: 1.8372 - VH_attention_linear_output_loss: 2.1258 - VL_attention_linear_output_acc: 0.4644 - VH_attention_linear_output_acc: 0.3349 - val_loss: 3.9830 - val_VL_attention_linear_output_loss: 1.8453 - val_VH_attention_linear_output_loss: 2.1377 - val_VL_attention_linear_output_acc: 0.4659 - val_VH_attention_linear_output_acc: 0.3267\n",
      "Epoch 562/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9664 - VL_attention_linear_output_loss: 1.8387 - VH_attention_linear_output_loss: 2.1277 - VL_attention_linear_output_acc: 0.4631 - VH_attention_linear_output_acc: 0.3338 - val_loss: 3.9737 - val_VL_attention_linear_output_loss: 1.8423 - val_VH_attention_linear_output_loss: 2.1314 - val_VL_attention_linear_output_acc: 0.4649 - val_VH_attention_linear_output_acc: 0.3281\n",
      "Epoch 563/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9817 - VL_attention_linear_output_loss: 1.8552 - VH_attention_linear_output_loss: 2.1265 - VL_attention_linear_output_acc: 0.4546 - VH_attention_linear_output_acc: 0.3352 - val_loss: 3.9788 - val_VL_attention_linear_output_loss: 1.8452 - val_VH_attention_linear_output_loss: 2.1336 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.3263\n",
      "Epoch 564/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9621 - VL_attention_linear_output_loss: 1.8375 - VH_attention_linear_output_loss: 2.1247 - VL_attention_linear_output_acc: 0.4663 - VH_attention_linear_output_acc: 0.3356 - val_loss: 3.9663 - val_VL_attention_linear_output_loss: 1.8423 - val_VH_attention_linear_output_loss: 2.1241 - val_VL_attention_linear_output_acc: 0.4683 - val_VH_attention_linear_output_acc: 0.3362\n",
      "Epoch 565/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9580 - VL_attention_linear_output_loss: 1.8306 - VH_attention_linear_output_loss: 2.1275 - VL_attention_linear_output_acc: 0.4674 - VH_attention_linear_output_acc: 0.3330 - val_loss: 3.9687 - val_VL_attention_linear_output_loss: 1.8421 - val_VH_attention_linear_output_loss: 2.1266 - val_VL_attention_linear_output_acc: 0.4640 - val_VH_attention_linear_output_acc: 0.3348\n",
      "Epoch 566/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9614 - VL_attention_linear_output_loss: 1.8327 - VH_attention_linear_output_loss: 2.1287 - VL_attention_linear_output_acc: 0.4665 - VH_attention_linear_output_acc: 0.3331 - val_loss: 3.9700 - val_VL_attention_linear_output_loss: 1.8421 - val_VH_attention_linear_output_loss: 2.1279 - val_VL_attention_linear_output_acc: 0.4672 - val_VH_attention_linear_output_acc: 0.3298\n",
      "Epoch 567/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9846 - VL_attention_linear_output_loss: 1.8593 - VH_attention_linear_output_loss: 2.1253 - VL_attention_linear_output_acc: 0.4524 - VH_attention_linear_output_acc: 0.3345 - val_loss: 3.9643 - val_VL_attention_linear_output_loss: 1.8438 - val_VH_attention_linear_output_loss: 2.1205 - val_VL_attention_linear_output_acc: 0.4642 - val_VH_attention_linear_output_acc: 0.3337\n",
      "Epoch 568/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9570 - VL_attention_linear_output_loss: 1.8347 - VH_attention_linear_output_loss: 2.1223 - VL_attention_linear_output_acc: 0.4657 - VH_attention_linear_output_acc: 0.3365 - val_loss: 3.9774 - val_VL_attention_linear_output_loss: 1.8473 - val_VH_attention_linear_output_loss: 2.1301 - val_VL_attention_linear_output_acc: 0.4651 - val_VH_attention_linear_output_acc: 0.3269\n",
      "Epoch 569/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9720 - VL_attention_linear_output_loss: 1.8446 - VH_attention_linear_output_loss: 2.1275 - VL_attention_linear_output_acc: 0.4604 - VH_attention_linear_output_acc: 0.3322 - val_loss: 4.0553 - val_VL_attention_linear_output_loss: 1.9298 - val_VH_attention_linear_output_loss: 2.1254 - val_VL_attention_linear_output_acc: 0.4257 - val_VH_attention_linear_output_acc: 0.3325\n",
      "Epoch 570/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9607 - VL_attention_linear_output_loss: 1.8387 - VH_attention_linear_output_loss: 2.1220 - VL_attention_linear_output_acc: 0.4637 - VH_attention_linear_output_acc: 0.3363 - val_loss: 3.9553 - val_VL_attention_linear_output_loss: 1.8391 - val_VH_attention_linear_output_loss: 2.1162 - val_VL_attention_linear_output_acc: 0.4642 - val_VH_attention_linear_output_acc: 0.3394\n",
      "Epoch 571/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9566 - VL_attention_linear_output_loss: 1.8332 - VH_attention_linear_output_loss: 2.1234 - VL_attention_linear_output_acc: 0.4644 - VH_attention_linear_output_acc: 0.3359 - val_loss: 4.0029 - val_VL_attention_linear_output_loss: 1.8480 - val_VH_attention_linear_output_loss: 2.1550 - val_VL_attention_linear_output_acc: 0.4635 - val_VH_attention_linear_output_acc: 0.3194\n",
      "Epoch 572/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9807 - VL_attention_linear_output_loss: 1.8485 - VH_attention_linear_output_loss: 2.1322 - VL_attention_linear_output_acc: 0.4570 - VH_attention_linear_output_acc: 0.3302 - val_loss: 3.9712 - val_VL_attention_linear_output_loss: 1.8480 - val_VH_attention_linear_output_loss: 2.1232 - val_VL_attention_linear_output_acc: 0.4621 - val_VH_attention_linear_output_acc: 0.3331\n",
      "Epoch 573/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9511 - VL_attention_linear_output_loss: 1.8342 - VH_attention_linear_output_loss: 2.1169 - VL_attention_linear_output_acc: 0.4651 - VH_attention_linear_output_acc: 0.3390 - val_loss: 3.9692 - val_VL_attention_linear_output_loss: 1.8436 - val_VH_attention_linear_output_loss: 2.1257 - val_VL_attention_linear_output_acc: 0.4681 - val_VH_attention_linear_output_acc: 0.3342\n",
      "Epoch 574/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9764 - VL_attention_linear_output_loss: 1.8535 - VH_attention_linear_output_loss: 2.1229 - VL_attention_linear_output_acc: 0.4553 - VH_attention_linear_output_acc: 0.3352 - val_loss: 3.9687 - val_VL_attention_linear_output_loss: 1.8394 - val_VH_attention_linear_output_loss: 2.1293 - val_VL_attention_linear_output_acc: 0.4648 - val_VH_attention_linear_output_acc: 0.3349\n",
      "Epoch 575/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9442 - VL_attention_linear_output_loss: 1.8264 - VH_attention_linear_output_loss: 2.1177 - VL_attention_linear_output_acc: 0.4695 - VH_attention_linear_output_acc: 0.3383 - val_loss: 3.9891 - val_VL_attention_linear_output_loss: 1.8418 - val_VH_attention_linear_output_loss: 2.1473 - val_VL_attention_linear_output_acc: 0.4715 - val_VH_attention_linear_output_acc: 0.3167\n",
      "Epoch 576/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9601 - VL_attention_linear_output_loss: 1.8388 - VH_attention_linear_output_loss: 2.1213 - VL_attention_linear_output_acc: 0.4627 - VH_attention_linear_output_acc: 0.3356 - val_loss: 3.9723 - val_VL_attention_linear_output_loss: 1.8414 - val_VH_attention_linear_output_loss: 2.1308 - val_VL_attention_linear_output_acc: 0.4616 - val_VH_attention_linear_output_acc: 0.3304\n",
      "Epoch 577/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9474 - VL_attention_linear_output_loss: 1.8290 - VH_attention_linear_output_loss: 2.1184 - VL_attention_linear_output_acc: 0.4686 - VH_attention_linear_output_acc: 0.3371 - val_loss: 3.9551 - val_VL_attention_linear_output_loss: 1.8401 - val_VH_attention_linear_output_loss: 2.1150 - val_VL_attention_linear_output_acc: 0.4665 - val_VH_attention_linear_output_acc: 0.3402\n",
      "Epoch 578/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9669 - VL_attention_linear_output_loss: 1.8440 - VH_attention_linear_output_loss: 2.1229 - VL_attention_linear_output_acc: 0.4585 - VH_attention_linear_output_acc: 0.3333 - val_loss: 3.9782 - val_VL_attention_linear_output_loss: 1.8559 - val_VH_attention_linear_output_loss: 2.1223 - val_VL_attention_linear_output_acc: 0.4637 - val_VH_attention_linear_output_acc: 0.3359\n",
      "Epoch 579/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9514 - VL_attention_linear_output_loss: 1.8301 - VH_attention_linear_output_loss: 2.1213 - VL_attention_linear_output_acc: 0.4671 - VH_attention_linear_output_acc: 0.3357 - val_loss: 3.9563 - val_VL_attention_linear_output_loss: 1.8406 - val_VH_attention_linear_output_loss: 2.1157 - val_VL_attention_linear_output_acc: 0.4632 - val_VH_attention_linear_output_acc: 0.3389\n",
      "Epoch 580/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9582 - VL_attention_linear_output_loss: 1.8368 - VH_attention_linear_output_loss: 2.1213 - VL_attention_linear_output_acc: 0.4642 - VH_attention_linear_output_acc: 0.3363 - val_loss: 4.0311 - val_VL_attention_linear_output_loss: 1.9036 - val_VH_attention_linear_output_loss: 2.1275 - val_VL_attention_linear_output_acc: 0.4245 - val_VH_attention_linear_output_acc: 0.3360\n",
      "Epoch 581/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9661 - VL_attention_linear_output_loss: 1.8428 - VH_attention_linear_output_loss: 2.1233 - VL_attention_linear_output_acc: 0.4608 - VH_attention_linear_output_acc: 0.3343 - val_loss: 4.0187 - val_VL_attention_linear_output_loss: 1.8610 - val_VH_attention_linear_output_loss: 2.1577 - val_VL_attention_linear_output_acc: 0.4513 - val_VH_attention_linear_output_acc: 0.3103\n",
      "Epoch 582/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9597 - VL_attention_linear_output_loss: 1.8429 - VH_attention_linear_output_loss: 2.1168 - VL_attention_linear_output_acc: 0.4603 - VH_attention_linear_output_acc: 0.3379 - val_loss: 3.9812 - val_VL_attention_linear_output_loss: 1.8460 - val_VH_attention_linear_output_loss: 2.1352 - val_VL_attention_linear_output_acc: 0.4611 - val_VH_attention_linear_output_acc: 0.3300\n",
      "Epoch 583/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9564 - VL_attention_linear_output_loss: 1.8358 - VH_attention_linear_output_loss: 2.1206 - VL_attention_linear_output_acc: 0.4649 - VH_attention_linear_output_acc: 0.3366 - val_loss: 3.9650 - val_VL_attention_linear_output_loss: 1.8394 - val_VH_attention_linear_output_loss: 2.1255 - val_VL_attention_linear_output_acc: 0.4684 - val_VH_attention_linear_output_acc: 0.3315\n",
      "Epoch 584/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9628 - VL_attention_linear_output_loss: 1.8465 - VH_attention_linear_output_loss: 2.1163 - VL_attention_linear_output_acc: 0.4580 - VH_attention_linear_output_acc: 0.3383 - val_loss: 3.9652 - val_VL_attention_linear_output_loss: 1.8412 - val_VH_attention_linear_output_loss: 2.1239 - val_VL_attention_linear_output_acc: 0.4680 - val_VH_attention_linear_output_acc: 0.3372\n",
      "Epoch 585/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9506 - VL_attention_linear_output_loss: 1.8303 - VH_attention_linear_output_loss: 2.1202 - VL_attention_linear_output_acc: 0.4666 - VH_attention_linear_output_acc: 0.3360 - val_loss: 4.0050 - val_VL_attention_linear_output_loss: 1.8527 - val_VH_attention_linear_output_loss: 2.1523 - val_VL_attention_linear_output_acc: 0.4594 - val_VH_attention_linear_output_acc: 0.3144\n",
      "Epoch 586/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9581 - VL_attention_linear_output_loss: 1.8428 - VH_attention_linear_output_loss: 2.1153 - VL_attention_linear_output_acc: 0.4604 - VH_attention_linear_output_acc: 0.3386 - val_loss: 3.9581 - val_VL_attention_linear_output_loss: 1.8451 - val_VH_attention_linear_output_loss: 2.1129 - val_VL_attention_linear_output_acc: 0.4649 - val_VH_attention_linear_output_acc: 0.3401\n",
      "Epoch 587/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9489 - VL_attention_linear_output_loss: 1.8334 - VH_attention_linear_output_loss: 2.1155 - VL_attention_linear_output_acc: 0.4652 - VH_attention_linear_output_acc: 0.3382 - val_loss: 3.9842 - val_VL_attention_linear_output_loss: 1.8684 - val_VH_attention_linear_output_loss: 2.1158 - val_VL_attention_linear_output_acc: 0.4437 - val_VH_attention_linear_output_acc: 0.3373\n",
      "Epoch 588/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9525 - VL_attention_linear_output_loss: 1.8329 - VH_attention_linear_output_loss: 2.1196 - VL_attention_linear_output_acc: 0.4653 - VH_attention_linear_output_acc: 0.3364 - val_loss: 3.9460 - val_VL_attention_linear_output_loss: 1.8360 - val_VH_attention_linear_output_loss: 2.1100 - val_VL_attention_linear_output_acc: 0.4680 - val_VH_attention_linear_output_acc: 0.3457\n",
      "Epoch 589/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9569 - VL_attention_linear_output_loss: 1.8420 - VH_attention_linear_output_loss: 2.1149 - VL_attention_linear_output_acc: 0.4601 - VH_attention_linear_output_acc: 0.3390 - val_loss: 3.9736 - val_VL_attention_linear_output_loss: 1.8445 - val_VH_attention_linear_output_loss: 2.1291 - val_VL_attention_linear_output_acc: 0.4643 - val_VH_attention_linear_output_acc: 0.3300\n",
      "Epoch 590/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9616 - VL_attention_linear_output_loss: 1.8494 - VH_attention_linear_output_loss: 2.1122 - VL_attention_linear_output_acc: 0.4574 - VH_attention_linear_output_acc: 0.3403 - val_loss: 3.9951 - val_VL_attention_linear_output_loss: 1.8628 - val_VH_attention_linear_output_loss: 2.1323 - val_VL_attention_linear_output_acc: 0.4554 - val_VH_attention_linear_output_acc: 0.3244\n",
      "Epoch 591/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9401 - VL_attention_linear_output_loss: 1.8284 - VH_attention_linear_output_loss: 2.1117 - VL_attention_linear_output_acc: 0.4679 - VH_attention_linear_output_acc: 0.3414 - val_loss: 3.9667 - val_VL_attention_linear_output_loss: 1.8405 - val_VH_attention_linear_output_loss: 2.1262 - val_VL_attention_linear_output_acc: 0.4659 - val_VH_attention_linear_output_acc: 0.3299\n",
      "Epoch 592/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9494 - VL_attention_linear_output_loss: 1.8303 - VH_attention_linear_output_loss: 2.1192 - VL_attention_linear_output_acc: 0.4664 - VH_attention_linear_output_acc: 0.3360 - val_loss: 3.9835 - val_VL_attention_linear_output_loss: 1.8665 - val_VH_attention_linear_output_loss: 2.1170 - val_VL_attention_linear_output_acc: 0.4483 - val_VH_attention_linear_output_acc: 0.3353\n",
      "Epoch 593/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9533 - VL_attention_linear_output_loss: 1.8419 - VH_attention_linear_output_loss: 2.1115 - VL_attention_linear_output_acc: 0.4610 - VH_attention_linear_output_acc: 0.3417 - val_loss: 3.9716 - val_VL_attention_linear_output_loss: 1.8465 - val_VH_attention_linear_output_loss: 2.1251 - val_VL_attention_linear_output_acc: 0.4623 - val_VH_attention_linear_output_acc: 0.3319\n",
      "Epoch 594/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9432 - VL_attention_linear_output_loss: 1.8315 - VH_attention_linear_output_loss: 2.1117 - VL_attention_linear_output_acc: 0.4657 - VH_attention_linear_output_acc: 0.3409 - val_loss: 3.9520 - val_VL_attention_linear_output_loss: 1.8346 - val_VH_attention_linear_output_loss: 2.1173 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.3358\n",
      "Epoch 595/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9517 - VL_attention_linear_output_loss: 1.8355 - VH_attention_linear_output_loss: 2.1162 - VL_attention_linear_output_acc: 0.4643 - VH_attention_linear_output_acc: 0.3389 - val_loss: 3.9981 - val_VL_attention_linear_output_loss: 1.8525 - val_VH_attention_linear_output_loss: 2.1456 - val_VL_attention_linear_output_acc: 0.4578 - val_VH_attention_linear_output_acc: 0.3192\n",
      "Epoch 596/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9424 - VL_attention_linear_output_loss: 1.8251 - VH_attention_linear_output_loss: 2.1173 - VL_attention_linear_output_acc: 0.4690 - VH_attention_linear_output_acc: 0.3376 - val_loss: 3.9698 - val_VL_attention_linear_output_loss: 1.8379 - val_VH_attention_linear_output_loss: 2.1320 - val_VL_attention_linear_output_acc: 0.4676 - val_VH_attention_linear_output_acc: 0.3296\n",
      "Epoch 597/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9537 - VL_attention_linear_output_loss: 1.8330 - VH_attention_linear_output_loss: 2.1207 - VL_attention_linear_output_acc: 0.4651 - VH_attention_linear_output_acc: 0.3377 - val_loss: 3.9923 - val_VL_attention_linear_output_loss: 1.8453 - val_VH_attention_linear_output_loss: 2.1470 - val_VL_attention_linear_output_acc: 0.4647 - val_VH_attention_linear_output_acc: 0.3240\n",
      "Epoch 598/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9534 - VL_attention_linear_output_loss: 1.8324 - VH_attention_linear_output_loss: 2.1211 - VL_attention_linear_output_acc: 0.4663 - VH_attention_linear_output_acc: 0.3370 - val_loss: 3.9601 - val_VL_attention_linear_output_loss: 1.8444 - val_VH_attention_linear_output_loss: 2.1158 - val_VL_attention_linear_output_acc: 0.4635 - val_VH_attention_linear_output_acc: 0.3360\n",
      "Epoch 599/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9545 - VL_attention_linear_output_loss: 1.8404 - VH_attention_linear_output_loss: 2.1141 - VL_attention_linear_output_acc: 0.4618 - VH_attention_linear_output_acc: 0.3399 - val_loss: 3.9815 - val_VL_attention_linear_output_loss: 1.8569 - val_VH_attention_linear_output_loss: 2.1246 - val_VL_attention_linear_output_acc: 0.4647 - val_VH_attention_linear_output_acc: 0.3332\n",
      "Epoch 600/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9712 - VL_attention_linear_output_loss: 1.8414 - VH_attention_linear_output_loss: 2.1298 - VL_attention_linear_output_acc: 0.4611 - VH_attention_linear_output_acc: 0.3329 - val_loss: 3.9524 - val_VL_attention_linear_output_loss: 1.8383 - val_VH_attention_linear_output_loss: 2.1141 - val_VL_attention_linear_output_acc: 0.4692 - val_VH_attention_linear_output_acc: 0.3421\n",
      "Epoch 601/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9363 - VL_attention_linear_output_loss: 1.8234 - VH_attention_linear_output_loss: 2.1129 - VL_attention_linear_output_acc: 0.4708 - VH_attention_linear_output_acc: 0.3416 - val_loss: 3.9515 - val_VL_attention_linear_output_loss: 1.8377 - val_VH_attention_linear_output_loss: 2.1138 - val_VL_attention_linear_output_acc: 0.4677 - val_VH_attention_linear_output_acc: 0.3432\n",
      "Epoch 602/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9371 - VL_attention_linear_output_loss: 1.8257 - VH_attention_linear_output_loss: 2.1113 - VL_attention_linear_output_acc: 0.4687 - VH_attention_linear_output_acc: 0.3433 - val_loss: 3.9440 - val_VL_attention_linear_output_loss: 1.8348 - val_VH_attention_linear_output_loss: 2.1092 - val_VL_attention_linear_output_acc: 0.4671 - val_VH_attention_linear_output_acc: 0.3458\n",
      "Epoch 603/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9373 - VL_attention_linear_output_loss: 1.8256 - VH_attention_linear_output_loss: 2.1117 - VL_attention_linear_output_acc: 0.4677 - VH_attention_linear_output_acc: 0.3430 - val_loss: 3.9493 - val_VL_attention_linear_output_loss: 1.8367 - val_VH_attention_linear_output_loss: 2.1126 - val_VL_attention_linear_output_acc: 0.4663 - val_VH_attention_linear_output_acc: 0.3378\n",
      "Epoch 604/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9685 - VL_attention_linear_output_loss: 1.8411 - VH_attention_linear_output_loss: 2.1274 - VL_attention_linear_output_acc: 0.4608 - VH_attention_linear_output_acc: 0.3364 - val_loss: 4.0074 - val_VL_attention_linear_output_loss: 1.8595 - val_VH_attention_linear_output_loss: 2.1479 - val_VL_attention_linear_output_acc: 0.4569 - val_VH_attention_linear_output_acc: 0.3276\n",
      "Epoch 605/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9644 - VL_attention_linear_output_loss: 1.8468 - VH_attention_linear_output_loss: 2.1176 - VL_attention_linear_output_acc: 0.4585 - VH_attention_linear_output_acc: 0.3384 - val_loss: 3.9875 - val_VL_attention_linear_output_loss: 1.8771 - val_VH_attention_linear_output_loss: 2.1103 - val_VL_attention_linear_output_acc: 0.4465 - val_VH_attention_linear_output_acc: 0.3376\n",
      "Epoch 606/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9477 - VL_attention_linear_output_loss: 1.8424 - VH_attention_linear_output_loss: 2.1053 - VL_attention_linear_output_acc: 0.4601 - VH_attention_linear_output_acc: 0.3442 - val_loss: 3.9519 - val_VL_attention_linear_output_loss: 1.8474 - val_VH_attention_linear_output_loss: 2.1045 - val_VL_attention_linear_output_acc: 0.4600 - val_VH_attention_linear_output_acc: 0.3447\n",
      "Epoch 607/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9208 - VL_attention_linear_output_loss: 1.8181 - VH_attention_linear_output_loss: 2.1026 - VL_attention_linear_output_acc: 0.4723 - VH_attention_linear_output_acc: 0.3451 - val_loss: 3.9534 - val_VL_attention_linear_output_loss: 1.8403 - val_VH_attention_linear_output_loss: 2.1131 - val_VL_attention_linear_output_acc: 0.4695 - val_VH_attention_linear_output_acc: 0.3364\n",
      "Epoch 608/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9410 - VL_attention_linear_output_loss: 1.8323 - VH_attention_linear_output_loss: 2.1086 - VL_attention_linear_output_acc: 0.4655 - VH_attention_linear_output_acc: 0.3424 - val_loss: 3.9515 - val_VL_attention_linear_output_loss: 1.8410 - val_VH_attention_linear_output_loss: 2.1104 - val_VL_attention_linear_output_acc: 0.4647 - val_VH_attention_linear_output_acc: 0.3406\n",
      "Epoch 609/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9273 - VL_attention_linear_output_loss: 1.8230 - VH_attention_linear_output_loss: 2.1043 - VL_attention_linear_output_acc: 0.4703 - VH_attention_linear_output_acc: 0.3442 - val_loss: 3.9572 - val_VL_attention_linear_output_loss: 1.8319 - val_VH_attention_linear_output_loss: 2.1253 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.3322\n",
      "Epoch 610/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9522 - VL_attention_linear_output_loss: 1.8428 - VH_attention_linear_output_loss: 2.1094 - VL_attention_linear_output_acc: 0.4599 - VH_attention_linear_output_acc: 0.3418 - val_loss: 3.9411 - val_VL_attention_linear_output_loss: 1.8353 - val_VH_attention_linear_output_loss: 2.1057 - val_VL_attention_linear_output_acc: 0.4668 - val_VH_attention_linear_output_acc: 0.3460\n",
      "Epoch 611/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9283 - VL_attention_linear_output_loss: 1.8254 - VH_attention_linear_output_loss: 2.1029 - VL_attention_linear_output_acc: 0.4696 - VH_attention_linear_output_acc: 0.3456 - val_loss: 3.9414 - val_VL_attention_linear_output_loss: 1.8392 - val_VH_attention_linear_output_loss: 2.1022 - val_VL_attention_linear_output_acc: 0.4642 - val_VH_attention_linear_output_acc: 0.3439\n",
      "Epoch 612/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9284 - VL_attention_linear_output_loss: 1.8234 - VH_attention_linear_output_loss: 2.1050 - VL_attention_linear_output_acc: 0.4700 - VH_attention_linear_output_acc: 0.3435 - val_loss: 3.9498 - val_VL_attention_linear_output_loss: 1.8409 - val_VH_attention_linear_output_loss: 2.1089 - val_VL_attention_linear_output_acc: 0.4620 - val_VH_attention_linear_output_acc: 0.3407\n",
      "Epoch 613/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9581 - VL_attention_linear_output_loss: 1.8441 - VH_attention_linear_output_loss: 2.1140 - VL_attention_linear_output_acc: 0.4592 - VH_attention_linear_output_acc: 0.3400 - val_loss: 3.9797 - val_VL_attention_linear_output_loss: 1.8650 - val_VH_attention_linear_output_loss: 2.1148 - val_VL_attention_linear_output_acc: 0.4504 - val_VH_attention_linear_output_acc: 0.3362\n",
      "Epoch 614/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9281 - VL_attention_linear_output_loss: 1.8259 - VH_attention_linear_output_loss: 2.1022 - VL_attention_linear_output_acc: 0.4687 - VH_attention_linear_output_acc: 0.3453 - val_loss: 3.9474 - val_VL_attention_linear_output_loss: 1.8479 - val_VH_attention_linear_output_loss: 2.0994 - val_VL_attention_linear_output_acc: 0.4586 - val_VH_attention_linear_output_acc: 0.3492\n",
      "Epoch 615/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9228 - VL_attention_linear_output_loss: 1.8228 - VH_attention_linear_output_loss: 2.1001 - VL_attention_linear_output_acc: 0.4706 - VH_attention_linear_output_acc: 0.3471 - val_loss: 3.9377 - val_VL_attention_linear_output_loss: 1.8339 - val_VH_attention_linear_output_loss: 2.1038 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.3467\n",
      "Epoch 616/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9275 - VL_attention_linear_output_loss: 1.8267 - VH_attention_linear_output_loss: 2.1008 - VL_attention_linear_output_acc: 0.4675 - VH_attention_linear_output_acc: 0.3458 - val_loss: 3.9499 - val_VL_attention_linear_output_loss: 1.8462 - val_VH_attention_linear_output_loss: 2.1037 - val_VL_attention_linear_output_acc: 0.4622 - val_VH_attention_linear_output_acc: 0.3422\n",
      "Epoch 617/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9375 - VL_attention_linear_output_loss: 1.8331 - VH_attention_linear_output_loss: 2.1043 - VL_attention_linear_output_acc: 0.4654 - VH_attention_linear_output_acc: 0.3429 - val_loss: 3.9582 - val_VL_attention_linear_output_loss: 1.8574 - val_VH_attention_linear_output_loss: 2.1008 - val_VL_attention_linear_output_acc: 0.4540 - val_VH_attention_linear_output_acc: 0.3457\n",
      "Epoch 618/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9343 - VL_attention_linear_output_loss: 1.8307 - VH_attention_linear_output_loss: 2.1036 - VL_attention_linear_output_acc: 0.4658 - VH_attention_linear_output_acc: 0.3443 - val_loss: 4.0275 - val_VL_attention_linear_output_loss: 1.9257 - val_VH_attention_linear_output_loss: 2.1018 - val_VL_attention_linear_output_acc: 0.4222 - val_VH_attention_linear_output_acc: 0.3446\n",
      "Epoch 619/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9356 - VL_attention_linear_output_loss: 1.8284 - VH_attention_linear_output_loss: 2.1071 - VL_attention_linear_output_acc: 0.4654 - VH_attention_linear_output_acc: 0.3419 - val_loss: 3.9478 - val_VL_attention_linear_output_loss: 1.8339 - val_VH_attention_linear_output_loss: 2.1139 - val_VL_attention_linear_output_acc: 0.4712 - val_VH_attention_linear_output_acc: 0.3385\n",
      "Epoch 620/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9417 - VL_attention_linear_output_loss: 1.8236 - VH_attention_linear_output_loss: 2.1180 - VL_attention_linear_output_acc: 0.4690 - VH_attention_linear_output_acc: 0.3392 - val_loss: 3.9742 - val_VL_attention_linear_output_loss: 1.8491 - val_VH_attention_linear_output_loss: 2.1252 - val_VL_attention_linear_output_acc: 0.4636 - val_VH_attention_linear_output_acc: 0.3398\n",
      "Epoch 621/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9329 - VL_attention_linear_output_loss: 1.8229 - VH_attention_linear_output_loss: 2.1100 - VL_attention_linear_output_acc: 0.4707 - VH_attention_linear_output_acc: 0.3445 - val_loss: 3.9442 - val_VL_attention_linear_output_loss: 1.8371 - val_VH_attention_linear_output_loss: 2.1071 - val_VL_attention_linear_output_acc: 0.4680 - val_VH_attention_linear_output_acc: 0.3404\n",
      "Epoch 622/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9237 - VL_attention_linear_output_loss: 1.8210 - VH_attention_linear_output_loss: 2.1028 - VL_attention_linear_output_acc: 0.4701 - VH_attention_linear_output_acc: 0.3469 - val_loss: 3.9344 - val_VL_attention_linear_output_loss: 1.8340 - val_VH_attention_linear_output_loss: 2.1004 - val_VL_attention_linear_output_acc: 0.4678 - val_VH_attention_linear_output_acc: 0.3487\n",
      "Epoch 623/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9406 - VL_attention_linear_output_loss: 1.8321 - VH_attention_linear_output_loss: 2.1086 - VL_attention_linear_output_acc: 0.4657 - VH_attention_linear_output_acc: 0.3447 - val_loss: 3.9389 - val_VL_attention_linear_output_loss: 1.8338 - val_VH_attention_linear_output_loss: 2.1051 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.3426\n",
      "Epoch 624/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9381 - VL_attention_linear_output_loss: 1.8352 - VH_attention_linear_output_loss: 2.1028 - VL_attention_linear_output_acc: 0.4644 - VH_attention_linear_output_acc: 0.3468 - val_loss: 3.9382 - val_VL_attention_linear_output_loss: 1.8391 - val_VH_attention_linear_output_loss: 2.0991 - val_VL_attention_linear_output_acc: 0.4635 - val_VH_attention_linear_output_acc: 0.3475\n",
      "Epoch 625/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9221 - VL_attention_linear_output_loss: 1.8219 - VH_attention_linear_output_loss: 2.1002 - VL_attention_linear_output_acc: 0.4693 - VH_attention_linear_output_acc: 0.3476 - val_loss: 3.9391 - val_VL_attention_linear_output_loss: 1.8404 - val_VH_attention_linear_output_loss: 2.0987 - val_VL_attention_linear_output_acc: 0.4630 - val_VH_attention_linear_output_acc: 0.3470\n",
      "Epoch 626/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9248 - VL_attention_linear_output_loss: 1.8281 - VH_attention_linear_output_loss: 2.0967 - VL_attention_linear_output_acc: 0.4677 - VH_attention_linear_output_acc: 0.3487 - val_loss: 3.9429 - val_VL_attention_linear_output_loss: 1.8465 - val_VH_attention_linear_output_loss: 2.0964 - val_VL_attention_linear_output_acc: 0.4614 - val_VH_attention_linear_output_acc: 0.3479\n",
      "Epoch 627/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9212 - VL_attention_linear_output_loss: 1.8243 - VH_attention_linear_output_loss: 2.0969 - VL_attention_linear_output_acc: 0.4679 - VH_attention_linear_output_acc: 0.3476 - val_loss: 3.9499 - val_VL_attention_linear_output_loss: 1.8524 - val_VH_attention_linear_output_loss: 2.0975 - val_VL_attention_linear_output_acc: 0.4570 - val_VH_attention_linear_output_acc: 0.3480\n",
      "Epoch 628/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9340 - VL_attention_linear_output_loss: 1.8360 - VH_attention_linear_output_loss: 2.0980 - VL_attention_linear_output_acc: 0.4625 - VH_attention_linear_output_acc: 0.3469 - val_loss: 3.9691 - val_VL_attention_linear_output_loss: 1.8562 - val_VH_attention_linear_output_loss: 2.1129 - val_VL_attention_linear_output_acc: 0.4604 - val_VH_attention_linear_output_acc: 0.3408\n",
      "Epoch 629/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9178 - VL_attention_linear_output_loss: 1.8215 - VH_attention_linear_output_loss: 2.0963 - VL_attention_linear_output_acc: 0.4708 - VH_attention_linear_output_acc: 0.3475 - val_loss: 3.9355 - val_VL_attention_linear_output_loss: 1.8384 - val_VH_attention_linear_output_loss: 2.0971 - val_VL_attention_linear_output_acc: 0.4676 - val_VH_attention_linear_output_acc: 0.3474\n",
      "Epoch 630/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9274 - VL_attention_linear_output_loss: 1.8332 - VH_attention_linear_output_loss: 2.0942 - VL_attention_linear_output_acc: 0.4639 - VH_attention_linear_output_acc: 0.3487 - val_loss: 3.9354 - val_VL_attention_linear_output_loss: 1.8330 - val_VH_attention_linear_output_loss: 2.1024 - val_VL_attention_linear_output_acc: 0.4692 - val_VH_attention_linear_output_acc: 0.3429\n",
      "Epoch 631/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9148 - VL_attention_linear_output_loss: 1.8193 - VH_attention_linear_output_loss: 2.0955 - VL_attention_linear_output_acc: 0.4712 - VH_attention_linear_output_acc: 0.3473 - val_loss: 3.9529 - val_VL_attention_linear_output_loss: 1.8368 - val_VH_attention_linear_output_loss: 2.1161 - val_VL_attention_linear_output_acc: 0.4720 - val_VH_attention_linear_output_acc: 0.3313\n",
      "Epoch 632/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9153 - VL_attention_linear_output_loss: 1.8215 - VH_attention_linear_output_loss: 2.0938 - VL_attention_linear_output_acc: 0.4695 - VH_attention_linear_output_acc: 0.3483 - val_loss: 3.9372 - val_VL_attention_linear_output_loss: 1.8396 - val_VH_attention_linear_output_loss: 2.0976 - val_VL_attention_linear_output_acc: 0.4677 - val_VH_attention_linear_output_acc: 0.3468\n",
      "Epoch 633/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9183 - VL_attention_linear_output_loss: 1.8252 - VH_attention_linear_output_loss: 2.0931 - VL_attention_linear_output_acc: 0.4683 - VH_attention_linear_output_acc: 0.3480 - val_loss: 3.9386 - val_VL_attention_linear_output_loss: 1.8378 - val_VH_attention_linear_output_loss: 2.1008 - val_VL_attention_linear_output_acc: 0.4675 - val_VH_attention_linear_output_acc: 0.3459\n",
      "Epoch 634/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9238 - VL_attention_linear_output_loss: 1.8264 - VH_attention_linear_output_loss: 2.0974 - VL_attention_linear_output_acc: 0.4679 - VH_attention_linear_output_acc: 0.3450 - val_loss: 3.9371 - val_VL_attention_linear_output_loss: 1.8431 - val_VH_attention_linear_output_loss: 2.0940 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.3502\n",
      "Epoch 635/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9267 - VL_attention_linear_output_loss: 1.8342 - VH_attention_linear_output_loss: 2.0925 - VL_attention_linear_output_acc: 0.4645 - VH_attention_linear_output_acc: 0.3484 - val_loss: 3.9317 - val_VL_attention_linear_output_loss: 1.8381 - val_VH_attention_linear_output_loss: 2.0936 - val_VL_attention_linear_output_acc: 0.4661 - val_VH_attention_linear_output_acc: 0.3462\n",
      "Epoch 636/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9222 - VL_attention_linear_output_loss: 1.8276 - VH_attention_linear_output_loss: 2.0946 - VL_attention_linear_output_acc: 0.4674 - VH_attention_linear_output_acc: 0.3464 - val_loss: 3.9284 - val_VL_attention_linear_output_loss: 1.8317 - val_VH_attention_linear_output_loss: 2.0967 - val_VL_attention_linear_output_acc: 0.4688 - val_VH_attention_linear_output_acc: 0.3452\n",
      "Epoch 637/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9171 - VL_attention_linear_output_loss: 1.8263 - VH_attention_linear_output_loss: 2.0908 - VL_attention_linear_output_acc: 0.4672 - VH_attention_linear_output_acc: 0.3490 - val_loss: 3.9499 - val_VL_attention_linear_output_loss: 1.8589 - val_VH_attention_linear_output_loss: 2.0910 - val_VL_attention_linear_output_acc: 0.4566 - val_VH_attention_linear_output_acc: 0.3471\n",
      "Epoch 638/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9190 - VL_attention_linear_output_loss: 1.8281 - VH_attention_linear_output_loss: 2.0909 - VL_attention_linear_output_acc: 0.4674 - VH_attention_linear_output_acc: 0.3485 - val_loss: 3.9666 - val_VL_attention_linear_output_loss: 1.8367 - val_VH_attention_linear_output_loss: 2.1299 - val_VL_attention_linear_output_acc: 0.4666 - val_VH_attention_linear_output_acc: 0.3270\n",
      "Epoch 639/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9174 - VL_attention_linear_output_loss: 1.8208 - VH_attention_linear_output_loss: 2.0966 - VL_attention_linear_output_acc: 0.4699 - VH_attention_linear_output_acc: 0.3462 - val_loss: 3.9298 - val_VL_attention_linear_output_loss: 1.8365 - val_VH_attention_linear_output_loss: 2.0933 - val_VL_attention_linear_output_acc: 0.4687 - val_VH_attention_linear_output_acc: 0.3503\n",
      "Epoch 640/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9282 - VL_attention_linear_output_loss: 1.8345 - VH_attention_linear_output_loss: 2.0937 - VL_attention_linear_output_acc: 0.4643 - VH_attention_linear_output_acc: 0.3478 - val_loss: 3.9464 - val_VL_attention_linear_output_loss: 1.8353 - val_VH_attention_linear_output_loss: 2.1111 - val_VL_attention_linear_output_acc: 0.4630 - val_VH_attention_linear_output_acc: 0.3396\n",
      "Epoch 641/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9247 - VL_attention_linear_output_loss: 1.8328 - VH_attention_linear_output_loss: 2.0919 - VL_attention_linear_output_acc: 0.4642 - VH_attention_linear_output_acc: 0.3479 - val_loss: 3.9433 - val_VL_attention_linear_output_loss: 1.8505 - val_VH_attention_linear_output_loss: 2.0928 - val_VL_attention_linear_output_acc: 0.4584 - val_VH_attention_linear_output_acc: 0.3477\n",
      "Epoch 642/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9332 - VL_attention_linear_output_loss: 1.8348 - VH_attention_linear_output_loss: 2.0984 - VL_attention_linear_output_acc: 0.4631 - VH_attention_linear_output_acc: 0.3427 - val_loss: 3.9335 - val_VL_attention_linear_output_loss: 1.8421 - val_VH_attention_linear_output_loss: 2.0914 - val_VL_attention_linear_output_acc: 0.4755 - val_VH_attention_linear_output_acc: 0.3509\n",
      "Epoch 643/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9155 - VL_attention_linear_output_loss: 1.8260 - VH_attention_linear_output_loss: 2.0896 - VL_attention_linear_output_acc: 0.4676 - VH_attention_linear_output_acc: 0.3496 - val_loss: 3.9611 - val_VL_attention_linear_output_loss: 1.8616 - val_VH_attention_linear_output_loss: 2.0996 - val_VL_attention_linear_output_acc: 0.4528 - val_VH_attention_linear_output_acc: 0.3436\n",
      "Epoch 644/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9254 - VL_attention_linear_output_loss: 1.8319 - VH_attention_linear_output_loss: 2.0935 - VL_attention_linear_output_acc: 0.4640 - VH_attention_linear_output_acc: 0.3467 - val_loss: 3.9208 - val_VL_attention_linear_output_loss: 1.8338 - val_VH_attention_linear_output_loss: 2.0871 - val_VL_attention_linear_output_acc: 0.4686 - val_VH_attention_linear_output_acc: 0.3516\n",
      "Epoch 645/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9128 - VL_attention_linear_output_loss: 1.8208 - VH_attention_linear_output_loss: 2.0919 - VL_attention_linear_output_acc: 0.4702 - VH_attention_linear_output_acc: 0.3472 - val_loss: 3.9290 - val_VL_attention_linear_output_loss: 1.8348 - val_VH_attention_linear_output_loss: 2.0942 - val_VL_attention_linear_output_acc: 0.4735 - val_VH_attention_linear_output_acc: 0.3478\n",
      "Epoch 646/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9498 - VL_attention_linear_output_loss: 1.8530 - VH_attention_linear_output_loss: 2.0968 - VL_attention_linear_output_acc: 0.4538 - VH_attention_linear_output_acc: 0.3448 - val_loss: 3.9658 - val_VL_attention_linear_output_loss: 1.8665 - val_VH_attention_linear_output_loss: 2.0993 - val_VL_attention_linear_output_acc: 0.4524 - val_VH_attention_linear_output_acc: 0.3487\n",
      "Epoch 647/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9135 - VL_attention_linear_output_loss: 1.8251 - VH_attention_linear_output_loss: 2.0884 - VL_attention_linear_output_acc: 0.4684 - VH_attention_linear_output_acc: 0.3495 - val_loss: 3.9406 - val_VL_attention_linear_output_loss: 1.8507 - val_VH_attention_linear_output_loss: 2.0899 - val_VL_attention_linear_output_acc: 0.4564 - val_VH_attention_linear_output_acc: 0.3553\n",
      "Epoch 648/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9062 - VL_attention_linear_output_loss: 1.8187 - VH_attention_linear_output_loss: 2.0875 - VL_attention_linear_output_acc: 0.4708 - VH_attention_linear_output_acc: 0.3505 - val_loss: 3.9320 - val_VL_attention_linear_output_loss: 1.8338 - val_VH_attention_linear_output_loss: 2.0981 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.3457\n",
      "Epoch 649/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9316 - VL_attention_linear_output_loss: 1.8357 - VH_attention_linear_output_loss: 2.0960 - VL_attention_linear_output_acc: 0.4635 - VH_attention_linear_output_acc: 0.3451 - val_loss: 3.9336 - val_VL_attention_linear_output_loss: 1.8390 - val_VH_attention_linear_output_loss: 2.0946 - val_VL_attention_linear_output_acc: 0.4625 - val_VH_attention_linear_output_acc: 0.3468\n",
      "Epoch 650/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9128 - VL_attention_linear_output_loss: 1.8189 - VH_attention_linear_output_loss: 2.0939 - VL_attention_linear_output_acc: 0.4723 - VH_attention_linear_output_acc: 0.3457 - val_loss: 3.9568 - val_VL_attention_linear_output_loss: 1.8627 - val_VH_attention_linear_output_loss: 2.0941 - val_VL_attention_linear_output_acc: 0.4516 - val_VH_attention_linear_output_acc: 0.3440\n",
      "Epoch 651/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9324 - VL_attention_linear_output_loss: 1.8382 - VH_attention_linear_output_loss: 2.0942 - VL_attention_linear_output_acc: 0.4613 - VH_attention_linear_output_acc: 0.3456 - val_loss: 3.9452 - val_VL_attention_linear_output_loss: 1.8407 - val_VH_attention_linear_output_loss: 2.1045 - val_VL_attention_linear_output_acc: 0.4636 - val_VH_attention_linear_output_acc: 0.3437\n",
      "Epoch 652/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9118 - VL_attention_linear_output_loss: 1.8171 - VH_attention_linear_output_loss: 2.0947 - VL_attention_linear_output_acc: 0.4717 - VH_attention_linear_output_acc: 0.3460 - val_loss: 3.9328 - val_VL_attention_linear_output_loss: 1.8401 - val_VH_attention_linear_output_loss: 2.0928 - val_VL_attention_linear_output_acc: 0.4664 - val_VH_attention_linear_output_acc: 0.3530\n",
      "Epoch 653/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9224 - VL_attention_linear_output_loss: 1.8301 - VH_attention_linear_output_loss: 2.0923 - VL_attention_linear_output_acc: 0.4667 - VH_attention_linear_output_acc: 0.3479 - val_loss: 3.9331 - val_VL_attention_linear_output_loss: 1.8403 - val_VH_attention_linear_output_loss: 2.0928 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.3472\n",
      "Epoch 654/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9208 - VL_attention_linear_output_loss: 1.8298 - VH_attention_linear_output_loss: 2.0910 - VL_attention_linear_output_acc: 0.4652 - VH_attention_linear_output_acc: 0.3491 - val_loss: 3.9599 - val_VL_attention_linear_output_loss: 1.8597 - val_VH_attention_linear_output_loss: 2.1002 - val_VL_attention_linear_output_acc: 0.4615 - val_VH_attention_linear_output_acc: 0.3428\n",
      "Epoch 655/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9428 - VL_attention_linear_output_loss: 1.8486 - VH_attention_linear_output_loss: 2.0942 - VL_attention_linear_output_acc: 0.4558 - VH_attention_linear_output_acc: 0.3460 - val_loss: 3.9261 - val_VL_attention_linear_output_loss: 1.8379 - val_VH_attention_linear_output_loss: 2.0882 - val_VL_attention_linear_output_acc: 0.4599 - val_VH_attention_linear_output_acc: 0.3462\n",
      "Epoch 656/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9066 - VL_attention_linear_output_loss: 1.8140 - VH_attention_linear_output_loss: 2.0926 - VL_attention_linear_output_acc: 0.4731 - VH_attention_linear_output_acc: 0.3462 - val_loss: 3.9292 - val_VL_attention_linear_output_loss: 1.8407 - val_VH_attention_linear_output_loss: 2.0885 - val_VL_attention_linear_output_acc: 0.4736 - val_VH_attention_linear_output_acc: 0.3507\n",
      "Epoch 657/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9291 - VL_attention_linear_output_loss: 1.8351 - VH_attention_linear_output_loss: 2.0939 - VL_attention_linear_output_acc: 0.4632 - VH_attention_linear_output_acc: 0.3452 - val_loss: 3.9784 - val_VL_attention_linear_output_loss: 1.8734 - val_VH_attention_linear_output_loss: 2.1051 - val_VL_attention_linear_output_acc: 0.4502 - val_VH_attention_linear_output_acc: 0.3436\n",
      "Epoch 658/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9239 - VL_attention_linear_output_loss: 1.8286 - VH_attention_linear_output_loss: 2.0953 - VL_attention_linear_output_acc: 0.4659 - VH_attention_linear_output_acc: 0.3466 - val_loss: 3.9274 - val_VL_attention_linear_output_loss: 1.8327 - val_VH_attention_linear_output_loss: 2.0948 - val_VL_attention_linear_output_acc: 0.4689 - val_VH_attention_linear_output_acc: 0.3514\n",
      "Epoch 659/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9337 - VL_attention_linear_output_loss: 1.8290 - VH_attention_linear_output_loss: 2.1047 - VL_attention_linear_output_acc: 0.4648 - VH_attention_linear_output_acc: 0.3448 - val_loss: 3.9496 - val_VL_attention_linear_output_loss: 1.8500 - val_VH_attention_linear_output_loss: 2.0997 - val_VL_attention_linear_output_acc: 0.4595 - val_VH_attention_linear_output_acc: 0.3511\n",
      "Epoch 660/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9172 - VL_attention_linear_output_loss: 1.8210 - VH_attention_linear_output_loss: 2.0962 - VL_attention_linear_output_acc: 0.4702 - VH_attention_linear_output_acc: 0.3495 - val_loss: 3.9408 - val_VL_attention_linear_output_loss: 1.8491 - val_VH_attention_linear_output_loss: 2.0917 - val_VL_attention_linear_output_acc: 0.4565 - val_VH_attention_linear_output_acc: 0.3483\n",
      "Epoch 661/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9299 - VL_attention_linear_output_loss: 1.8268 - VH_attention_linear_output_loss: 2.1030 - VL_attention_linear_output_acc: 0.4678 - VH_attention_linear_output_acc: 0.3467 - val_loss: 3.9433 - val_VL_attention_linear_output_loss: 1.8318 - val_VH_attention_linear_output_loss: 2.1115 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.3427\n",
      "Epoch 662/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9555 - VL_attention_linear_output_loss: 1.8244 - VH_attention_linear_output_loss: 2.1311 - VL_attention_linear_output_acc: 0.4688 - VH_attention_linear_output_acc: 0.3342 - val_loss: 3.9424 - val_VL_attention_linear_output_loss: 1.8340 - val_VH_attention_linear_output_loss: 2.1084 - val_VL_attention_linear_output_acc: 0.4674 - val_VH_attention_linear_output_acc: 0.3452\n",
      "Epoch 663/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9205 - VL_attention_linear_output_loss: 1.8227 - VH_attention_linear_output_loss: 2.0978 - VL_attention_linear_output_acc: 0.4689 - VH_attention_linear_output_acc: 0.3488 - val_loss: 3.9341 - val_VL_attention_linear_output_loss: 1.8392 - val_VH_attention_linear_output_loss: 2.0949 - val_VL_attention_linear_output_acc: 0.4690 - val_VH_attention_linear_output_acc: 0.3471\n",
      "Epoch 664/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9100 - VL_attention_linear_output_loss: 1.8170 - VH_attention_linear_output_loss: 2.0931 - VL_attention_linear_output_acc: 0.4713 - VH_attention_linear_output_acc: 0.3510 - val_loss: 3.9251 - val_VL_attention_linear_output_loss: 1.8304 - val_VH_attention_linear_output_loss: 2.0947 - val_VL_attention_linear_output_acc: 0.4667 - val_VH_attention_linear_output_acc: 0.3490\n",
      "Epoch 665/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9068 - VL_attention_linear_output_loss: 1.8161 - VH_attention_linear_output_loss: 2.0907 - VL_attention_linear_output_acc: 0.4720 - VH_attention_linear_output_acc: 0.3515 - val_loss: 3.9368 - val_VL_attention_linear_output_loss: 1.8446 - val_VH_attention_linear_output_loss: 2.0922 - val_VL_attention_linear_output_acc: 0.4571 - val_VH_attention_linear_output_acc: 0.3534\n",
      "Epoch 666/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9153 - VL_attention_linear_output_loss: 1.8264 - VH_attention_linear_output_loss: 2.0889 - VL_attention_linear_output_acc: 0.4667 - VH_attention_linear_output_acc: 0.3525 - val_loss: 3.9241 - val_VL_attention_linear_output_loss: 1.8279 - val_VH_attention_linear_output_loss: 2.0962 - val_VL_attention_linear_output_acc: 0.4716 - val_VH_attention_linear_output_acc: 0.3509\n",
      "Epoch 667/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9066 - VL_attention_linear_output_loss: 1.8194 - VH_attention_linear_output_loss: 2.0873 - VL_attention_linear_output_acc: 0.4699 - VH_attention_linear_output_acc: 0.3535 - val_loss: 3.9527 - val_VL_attention_linear_output_loss: 1.8449 - val_VH_attention_linear_output_loss: 2.1078 - val_VL_attention_linear_output_acc: 0.4699 - val_VH_attention_linear_output_acc: 0.3387\n",
      "Epoch 668/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9103 - VL_attention_linear_output_loss: 1.8237 - VH_attention_linear_output_loss: 2.0866 - VL_attention_linear_output_acc: 0.4689 - VH_attention_linear_output_acc: 0.3536 - val_loss: 3.9238 - val_VL_attention_linear_output_loss: 1.8333 - val_VH_attention_linear_output_loss: 2.0905 - val_VL_attention_linear_output_acc: 0.4712 - val_VH_attention_linear_output_acc: 0.3509\n",
      "Epoch 669/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9032 - VL_attention_linear_output_loss: 1.8184 - VH_attention_linear_output_loss: 2.0848 - VL_attention_linear_output_acc: 0.4704 - VH_attention_linear_output_acc: 0.3549 - val_loss: 3.9264 - val_VL_attention_linear_output_loss: 1.8388 - val_VH_attention_linear_output_loss: 2.0875 - val_VL_attention_linear_output_acc: 0.4639 - val_VH_attention_linear_output_acc: 0.3508\n",
      "Epoch 670/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9087 - VL_attention_linear_output_loss: 1.8210 - VH_attention_linear_output_loss: 2.0877 - VL_attention_linear_output_acc: 0.4701 - VH_attention_linear_output_acc: 0.3524 - val_loss: 3.9270 - val_VL_attention_linear_output_loss: 1.8400 - val_VH_attention_linear_output_loss: 2.0871 - val_VL_attention_linear_output_acc: 0.4653 - val_VH_attention_linear_output_acc: 0.3501\n",
      "Epoch 671/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9082 - VL_attention_linear_output_loss: 1.8237 - VH_attention_linear_output_loss: 2.0844 - VL_attention_linear_output_acc: 0.4673 - VH_attention_linear_output_acc: 0.3550 - val_loss: 3.9206 - val_VL_attention_linear_output_loss: 1.8260 - val_VH_attention_linear_output_loss: 2.0945 - val_VL_attention_linear_output_acc: 0.4728 - val_VH_attention_linear_output_acc: 0.3491\n",
      "Epoch 672/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9039 - VL_attention_linear_output_loss: 1.8191 - VH_attention_linear_output_loss: 2.0847 - VL_attention_linear_output_acc: 0.4697 - VH_attention_linear_output_acc: 0.3545 - val_loss: 3.9246 - val_VL_attention_linear_output_loss: 1.8367 - val_VH_attention_linear_output_loss: 2.0878 - val_VL_attention_linear_output_acc: 0.4698 - val_VH_attention_linear_output_acc: 0.3506\n",
      "Epoch 673/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9099 - VL_attention_linear_output_loss: 1.8254 - VH_attention_linear_output_loss: 2.0845 - VL_attention_linear_output_acc: 0.4679 - VH_attention_linear_output_acc: 0.3552 - val_loss: 3.9214 - val_VL_attention_linear_output_loss: 1.8349 - val_VH_attention_linear_output_loss: 2.0865 - val_VL_attention_linear_output_acc: 0.4723 - val_VH_attention_linear_output_acc: 0.3520\n",
      "Epoch 674/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9003 - VL_attention_linear_output_loss: 1.8166 - VH_attention_linear_output_loss: 2.0837 - VL_attention_linear_output_acc: 0.4715 - VH_attention_linear_output_acc: 0.3550 - val_loss: 3.9240 - val_VL_attention_linear_output_loss: 1.8359 - val_VH_attention_linear_output_loss: 2.0882 - val_VL_attention_linear_output_acc: 0.4656 - val_VH_attention_linear_output_acc: 0.3531\n",
      "Epoch 675/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9001 - VL_attention_linear_output_loss: 1.8163 - VH_attention_linear_output_loss: 2.0838 - VL_attention_linear_output_acc: 0.4713 - VH_attention_linear_output_acc: 0.3553 - val_loss: 3.9198 - val_VL_attention_linear_output_loss: 1.8275 - val_VH_attention_linear_output_loss: 2.0923 - val_VL_attention_linear_output_acc: 0.4707 - val_VH_attention_linear_output_acc: 0.3482\n",
      "Epoch 676/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9060 - VL_attention_linear_output_loss: 1.8231 - VH_attention_linear_output_loss: 2.0829 - VL_attention_linear_output_acc: 0.4669 - VH_attention_linear_output_acc: 0.3549 - val_loss: 3.9339 - val_VL_attention_linear_output_loss: 1.8458 - val_VH_attention_linear_output_loss: 2.0881 - val_VL_attention_linear_output_acc: 0.4610 - val_VH_attention_linear_output_acc: 0.3576\n",
      "Epoch 677/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9023 - VL_attention_linear_output_loss: 1.8194 - VH_attention_linear_output_loss: 2.0829 - VL_attention_linear_output_acc: 0.4710 - VH_attention_linear_output_acc: 0.3557 - val_loss: 3.9173 - val_VL_attention_linear_output_loss: 1.8271 - val_VH_attention_linear_output_loss: 2.0902 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.3516\n",
      "Epoch 678/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9031 - VL_attention_linear_output_loss: 1.8138 - VH_attention_linear_output_loss: 2.0893 - VL_attention_linear_output_acc: 0.4727 - VH_attention_linear_output_acc: 0.3523 - val_loss: 3.9650 - val_VL_attention_linear_output_loss: 1.8688 - val_VH_attention_linear_output_loss: 2.0962 - val_VL_attention_linear_output_acc: 0.4444 - val_VH_attention_linear_output_acc: 0.3488\n",
      "Epoch 679/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9048 - VL_attention_linear_output_loss: 1.8212 - VH_attention_linear_output_loss: 2.0837 - VL_attention_linear_output_acc: 0.4682 - VH_attention_linear_output_acc: 0.3558 - val_loss: 3.9352 - val_VL_attention_linear_output_loss: 1.8426 - val_VH_attention_linear_output_loss: 2.0926 - val_VL_attention_linear_output_acc: 0.4653 - val_VH_attention_linear_output_acc: 0.3502\n",
      "Epoch 680/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9101 - VL_attention_linear_output_loss: 1.8257 - VH_attention_linear_output_loss: 2.0843 - VL_attention_linear_output_acc: 0.4673 - VH_attention_linear_output_acc: 0.3548 - val_loss: 3.9209 - val_VL_attention_linear_output_loss: 1.8279 - val_VH_attention_linear_output_loss: 2.0929 - val_VL_attention_linear_output_acc: 0.4667 - val_VH_attention_linear_output_acc: 0.3510\n",
      "Epoch 681/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9017 - VL_attention_linear_output_loss: 1.8149 - VH_attention_linear_output_loss: 2.0868 - VL_attention_linear_output_acc: 0.4714 - VH_attention_linear_output_acc: 0.3535 - val_loss: 3.9279 - val_VL_attention_linear_output_loss: 1.8374 - val_VH_attention_linear_output_loss: 2.0906 - val_VL_attention_linear_output_acc: 0.4675 - val_VH_attention_linear_output_acc: 0.3500\n",
      "Epoch 682/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9110 - VL_attention_linear_output_loss: 1.8243 - VH_attention_linear_output_loss: 2.0867 - VL_attention_linear_output_acc: 0.4676 - VH_attention_linear_output_acc: 0.3529 - val_loss: 3.9567 - val_VL_attention_linear_output_loss: 1.8601 - val_VH_attention_linear_output_loss: 2.0967 - val_VL_attention_linear_output_acc: 0.4598 - val_VH_attention_linear_output_acc: 0.3439\n",
      "Epoch 683/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9057 - VL_attention_linear_output_loss: 1.8237 - VH_attention_linear_output_loss: 2.0820 - VL_attention_linear_output_acc: 0.4694 - VH_attention_linear_output_acc: 0.3560 - val_loss: 3.9377 - val_VL_attention_linear_output_loss: 1.8544 - val_VH_attention_linear_output_loss: 2.0833 - val_VL_attention_linear_output_acc: 0.4573 - val_VH_attention_linear_output_acc: 0.3560\n",
      "Epoch 684/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8997 - VL_attention_linear_output_loss: 1.8147 - VH_attention_linear_output_loss: 2.0850 - VL_attention_linear_output_acc: 0.4711 - VH_attention_linear_output_acc: 0.3539 - val_loss: 3.9574 - val_VL_attention_linear_output_loss: 1.8374 - val_VH_attention_linear_output_loss: 2.1200 - val_VL_attention_linear_output_acc: 0.4688 - val_VH_attention_linear_output_acc: 0.3313\n",
      "Epoch 685/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9241 - VL_attention_linear_output_loss: 1.8374 - VH_attention_linear_output_loss: 2.0867 - VL_attention_linear_output_acc: 0.4612 - VH_attention_linear_output_acc: 0.3527 - val_loss: 3.9997 - val_VL_attention_linear_output_loss: 1.8673 - val_VH_attention_linear_output_loss: 2.1324 - val_VL_attention_linear_output_acc: 0.4511 - val_VH_attention_linear_output_acc: 0.3299\n",
      "Epoch 686/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8988 - VL_attention_linear_output_loss: 1.8161 - VH_attention_linear_output_loss: 2.0827 - VL_attention_linear_output_acc: 0.4710 - VH_attention_linear_output_acc: 0.3556 - val_loss: 3.9240 - val_VL_attention_linear_output_loss: 1.8353 - val_VH_attention_linear_output_loss: 2.0887 - val_VL_attention_linear_output_acc: 0.4659 - val_VH_attention_linear_output_acc: 0.3494\n",
      "Epoch 687/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9034 - VL_attention_linear_output_loss: 1.8209 - VH_attention_linear_output_loss: 2.0825 - VL_attention_linear_output_acc: 0.4706 - VH_attention_linear_output_acc: 0.3561 - val_loss: 3.9447 - val_VL_attention_linear_output_loss: 1.8485 - val_VH_attention_linear_output_loss: 2.0962 - val_VL_attention_linear_output_acc: 0.4592 - val_VH_attention_linear_output_acc: 0.3468\n",
      "Epoch 688/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9169 - VL_attention_linear_output_loss: 1.8313 - VH_attention_linear_output_loss: 2.0856 - VL_attention_linear_output_acc: 0.4627 - VH_attention_linear_output_acc: 0.3540 - val_loss: 3.9118 - val_VL_attention_linear_output_loss: 1.8257 - val_VH_attention_linear_output_loss: 2.0861 - val_VL_attention_linear_output_acc: 0.4735 - val_VH_attention_linear_output_acc: 0.3537\n",
      "Epoch 689/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8965 - VL_attention_linear_output_loss: 1.8142 - VH_attention_linear_output_loss: 2.0823 - VL_attention_linear_output_acc: 0.4725 - VH_attention_linear_output_acc: 0.3550 - val_loss: 3.9097 - val_VL_attention_linear_output_loss: 1.8251 - val_VH_attention_linear_output_loss: 2.0845 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.3564\n",
      "Epoch 690/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8951 - VL_attention_linear_output_loss: 1.8121 - VH_attention_linear_output_loss: 2.0830 - VL_attention_linear_output_acc: 0.4735 - VH_attention_linear_output_acc: 0.3555 - val_loss: 3.9153 - val_VL_attention_linear_output_loss: 1.8313 - val_VH_attention_linear_output_loss: 2.0839 - val_VL_attention_linear_output_acc: 0.4685 - val_VH_attention_linear_output_acc: 0.3572\n",
      "Epoch 691/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9092 - VL_attention_linear_output_loss: 1.8190 - VH_attention_linear_output_loss: 2.0901 - VL_attention_linear_output_acc: 0.4697 - VH_attention_linear_output_acc: 0.3510 - val_loss: 3.9126 - val_VL_attention_linear_output_loss: 1.8293 - val_VH_attention_linear_output_loss: 2.0834 - val_VL_attention_linear_output_acc: 0.4677 - val_VH_attention_linear_output_acc: 0.3570\n",
      "Epoch 692/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9163 - VL_attention_linear_output_loss: 1.8259 - VH_attention_linear_output_loss: 2.0904 - VL_attention_linear_output_acc: 0.4664 - VH_attention_linear_output_acc: 0.3513 - val_loss: 3.9215 - val_VL_attention_linear_output_loss: 1.8323 - val_VH_attention_linear_output_loss: 2.0893 - val_VL_attention_linear_output_acc: 0.4651 - val_VH_attention_linear_output_acc: 0.3503\n",
      "Epoch 693/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9117 - VL_attention_linear_output_loss: 1.8261 - VH_attention_linear_output_loss: 2.0856 - VL_attention_linear_output_acc: 0.4671 - VH_attention_linear_output_acc: 0.3538 - val_loss: 3.9572 - val_VL_attention_linear_output_loss: 1.8687 - val_VH_attention_linear_output_loss: 2.0885 - val_VL_attention_linear_output_acc: 0.4512 - val_VH_attention_linear_output_acc: 0.3570\n",
      "Epoch 694/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9142 - VL_attention_linear_output_loss: 1.8238 - VH_attention_linear_output_loss: 2.0904 - VL_attention_linear_output_acc: 0.4683 - VH_attention_linear_output_acc: 0.3515 - val_loss: 3.9155 - val_VL_attention_linear_output_loss: 1.8328 - val_VH_attention_linear_output_loss: 2.0827 - val_VL_attention_linear_output_acc: 0.4667 - val_VH_attention_linear_output_acc: 0.3551\n",
      "Epoch 695/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9312 - VL_attention_linear_output_loss: 1.8343 - VH_attention_linear_output_loss: 2.0968 - VL_attention_linear_output_acc: 0.4623 - VH_attention_linear_output_acc: 0.3480 - val_loss: 3.9187 - val_VL_attention_linear_output_loss: 1.8256 - val_VH_attention_linear_output_loss: 2.0930 - val_VL_attention_linear_output_acc: 0.4692 - val_VH_attention_linear_output_acc: 0.3513\n",
      "Epoch 696/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8929 - VL_attention_linear_output_loss: 1.8127 - VH_attention_linear_output_loss: 2.0802 - VL_attention_linear_output_acc: 0.4727 - VH_attention_linear_output_acc: 0.3568 - val_loss: 3.9219 - val_VL_attention_linear_output_loss: 1.8275 - val_VH_attention_linear_output_loss: 2.0944 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.3492\n",
      "Epoch 697/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9020 - VL_attention_linear_output_loss: 1.8169 - VH_attention_linear_output_loss: 2.0851 - VL_attention_linear_output_acc: 0.4702 - VH_attention_linear_output_acc: 0.3550 - val_loss: 3.9223 - val_VL_attention_linear_output_loss: 1.8347 - val_VH_attention_linear_output_loss: 2.0876 - val_VL_attention_linear_output_acc: 0.4679 - val_VH_attention_linear_output_acc: 0.3546\n",
      "Epoch 698/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9058 - VL_attention_linear_output_loss: 1.8173 - VH_attention_linear_output_loss: 2.0884 - VL_attention_linear_output_acc: 0.4707 - VH_attention_linear_output_acc: 0.3529 - val_loss: 3.9511 - val_VL_attention_linear_output_loss: 1.8470 - val_VH_attention_linear_output_loss: 2.1042 - val_VL_attention_linear_output_acc: 0.4600 - val_VH_attention_linear_output_acc: 0.3439\n",
      "Epoch 699/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9023 - VL_attention_linear_output_loss: 1.8201 - VH_attention_linear_output_loss: 2.0822 - VL_attention_linear_output_acc: 0.4689 - VH_attention_linear_output_acc: 0.3557 - val_loss: 3.9607 - val_VL_attention_linear_output_loss: 1.8605 - val_VH_attention_linear_output_loss: 2.1003 - val_VL_attention_linear_output_acc: 0.4558 - val_VH_attention_linear_output_acc: 0.3374\n",
      "Epoch 700/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9139 - VL_attention_linear_output_loss: 1.8231 - VH_attention_linear_output_loss: 2.0908 - VL_attention_linear_output_acc: 0.4676 - VH_attention_linear_output_acc: 0.3517 - val_loss: 3.9265 - val_VL_attention_linear_output_loss: 1.8418 - val_VH_attention_linear_output_loss: 2.0847 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.3551\n",
      "Epoch 701/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9053 - VL_attention_linear_output_loss: 1.8193 - VH_attention_linear_output_loss: 2.0860 - VL_attention_linear_output_acc: 0.4690 - VH_attention_linear_output_acc: 0.3537 - val_loss: 3.9325 - val_VL_attention_linear_output_loss: 1.8363 - val_VH_attention_linear_output_loss: 2.0962 - val_VL_attention_linear_output_acc: 0.4631 - val_VH_attention_linear_output_acc: 0.3450\n",
      "Epoch 702/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9256 - VL_attention_linear_output_loss: 1.8395 - VH_attention_linear_output_loss: 2.0861 - VL_attention_linear_output_acc: 0.4594 - VH_attention_linear_output_acc: 0.3534 - val_loss: 3.9191 - val_VL_attention_linear_output_loss: 1.8244 - val_VH_attention_linear_output_loss: 2.0947 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.3492\n",
      "Epoch 703/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9073 - VL_attention_linear_output_loss: 1.8211 - VH_attention_linear_output_loss: 2.0862 - VL_attention_linear_output_acc: 0.4691 - VH_attention_linear_output_acc: 0.3534 - val_loss: 3.9199 - val_VL_attention_linear_output_loss: 1.8322 - val_VH_attention_linear_output_loss: 2.0876 - val_VL_attention_linear_output_acc: 0.4675 - val_VH_attention_linear_output_acc: 0.3519\n",
      "Epoch 704/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0395 - VL_attention_linear_output_loss: 1.8395 - VH_attention_linear_output_loss: 2.2001 - VL_attention_linear_output_acc: 0.4606 - VH_attention_linear_output_acc: 0.3254 - val_loss: 3.9440 - val_VL_attention_linear_output_loss: 1.8393 - val_VH_attention_linear_output_loss: 2.1047 - val_VL_attention_linear_output_acc: 0.4665 - val_VH_attention_linear_output_acc: 0.3439\n",
      "Epoch 705/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9100 - VL_attention_linear_output_loss: 1.8226 - VH_attention_linear_output_loss: 2.0874 - VL_attention_linear_output_acc: 0.4681 - VH_attention_linear_output_acc: 0.3559 - val_loss: 3.9222 - val_VL_attention_linear_output_loss: 1.8292 - val_VH_attention_linear_output_loss: 2.0931 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.3511\n",
      "Epoch 706/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8924 - VL_attention_linear_output_loss: 1.8118 - VH_attention_linear_output_loss: 2.0806 - VL_attention_linear_output_acc: 0.4743 - VH_attention_linear_output_acc: 0.3579 - val_loss: 3.9059 - val_VL_attention_linear_output_loss: 1.8234 - val_VH_attention_linear_output_loss: 2.0825 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.3587\n",
      "Epoch 707/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1416 - VL_attention_linear_output_loss: 1.8334 - VH_attention_linear_output_loss: 2.3082 - VL_attention_linear_output_acc: 0.4643 - VH_attention_linear_output_acc: 0.3149 - val_loss: 4.6872 - val_VL_attention_linear_output_loss: 1.9178 - val_VH_attention_linear_output_loss: 2.7694 - val_VL_attention_linear_output_acc: 0.4364 - val_VH_attention_linear_output_acc: 0.2071\n",
      "Epoch 708/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.3228 - VL_attention_linear_output_loss: 1.8445 - VH_attention_linear_output_loss: 2.4783 - VL_attention_linear_output_acc: 0.4601 - VH_attention_linear_output_acc: 0.2816 - val_loss: 4.2327 - val_VL_attention_linear_output_loss: 1.8524 - val_VH_attention_linear_output_loss: 2.3803 - val_VL_attention_linear_output_acc: 0.4610 - val_VH_attention_linear_output_acc: 0.3059\n",
      "Epoch 709/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1819 - VL_attention_linear_output_loss: 1.8304 - VH_attention_linear_output_loss: 2.3515 - VL_attention_linear_output_acc: 0.4648 - VH_attention_linear_output_acc: 0.3080 - val_loss: 4.1854 - val_VL_attention_linear_output_loss: 1.8693 - val_VH_attention_linear_output_loss: 2.3161 - val_VL_attention_linear_output_acc: 0.4549 - val_VH_attention_linear_output_acc: 0.3113\n",
      "Epoch 710/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1298 - VL_attention_linear_output_loss: 1.8273 - VH_attention_linear_output_loss: 2.3025 - VL_attention_linear_output_acc: 0.4661 - VH_attention_linear_output_acc: 0.3172 - val_loss: 4.1280 - val_VL_attention_linear_output_loss: 1.8400 - val_VH_attention_linear_output_loss: 2.2881 - val_VL_attention_linear_output_acc: 0.4712 - val_VH_attention_linear_output_acc: 0.3184\n",
      "Epoch 711/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1220 - VL_attention_linear_output_loss: 1.8321 - VH_attention_linear_output_loss: 2.2900 - VL_attention_linear_output_acc: 0.4645 - VH_attention_linear_output_acc: 0.3163 - val_loss: 4.2290 - val_VL_attention_linear_output_loss: 1.9468 - val_VH_attention_linear_output_loss: 2.2822 - val_VL_attention_linear_output_acc: 0.4121 - val_VH_attention_linear_output_acc: 0.3161\n",
      "Epoch 712/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1031 - VL_attention_linear_output_loss: 1.8236 - VH_attention_linear_output_loss: 2.2795 - VL_attention_linear_output_acc: 0.4689 - VH_attention_linear_output_acc: 0.3180 - val_loss: 4.1130 - val_VL_attention_linear_output_loss: 1.8416 - val_VH_attention_linear_output_loss: 2.2714 - val_VL_attention_linear_output_acc: 0.4638 - val_VH_attention_linear_output_acc: 0.3168\n",
      "Epoch 713/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0745 - VL_attention_linear_output_loss: 1.8215 - VH_attention_linear_output_loss: 2.2530 - VL_attention_linear_output_acc: 0.4701 - VH_attention_linear_output_acc: 0.3258 - val_loss: 4.1476 - val_VL_attention_linear_output_loss: 1.8980 - val_VH_attention_linear_output_loss: 2.2497 - val_VL_attention_linear_output_acc: 0.4378 - val_VH_attention_linear_output_acc: 0.3246\n",
      "Epoch 714/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0861 - VL_attention_linear_output_loss: 1.8333 - VH_attention_linear_output_loss: 2.2527 - VL_attention_linear_output_acc: 0.4646 - VH_attention_linear_output_acc: 0.3233 - val_loss: 4.0808 - val_VL_attention_linear_output_loss: 1.8370 - val_VH_attention_linear_output_loss: 2.2438 - val_VL_attention_linear_output_acc: 0.4654 - val_VH_attention_linear_output_acc: 0.3259\n",
      "Epoch 715/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0816 - VL_attention_linear_output_loss: 1.8397 - VH_attention_linear_output_loss: 2.2419 - VL_attention_linear_output_acc: 0.4614 - VH_attention_linear_output_acc: 0.3274 - val_loss: 4.0888 - val_VL_attention_linear_output_loss: 1.8590 - val_VH_attention_linear_output_loss: 2.2298 - val_VL_attention_linear_output_acc: 0.4558 - val_VH_attention_linear_output_acc: 0.3315\n",
      "Epoch 716/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0671 - VL_attention_linear_output_loss: 1.8264 - VH_attention_linear_output_loss: 2.2406 - VL_attention_linear_output_acc: 0.4676 - VH_attention_linear_output_acc: 0.3271 - val_loss: 4.0685 - val_VL_attention_linear_output_loss: 1.8462 - val_VH_attention_linear_output_loss: 2.2224 - val_VL_attention_linear_output_acc: 0.4574 - val_VH_attention_linear_output_acc: 0.3309\n",
      "Epoch 717/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0742 - VL_attention_linear_output_loss: 1.8238 - VH_attention_linear_output_loss: 2.2504 - VL_attention_linear_output_acc: 0.4679 - VH_attention_linear_output_acc: 0.3211 - val_loss: 4.0535 - val_VL_attention_linear_output_loss: 1.8372 - val_VH_attention_linear_output_loss: 2.2164 - val_VL_attention_linear_output_acc: 0.4619 - val_VH_attention_linear_output_acc: 0.3306\n",
      "Epoch 718/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0597 - VL_attention_linear_output_loss: 1.8234 - VH_attention_linear_output_loss: 2.2362 - VL_attention_linear_output_acc: 0.4687 - VH_attention_linear_output_acc: 0.3268 - val_loss: 4.1051 - val_VL_attention_linear_output_loss: 1.8308 - val_VH_attention_linear_output_loss: 2.2743 - val_VL_attention_linear_output_acc: 0.4668 - val_VH_attention_linear_output_acc: 0.3103\n",
      "Epoch 719/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0421 - VL_attention_linear_output_loss: 1.8231 - VH_attention_linear_output_loss: 2.2190 - VL_attention_linear_output_acc: 0.4687 - VH_attention_linear_output_acc: 0.3324 - val_loss: 4.0532 - val_VL_attention_linear_output_loss: 1.8407 - val_VH_attention_linear_output_loss: 2.2124 - val_VL_attention_linear_output_acc: 0.4666 - val_VH_attention_linear_output_acc: 0.3310\n",
      "Epoch 720/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1778 - VL_attention_linear_output_loss: 1.8348 - VH_attention_linear_output_loss: 2.3430 - VL_attention_linear_output_acc: 0.4648 - VH_attention_linear_output_acc: 0.2908 - val_loss: 4.1619 - val_VL_attention_linear_output_loss: 1.8384 - val_VH_attention_linear_output_loss: 2.3235 - val_VL_attention_linear_output_acc: 0.4664 - val_VH_attention_linear_output_acc: 0.2895\n",
      "Epoch 721/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1663 - VL_attention_linear_output_loss: 1.8297 - VH_attention_linear_output_loss: 2.3366 - VL_attention_linear_output_acc: 0.4660 - VH_attention_linear_output_acc: 0.2879 - val_loss: 4.1814 - val_VL_attention_linear_output_loss: 1.8397 - val_VH_attention_linear_output_loss: 2.3416 - val_VL_attention_linear_output_acc: 0.4670 - val_VH_attention_linear_output_acc: 0.2764\n",
      "Epoch 722/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1444 - VL_attention_linear_output_loss: 1.8366 - VH_attention_linear_output_loss: 2.3077 - VL_attention_linear_output_acc: 0.4621 - VH_attention_linear_output_acc: 0.2944 - val_loss: 4.1136 - val_VL_attention_linear_output_loss: 1.8333 - val_VH_attention_linear_output_loss: 2.2803 - val_VL_attention_linear_output_acc: 0.4672 - val_VH_attention_linear_output_acc: 0.3019\n",
      "Epoch 723/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.1050 - VL_attention_linear_output_loss: 1.8277 - VH_attention_linear_output_loss: 2.2773 - VL_attention_linear_output_acc: 0.4662 - VH_attention_linear_output_acc: 0.3047 - val_loss: 4.1034 - val_VL_attention_linear_output_loss: 1.8353 - val_VH_attention_linear_output_loss: 2.2680 - val_VL_attention_linear_output_acc: 0.4655 - val_VH_attention_linear_output_acc: 0.3065\n",
      "Epoch 724/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0986 - VL_attention_linear_output_loss: 1.8353 - VH_attention_linear_output_loss: 2.2633 - VL_attention_linear_output_acc: 0.4626 - VH_attention_linear_output_acc: 0.3116 - val_loss: 4.0865 - val_VL_attention_linear_output_loss: 1.8306 - val_VH_attention_linear_output_loss: 2.2560 - val_VL_attention_linear_output_acc: 0.4687 - val_VH_attention_linear_output_acc: 0.3121\n",
      "Epoch 725/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0717 - VL_attention_linear_output_loss: 1.8220 - VH_attention_linear_output_loss: 2.2498 - VL_attention_linear_output_acc: 0.4685 - VH_attention_linear_output_acc: 0.3170 - val_loss: 4.0735 - val_VL_attention_linear_output_loss: 1.8307 - val_VH_attention_linear_output_loss: 2.2429 - val_VL_attention_linear_output_acc: 0.4683 - val_VH_attention_linear_output_acc: 0.3198\n",
      "Epoch 726/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0596 - VL_attention_linear_output_loss: 1.8182 - VH_attention_linear_output_loss: 2.2414 - VL_attention_linear_output_acc: 0.4699 - VH_attention_linear_output_acc: 0.3187 - val_loss: 4.0695 - val_VL_attention_linear_output_loss: 1.8341 - val_VH_attention_linear_output_loss: 2.2354 - val_VL_attention_linear_output_acc: 0.4660 - val_VH_attention_linear_output_acc: 0.3211: 2.2427 - VL_attention_linear_output_acc: 0.4695 - VH_attenti\n",
      "Epoch 727/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0624 - VL_attention_linear_output_loss: 1.8303 - VH_attention_linear_output_loss: 2.2320 - VL_attention_linear_output_acc: 0.4649 - VH_attention_linear_output_acc: 0.3223 - val_loss: 4.0892 - val_VL_attention_linear_output_loss: 1.8605 - val_VH_attention_linear_output_loss: 2.2288 - val_VL_attention_linear_output_acc: 0.4565 - val_VH_attention_linear_output_acc: 0.3207\n",
      "Epoch 728/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0475 - VL_attention_linear_output_loss: 1.8205 - VH_attention_linear_output_loss: 2.2270 - VL_attention_linear_output_acc: 0.4704 - VH_attention_linear_output_acc: 0.3239 - val_loss: 4.0682 - val_VL_attention_linear_output_loss: 1.8347 - val_VH_attention_linear_output_loss: 2.2335 - val_VL_attention_linear_output_acc: 0.4669 - val_VH_attention_linear_output_acc: 0.3193\n",
      "Epoch 729/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0444 - VL_attention_linear_output_loss: 1.8240 - VH_attention_linear_output_loss: 2.2204 - VL_attention_linear_output_acc: 0.4680 - VH_attention_linear_output_acc: 0.3259 - val_loss: 4.1267 - val_VL_attention_linear_output_loss: 1.9063 - val_VH_attention_linear_output_loss: 2.2204 - val_VL_attention_linear_output_acc: 0.4293 - val_VH_attention_linear_output_acc: 0.3178\n",
      "Epoch 730/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0764 - VL_attention_linear_output_loss: 1.8353 - VH_attention_linear_output_loss: 2.2411 - VL_attention_linear_output_acc: 0.4620 - VH_attention_linear_output_acc: 0.3156 - val_loss: 4.0913 - val_VL_attention_linear_output_loss: 1.8387 - val_VH_attention_linear_output_loss: 2.2525 - val_VL_attention_linear_output_acc: 0.4700 - val_VH_attention_linear_output_acc: 0.3033\n",
      "Epoch 731/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0421 - VL_attention_linear_output_loss: 1.8190 - VH_attention_linear_output_loss: 2.2231 - VL_attention_linear_output_acc: 0.4699 - VH_attention_linear_output_acc: 0.3224 - val_loss: 4.0360 - val_VL_attention_linear_output_loss: 1.8252 - val_VH_attention_linear_output_loss: 2.2107 - val_VL_attention_linear_output_acc: 0.4746 - val_VH_attention_linear_output_acc: 0.3257\n",
      "Epoch 732/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0314 - VL_attention_linear_output_loss: 1.8185 - VH_attention_linear_output_loss: 2.2129 - VL_attention_linear_output_acc: 0.4708 - VH_attention_linear_output_acc: 0.3260 - val_loss: 4.0620 - val_VL_attention_linear_output_loss: 1.8569 - val_VH_attention_linear_output_loss: 2.2051 - val_VL_attention_linear_output_acc: 0.4605 - val_VH_attention_linear_output_acc: 0.3312\n",
      "Epoch 733/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0279 - VL_attention_linear_output_loss: 1.8229 - VH_attention_linear_output_loss: 2.2050 - VL_attention_linear_output_acc: 0.4681 - VH_attention_linear_output_acc: 0.3299 - val_loss: 4.0289 - val_VL_attention_linear_output_loss: 1.8302 - val_VH_attention_linear_output_loss: 2.1987 - val_VL_attention_linear_output_acc: 0.4676 - val_VH_attention_linear_output_acc: 0.3267\n",
      "Epoch 734/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0221 - VL_attention_linear_output_loss: 1.8260 - VH_attention_linear_output_loss: 2.1961 - VL_attention_linear_output_acc: 0.4665 - VH_attention_linear_output_acc: 0.3327 - val_loss: 4.0647 - val_VL_attention_linear_output_loss: 1.8589 - val_VH_attention_linear_output_loss: 2.2058 - val_VL_attention_linear_output_acc: 0.4608 - val_VH_attention_linear_output_acc: 0.3237\n",
      "Epoch 735/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0127 - VL_attention_linear_output_loss: 1.8156 - VH_attention_linear_output_loss: 2.1971 - VL_attention_linear_output_acc: 0.4720 - VH_attention_linear_output_acc: 0.3322 - val_loss: 4.0144 - val_VL_attention_linear_output_loss: 1.8285 - val_VH_attention_linear_output_loss: 2.1858 - val_VL_attention_linear_output_acc: 0.4779 - val_VH_attention_linear_output_acc: 0.3367\n",
      "Epoch 736/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0054 - VL_attention_linear_output_loss: 1.8142 - VH_attention_linear_output_loss: 2.1912 - VL_attention_linear_output_acc: 0.4733 - VH_attention_linear_output_acc: 0.3343 - val_loss: 4.0140 - val_VL_attention_linear_output_loss: 1.8335 - val_VH_attention_linear_output_loss: 2.1805 - val_VL_attention_linear_output_acc: 0.4690 - val_VH_attention_linear_output_acc: 0.3425\n",
      "Epoch 737/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0027 - VL_attention_linear_output_loss: 1.8167 - VH_attention_linear_output_loss: 2.1860 - VL_attention_linear_output_acc: 0.4710 - VH_attention_linear_output_acc: 0.3374 - val_loss: 4.0098 - val_VL_attention_linear_output_loss: 1.8325 - val_VH_attention_linear_output_loss: 2.1774 - val_VL_attention_linear_output_acc: 0.4668 - val_VH_attention_linear_output_acc: 0.3427\n",
      "Epoch 738/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0007 - VL_attention_linear_output_loss: 1.8191 - VH_attention_linear_output_loss: 2.1817 - VL_attention_linear_output_acc: 0.4714 - VH_attention_linear_output_acc: 0.3402 - val_loss: 4.0517 - val_VL_attention_linear_output_loss: 1.8271 - val_VH_attention_linear_output_loss: 2.2246 - val_VL_attention_linear_output_acc: 0.4682 - val_VH_attention_linear_output_acc: 0.3085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0066 - VL_attention_linear_output_loss: 1.8248 - VH_attention_linear_output_loss: 2.1819 - VL_attention_linear_output_acc: 0.4676 - VH_attention_linear_output_acc: 0.3378 - val_loss: 4.0996 - val_VL_attention_linear_output_loss: 1.9074 - val_VH_attention_linear_output_loss: 2.1922 - val_VL_attention_linear_output_acc: 0.4299 - val_VH_attention_linear_output_acc: 0.3331\n",
      "Epoch 740/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0120 - VL_attention_linear_output_loss: 1.8351 - VH_attention_linear_output_loss: 2.1769 - VL_attention_linear_output_acc: 0.4623 - VH_attention_linear_output_acc: 0.3397 - val_loss: 3.9969 - val_VL_attention_linear_output_loss: 1.8330 - val_VH_attention_linear_output_loss: 2.1639 - val_VL_attention_linear_output_acc: 0.4704 - val_VH_attention_linear_output_acc: 0.3449\n",
      "Epoch 741/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9790 - VL_attention_linear_output_loss: 1.8087 - VH_attention_linear_output_loss: 2.1703 - VL_attention_linear_output_acc: 0.4756 - VH_attention_linear_output_acc: 0.3431 - val_loss: 3.9950 - val_VL_attention_linear_output_loss: 1.8358 - val_VH_attention_linear_output_loss: 2.1592 - val_VL_attention_linear_output_acc: 0.4657 - val_VH_attention_linear_output_acc: 0.3527\n",
      "Epoch 742/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0240 - VL_attention_linear_output_loss: 1.8164 - VH_attention_linear_output_loss: 2.2076 - VL_attention_linear_output_acc: 0.4716 - VH_attention_linear_output_acc: 0.3326 - val_loss: 4.0553 - val_VL_attention_linear_output_loss: 1.8334 - val_VH_attention_linear_output_loss: 2.2220 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.3295\n",
      "Epoch 743/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0233 - VL_attention_linear_output_loss: 1.8173 - VH_attention_linear_output_loss: 2.2060 - VL_attention_linear_output_acc: 0.4699 - VH_attention_linear_output_acc: 0.3308 - val_loss: 4.0604 - val_VL_attention_linear_output_loss: 1.8400 - val_VH_attention_linear_output_loss: 2.2204 - val_VL_attention_linear_output_acc: 0.4659 - val_VH_attention_linear_output_acc: 0.3132\n",
      "Epoch 744/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 4.0108 - VL_attention_linear_output_loss: 1.8270 - VH_attention_linear_output_loss: 2.1838 - VL_attention_linear_output_acc: 0.4675 - VH_attention_linear_output_acc: 0.3357 - val_loss: 4.0221 - val_VL_attention_linear_output_loss: 1.8476 - val_VH_attention_linear_output_loss: 2.1745 - val_VL_attention_linear_output_acc: 0.4619 - val_VH_attention_linear_output_acc: 0.3349\n",
      "Epoch 745/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9764 - VL_attention_linear_output_loss: 1.8127 - VH_attention_linear_output_loss: 2.1637 - VL_attention_linear_output_acc: 0.4731 - VH_attention_linear_output_acc: 0.3444 - val_loss: 3.9841 - val_VL_attention_linear_output_loss: 1.8219 - val_VH_attention_linear_output_loss: 2.1622 - val_VL_attention_linear_output_acc: 0.4717 - val_VH_attention_linear_output_acc: 0.3453\n",
      "Epoch 746/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9699 - VL_attention_linear_output_loss: 1.8118 - VH_attention_linear_output_loss: 2.1581 - VL_attention_linear_output_acc: 0.4732 - VH_attention_linear_output_acc: 0.3475 - val_loss: 3.9942 - val_VL_attention_linear_output_loss: 1.8311 - val_VH_attention_linear_output_loss: 2.1632 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.3448\n",
      "Epoch 747/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9671 - VL_attention_linear_output_loss: 1.8125 - VH_attention_linear_output_loss: 2.1546 - VL_attention_linear_output_acc: 0.4719 - VH_attention_linear_output_acc: 0.3479 - val_loss: 3.9927 - val_VL_attention_linear_output_loss: 1.8298 - val_VH_attention_linear_output_loss: 2.1630 - val_VL_attention_linear_output_acc: 0.4686 - val_VH_attention_linear_output_acc: 0.3455\n",
      "Epoch 748/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9595 - VL_attention_linear_output_loss: 1.8098 - VH_attention_linear_output_loss: 2.1497 - VL_attention_linear_output_acc: 0.4755 - VH_attention_linear_output_acc: 0.3504 - val_loss: 3.9821 - val_VL_attention_linear_output_loss: 1.8359 - val_VH_attention_linear_output_loss: 2.1461 - val_VL_attention_linear_output_acc: 0.4662 - val_VH_attention_linear_output_acc: 0.3525\n",
      "Epoch 749/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9699 - VL_attention_linear_output_loss: 1.8211 - VH_attention_linear_output_loss: 2.1488 - VL_attention_linear_output_acc: 0.4685 - VH_attention_linear_output_acc: 0.3496 - val_loss: 3.9853 - val_VL_attention_linear_output_loss: 1.8327 - val_VH_attention_linear_output_loss: 2.1525 - val_VL_attention_linear_output_acc: 0.4661 - val_VH_attention_linear_output_acc: 0.3473\n",
      "Epoch 750/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9552 - VL_attention_linear_output_loss: 1.8091 - VH_attention_linear_output_loss: 2.1461 - VL_attention_linear_output_acc: 0.4739 - VH_attention_linear_output_acc: 0.3507 - val_loss: 3.9702 - val_VL_attention_linear_output_loss: 1.8251 - val_VH_attention_linear_output_loss: 2.1450 - val_VL_attention_linear_output_acc: 0.4774 - val_VH_attention_linear_output_acc: 0.3500\n",
      "Epoch 751/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9574 - VL_attention_linear_output_loss: 1.8142 - VH_attention_linear_output_loss: 2.1432 - VL_attention_linear_output_acc: 0.4724 - VH_attention_linear_output_acc: 0.3506 - val_loss: 3.9743 - val_VL_attention_linear_output_loss: 1.8272 - val_VH_attention_linear_output_loss: 2.1471 - val_VL_attention_linear_output_acc: 0.4726 - val_VH_attention_linear_output_acc: 0.3449\n",
      "Epoch 752/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9480 - VL_attention_linear_output_loss: 1.8051 - VH_attention_linear_output_loss: 2.1429 - VL_attention_linear_output_acc: 0.4763 - VH_attention_linear_output_acc: 0.3513 - val_loss: 3.9824 - val_VL_attention_linear_output_loss: 1.8261 - val_VH_attention_linear_output_loss: 2.1562 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.3444\n",
      "Epoch 753/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9637 - VL_attention_linear_output_loss: 1.8175 - VH_attention_linear_output_loss: 2.1462 - VL_attention_linear_output_acc: 0.4707 - VH_attention_linear_output_acc: 0.3477 - val_loss: 4.0110 - val_VL_attention_linear_output_loss: 1.8436 - val_VH_attention_linear_output_loss: 2.1675 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.3355\n",
      "Epoch 754/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9582 - VL_attention_linear_output_loss: 1.8218 - VH_attention_linear_output_loss: 2.1363 - VL_attention_linear_output_acc: 0.4694 - VH_attention_linear_output_acc: 0.3523 - val_loss: 3.9651 - val_VL_attention_linear_output_loss: 1.8284 - val_VH_attention_linear_output_loss: 2.1367 - val_VL_attention_linear_output_acc: 0.4674 - val_VH_attention_linear_output_acc: 0.3550\n",
      "Epoch 755/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9543 - VL_attention_linear_output_loss: 1.8149 - VH_attention_linear_output_loss: 2.1394 - VL_attention_linear_output_acc: 0.4723 - VH_attention_linear_output_acc: 0.3499 - val_loss: 3.9598 - val_VL_attention_linear_output_loss: 1.8251 - val_VH_attention_linear_output_loss: 2.1346 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.3519\n",
      "Epoch 756/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9430 - VL_attention_linear_output_loss: 1.8108 - VH_attention_linear_output_loss: 2.1322 - VL_attention_linear_output_acc: 0.4735 - VH_attention_linear_output_acc: 0.3530 - val_loss: 3.9748 - val_VL_attention_linear_output_loss: 1.8273 - val_VH_attention_linear_output_loss: 2.1476 - val_VL_attention_linear_output_acc: 0.4682 - val_VH_attention_linear_output_acc: 0.3384\n",
      "Epoch 757/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9583 - VL_attention_linear_output_loss: 1.8202 - VH_attention_linear_output_loss: 2.1382 - VL_attention_linear_output_acc: 0.4676 - VH_attention_linear_output_acc: 0.3499 - val_loss: 3.9717 - val_VL_attention_linear_output_loss: 1.8277 - val_VH_attention_linear_output_loss: 2.1441 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.3430\n",
      "Epoch 758/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9442 - VL_attention_linear_output_loss: 1.8098 - VH_attention_linear_output_loss: 2.1344 - VL_attention_linear_output_acc: 0.4738 - VH_attention_linear_output_acc: 0.3518 - val_loss: 3.9596 - val_VL_attention_linear_output_loss: 1.8295 - val_VH_attention_linear_output_loss: 2.1302 - val_VL_attention_linear_output_acc: 0.4715 - val_VH_attention_linear_output_acc: 0.3561\n",
      "Epoch 759/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9423 - VL_attention_linear_output_loss: 1.8104 - VH_attention_linear_output_loss: 2.1319 - VL_attention_linear_output_acc: 0.4751 - VH_attention_linear_output_acc: 0.3520 - val_loss: 3.9600 - val_VL_attention_linear_output_loss: 1.8369 - val_VH_attention_linear_output_loss: 2.1231 - val_VL_attention_linear_output_acc: 0.4654 - val_VH_attention_linear_output_acc: 0.3563\n",
      "Epoch 760/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9538 - VL_attention_linear_output_loss: 1.8123 - VH_attention_linear_output_loss: 2.1416 - VL_attention_linear_output_acc: 0.4725 - VH_attention_linear_output_acc: 0.3449 - val_loss: 3.9657 - val_VL_attention_linear_output_loss: 1.8381 - val_VH_attention_linear_output_loss: 2.1276 - val_VL_attention_linear_output_acc: 0.4632 - val_VH_attention_linear_output_acc: 0.3559\n",
      "Epoch 761/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9561 - VL_attention_linear_output_loss: 1.8258 - VH_attention_linear_output_loss: 2.1303 - VL_attention_linear_output_acc: 0.4659 - VH_attention_linear_output_acc: 0.3522 - val_loss: 3.9726 - val_VL_attention_linear_output_loss: 1.8276 - val_VH_attention_linear_output_loss: 2.1450 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.3402\n",
      "Epoch 762/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9543 - VL_attention_linear_output_loss: 1.8067 - VH_attention_linear_output_loss: 2.1476 - VL_attention_linear_output_acc: 0.4760 - VH_attention_linear_output_acc: 0.3452 - val_loss: 3.9847 - val_VL_attention_linear_output_loss: 1.8265 - val_VH_attention_linear_output_loss: 2.1582 - val_VL_attention_linear_output_acc: 0.4759 - val_VH_attention_linear_output_acc: 0.3343\n",
      "Epoch 763/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9522 - VL_attention_linear_output_loss: 1.8127 - VH_attention_linear_output_loss: 2.1395 - VL_attention_linear_output_acc: 0.4726 - VH_attention_linear_output_acc: 0.3498 - val_loss: 4.0019 - val_VL_attention_linear_output_loss: 1.8291 - val_VH_attention_linear_output_loss: 2.1728 - val_VL_attention_linear_output_acc: 0.4779 - val_VH_attention_linear_output_acc: 0.3324\n",
      "Epoch 764/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9463 - VL_attention_linear_output_loss: 1.8108 - VH_attention_linear_output_loss: 2.1355 - VL_attention_linear_output_acc: 0.4741 - VH_attention_linear_output_acc: 0.3479 - val_loss: 3.9566 - val_VL_attention_linear_output_loss: 1.8374 - val_VH_attention_linear_output_loss: 2.1192 - val_VL_attention_linear_output_acc: 0.4728 - val_VH_attention_linear_output_acc: 0.3537\n",
      "Epoch 765/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9554 - VL_attention_linear_output_loss: 1.8273 - VH_attention_linear_output_loss: 2.1281 - VL_attention_linear_output_acc: 0.4652 - VH_attention_linear_output_acc: 0.3524 - val_loss: 3.9472 - val_VL_attention_linear_output_loss: 1.8209 - val_VH_attention_linear_output_loss: 2.1264 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.3490\n",
      "Epoch 766/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9327 - VL_attention_linear_output_loss: 1.8071 - VH_attention_linear_output_loss: 2.1255 - VL_attention_linear_output_acc: 0.4769 - VH_attention_linear_output_acc: 0.3536 - val_loss: 3.9477 - val_VL_attention_linear_output_loss: 1.8241 - val_VH_attention_linear_output_loss: 2.1236 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.3560\n",
      "Epoch 767/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9379 - VL_attention_linear_output_loss: 1.8131 - VH_attention_linear_output_loss: 2.1248 - VL_attention_linear_output_acc: 0.4721 - VH_attention_linear_output_acc: 0.3527 - val_loss: 3.9729 - val_VL_attention_linear_output_loss: 1.8298 - val_VH_attention_linear_output_loss: 2.1431 - val_VL_attention_linear_output_acc: 0.4687 - val_VH_attention_linear_output_acc: 0.3399\n",
      "Epoch 768/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9297 - VL_attention_linear_output_loss: 1.8112 - VH_attention_linear_output_loss: 2.1186 - VL_attention_linear_output_acc: 0.4726 - VH_attention_linear_output_acc: 0.3543 - val_loss: 3.9579 - val_VL_attention_linear_output_loss: 1.8346 - val_VH_attention_linear_output_loss: 2.1233 - val_VL_attention_linear_output_acc: 0.4643 - val_VH_attention_linear_output_acc: 0.3562\n",
      "Epoch 769/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9390 - VL_attention_linear_output_loss: 1.8095 - VH_attention_linear_output_loss: 2.1295 - VL_attention_linear_output_acc: 0.4750 - VH_attention_linear_output_acc: 0.3481 - val_loss: 3.9405 - val_VL_attention_linear_output_loss: 1.8271 - val_VH_attention_linear_output_loss: 2.1134 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.3616\n",
      "Epoch 770/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9522 - VL_attention_linear_output_loss: 1.8280 - VH_attention_linear_output_loss: 2.1242 - VL_attention_linear_output_acc: 0.4657 - VH_attention_linear_output_acc: 0.3499 - val_loss: 3.9353 - val_VL_attention_linear_output_loss: 1.8291 - val_VH_attention_linear_output_loss: 2.1063 - val_VL_attention_linear_output_acc: 0.4718 - val_VH_attention_linear_output_acc: 0.3613\n",
      "Epoch 771/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9165 - VL_attention_linear_output_loss: 1.8084 - VH_attention_linear_output_loss: 2.1081 - VL_attention_linear_output_acc: 0.4733 - VH_attention_linear_output_acc: 0.3584 - val_loss: 3.9562 - val_VL_attention_linear_output_loss: 1.8377 - val_VH_attention_linear_output_loss: 2.1185 - val_VL_attention_linear_output_acc: 0.4611 - val_VH_attention_linear_output_acc: 0.3475\n",
      "Epoch 772/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9300 - VL_attention_linear_output_loss: 1.8137 - VH_attention_linear_output_loss: 2.1164 - VL_attention_linear_output_acc: 0.4728 - VH_attention_linear_output_acc: 0.3541 - val_loss: 3.9819 - val_VL_attention_linear_output_loss: 1.8734 - val_VH_attention_linear_output_loss: 2.1085 - val_VL_attention_linear_output_acc: 0.4569 - val_VH_attention_linear_output_acc: 0.3585\n",
      "Epoch 773/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9420 - VL_attention_linear_output_loss: 1.8277 - VH_attention_linear_output_loss: 2.1143 - VL_attention_linear_output_acc: 0.4665 - VH_attention_linear_output_acc: 0.3536 - val_loss: 4.0780 - val_VL_attention_linear_output_loss: 1.8645 - val_VH_attention_linear_output_loss: 2.2135 - val_VL_attention_linear_output_acc: 0.4458 - val_VH_attention_linear_output_acc: 0.3060\n",
      "Epoch 774/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9389 - VL_attention_linear_output_loss: 1.8208 - VH_attention_linear_output_loss: 2.1181 - VL_attention_linear_output_acc: 0.4692 - VH_attention_linear_output_acc: 0.3515 - val_loss: 4.0074 - val_VL_attention_linear_output_loss: 1.8914 - val_VH_attention_linear_output_loss: 2.1160 - val_VL_attention_linear_output_acc: 0.4423 - val_VH_attention_linear_output_acc: 0.3507\n",
      "Epoch 775/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9176 - VL_attention_linear_output_loss: 1.8134 - VH_attention_linear_output_loss: 2.1042 - VL_attention_linear_output_acc: 0.4722 - VH_attention_linear_output_acc: 0.3576 - val_loss: 3.9414 - val_VL_attention_linear_output_loss: 1.8254 - val_VH_attention_linear_output_loss: 2.1160 - val_VL_attention_linear_output_acc: 0.4746 - val_VH_attention_linear_output_acc: 0.3540\n",
      "Epoch 776/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9373 - VL_attention_linear_output_loss: 1.8282 - VH_attention_linear_output_loss: 2.1090 - VL_attention_linear_output_acc: 0.4645 - VH_attention_linear_output_acc: 0.3542 - val_loss: 3.9377 - val_VL_attention_linear_output_loss: 1.8308 - val_VH_attention_linear_output_loss: 2.1069 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.3527\n",
      "Epoch 777/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9184 - VL_attention_linear_output_loss: 1.8172 - VH_attention_linear_output_loss: 2.1012 - VL_attention_linear_output_acc: 0.4716 - VH_attention_linear_output_acc: 0.3587 - val_loss: 3.9342 - val_VL_attention_linear_output_loss: 1.8317 - val_VH_attention_linear_output_loss: 2.1026 - val_VL_attention_linear_output_acc: 0.4675 - val_VH_attention_linear_output_acc: 0.3567\n",
      "Epoch 778/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9138 - VL_attention_linear_output_loss: 1.8105 - VH_attention_linear_output_loss: 2.1032 - VL_attention_linear_output_acc: 0.4729 - VH_attention_linear_output_acc: 0.3584 - val_loss: 3.9347 - val_VL_attention_linear_output_loss: 1.8343 - val_VH_attention_linear_output_loss: 2.1004 - val_VL_attention_linear_output_acc: 0.4686 - val_VH_attention_linear_output_acc: 0.3567\n",
      "Epoch 779/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9173 - VL_attention_linear_output_loss: 1.8152 - VH_attention_linear_output_loss: 2.1021 - VL_attention_linear_output_acc: 0.4727 - VH_attention_linear_output_acc: 0.3588 - val_loss: 3.9593 - val_VL_attention_linear_output_loss: 1.8338 - val_VH_attention_linear_output_loss: 2.1255 - val_VL_attention_linear_output_acc: 0.4720 - val_VH_attention_linear_output_acc: 0.3429\n",
      "Epoch 780/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9298 - VL_attention_linear_output_loss: 1.8294 - VH_attention_linear_output_loss: 2.1004 - VL_attention_linear_output_acc: 0.4646 - VH_attention_linear_output_acc: 0.3578 - val_loss: 3.9389 - val_VL_attention_linear_output_loss: 1.8265 - val_VH_attention_linear_output_loss: 2.1125 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.3456\n",
      "Epoch 781/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9184 - VL_attention_linear_output_loss: 1.8168 - VH_attention_linear_output_loss: 2.1016 - VL_attention_linear_output_acc: 0.4708 - VH_attention_linear_output_acc: 0.3566 - val_loss: 3.9513 - val_VL_attention_linear_output_loss: 1.8372 - val_VH_attention_linear_output_loss: 2.1142 - val_VL_attention_linear_output_acc: 0.4607 - val_VH_attention_linear_output_acc: 0.3498\n",
      "Epoch 782/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9170 - VL_attention_linear_output_loss: 1.8215 - VH_attention_linear_output_loss: 2.0955 - VL_attention_linear_output_acc: 0.4654 - VH_attention_linear_output_acc: 0.3599 - val_loss: 3.9243 - val_VL_attention_linear_output_loss: 1.8324 - val_VH_attention_linear_output_loss: 2.0919 - val_VL_attention_linear_output_acc: 0.4624 - val_VH_attention_linear_output_acc: 0.3600\n",
      "Epoch 783/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9447 - VL_attention_linear_output_loss: 1.8417 - VH_attention_linear_output_loss: 2.1029 - VL_attention_linear_output_acc: 0.4579 - VH_attention_linear_output_acc: 0.3547 - val_loss: 3.9164 - val_VL_attention_linear_output_loss: 1.8235 - val_VH_attention_linear_output_loss: 2.0929 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.3651\n",
      "Epoch 784/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8974 - VL_attention_linear_output_loss: 1.8059 - VH_attention_linear_output_loss: 2.0915 - VL_attention_linear_output_acc: 0.4754 - VH_attention_linear_output_acc: 0.3620 - val_loss: 3.9415 - val_VL_attention_linear_output_loss: 1.8432 - val_VH_attention_linear_output_loss: 2.0983 - val_VL_attention_linear_output_acc: 0.4694 - val_VH_attention_linear_output_acc: 0.3654\n",
      "Epoch 785/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9087 - VL_attention_linear_output_loss: 1.8104 - VH_attention_linear_output_loss: 2.0983 - VL_attention_linear_output_acc: 0.4751 - VH_attention_linear_output_acc: 0.3598 - val_loss: 3.9292 - val_VL_attention_linear_output_loss: 1.8227 - val_VH_attention_linear_output_loss: 2.1065 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.3528\n",
      "Epoch 786/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9093 - VL_attention_linear_output_loss: 1.8215 - VH_attention_linear_output_loss: 2.0878 - VL_attention_linear_output_acc: 0.4681 - VH_attention_linear_output_acc: 0.3649 - val_loss: 3.9207 - val_VL_attention_linear_output_loss: 1.8295 - val_VH_attention_linear_output_loss: 2.0912 - val_VL_attention_linear_output_acc: 0.4702 - val_VH_attention_linear_output_acc: 0.3689\n",
      "Epoch 787/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9032 - VL_attention_linear_output_loss: 1.8046 - VH_attention_linear_output_loss: 2.0986 - VL_attention_linear_output_acc: 0.4755 - VH_attention_linear_output_acc: 0.3599 - val_loss: 3.9044 - val_VL_attention_linear_output_loss: 1.8197 - val_VH_attention_linear_output_loss: 2.0847 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.3692\n",
      "Epoch 788/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9139 - VL_attention_linear_output_loss: 1.8189 - VH_attention_linear_output_loss: 2.0951 - VL_attention_linear_output_acc: 0.4697 - VH_attention_linear_output_acc: 0.3614 - val_loss: 3.9294 - val_VL_attention_linear_output_loss: 1.8222 - val_VH_attention_linear_output_loss: 2.1071 - val_VL_attention_linear_output_acc: 0.4750 - val_VH_attention_linear_output_acc: 0.3565\n",
      "Epoch 789/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8980 - VL_attention_linear_output_loss: 1.8098 - VH_attention_linear_output_loss: 2.0882 - VL_attention_linear_output_acc: 0.4742 - VH_attention_linear_output_acc: 0.3652 - val_loss: 3.9287 - val_VL_attention_linear_output_loss: 1.8245 - val_VH_attention_linear_output_loss: 2.1042 - val_VL_attention_linear_output_acc: 0.4759 - val_VH_attention_linear_output_acc: 0.3503\n",
      "Epoch 790/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9061 - VL_attention_linear_output_loss: 1.8124 - VH_attention_linear_output_loss: 2.0937 - VL_attention_linear_output_acc: 0.4728 - VH_attention_linear_output_acc: 0.3625 - val_loss: 3.9358 - val_VL_attention_linear_output_loss: 1.8568 - val_VH_attention_linear_output_loss: 2.0790 - val_VL_attention_linear_output_acc: 0.4548 - val_VH_attention_linear_output_acc: 0.3737\n",
      "Epoch 791/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9101 - VL_attention_linear_output_loss: 1.8206 - VH_attention_linear_output_loss: 2.0895 - VL_attention_linear_output_acc: 0.4683 - VH_attention_linear_output_acc: 0.3643 - val_loss: 3.9206 - val_VL_attention_linear_output_loss: 1.8281 - val_VH_attention_linear_output_loss: 2.0924 - val_VL_attention_linear_output_acc: 0.4671 - val_VH_attention_linear_output_acc: 0.3634\n",
      "Epoch 792/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8853 - VL_attention_linear_output_loss: 1.8062 - VH_attention_linear_output_loss: 2.0791 - VL_attention_linear_output_acc: 0.4749 - VH_attention_linear_output_acc: 0.3710 - val_loss: 3.9461 - val_VL_attention_linear_output_loss: 1.8392 - val_VH_attention_linear_output_loss: 2.1068 - val_VL_attention_linear_output_acc: 0.4686 - val_VH_attention_linear_output_acc: 0.3558\n",
      "Epoch 793/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9073 - VL_attention_linear_output_loss: 1.8242 - VH_attention_linear_output_loss: 2.0831 - VL_attention_linear_output_acc: 0.4687 - VH_attention_linear_output_acc: 0.3680 - val_loss: 3.9948 - val_VL_attention_linear_output_loss: 1.8366 - val_VH_attention_linear_output_loss: 2.1582 - val_VL_attention_linear_output_acc: 0.4708 - val_VH_attention_linear_output_acc: 0.3264\n",
      "Epoch 794/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9046 - VL_attention_linear_output_loss: 1.8218 - VH_attention_linear_output_loss: 2.0828 - VL_attention_linear_output_acc: 0.4679 - VH_attention_linear_output_acc: 0.3681 - val_loss: 3.9132 - val_VL_attention_linear_output_loss: 1.8236 - val_VH_attention_linear_output_loss: 2.0897 - val_VL_attention_linear_output_acc: 0.4716 - val_VH_attention_linear_output_acc: 0.3666\n",
      "Epoch 795/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8988 - VL_attention_linear_output_loss: 1.8109 - VH_attention_linear_output_loss: 2.0878 - VL_attention_linear_output_acc: 0.4732 - VH_attention_linear_output_acc: 0.3668 - val_loss: 3.9512 - val_VL_attention_linear_output_loss: 1.8626 - val_VH_attention_linear_output_loss: 2.0886 - val_VL_attention_linear_output_acc: 0.4517 - val_VH_attention_linear_output_acc: 0.3733\n",
      "Epoch 796/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9476 - VL_attention_linear_output_loss: 1.8363 - VH_attention_linear_output_loss: 2.1113 - VL_attention_linear_output_acc: 0.4598 - VH_attention_linear_output_acc: 0.3622 - val_loss: 3.9459 - val_VL_attention_linear_output_loss: 1.8313 - val_VH_attention_linear_output_loss: 2.1146 - val_VL_attention_linear_output_acc: 0.4680 - val_VH_attention_linear_output_acc: 0.3616\n",
      "Epoch 797/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9084 - VL_attention_linear_output_loss: 1.8095 - VH_attention_linear_output_loss: 2.0989 - VL_attention_linear_output_acc: 0.4735 - VH_attention_linear_output_acc: 0.3684 - val_loss: 3.9618 - val_VL_attention_linear_output_loss: 1.8311 - val_VH_attention_linear_output_loss: 2.1307 - val_VL_attention_linear_output_acc: 0.4711 - val_VH_attention_linear_output_acc: 0.3442\n",
      "Epoch 798/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9067 - VL_attention_linear_output_loss: 1.8114 - VH_attention_linear_output_loss: 2.0953 - VL_attention_linear_output_acc: 0.4725 - VH_attention_linear_output_acc: 0.3668 - val_loss: 3.9184 - val_VL_attention_linear_output_loss: 1.8233 - val_VH_attention_linear_output_loss: 2.0951 - val_VL_attention_linear_output_acc: 0.4672 - val_VH_attention_linear_output_acc: 0.3627\n",
      "Epoch 799/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8861 - VL_attention_linear_output_loss: 1.8060 - VH_attention_linear_output_loss: 2.0801 - VL_attention_linear_output_acc: 0.4737 - VH_attention_linear_output_acc: 0.3711 - val_loss: 3.9003 - val_VL_attention_linear_output_loss: 1.8252 - val_VH_attention_linear_output_loss: 2.0751 - val_VL_attention_linear_output_acc: 0.4710 - val_VH_attention_linear_output_acc: 0.3739\n",
      "Epoch 800/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8931 - VL_attention_linear_output_loss: 1.8122 - VH_attention_linear_output_loss: 2.0809 - VL_attention_linear_output_acc: 0.4716 - VH_attention_linear_output_acc: 0.3679 - val_loss: 3.9122 - val_VL_attention_linear_output_loss: 1.8338 - val_VH_attention_linear_output_loss: 2.0783 - val_VL_attention_linear_output_acc: 0.4686 - val_VH_attention_linear_output_acc: 0.3693\n",
      "Epoch 801/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9000 - VL_attention_linear_output_loss: 1.8180 - VH_attention_linear_output_loss: 2.0820 - VL_attention_linear_output_acc: 0.4682 - VH_attention_linear_output_acc: 0.3679 - val_loss: 3.9273 - val_VL_attention_linear_output_loss: 1.8419 - val_VH_attention_linear_output_loss: 2.0854 - val_VL_attention_linear_output_acc: 0.4617 - val_VH_attention_linear_output_acc: 0.3653\n",
      "Epoch 802/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9042 - VL_attention_linear_output_loss: 1.8100 - VH_attention_linear_output_loss: 2.0942 - VL_attention_linear_output_acc: 0.4736 - VH_attention_linear_output_acc: 0.3620 - val_loss: 3.9399 - val_VL_attention_linear_output_loss: 1.8384 - val_VH_attention_linear_output_loss: 2.1016 - val_VL_attention_linear_output_acc: 0.4615 - val_VH_attention_linear_output_acc: 0.3612\n",
      "Epoch 803/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.9068 - VL_attention_linear_output_loss: 1.8163 - VH_attention_linear_output_loss: 2.0904 - VL_attention_linear_output_acc: 0.4693 - VH_attention_linear_output_acc: 0.3671 - val_loss: 3.9282 - val_VL_attention_linear_output_loss: 1.8299 - val_VH_attention_linear_output_loss: 2.0983 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.3634\n",
      "Epoch 804/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8986 - VL_attention_linear_output_loss: 1.8045 - VH_attention_linear_output_loss: 2.0941 - VL_attention_linear_output_acc: 0.4753 - VH_attention_linear_output_acc: 0.3691 - val_loss: 3.9318 - val_VL_attention_linear_output_loss: 1.8252 - val_VH_attention_linear_output_loss: 2.1066 - val_VL_attention_linear_output_acc: 0.4694 - val_VH_attention_linear_output_acc: 0.3596\n",
      "Epoch 805/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8815 - VL_attention_linear_output_loss: 1.8053 - VH_attention_linear_output_loss: 2.0763 - VL_attention_linear_output_acc: 0.4744 - VH_attention_linear_output_acc: 0.3753 - val_loss: 3.9008 - val_VL_attention_linear_output_loss: 1.8175 - val_VH_attention_linear_output_loss: 2.0833 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.3723\n",
      "Epoch 806/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8853 - VL_attention_linear_output_loss: 1.8105 - VH_attention_linear_output_loss: 2.0748 - VL_attention_linear_output_acc: 0.4727 - VH_attention_linear_output_acc: 0.3746 - val_loss: 3.9215 - val_VL_attention_linear_output_loss: 1.8430 - val_VH_attention_linear_output_loss: 2.0785 - val_VL_attention_linear_output_acc: 0.4652 - val_VH_attention_linear_output_acc: 0.3775\n",
      "Epoch 807/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8886 - VL_attention_linear_output_loss: 1.8137 - VH_attention_linear_output_loss: 2.0748 - VL_attention_linear_output_acc: 0.4718 - VH_attention_linear_output_acc: 0.3731 - val_loss: 3.9045 - val_VL_attention_linear_output_loss: 1.8218 - val_VH_attention_linear_output_loss: 2.0827 - val_VL_attention_linear_output_acc: 0.4685 - val_VH_attention_linear_output_acc: 0.3696\n",
      "Epoch 808/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8776 - VL_attention_linear_output_loss: 1.8044 - VH_attention_linear_output_loss: 2.0732 - VL_attention_linear_output_acc: 0.4757 - VH_attention_linear_output_acc: 0.3741 - val_loss: 3.9111 - val_VL_attention_linear_output_loss: 1.8318 - val_VH_attention_linear_output_loss: 2.0793 - val_VL_attention_linear_output_acc: 0.4670 - val_VH_attention_linear_output_acc: 0.3692\n",
      "Epoch 809/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8909 - VL_attention_linear_output_loss: 1.8245 - VH_attention_linear_output_loss: 2.0664 - VL_attention_linear_output_acc: 0.4664 - VH_attention_linear_output_acc: 0.3771 - val_loss: 3.9059 - val_VL_attention_linear_output_loss: 1.8276 - val_VH_attention_linear_output_loss: 2.0783 - val_VL_attention_linear_output_acc: 0.4682 - val_VH_attention_linear_output_acc: 0.3722\n",
      "Epoch 810/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8697 - VL_attention_linear_output_loss: 1.8014 - VH_attention_linear_output_loss: 2.0684 - VL_attention_linear_output_acc: 0.4764 - VH_attention_linear_output_acc: 0.3750 - val_loss: 3.8951 - val_VL_attention_linear_output_loss: 1.8171 - val_VH_attention_linear_output_loss: 2.0780 - val_VL_attention_linear_output_acc: 0.4692 - val_VH_attention_linear_output_acc: 0.3685\n",
      "Epoch 811/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8680 - VL_attention_linear_output_loss: 1.8034 - VH_attention_linear_output_loss: 2.0645 - VL_attention_linear_output_acc: 0.4751 - VH_attention_linear_output_acc: 0.3771 - val_loss: 3.9060 - val_VL_attention_linear_output_loss: 1.8272 - val_VH_attention_linear_output_loss: 2.0788 - val_VL_attention_linear_output_acc: 0.4654 - val_VH_attention_linear_output_acc: 0.3716\n",
      "Epoch 812/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8798 - VL_attention_linear_output_loss: 1.8105 - VH_attention_linear_output_loss: 2.0694 - VL_attention_linear_output_acc: 0.4717 - VH_attention_linear_output_acc: 0.3743 - val_loss: 3.9022 - val_VL_attention_linear_output_loss: 1.8274 - val_VH_attention_linear_output_loss: 2.0749 - val_VL_attention_linear_output_acc: 0.4699 - val_VH_attention_linear_output_acc: 0.3712\n",
      "Epoch 813/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8871 - VL_attention_linear_output_loss: 1.8199 - VH_attention_linear_output_loss: 2.0673 - VL_attention_linear_output_acc: 0.4673 - VH_attention_linear_output_acc: 0.3753 - val_loss: 3.9762 - val_VL_attention_linear_output_loss: 1.8236 - val_VH_attention_linear_output_loss: 2.1526 - val_VL_attention_linear_output_acc: 0.4694 - val_VH_attention_linear_output_acc: 0.3300\n",
      "Epoch 814/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8711 - VL_attention_linear_output_loss: 1.8015 - VH_attention_linear_output_loss: 2.0696 - VL_attention_linear_output_acc: 0.4774 - VH_attention_linear_output_acc: 0.3742 - val_loss: 3.8821 - val_VL_attention_linear_output_loss: 1.8152 - val_VH_attention_linear_output_loss: 2.0669 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.3774\n",
      "Epoch 815/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8651 - VL_attention_linear_output_loss: 1.8006 - VH_attention_linear_output_loss: 2.0645 - VL_attention_linear_output_acc: 0.4750 - VH_attention_linear_output_acc: 0.3763 - val_loss: 3.8982 - val_VL_attention_linear_output_loss: 1.8358 - val_VH_attention_linear_output_loss: 2.0624 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.3799\n",
      "Epoch 816/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8682 - VL_attention_linear_output_loss: 1.8071 - VH_attention_linear_output_loss: 2.0610 - VL_attention_linear_output_acc: 0.4730 - VH_attention_linear_output_acc: 0.3780 - val_loss: 3.9001 - val_VL_attention_linear_output_loss: 1.8322 - val_VH_attention_linear_output_loss: 2.0679 - val_VL_attention_linear_output_acc: 0.4638 - val_VH_attention_linear_output_acc: 0.3741\n",
      "Epoch 817/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8801 - VL_attention_linear_output_loss: 1.8145 - VH_attention_linear_output_loss: 2.0656 - VL_attention_linear_output_acc: 0.4680 - VH_attention_linear_output_acc: 0.3739 - val_loss: 3.8793 - val_VL_attention_linear_output_loss: 1.8193 - val_VH_attention_linear_output_loss: 2.0600 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.3804\n",
      "Epoch 818/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8617 - VL_attention_linear_output_loss: 1.8004 - VH_attention_linear_output_loss: 2.0614 - VL_attention_linear_output_acc: 0.4764 - VH_attention_linear_output_acc: 0.3772 - val_loss: 3.9085 - val_VL_attention_linear_output_loss: 1.8259 - val_VH_attention_linear_output_loss: 2.0826 - val_VL_attention_linear_output_acc: 0.4716 - val_VH_attention_linear_output_acc: 0.3684\n",
      "Epoch 819/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8704 - VL_attention_linear_output_loss: 1.8098 - VH_attention_linear_output_loss: 2.0606 - VL_attention_linear_output_acc: 0.4715 - VH_attention_linear_output_acc: 0.3770 - val_loss: 3.9349 - val_VL_attention_linear_output_loss: 1.8637 - val_VH_attention_linear_output_loss: 2.0712 - val_VL_attention_linear_output_acc: 0.4538 - val_VH_attention_linear_output_acc: 0.3758\n",
      "Epoch 820/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8748 - VL_attention_linear_output_loss: 1.8097 - VH_attention_linear_output_loss: 2.0651 - VL_attention_linear_output_acc: 0.4715 - VH_attention_linear_output_acc: 0.3747 - val_loss: 3.9018 - val_VL_attention_linear_output_loss: 1.8369 - val_VH_attention_linear_output_loss: 2.0649 - val_VL_attention_linear_output_acc: 0.4688 - val_VH_attention_linear_output_acc: 0.3758\n",
      "Epoch 821/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8823 - VL_attention_linear_output_loss: 1.8160 - VH_attention_linear_output_loss: 2.0663 - VL_attention_linear_output_acc: 0.4679 - VH_attention_linear_output_acc: 0.3743 - val_loss: 3.9161 - val_VL_attention_linear_output_loss: 1.8324 - val_VH_attention_linear_output_loss: 2.0837 - val_VL_attention_linear_output_acc: 0.4649 - val_VH_attention_linear_output_acc: 0.3633\n",
      "Epoch 822/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8665 - VL_attention_linear_output_loss: 1.8046 - VH_attention_linear_output_loss: 2.0619 - VL_attention_linear_output_acc: 0.4751 - VH_attention_linear_output_acc: 0.3759 - val_loss: 3.8747 - val_VL_attention_linear_output_loss: 1.8169 - val_VH_attention_linear_output_loss: 2.0578 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.3764\n",
      "Epoch 823/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8693 - VL_attention_linear_output_loss: 1.8107 - VH_attention_linear_output_loss: 2.0587 - VL_attention_linear_output_acc: 0.4722 - VH_attention_linear_output_acc: 0.3769 - val_loss: 3.8940 - val_VL_attention_linear_output_loss: 1.8264 - val_VH_attention_linear_output_loss: 2.0675 - val_VL_attention_linear_output_acc: 0.4672 - val_VH_attention_linear_output_acc: 0.3728\n",
      "Epoch 824/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8671 - VL_attention_linear_output_loss: 1.8048 - VH_attention_linear_output_loss: 2.0623 - VL_attention_linear_output_acc: 0.4737 - VH_attention_linear_output_acc: 0.3745 - val_loss: 3.8903 - val_VL_attention_linear_output_loss: 1.8196 - val_VH_attention_linear_output_loss: 2.0707 - val_VL_attention_linear_output_acc: 0.4695 - val_VH_attention_linear_output_acc: 0.3739\n",
      "Epoch 825/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8638 - VL_attention_linear_output_loss: 1.8065 - VH_attention_linear_output_loss: 2.0573 - VL_attention_linear_output_acc: 0.4722 - VH_attention_linear_output_acc: 0.3782 - val_loss: 3.9317 - val_VL_attention_linear_output_loss: 1.8275 - val_VH_attention_linear_output_loss: 2.1042 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.3491\n",
      "Epoch 826/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8775 - VL_attention_linear_output_loss: 1.8051 - VH_attention_linear_output_loss: 2.0724 - VL_attention_linear_output_acc: 0.4744 - VH_attention_linear_output_acc: 0.3711 - val_loss: 3.9358 - val_VL_attention_linear_output_loss: 1.8600 - val_VH_attention_linear_output_loss: 2.0758 - val_VL_attention_linear_output_acc: 0.4549 - val_VH_attention_linear_output_acc: 0.3720\n",
      "Epoch 827/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8601 - VL_attention_linear_output_loss: 1.8057 - VH_attention_linear_output_loss: 2.0544 - VL_attention_linear_output_acc: 0.4725 - VH_attention_linear_output_acc: 0.3776 - val_loss: 3.8897 - val_VL_attention_linear_output_loss: 1.8239 - val_VH_attention_linear_output_loss: 2.0659 - val_VL_attention_linear_output_acc: 0.4654 - val_VH_attention_linear_output_acc: 0.3744\n",
      "Epoch 828/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8809 - VL_attention_linear_output_loss: 1.8120 - VH_attention_linear_output_loss: 2.0689 - VL_attention_linear_output_acc: 0.4704 - VH_attention_linear_output_acc: 0.3694 - val_loss: 3.9213 - val_VL_attention_linear_output_loss: 1.8367 - val_VH_attention_linear_output_loss: 2.0846 - val_VL_attention_linear_output_acc: 0.4655 - val_VH_attention_linear_output_acc: 0.3675\n",
      "Epoch 829/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8753 - VL_attention_linear_output_loss: 1.8114 - VH_attention_linear_output_loss: 2.0639 - VL_attention_linear_output_acc: 0.4699 - VH_attention_linear_output_acc: 0.3723 - val_loss: 3.8962 - val_VL_attention_linear_output_loss: 1.8346 - val_VH_attention_linear_output_loss: 2.0615 - val_VL_attention_linear_output_acc: 0.4612 - val_VH_attention_linear_output_acc: 0.3782\n",
      "Epoch 830/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8605 - VL_attention_linear_output_loss: 1.8088 - VH_attention_linear_output_loss: 2.0517 - VL_attention_linear_output_acc: 0.4724 - VH_attention_linear_output_acc: 0.3789 - val_loss: 3.8978 - val_VL_attention_linear_output_loss: 1.8479 - val_VH_attention_linear_output_loss: 2.0499 - val_VL_attention_linear_output_acc: 0.4578 - val_VH_attention_linear_output_acc: 0.3819\n",
      "Epoch 831/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8690 - VL_attention_linear_output_loss: 1.8171 - VH_attention_linear_output_loss: 2.0519 - VL_attention_linear_output_acc: 0.4694 - VH_attention_linear_output_acc: 0.3784 - val_loss: 3.8915 - val_VL_attention_linear_output_loss: 1.8365 - val_VH_attention_linear_output_loss: 2.0551 - val_VL_attention_linear_output_acc: 0.4667 - val_VH_attention_linear_output_acc: 0.3788\n",
      "Epoch 832/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8718 - VL_attention_linear_output_loss: 1.8116 - VH_attention_linear_output_loss: 2.0602 - VL_attention_linear_output_acc: 0.4704 - VH_attention_linear_output_acc: 0.3740 - val_loss: 4.1575 - val_VL_attention_linear_output_loss: 1.8414 - val_VH_attention_linear_output_loss: 2.3160 - val_VL_attention_linear_output_acc: 0.4531 - val_VH_attention_linear_output_acc: 0.2789\n",
      "Epoch 833/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8800 - VL_attention_linear_output_loss: 1.8185 - VH_attention_linear_output_loss: 2.0615 - VL_attention_linear_output_acc: 0.4657 - VH_attention_linear_output_acc: 0.3733 - val_loss: 3.8741 - val_VL_attention_linear_output_loss: 1.8253 - val_VH_attention_linear_output_loss: 2.0487 - val_VL_attention_linear_output_acc: 0.4686 - val_VH_attention_linear_output_acc: 0.3812\n",
      "Epoch 834/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8537 - VL_attention_linear_output_loss: 1.8048 - VH_attention_linear_output_loss: 2.0489 - VL_attention_linear_output_acc: 0.4746 - VH_attention_linear_output_acc: 0.3789 - val_loss: 3.9047 - val_VL_attention_linear_output_loss: 1.8216 - val_VH_attention_linear_output_loss: 2.0831 - val_VL_attention_linear_output_acc: 0.4673 - val_VH_attention_linear_output_acc: 0.3620\n",
      "Epoch 835/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8751 - VL_attention_linear_output_loss: 1.8181 - VH_attention_linear_output_loss: 2.0570 - VL_attention_linear_output_acc: 0.4660 - VH_attention_linear_output_acc: 0.3733 - val_loss: 3.8889 - val_VL_attention_linear_output_loss: 1.8395 - val_VH_attention_linear_output_loss: 2.0494 - val_VL_attention_linear_output_acc: 0.4608 - val_VH_attention_linear_output_acc: 0.3788\n",
      "Epoch 836/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8470 - VL_attention_linear_output_loss: 1.8034 - VH_attention_linear_output_loss: 2.0436 - VL_attention_linear_output_acc: 0.4760 - VH_attention_linear_output_acc: 0.3807 - val_loss: 3.8727 - val_VL_attention_linear_output_loss: 1.8278 - val_VH_attention_linear_output_loss: 2.0449 - val_VL_attention_linear_output_acc: 0.4663 - val_VH_attention_linear_output_acc: 0.3831\n",
      "Epoch 837/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8603 - VL_attention_linear_output_loss: 1.8027 - VH_attention_linear_output_loss: 2.0576 - VL_attention_linear_output_acc: 0.4752 - VH_attention_linear_output_acc: 0.3731 - val_loss: 3.9055 - val_VL_attention_linear_output_loss: 1.8194 - val_VH_attention_linear_output_loss: 2.0861 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.3595\n",
      "Epoch 838/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8483 - VL_attention_linear_output_loss: 1.8047 - VH_attention_linear_output_loss: 2.0436 - VL_attention_linear_output_acc: 0.4736 - VH_attention_linear_output_acc: 0.3798 - val_loss: 3.8803 - val_VL_attention_linear_output_loss: 1.8233 - val_VH_attention_linear_output_loss: 2.0570 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.3784\n",
      "Epoch 839/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8716 - VL_attention_linear_output_loss: 1.8242 - VH_attention_linear_output_loss: 2.0474 - VL_attention_linear_output_acc: 0.4657 - VH_attention_linear_output_acc: 0.3775 - val_loss: 3.8719 - val_VL_attention_linear_output_loss: 1.8254 - val_VH_attention_linear_output_loss: 2.0466 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.3826\n",
      "Epoch 840/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8550 - VL_attention_linear_output_loss: 1.8053 - VH_attention_linear_output_loss: 2.0497 - VL_attention_linear_output_acc: 0.4718 - VH_attention_linear_output_acc: 0.3764 - val_loss: 3.8896 - val_VL_attention_linear_output_loss: 1.8309 - val_VH_attention_linear_output_loss: 2.0587 - val_VL_attention_linear_output_acc: 0.4698 - val_VH_attention_linear_output_acc: 0.3768\n",
      "Epoch 841/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8660 - VL_attention_linear_output_loss: 1.8048 - VH_attention_linear_output_loss: 2.0612 - VL_attention_linear_output_acc: 0.4733 - VH_attention_linear_output_acc: 0.3732 - val_loss: 3.8774 - val_VL_attention_linear_output_loss: 1.8266 - val_VH_attention_linear_output_loss: 2.0508 - val_VL_attention_linear_output_acc: 0.4690 - val_VH_attention_linear_output_acc: 0.3762\n",
      "Epoch 842/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8699 - VL_attention_linear_output_loss: 1.8193 - VH_attention_linear_output_loss: 2.0506 - VL_attention_linear_output_acc: 0.4657 - VH_attention_linear_output_acc: 0.3777 - val_loss: 3.8690 - val_VL_attention_linear_output_loss: 1.8237 - val_VH_attention_linear_output_loss: 2.0453 - val_VL_attention_linear_output_acc: 0.4676 - val_VH_attention_linear_output_acc: 0.3812\n",
      "Epoch 843/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8507 - VL_attention_linear_output_loss: 1.8050 - VH_attention_linear_output_loss: 2.0457 - VL_attention_linear_output_acc: 0.4734 - VH_attention_linear_output_acc: 0.3787 - val_loss: 3.9607 - val_VL_attention_linear_output_loss: 1.8914 - val_VH_attention_linear_output_loss: 2.0693 - val_VL_attention_linear_output_acc: 0.4335 - val_VH_attention_linear_output_acc: 0.3690\n",
      "Epoch 844/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8626 - VL_attention_linear_output_loss: 1.8121 - VH_attention_linear_output_loss: 2.0504 - VL_attention_linear_output_acc: 0.4681 - VH_attention_linear_output_acc: 0.3764 - val_loss: 3.8750 - val_VL_attention_linear_output_loss: 1.8230 - val_VH_attention_linear_output_loss: 2.0519 - val_VL_attention_linear_output_acc: 0.4705 - val_VH_attention_linear_output_acc: 0.3754\n",
      "Epoch 845/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8476 - VL_attention_linear_output_loss: 1.8113 - VH_attention_linear_output_loss: 2.0363 - VL_attention_linear_output_acc: 0.4703 - VH_attention_linear_output_acc: 0.3829 - val_loss: 3.8639 - val_VL_attention_linear_output_loss: 1.8168 - val_VH_attention_linear_output_loss: 2.0471 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.3800\n",
      "Epoch 846/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8521 - VL_attention_linear_output_loss: 1.8093 - VH_attention_linear_output_loss: 2.0428 - VL_attention_linear_output_acc: 0.4704 - VH_attention_linear_output_acc: 0.3779 - val_loss: 3.8944 - val_VL_attention_linear_output_loss: 1.8310 - val_VH_attention_linear_output_loss: 2.0634 - val_VL_attention_linear_output_acc: 0.4658 - val_VH_attention_linear_output_acc: 0.3713\n",
      "Epoch 847/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8498 - VL_attention_linear_output_loss: 1.8117 - VH_attention_linear_output_loss: 2.0381 - VL_attention_linear_output_acc: 0.4712 - VH_attention_linear_output_acc: 0.3805 - val_loss: 3.8723 - val_VL_attention_linear_output_loss: 1.8297 - val_VH_attention_linear_output_loss: 2.0426 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.3789\n",
      "Epoch 848/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8392 - VL_attention_linear_output_loss: 1.7996 - VH_attention_linear_output_loss: 2.0395 - VL_attention_linear_output_acc: 0.4764 - VH_attention_linear_output_acc: 0.3787 - val_loss: 3.9320 - val_VL_attention_linear_output_loss: 1.8224 - val_VH_attention_linear_output_loss: 2.1096 - val_VL_attention_linear_output_acc: 0.4700 - val_VH_attention_linear_output_acc: 0.3398\n",
      "Epoch 849/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8511 - VL_attention_linear_output_loss: 1.8095 - VH_attention_linear_output_loss: 2.0416 - VL_attention_linear_output_acc: 0.4705 - VH_attention_linear_output_acc: 0.3780 - val_loss: 3.8544 - val_VL_attention_linear_output_loss: 1.8190 - val_VH_attention_linear_output_loss: 2.0354 - val_VL_attention_linear_output_acc: 0.4701 - val_VH_attention_linear_output_acc: 0.3851\n",
      "Epoch 850/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8334 - VL_attention_linear_output_loss: 1.7992 - VH_attention_linear_output_loss: 2.0342 - VL_attention_linear_output_acc: 0.4760 - VH_attention_linear_output_acc: 0.3816 - val_loss: 3.8681 - val_VL_attention_linear_output_loss: 1.8190 - val_VH_attention_linear_output_loss: 2.0491 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.3772\n",
      "Epoch 851/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8479 - VL_attention_linear_output_loss: 1.8058 - VH_attention_linear_output_loss: 2.0421 - VL_attention_linear_output_acc: 0.4726 - VH_attention_linear_output_acc: 0.3786 - val_loss: 3.8752 - val_VL_attention_linear_output_loss: 1.8401 - val_VH_attention_linear_output_loss: 2.0351 - val_VL_attention_linear_output_acc: 0.4583 - val_VH_attention_linear_output_acc: 0.3815\n",
      "Epoch 852/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8589 - VL_attention_linear_output_loss: 1.8153 - VH_attention_linear_output_loss: 2.0436 - VL_attention_linear_output_acc: 0.4673 - VH_attention_linear_output_acc: 0.3792 - val_loss: 3.8773 - val_VL_attention_linear_output_loss: 1.8341 - val_VH_attention_linear_output_loss: 2.0432 - val_VL_attention_linear_output_acc: 0.4684 - val_VH_attention_linear_output_acc: 0.3829\n",
      "Epoch 853/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8482 - VL_attention_linear_output_loss: 1.8078 - VH_attention_linear_output_loss: 2.0404 - VL_attention_linear_output_acc: 0.4723 - VH_attention_linear_output_acc: 0.3817 - val_loss: 3.8879 - val_VL_attention_linear_output_loss: 1.8428 - val_VH_attention_linear_output_loss: 2.0452 - val_VL_attention_linear_output_acc: 0.4560 - val_VH_attention_linear_output_acc: 0.3806\n",
      "Epoch 854/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8491 - VL_attention_linear_output_loss: 1.8108 - VH_attention_linear_output_loss: 2.0383 - VL_attention_linear_output_acc: 0.4697 - VH_attention_linear_output_acc: 0.3818 - val_loss: 3.8568 - val_VL_attention_linear_output_loss: 1.8160 - val_VH_attention_linear_output_loss: 2.0409 - val_VL_attention_linear_output_acc: 0.4720 - val_VH_attention_linear_output_acc: 0.3798\n",
      "Epoch 855/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8282 - VL_attention_linear_output_loss: 1.7975 - VH_attention_linear_output_loss: 2.0307 - VL_attention_linear_output_acc: 0.4768 - VH_attention_linear_output_acc: 0.3840 - val_loss: 3.8535 - val_VL_attention_linear_output_loss: 1.8220 - val_VH_attention_linear_output_loss: 2.0315 - val_VL_attention_linear_output_acc: 0.4689 - val_VH_attention_linear_output_acc: 0.3853\n",
      "Epoch 856/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8289 - VL_attention_linear_output_loss: 1.7991 - VH_attention_linear_output_loss: 2.0298 - VL_attention_linear_output_acc: 0.4766 - VH_attention_linear_output_acc: 0.3835 - val_loss: 3.8481 - val_VL_attention_linear_output_loss: 1.8172 - val_VH_attention_linear_output_loss: 2.0309 - val_VL_attention_linear_output_acc: 0.4782 - val_VH_attention_linear_output_acc: 0.3824\n",
      "Epoch 857/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8285 - VL_attention_linear_output_loss: 1.7994 - VH_attention_linear_output_loss: 2.0291 - VL_attention_linear_output_acc: 0.4752 - VH_attention_linear_output_acc: 0.3837 - val_loss: 3.8797 - val_VL_attention_linear_output_loss: 1.8445 - val_VH_attention_linear_output_loss: 2.0352 - val_VL_attention_linear_output_acc: 0.4587 - val_VH_attention_linear_output_acc: 0.3843\n",
      "Epoch 858/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8409 - VL_attention_linear_output_loss: 1.8121 - VH_attention_linear_output_loss: 2.0288 - VL_attention_linear_output_acc: 0.4686 - VH_attention_linear_output_acc: 0.3845 - val_loss: 3.9127 - val_VL_attention_linear_output_loss: 1.8756 - val_VH_attention_linear_output_loss: 2.0371 - val_VL_attention_linear_output_acc: 0.4450 - val_VH_attention_linear_output_acc: 0.3829\n",
      "Epoch 859/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8303 - VL_attention_linear_output_loss: 1.8002 - VH_attention_linear_output_loss: 2.0300 - VL_attention_linear_output_acc: 0.4743 - VH_attention_linear_output_acc: 0.3833 - val_loss: 3.8533 - val_VL_attention_linear_output_loss: 1.8276 - val_VH_attention_linear_output_loss: 2.0258 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.3828\n",
      "Epoch 860/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8291 - VL_attention_linear_output_loss: 1.7998 - VH_attention_linear_output_loss: 2.0293 - VL_attention_linear_output_acc: 0.4755 - VH_attention_linear_output_acc: 0.3821 - val_loss: 3.8397 - val_VL_attention_linear_output_loss: 1.8156 - val_VH_attention_linear_output_loss: 2.0241 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.3873\n",
      "Epoch 861/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8209 - VL_attention_linear_output_loss: 1.7959 - VH_attention_linear_output_loss: 2.0250 - VL_attention_linear_output_acc: 0.4757 - VH_attention_linear_output_acc: 0.3839 - val_loss: 3.8401 - val_VL_attention_linear_output_loss: 1.8159 - val_VH_attention_linear_output_loss: 2.0242 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.3865\n",
      "Epoch 862/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8352 - VL_attention_linear_output_loss: 1.8127 - VH_attention_linear_output_loss: 2.0225 - VL_attention_linear_output_acc: 0.4678 - VH_attention_linear_output_acc: 0.3846 - val_loss: 3.9129 - val_VL_attention_linear_output_loss: 1.8183 - val_VH_attention_linear_output_loss: 2.0946 - val_VL_attention_linear_output_acc: 0.4685 - val_VH_attention_linear_output_acc: 0.3468\n",
      "Epoch 863/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8292 - VL_attention_linear_output_loss: 1.7973 - VH_attention_linear_output_loss: 2.0319 - VL_attention_linear_output_acc: 0.4752 - VH_attention_linear_output_acc: 0.3793 - val_loss: 3.8650 - val_VL_attention_linear_output_loss: 1.8373 - val_VH_attention_linear_output_loss: 2.0277 - val_VL_attention_linear_output_acc: 0.4642 - val_VH_attention_linear_output_acc: 0.3852\n",
      "Epoch 864/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8283 - VL_attention_linear_output_loss: 1.8008 - VH_attention_linear_output_loss: 2.0275 - VL_attention_linear_output_acc: 0.4745 - VH_attention_linear_output_acc: 0.3819 - val_loss: 3.8804 - val_VL_attention_linear_output_loss: 1.8428 - val_VH_attention_linear_output_loss: 2.0377 - val_VL_attention_linear_output_acc: 0.4625 - val_VH_attention_linear_output_acc: 0.3822\n",
      "Epoch 865/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8740 - VL_attention_linear_output_loss: 1.8107 - VH_attention_linear_output_loss: 2.0633 - VL_attention_linear_output_acc: 0.4701 - VH_attention_linear_output_acc: 0.3729 - val_loss: 3.9235 - val_VL_attention_linear_output_loss: 1.8371 - val_VH_attention_linear_output_loss: 2.0864 - val_VL_attention_linear_output_acc: 0.4632 - val_VH_attention_linear_output_acc: 0.3572\n",
      "Epoch 866/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8913 - VL_attention_linear_output_loss: 1.8188 - VH_attention_linear_output_loss: 2.0725 - VL_attention_linear_output_acc: 0.4663 - VH_attention_linear_output_acc: 0.3695 - val_loss: 3.8806 - val_VL_attention_linear_output_loss: 1.8213 - val_VH_attention_linear_output_loss: 2.0593 - val_VL_attention_linear_output_acc: 0.4673 - val_VH_attention_linear_output_acc: 0.3705\n",
      "Epoch 867/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8524 - VL_attention_linear_output_loss: 1.7983 - VH_attention_linear_output_loss: 2.0541 - VL_attention_linear_output_acc: 0.4750 - VH_attention_linear_output_acc: 0.3736 - val_loss: 3.8720 - val_VL_attention_linear_output_loss: 1.8196 - val_VH_attention_linear_output_loss: 2.0524 - val_VL_attention_linear_output_acc: 0.4678 - val_VH_attention_linear_output_acc: 0.3721\n",
      "Epoch 868/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8398 - VL_attention_linear_output_loss: 1.7983 - VH_attention_linear_output_loss: 2.0415 - VL_attention_linear_output_acc: 0.4768 - VH_attention_linear_output_acc: 0.3791 - val_loss: 3.8594 - val_VL_attention_linear_output_loss: 1.8164 - val_VH_attention_linear_output_loss: 2.0430 - val_VL_attention_linear_output_acc: 0.4694 - val_VH_attention_linear_output_acc: 0.3720\n",
      "Epoch 869/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8430 - VL_attention_linear_output_loss: 1.8090 - VH_attention_linear_output_loss: 2.0340 - VL_attention_linear_output_acc: 0.4712 - VH_attention_linear_output_acc: 0.3803 - val_loss: 3.8421 - val_VL_attention_linear_output_loss: 1.8178 - val_VH_attention_linear_output_loss: 2.0243 - val_VL_attention_linear_output_acc: 0.4688 - val_VH_attention_linear_output_acc: 0.3846\n",
      "Epoch 870/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8256 - VL_attention_linear_output_loss: 1.7985 - VH_attention_linear_output_loss: 2.0271 - VL_attention_linear_output_acc: 0.4761 - VH_attention_linear_output_acc: 0.3832 - val_loss: 3.8426 - val_VL_attention_linear_output_loss: 1.8192 - val_VH_attention_linear_output_loss: 2.0234 - val_VL_attention_linear_output_acc: 0.4699 - val_VH_attention_linear_output_acc: 0.3847\n",
      "Epoch 871/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8314 - VL_attention_linear_output_loss: 1.8050 - VH_attention_linear_output_loss: 2.0263 - VL_attention_linear_output_acc: 0.4718 - VH_attention_linear_output_acc: 0.3830 - val_loss: 3.8547 - val_VL_attention_linear_output_loss: 1.8164 - val_VH_attention_linear_output_loss: 2.0383 - val_VL_attention_linear_output_acc: 0.4713 - val_VH_attention_linear_output_acc: 0.3779\n",
      "Epoch 872/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8361 - VL_attention_linear_output_loss: 1.8090 - VH_attention_linear_output_loss: 2.0271 - VL_attention_linear_output_acc: 0.4697 - VH_attention_linear_output_acc: 0.3808 - val_loss: 3.8693 - val_VL_attention_linear_output_loss: 1.8181 - val_VH_attention_linear_output_loss: 2.0511 - val_VL_attention_linear_output_acc: 0.4716 - val_VH_attention_linear_output_acc: 0.3716\n",
      "Epoch 873/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8147 - VL_attention_linear_output_loss: 1.7959 - VH_attention_linear_output_loss: 2.0188 - VL_attention_linear_output_acc: 0.4770 - VH_attention_linear_output_acc: 0.3848 - val_loss: 3.8416 - val_VL_attention_linear_output_loss: 1.8207 - val_VH_attention_linear_output_loss: 2.0209 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.3859\n",
      "Epoch 874/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8319 - VL_attention_linear_output_loss: 1.8053 - VH_attention_linear_output_loss: 2.0266 - VL_attention_linear_output_acc: 0.4712 - VH_attention_linear_output_acc: 0.3800 - val_loss: 3.8502 - val_VL_attention_linear_output_loss: 1.8302 - val_VH_attention_linear_output_loss: 2.0200 - val_VL_attention_linear_output_acc: 0.4698 - val_VH_attention_linear_output_acc: 0.3856\n",
      "Epoch 875/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8317 - VL_attention_linear_output_loss: 1.8056 - VH_attention_linear_output_loss: 2.0260 - VL_attention_linear_output_acc: 0.4727 - VH_attention_linear_output_acc: 0.3810 - val_loss: 3.8570 - val_VL_attention_linear_output_loss: 1.8216 - val_VH_attention_linear_output_loss: 2.0354 - val_VL_attention_linear_output_acc: 0.4674 - val_VH_attention_linear_output_acc: 0.3767\n",
      "Epoch 876/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8302 - VL_attention_linear_output_loss: 1.8016 - VH_attention_linear_output_loss: 2.0286 - VL_attention_linear_output_acc: 0.4730 - VH_attention_linear_output_acc: 0.3785 - val_loss: 3.8458 - val_VL_attention_linear_output_loss: 1.8263 - val_VH_attention_linear_output_loss: 2.0195 - val_VL_attention_linear_output_acc: 0.4666 - val_VH_attention_linear_output_acc: 0.3824\n",
      "Epoch 877/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8243 - VL_attention_linear_output_loss: 1.8093 - VH_attention_linear_output_loss: 2.0150 - VL_attention_linear_output_acc: 0.4694 - VH_attention_linear_output_acc: 0.3853 - val_loss: 3.8482 - val_VL_attention_linear_output_loss: 1.8229 - val_VH_attention_linear_output_loss: 2.0253 - val_VL_attention_linear_output_acc: 0.4726 - val_VH_attention_linear_output_acc: 0.3804\n",
      "Epoch 878/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8200 - VL_attention_linear_output_loss: 1.8038 - VH_attention_linear_output_loss: 2.0161 - VL_attention_linear_output_acc: 0.4712 - VH_attention_linear_output_acc: 0.3842 - val_loss: 3.8533 - val_VL_attention_linear_output_loss: 1.8390 - val_VH_attention_linear_output_loss: 2.0143 - val_VL_attention_linear_output_acc: 0.4623 - val_VH_attention_linear_output_acc: 0.3878\n",
      "Epoch 879/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8330 - VL_attention_linear_output_loss: 1.8078 - VH_attention_linear_output_loss: 2.0252 - VL_attention_linear_output_acc: 0.4717 - VH_attention_linear_output_acc: 0.3804 - val_loss: 3.8533 - val_VL_attention_linear_output_loss: 1.8171 - val_VH_attention_linear_output_loss: 2.0362 - val_VL_attention_linear_output_acc: 0.4750 - val_VH_attention_linear_output_acc: 0.3772\n",
      "Epoch 880/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8291 - VL_attention_linear_output_loss: 1.8085 - VH_attention_linear_output_loss: 2.0206 - VL_attention_linear_output_acc: 0.4695 - VH_attention_linear_output_acc: 0.3829 - val_loss: 3.8772 - val_VL_attention_linear_output_loss: 1.8242 - val_VH_attention_linear_output_loss: 2.0530 - val_VL_attention_linear_output_acc: 0.4666 - val_VH_attention_linear_output_acc: 0.3711\n",
      "Epoch 881/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8248 - VL_attention_linear_output_loss: 1.8012 - VH_attention_linear_output_loss: 2.0236 - VL_attention_linear_output_acc: 0.4732 - VH_attention_linear_output_acc: 0.3820 - val_loss: 3.8423 - val_VL_attention_linear_output_loss: 1.8192 - val_VH_attention_linear_output_loss: 2.0231 - val_VL_attention_linear_output_acc: 0.4767 - val_VH_attention_linear_output_acc: 0.3823\n",
      "Epoch 882/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8133 - VL_attention_linear_output_loss: 1.7947 - VH_attention_linear_output_loss: 2.0186 - VL_attention_linear_output_acc: 0.4762 - VH_attention_linear_output_acc: 0.3832 - val_loss: 3.9202 - val_VL_attention_linear_output_loss: 1.8352 - val_VH_attention_linear_output_loss: 2.0851 - val_VL_attention_linear_output_acc: 0.4579 - val_VH_attention_linear_output_acc: 0.3463\n",
      "Epoch 883/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8161 - VL_attention_linear_output_loss: 1.8000 - VH_attention_linear_output_loss: 2.0161 - VL_attention_linear_output_acc: 0.4735 - VH_attention_linear_output_acc: 0.3832 - val_loss: 3.8626 - val_VL_attention_linear_output_loss: 1.8278 - val_VH_attention_linear_output_loss: 2.0348 - val_VL_attention_linear_output_acc: 0.4644 - val_VH_attention_linear_output_acc: 0.3767\n",
      "Epoch 884/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8278 - VL_attention_linear_output_loss: 1.8032 - VH_attention_linear_output_loss: 2.0246 - VL_attention_linear_output_acc: 0.4718 - VH_attention_linear_output_acc: 0.3806 - val_loss: 3.9050 - val_VL_attention_linear_output_loss: 1.8892 - val_VH_attention_linear_output_loss: 2.0158 - val_VL_attention_linear_output_acc: 0.4396 - val_VH_attention_linear_output_acc: 0.3842\n",
      "Epoch 885/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8265 - VL_attention_linear_output_loss: 1.8077 - VH_attention_linear_output_loss: 2.0188 - VL_attention_linear_output_acc: 0.4716 - VH_attention_linear_output_acc: 0.3822 - val_loss: 3.8351 - val_VL_attention_linear_output_loss: 1.8227 - val_VH_attention_linear_output_loss: 2.0124 - val_VL_attention_linear_output_acc: 0.4663 - val_VH_attention_linear_output_acc: 0.3829\n",
      "Epoch 886/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8155 - VL_attention_linear_output_loss: 1.8003 - VH_attention_linear_output_loss: 2.0151 - VL_attention_linear_output_acc: 0.4730 - VH_attention_linear_output_acc: 0.3833 - val_loss: 3.8470 - val_VL_attention_linear_output_loss: 1.8282 - val_VH_attention_linear_output_loss: 2.0188 - val_VL_attention_linear_output_acc: 0.4647 - val_VH_attention_linear_output_acc: 0.3832\n",
      "Epoch 887/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8265 - VL_attention_linear_output_loss: 1.8122 - VH_attention_linear_output_loss: 2.0144 - VL_attention_linear_output_acc: 0.4675 - VH_attention_linear_output_acc: 0.3835 - val_loss: 3.8291 - val_VL_attention_linear_output_loss: 1.8184 - val_VH_attention_linear_output_loss: 2.0107 - val_VL_attention_linear_output_acc: 0.4712 - val_VH_attention_linear_output_acc: 0.3862\n",
      "Epoch 888/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8026 - VL_attention_linear_output_loss: 1.7913 - VH_attention_linear_output_loss: 2.0112 - VL_attention_linear_output_acc: 0.4764 - VH_attention_linear_output_acc: 0.3852 - val_loss: 3.8293 - val_VL_attention_linear_output_loss: 1.8147 - val_VH_attention_linear_output_loss: 2.0146 - val_VL_attention_linear_output_acc: 0.4725 - val_VH_attention_linear_output_acc: 0.3857\n",
      "Epoch 889/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8213 - VL_attention_linear_output_loss: 1.8110 - VH_attention_linear_output_loss: 2.0103 - VL_attention_linear_output_acc: 0.4687 - VH_attention_linear_output_acc: 0.3852 - val_loss: 3.8352 - val_VL_attention_linear_output_loss: 1.8228 - val_VH_attention_linear_output_loss: 2.0123 - val_VL_attention_linear_output_acc: 0.4661 - val_VH_attention_linear_output_acc: 0.3857\n",
      "Epoch 890/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8165 - VL_attention_linear_output_loss: 1.7938 - VH_attention_linear_output_loss: 2.0227 - VL_attention_linear_output_acc: 0.4769 - VH_attention_linear_output_acc: 0.3817 - val_loss: 3.8391 - val_VL_attention_linear_output_loss: 1.8158 - val_VH_attention_linear_output_loss: 2.0233 - val_VL_attention_linear_output_acc: 0.4695 - val_VH_attention_linear_output_acc: 0.3793\n",
      "Epoch 891/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8320 - VL_attention_linear_output_loss: 1.8041 - VH_attention_linear_output_loss: 2.0279 - VL_attention_linear_output_acc: 0.4708 - VH_attention_linear_output_acc: 0.3808 - val_loss: 3.8418 - val_VL_attention_linear_output_loss: 1.8185 - val_VH_attention_linear_output_loss: 2.0234 - val_VL_attention_linear_output_acc: 0.4729 - val_VH_attention_linear_output_acc: 0.3818\n",
      "Epoch 892/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8190 - VL_attention_linear_output_loss: 1.7954 - VH_attention_linear_output_loss: 2.0236 - VL_attention_linear_output_acc: 0.4752 - VH_attention_linear_output_acc: 0.3818 - val_loss: 3.8294 - val_VL_attention_linear_output_loss: 1.8157 - val_VH_attention_linear_output_loss: 2.0137 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.3868\n",
      "Epoch 893/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8217 - VL_attention_linear_output_loss: 1.7998 - VH_attention_linear_output_loss: 2.0218 - VL_attention_linear_output_acc: 0.4744 - VH_attention_linear_output_acc: 0.3825 - val_loss: 3.8340 - val_VL_attention_linear_output_loss: 1.8187 - val_VH_attention_linear_output_loss: 2.0153 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.3876\n",
      "Epoch 894/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8193 - VL_attention_linear_output_loss: 1.7991 - VH_attention_linear_output_loss: 2.0203 - VL_attention_linear_output_acc: 0.4754 - VH_attention_linear_output_acc: 0.3820 - val_loss: 3.8718 - val_VL_attention_linear_output_loss: 1.8500 - val_VH_attention_linear_output_loss: 2.0219 - val_VL_attention_linear_output_acc: 0.4638 - val_VH_attention_linear_output_acc: 0.3844\n",
      "Epoch 895/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8189 - VL_attention_linear_output_loss: 1.8049 - VH_attention_linear_output_loss: 2.0141 - VL_attention_linear_output_acc: 0.4715 - VH_attention_linear_output_acc: 0.3847 - val_loss: 3.8318 - val_VL_attention_linear_output_loss: 1.8176 - val_VH_attention_linear_output_loss: 2.0142 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.3866\n",
      "Epoch 896/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8188 - VL_attention_linear_output_loss: 1.8037 - VH_attention_linear_output_loss: 2.0152 - VL_attention_linear_output_acc: 0.4729 - VH_attention_linear_output_acc: 0.3834 - val_loss: 3.8837 - val_VL_attention_linear_output_loss: 1.8697 - val_VH_attention_linear_output_loss: 2.0140 - val_VL_attention_linear_output_acc: 0.4464 - val_VH_attention_linear_output_acc: 0.3827\n",
      "Epoch 897/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8225 - VL_attention_linear_output_loss: 1.8068 - VH_attention_linear_output_loss: 2.0157 - VL_attention_linear_output_acc: 0.4706 - VH_attention_linear_output_acc: 0.3829 - val_loss: 3.8616 - val_VL_attention_linear_output_loss: 1.8159 - val_VH_attention_linear_output_loss: 2.0456 - val_VL_attention_linear_output_acc: 0.4742 - val_VH_attention_linear_output_acc: 0.3678\n",
      "Epoch 898/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8305 - VL_attention_linear_output_loss: 1.8064 - VH_attention_linear_output_loss: 2.0241 - VL_attention_linear_output_acc: 0.4696 - VH_attention_linear_output_acc: 0.3809 - val_loss: 3.8498 - val_VL_attention_linear_output_loss: 1.8166 - val_VH_attention_linear_output_loss: 2.0332 - val_VL_attention_linear_output_acc: 0.4778 - val_VH_attention_linear_output_acc: 0.3751\n",
      "Epoch 899/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8241 - VL_attention_linear_output_loss: 1.8026 - VH_attention_linear_output_loss: 2.0215 - VL_attention_linear_output_acc: 0.4729 - VH_attention_linear_output_acc: 0.3828 - val_loss: 3.8572 - val_VL_attention_linear_output_loss: 1.8192 - val_VH_attention_linear_output_loss: 2.0380 - val_VL_attention_linear_output_acc: 0.4736 - val_VH_attention_linear_output_acc: 0.3723\n",
      "Epoch 900/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8202 - VL_attention_linear_output_loss: 1.8023 - VH_attention_linear_output_loss: 2.0179 - VL_attention_linear_output_acc: 0.4720 - VH_attention_linear_output_acc: 0.3821 - val_loss: 3.8437 - val_VL_attention_linear_output_loss: 1.8136 - val_VH_attention_linear_output_loss: 2.0301 - val_VL_attention_linear_output_acc: 0.4712 - val_VH_attention_linear_output_acc: 0.3760\n",
      "Epoch 901/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8187 - VL_attention_linear_output_loss: 1.7956 - VH_attention_linear_output_loss: 2.0231 - VL_attention_linear_output_acc: 0.4753 - VH_attention_linear_output_acc: 0.3815 - val_loss: 3.8339 - val_VL_attention_linear_output_loss: 1.8159 - val_VH_attention_linear_output_loss: 2.0180 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.3825\n",
      "Epoch 902/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8208 - VL_attention_linear_output_loss: 1.7988 - VH_attention_linear_output_loss: 2.0220 - VL_attention_linear_output_acc: 0.4756 - VH_attention_linear_output_acc: 0.3819 - val_loss: 3.8288 - val_VL_attention_linear_output_loss: 1.8147 - val_VH_attention_linear_output_loss: 2.0141 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.3842\n",
      "Epoch 903/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8240 - VL_attention_linear_output_loss: 1.8123 - VH_attention_linear_output_loss: 2.0117 - VL_attention_linear_output_acc: 0.4680 - VH_attention_linear_output_acc: 0.3846 - val_loss: 3.8230 - val_VL_attention_linear_output_loss: 1.8143 - val_VH_attention_linear_output_loss: 2.0087 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.3853\n",
      "Epoch 904/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8095 - VL_attention_linear_output_loss: 1.7980 - VH_attention_linear_output_loss: 2.0115 - VL_attention_linear_output_acc: 0.4742 - VH_attention_linear_output_acc: 0.3841 - val_loss: 3.8444 - val_VL_attention_linear_output_loss: 1.8325 - val_VH_attention_linear_output_loss: 2.0119 - val_VL_attention_linear_output_acc: 0.4587 - val_VH_attention_linear_output_acc: 0.3828\n",
      "Epoch 905/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8161 - VL_attention_linear_output_loss: 1.8082 - VH_attention_linear_output_loss: 2.0079 - VL_attention_linear_output_acc: 0.4716 - VH_attention_linear_output_acc: 0.3854 - val_loss: 3.8926 - val_VL_attention_linear_output_loss: 1.8689 - val_VH_attention_linear_output_loss: 2.0237 - val_VL_attention_linear_output_acc: 0.4501 - val_VH_attention_linear_output_acc: 0.3770\n",
      "Epoch 906/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8320 - VL_attention_linear_output_loss: 1.8195 - VH_attention_linear_output_loss: 2.0125 - VL_attention_linear_output_acc: 0.4648 - VH_attention_linear_output_acc: 0.3826 - val_loss: 3.8555 - val_VL_attention_linear_output_loss: 1.8318 - val_VH_attention_linear_output_loss: 2.0237 - val_VL_attention_linear_output_acc: 0.4680 - val_VH_attention_linear_output_acc: 0.3793\n",
      "Epoch 907/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8176 - VL_attention_linear_output_loss: 1.8010 - VH_attention_linear_output_loss: 2.0166 - VL_attention_linear_output_acc: 0.4737 - VH_attention_linear_output_acc: 0.3805 - val_loss: 3.8183 - val_VL_attention_linear_output_loss: 1.8149 - val_VH_attention_linear_output_loss: 2.0034 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.3884\n",
      "Epoch 908/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8057 - VL_attention_linear_output_loss: 1.8000 - VH_attention_linear_output_loss: 2.0057 - VL_attention_linear_output_acc: 0.4753 - VH_attention_linear_output_acc: 0.3859 - val_loss: 3.8219 - val_VL_attention_linear_output_loss: 1.8170 - val_VH_attention_linear_output_loss: 2.0049 - val_VL_attention_linear_output_acc: 0.4694 - val_VH_attention_linear_output_acc: 0.3873\n",
      "Epoch 909/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8115 - VL_attention_linear_output_loss: 1.7962 - VH_attention_linear_output_loss: 2.0153 - VL_attention_linear_output_acc: 0.4765 - VH_attention_linear_output_acc: 0.3831 - val_loss: 3.8371 - val_VL_attention_linear_output_loss: 1.8198 - val_VH_attention_linear_output_loss: 2.0173 - val_VL_attention_linear_output_acc: 0.4723 - val_VH_attention_linear_output_acc: 0.3853\n",
      "Epoch 910/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8390 - VL_attention_linear_output_loss: 1.8188 - VH_attention_linear_output_loss: 2.0203 - VL_attention_linear_output_acc: 0.4649 - VH_attention_linear_output_acc: 0.3814 - val_loss: 3.8313 - val_VL_attention_linear_output_loss: 1.8175 - val_VH_attention_linear_output_loss: 2.0138 - val_VL_attention_linear_output_acc: 0.4710 - val_VH_attention_linear_output_acc: 0.3869\n",
      "Epoch 911/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8080 - VL_attention_linear_output_loss: 1.7904 - VH_attention_linear_output_loss: 2.0175 - VL_attention_linear_output_acc: 0.4767 - VH_attention_linear_output_acc: 0.3815 - val_loss: 3.8273 - val_VL_attention_linear_output_loss: 1.8163 - val_VH_attention_linear_output_loss: 2.0110 - val_VL_attention_linear_output_acc: 0.4759 - val_VH_attention_linear_output_acc: 0.3859\n",
      "Epoch 912/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8147 - VL_attention_linear_output_loss: 1.8034 - VH_attention_linear_output_loss: 2.0113 - VL_attention_linear_output_acc: 0.4716 - VH_attention_linear_output_acc: 0.3851 - val_loss: 3.8237 - val_VL_attention_linear_output_loss: 1.8129 - val_VH_attention_linear_output_loss: 2.0108 - val_VL_attention_linear_output_acc: 0.4771 - val_VH_attention_linear_output_acc: 0.3843\n",
      "Epoch 913/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7998 - VL_attention_linear_output_loss: 1.7912 - VH_attention_linear_output_loss: 2.0085 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.3846 - val_loss: 3.8337 - val_VL_attention_linear_output_loss: 1.8116 - val_VH_attention_linear_output_loss: 2.0220 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.3813\n",
      "Epoch 914/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8098 - VL_attention_linear_output_loss: 1.8012 - VH_attention_linear_output_loss: 2.0086 - VL_attention_linear_output_acc: 0.4738 - VH_attention_linear_output_acc: 0.3836 - val_loss: 3.8742 - val_VL_attention_linear_output_loss: 1.8534 - val_VH_attention_linear_output_loss: 2.0208 - val_VL_attention_linear_output_acc: 0.4570 - val_VH_attention_linear_output_acc: 0.3850\n",
      "Epoch 915/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8002 - VL_attention_linear_output_loss: 1.7943 - VH_attention_linear_output_loss: 2.0059 - VL_attention_linear_output_acc: 0.4760 - VH_attention_linear_output_acc: 0.3858 - val_loss: 3.8153 - val_VL_attention_linear_output_loss: 1.8101 - val_VH_attention_linear_output_loss: 2.0052 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.3855\n",
      "Epoch 916/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8065 - VL_attention_linear_output_loss: 1.8048 - VH_attention_linear_output_loss: 2.0017 - VL_attention_linear_output_acc: 0.4715 - VH_attention_linear_output_acc: 0.3868 - val_loss: 3.8488 - val_VL_attention_linear_output_loss: 1.8425 - val_VH_attention_linear_output_loss: 2.0063 - val_VL_attention_linear_output_acc: 0.4601 - val_VH_attention_linear_output_acc: 0.3828\n",
      "Epoch 917/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8253 - VL_attention_linear_output_loss: 1.8096 - VH_attention_linear_output_loss: 2.0157 - VL_attention_linear_output_acc: 0.4695 - VH_attention_linear_output_acc: 0.3798 - val_loss: 3.8730 - val_VL_attention_linear_output_loss: 1.8551 - val_VH_attention_linear_output_loss: 2.0179 - val_VL_attention_linear_output_acc: 0.4560 - val_VH_attention_linear_output_acc: 0.3820\n",
      "Epoch 918/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8382 - VL_attention_linear_output_loss: 1.8239 - VH_attention_linear_output_loss: 2.0144 - VL_attention_linear_output_acc: 0.4598 - VH_attention_linear_output_acc: 0.3802 - val_loss: 3.8596 - val_VL_attention_linear_output_loss: 1.8265 - val_VH_attention_linear_output_loss: 2.0331 - val_VL_attention_linear_output_acc: 0.4636 - val_VH_attention_linear_output_acc: 0.3699\n",
      "Epoch 919/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7982 - VL_attention_linear_output_loss: 1.7909 - VH_attention_linear_output_loss: 2.0073 - VL_attention_linear_output_acc: 0.4778 - VH_attention_linear_output_acc: 0.3835 - val_loss: 3.8231 - val_VL_attention_linear_output_loss: 1.8152 - val_VH_attention_linear_output_loss: 2.0079 - val_VL_attention_linear_output_acc: 0.4747 - val_VH_attention_linear_output_acc: 0.3844\n",
      "Epoch 920/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7944 - VL_attention_linear_output_loss: 1.7933 - VH_attention_linear_output_loss: 2.0011 - VL_attention_linear_output_acc: 0.4767 - VH_attention_linear_output_acc: 0.3861 - val_loss: 3.8431 - val_VL_attention_linear_output_loss: 1.8147 - val_VH_attention_linear_output_loss: 2.0284 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.3700\n",
      "Epoch 921/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8171 - VL_attention_linear_output_loss: 1.8104 - VH_attention_linear_output_loss: 2.0067 - VL_attention_linear_output_acc: 0.4684 - VH_attention_linear_output_acc: 0.3838 - val_loss: 4.1407 - val_VL_attention_linear_output_loss: 2.0658 - val_VH_attention_linear_output_loss: 2.0749 - val_VL_attention_linear_output_acc: 0.3489 - val_VH_attention_linear_output_acc: 0.3499\n",
      "Epoch 922/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8239 - VL_attention_linear_output_loss: 1.8129 - VH_attention_linear_output_loss: 2.0110 - VL_attention_linear_output_acc: 0.4653 - VH_attention_linear_output_acc: 0.3821 - val_loss: 3.8761 - val_VL_attention_linear_output_loss: 1.8179 - val_VH_attention_linear_output_loss: 2.0582 - val_VL_attention_linear_output_acc: 0.4672 - val_VH_attention_linear_output_acc: 0.3525\n",
      "Epoch 923/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7959 - VL_attention_linear_output_loss: 1.7929 - VH_attention_linear_output_loss: 2.0030 - VL_attention_linear_output_acc: 0.4770 - VH_attention_linear_output_acc: 0.3850 - val_loss: 3.8242 - val_VL_attention_linear_output_loss: 1.8191 - val_VH_attention_linear_output_loss: 2.0051 - val_VL_attention_linear_output_acc: 0.4742 - val_VH_attention_linear_output_acc: 0.3864\n",
      "Epoch 924/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7974 - VL_attention_linear_output_loss: 1.7982 - VH_attention_linear_output_loss: 1.9992 - VL_attention_linear_output_acc: 0.4750 - VH_attention_linear_output_acc: 0.3869 - val_loss: 3.8237 - val_VL_attention_linear_output_loss: 1.8246 - val_VH_attention_linear_output_loss: 1.9990 - val_VL_attention_linear_output_acc: 0.4687 - val_VH_attention_linear_output_acc: 0.3862\n",
      "Epoch 925/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8050 - VL_attention_linear_output_loss: 1.8013 - VH_attention_linear_output_loss: 2.0037 - VL_attention_linear_output_acc: 0.4726 - VH_attention_linear_output_acc: 0.3853 - val_loss: 3.8371 - val_VL_attention_linear_output_loss: 1.8266 - val_VH_attention_linear_output_loss: 2.0105 - val_VL_attention_linear_output_acc: 0.4634 - val_VH_attention_linear_output_acc: 0.3834\n",
      "Epoch 926/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8138 - VL_attention_linear_output_loss: 1.8064 - VH_attention_linear_output_loss: 2.0074 - VL_attention_linear_output_acc: 0.4690 - VH_attention_linear_output_acc: 0.3833 - val_loss: 3.8278 - val_VL_attention_linear_output_loss: 1.8221 - val_VH_attention_linear_output_loss: 2.0058 - val_VL_attention_linear_output_acc: 0.4690 - val_VH_attention_linear_output_acc: 0.3871\n",
      "Epoch 927/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8249 - VL_attention_linear_output_loss: 1.8151 - VH_attention_linear_output_loss: 2.0097 - VL_attention_linear_output_acc: 0.4658 - VH_attention_linear_output_acc: 0.3817 - val_loss: 3.8809 - val_VL_attention_linear_output_loss: 1.8527 - val_VH_attention_linear_output_loss: 2.0282 - val_VL_attention_linear_output_acc: 0.4577 - val_VH_attention_linear_output_acc: 0.3747\n",
      "Epoch 928/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8109 - VL_attention_linear_output_loss: 1.8025 - VH_attention_linear_output_loss: 2.0084 - VL_attention_linear_output_acc: 0.4730 - VH_attention_linear_output_acc: 0.3818 - val_loss: 3.8273 - val_VL_attention_linear_output_loss: 1.8299 - val_VH_attention_linear_output_loss: 1.9974 - val_VL_attention_linear_output_acc: 0.4635 - val_VH_attention_linear_output_acc: 0.3877\n",
      "Epoch 929/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7946 - VL_attention_linear_output_loss: 1.7961 - VH_attention_linear_output_loss: 1.9986 - VL_attention_linear_output_acc: 0.4740 - VH_attention_linear_output_acc: 0.3865 - val_loss: 3.8272 - val_VL_attention_linear_output_loss: 1.8214 - val_VH_attention_linear_output_loss: 2.0058 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.3852\n",
      "Epoch 930/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8067 - VL_attention_linear_output_loss: 1.7990 - VH_attention_linear_output_loss: 2.0078 - VL_attention_linear_output_acc: 0.4763 - VH_attention_linear_output_acc: 0.3824 - val_loss: 3.8668 - val_VL_attention_linear_output_loss: 1.8610 - val_VH_attention_linear_output_loss: 2.0058 - val_VL_attention_linear_output_acc: 0.4532 - val_VH_attention_linear_output_acc: 0.3826\n",
      "Epoch 931/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8164 - VL_attention_linear_output_loss: 1.8113 - VH_attention_linear_output_loss: 2.0051 - VL_attention_linear_output_acc: 0.4696 - VH_attention_linear_output_acc: 0.3832 - val_loss: 3.8109 - val_VL_attention_linear_output_loss: 1.8141 - val_VH_attention_linear_output_loss: 1.9969 - val_VL_attention_linear_output_acc: 0.4701 - val_VH_attention_linear_output_acc: 0.3874\n",
      "Epoch 932/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8331 - VL_attention_linear_output_loss: 1.8032 - VH_attention_linear_output_loss: 2.0300 - VL_attention_linear_output_acc: 0.4731 - VH_attention_linear_output_acc: 0.3784 - val_loss: 4.5156 - val_VL_attention_linear_output_loss: 1.9179 - val_VH_attention_linear_output_loss: 2.5978 - val_VL_attention_linear_output_acc: 0.4372 - val_VH_attention_linear_output_acc: 0.2882\n",
      "Epoch 933/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8658 - VL_attention_linear_output_loss: 1.8202 - VH_attention_linear_output_loss: 2.0456 - VL_attention_linear_output_acc: 0.4638 - VH_attention_linear_output_acc: 0.3754 - val_loss: 3.8489 - val_VL_attention_linear_output_loss: 1.8166 - val_VH_attention_linear_output_loss: 2.0323 - val_VL_attention_linear_output_acc: 0.4725 - val_VH_attention_linear_output_acc: 0.3711\n",
      "Epoch 934/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7998 - VL_attention_linear_output_loss: 1.7955 - VH_attention_linear_output_loss: 2.0043 - VL_attention_linear_output_acc: 0.4758 - VH_attention_linear_output_acc: 0.3858 - val_loss: 3.8180 - val_VL_attention_linear_output_loss: 1.8143 - val_VH_attention_linear_output_loss: 2.0037 - val_VL_attention_linear_output_acc: 0.4687 - val_VH_attention_linear_output_acc: 0.3865\n",
      "Epoch 935/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7953 - VL_attention_linear_output_loss: 1.7980 - VH_attention_linear_output_loss: 1.9973 - VL_attention_linear_output_acc: 0.4741 - VH_attention_linear_output_acc: 0.3884 - val_loss: 3.8121 - val_VL_attention_linear_output_loss: 1.8110 - val_VH_attention_linear_output_loss: 2.0012 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.3864\n",
      "Epoch 936/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7945 - VL_attention_linear_output_loss: 1.7972 - VH_attention_linear_output_loss: 1.9973 - VL_attention_linear_output_acc: 0.4743 - VH_attention_linear_output_acc: 0.3882 - val_loss: 3.8144 - val_VL_attention_linear_output_loss: 1.8127 - val_VH_attention_linear_output_loss: 2.0017 - val_VL_attention_linear_output_acc: 0.4754 - val_VH_attention_linear_output_acc: 0.3867\n",
      "Epoch 937/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7908 - VL_attention_linear_output_loss: 1.7926 - VH_attention_linear_output_loss: 1.9982 - VL_attention_linear_output_acc: 0.4758 - VH_attention_linear_output_acc: 0.3870 - val_loss: 3.8157 - val_VL_attention_linear_output_loss: 1.8186 - val_VH_attention_linear_output_loss: 1.9971 - val_VL_attention_linear_output_acc: 0.4687 - val_VH_attention_linear_output_acc: 0.3852\n",
      "Epoch 938/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7882 - VL_attention_linear_output_loss: 1.7966 - VH_attention_linear_output_loss: 1.9916 - VL_attention_linear_output_acc: 0.4747 - VH_attention_linear_output_acc: 0.3902 - val_loss: 3.8353 - val_VL_attention_linear_output_loss: 1.8326 - val_VH_attention_linear_output_loss: 2.0027 - val_VL_attention_linear_output_acc: 0.4607 - val_VH_attention_linear_output_acc: 0.3890\n",
      "Epoch 939/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7959 - VL_attention_linear_output_loss: 1.8002 - VH_attention_linear_output_loss: 1.9958 - VL_attention_linear_output_acc: 0.4720 - VH_attention_linear_output_acc: 0.3874 - val_loss: 3.8152 - val_VL_attention_linear_output_loss: 1.8204 - val_VH_attention_linear_output_loss: 1.9948 - val_VL_attention_linear_output_acc: 0.4730 - val_VH_attention_linear_output_acc: 0.3920\n",
      "Epoch 940/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7923 - VL_attention_linear_output_loss: 1.8017 - VH_attention_linear_output_loss: 1.9906 - VL_attention_linear_output_acc: 0.4720 - VH_attention_linear_output_acc: 0.3898 - val_loss: 3.8364 - val_VL_attention_linear_output_loss: 1.8122 - val_VH_attention_linear_output_loss: 2.0242 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.3724\n",
      "Epoch 941/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7923 - VL_attention_linear_output_loss: 1.7968 - VH_attention_linear_output_loss: 1.9955 - VL_attention_linear_output_acc: 0.4746 - VH_attention_linear_output_acc: 0.3878 - val_loss: 3.8249 - val_VL_attention_linear_output_loss: 1.8231 - val_VH_attention_linear_output_loss: 2.0018 - val_VL_attention_linear_output_acc: 0.4679 - val_VH_attention_linear_output_acc: 0.3874\n",
      "Epoch 942/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8012 - VL_attention_linear_output_loss: 1.7965 - VH_attention_linear_output_loss: 2.0047 - VL_attention_linear_output_acc: 0.4737 - VH_attention_linear_output_acc: 0.3848 - val_loss: 3.8358 - val_VL_attention_linear_output_loss: 1.8312 - val_VH_attention_linear_output_loss: 2.0046 - val_VL_attention_linear_output_acc: 0.4661 - val_VH_attention_linear_output_acc: 0.3861\n",
      "Epoch 943/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8235 - VL_attention_linear_output_loss: 1.8088 - VH_attention_linear_output_loss: 2.0146 - VL_attention_linear_output_acc: 0.4690 - VH_attention_linear_output_acc: 0.3853 - val_loss: 3.8122 - val_VL_attention_linear_output_loss: 1.8136 - val_VH_attention_linear_output_loss: 1.9986 - val_VL_attention_linear_output_acc: 0.4659 - val_VH_attention_linear_output_acc: 0.3863\n",
      "Epoch 944/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7879 - VL_attention_linear_output_loss: 1.7912 - VH_attention_linear_output_loss: 1.9967 - VL_attention_linear_output_acc: 0.4773 - VH_attention_linear_output_acc: 0.3867 - val_loss: 3.8260 - val_VL_attention_linear_output_loss: 1.8140 - val_VH_attention_linear_output_loss: 2.0120 - val_VL_attention_linear_output_acc: 0.4764 - val_VH_attention_linear_output_acc: 0.3808\n",
      "Epoch 945/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8042 - VL_attention_linear_output_loss: 1.8026 - VH_attention_linear_output_loss: 2.0016 - VL_attention_linear_output_acc: 0.4715 - VH_attention_linear_output_acc: 0.3863 - val_loss: 3.8377 - val_VL_attention_linear_output_loss: 1.8278 - val_VH_attention_linear_output_loss: 2.0099 - val_VL_attention_linear_output_acc: 0.4672 - val_VH_attention_linear_output_acc: 0.3842\n",
      "Epoch 946/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7924 - VL_attention_linear_output_loss: 1.7978 - VH_attention_linear_output_loss: 1.9945 - VL_attention_linear_output_acc: 0.4752 - VH_attention_linear_output_acc: 0.3899 - val_loss: 3.8586 - val_VL_attention_linear_output_loss: 1.8527 - val_VH_attention_linear_output_loss: 2.0059 - val_VL_attention_linear_output_acc: 0.4514 - val_VH_attention_linear_output_acc: 0.3825\n",
      "Epoch 947/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8070 - VL_attention_linear_output_loss: 1.8113 - VH_attention_linear_output_loss: 1.9957 - VL_attention_linear_output_acc: 0.4669 - VH_attention_linear_output_acc: 0.3876 - val_loss: 3.8062 - val_VL_attention_linear_output_loss: 1.8136 - val_VH_attention_linear_output_loss: 1.9925 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.3895\n",
      "Epoch 948/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7805 - VL_attention_linear_output_loss: 1.7870 - VH_attention_linear_output_loss: 1.9935 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.3888 - val_loss: 3.8130 - val_VL_attention_linear_output_loss: 1.8160 - val_VH_attention_linear_output_loss: 1.9970 - val_VL_attention_linear_output_acc: 0.4652 - val_VH_attention_linear_output_acc: 0.3848\n",
      "Epoch 949/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7864 - VL_attention_linear_output_loss: 1.7916 - VH_attention_linear_output_loss: 1.9948 - VL_attention_linear_output_acc: 0.4763 - VH_attention_linear_output_acc: 0.3873 - val_loss: 3.8229 - val_VL_attention_linear_output_loss: 1.8312 - val_VH_attention_linear_output_loss: 1.9917 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.3875\n",
      "Epoch 950/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7872 - VL_attention_linear_output_loss: 1.7946 - VH_attention_linear_output_loss: 1.9927 - VL_attention_linear_output_acc: 0.4750 - VH_attention_linear_output_acc: 0.3881 - val_loss: 3.8720 - val_VL_attention_linear_output_loss: 1.8813 - val_VH_attention_linear_output_loss: 1.9907 - val_VL_attention_linear_output_acc: 0.4452 - val_VH_attention_linear_output_acc: 0.3912\n",
      "Epoch 951/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7872 - VL_attention_linear_output_loss: 1.7950 - VH_attention_linear_output_loss: 1.9922 - VL_attention_linear_output_acc: 0.4731 - VH_attention_linear_output_acc: 0.3885 - val_loss: 3.8177 - val_VL_attention_linear_output_loss: 1.8137 - val_VH_attention_linear_output_loss: 2.0039 - val_VL_attention_linear_output_acc: 0.4726 - val_VH_attention_linear_output_acc: 0.3868\n",
      "Epoch 952/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7854 - VL_attention_linear_output_loss: 1.7942 - VH_attention_linear_output_loss: 1.9912 - VL_attention_linear_output_acc: 0.4781 - VH_attention_linear_output_acc: 0.3895 - val_loss: 3.8168 - val_VL_attention_linear_output_loss: 1.8120 - val_VH_attention_linear_output_loss: 2.0048 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.3868\n",
      "Epoch 953/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8005 - VL_attention_linear_output_loss: 1.8051 - VH_attention_linear_output_loss: 1.9954 - VL_attention_linear_output_acc: 0.4701 - VH_attention_linear_output_acc: 0.3868 - val_loss: 3.8409 - val_VL_attention_linear_output_loss: 1.8453 - val_VH_attention_linear_output_loss: 1.9956 - val_VL_attention_linear_output_acc: 0.4625 - val_VH_attention_linear_output_acc: 0.3913\n",
      "Epoch 954/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8020 - VL_attention_linear_output_loss: 1.8013 - VH_attention_linear_output_loss: 2.0008 - VL_attention_linear_output_acc: 0.4723 - VH_attention_linear_output_acc: 0.3842 - val_loss: 3.8813 - val_VL_attention_linear_output_loss: 1.8351 - val_VH_attention_linear_output_loss: 2.0463 - val_VL_attention_linear_output_acc: 0.4639 - val_VH_attention_linear_output_acc: 0.3637\n",
      "Epoch 955/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7915 - VL_attention_linear_output_loss: 1.7956 - VH_attention_linear_output_loss: 1.9959 - VL_attention_linear_output_acc: 0.4731 - VH_attention_linear_output_acc: 0.3875 - val_loss: 3.8127 - val_VL_attention_linear_output_loss: 1.8125 - val_VH_attention_linear_output_loss: 2.0002 - val_VL_attention_linear_output_acc: 0.4718 - val_VH_attention_linear_output_acc: 0.3870\n",
      "Epoch 956/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8097 - VL_attention_linear_output_loss: 1.8135 - VH_attention_linear_output_loss: 1.9962 - VL_attention_linear_output_acc: 0.4703 - VH_attention_linear_output_acc: 0.3871 - val_loss: 3.8927 - val_VL_attention_linear_output_loss: 1.8923 - val_VH_attention_linear_output_loss: 2.0004 - val_VL_attention_linear_output_acc: 0.4305 - val_VH_attention_linear_output_acc: 0.3853\n",
      "Epoch 957/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7973 - VL_attention_linear_output_loss: 1.7983 - VH_attention_linear_output_loss: 1.9990 - VL_attention_linear_output_acc: 0.4742 - VH_attention_linear_output_acc: 0.3858 - val_loss: 3.8189 - val_VL_attention_linear_output_loss: 1.8257 - val_VH_attention_linear_output_loss: 1.9931 - val_VL_attention_linear_output_acc: 0.4671 - val_VH_attention_linear_output_acc: 0.3888\n",
      "Epoch 958/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7854 - VL_attention_linear_output_loss: 1.7907 - VH_attention_linear_output_loss: 1.9947 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.3872 - val_loss: 3.8197 - val_VL_attention_linear_output_loss: 1.8149 - val_VH_attention_linear_output_loss: 2.0048 - val_VL_attention_linear_output_acc: 0.4735 - val_VH_attention_linear_output_acc: 0.3855\n",
      "Epoch 959/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7883 - VL_attention_linear_output_loss: 1.7938 - VH_attention_linear_output_loss: 1.9944 - VL_attention_linear_output_acc: 0.4740 - VH_attention_linear_output_acc: 0.3873 - val_loss: 3.9230 - val_VL_attention_linear_output_loss: 1.8376 - val_VH_attention_linear_output_loss: 2.0854 - val_VL_attention_linear_output_acc: 0.4654 - val_VH_attention_linear_output_acc: 0.3460\n",
      "Epoch 960/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7856 - VL_attention_linear_output_loss: 1.7950 - VH_attention_linear_output_loss: 1.9906 - VL_attention_linear_output_acc: 0.4750 - VH_attention_linear_output_acc: 0.3889 - val_loss: 3.8147 - val_VL_attention_linear_output_loss: 1.8273 - val_VH_attention_linear_output_loss: 1.9874 - val_VL_attention_linear_output_acc: 0.4638 - val_VH_attention_linear_output_acc: 0.3881\n",
      "Epoch 961/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8054 - VL_attention_linear_output_loss: 1.8046 - VH_attention_linear_output_loss: 2.0008 - VL_attention_linear_output_acc: 0.4703 - VH_attention_linear_output_acc: 0.3834 - val_loss: 3.8363 - val_VL_attention_linear_output_loss: 1.8213 - val_VH_attention_linear_output_loss: 2.0151 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.3803\n",
      "Epoch 962/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7937 - VL_attention_linear_output_loss: 1.7954 - VH_attention_linear_output_loss: 1.9984 - VL_attention_linear_output_acc: 0.4757 - VH_attention_linear_output_acc: 0.3854 - val_loss: 3.8166 - val_VL_attention_linear_output_loss: 1.8164 - val_VH_attention_linear_output_loss: 2.0002 - val_VL_attention_linear_output_acc: 0.4699 - val_VH_attention_linear_output_acc: 0.3846\n",
      "Epoch 963/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7923 - VL_attention_linear_output_loss: 1.7981 - VH_attention_linear_output_loss: 1.9942 - VL_attention_linear_output_acc: 0.4746 - VH_attention_linear_output_acc: 0.3868 - val_loss: 3.8176 - val_VL_attention_linear_output_loss: 1.8286 - val_VH_attention_linear_output_loss: 1.9890 - val_VL_attention_linear_output_acc: 0.4688 - val_VH_attention_linear_output_acc: 0.3909\n",
      "Epoch 964/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7977 - VL_attention_linear_output_loss: 1.8052 - VH_attention_linear_output_loss: 1.9925 - VL_attention_linear_output_acc: 0.4715 - VH_attention_linear_output_acc: 0.3887 - val_loss: 3.8219 - val_VL_attention_linear_output_loss: 1.8312 - val_VH_attention_linear_output_loss: 1.9907 - val_VL_attention_linear_output_acc: 0.4608 - val_VH_attention_linear_output_acc: 0.3884\n",
      "Epoch 965/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7870 - VL_attention_linear_output_loss: 1.7970 - VH_attention_linear_output_loss: 1.9900 - VL_attention_linear_output_acc: 0.4737 - VH_attention_linear_output_acc: 0.3887 - val_loss: 3.8022 - val_VL_attention_linear_output_loss: 1.8143 - val_VH_attention_linear_output_loss: 1.9879 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.3891\n",
      "Epoch 966/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7823 - VL_attention_linear_output_loss: 1.7951 - VH_attention_linear_output_loss: 1.9872 - VL_attention_linear_output_acc: 0.4739 - VH_attention_linear_output_acc: 0.3894 - val_loss: 3.8136 - val_VL_attention_linear_output_loss: 1.8182 - val_VH_attention_linear_output_loss: 1.9954 - val_VL_attention_linear_output_acc: 0.4717 - val_VH_attention_linear_output_acc: 0.3926\n",
      "Epoch 967/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7994 - VL_attention_linear_output_loss: 1.8017 - VH_attention_linear_output_loss: 1.9977 - VL_attention_linear_output_acc: 0.4717 - VH_attention_linear_output_acc: 0.3870 - val_loss: 3.8894 - val_VL_attention_linear_output_loss: 1.8620 - val_VH_attention_linear_output_loss: 2.0273 - val_VL_attention_linear_output_acc: 0.4490 - val_VH_attention_linear_output_acc: 0.3747\n",
      "Epoch 968/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8090 - VL_attention_linear_output_loss: 1.8138 - VH_attention_linear_output_loss: 1.9951 - VL_attention_linear_output_acc: 0.4661 - VH_attention_linear_output_acc: 0.3863 - val_loss: 3.8122 - val_VL_attention_linear_output_loss: 1.8140 - val_VH_attention_linear_output_loss: 1.9982 - val_VL_attention_linear_output_acc: 0.4744 - val_VH_attention_linear_output_acc: 0.3848\n",
      "Epoch 969/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7857 - VL_attention_linear_output_loss: 1.7925 - VH_attention_linear_output_loss: 1.9932 - VL_attention_linear_output_acc: 0.4753 - VH_attention_linear_output_acc: 0.3868 - val_loss: 3.8219 - val_VL_attention_linear_output_loss: 1.8202 - val_VH_attention_linear_output_loss: 2.0017 - val_VL_attention_linear_output_acc: 0.4712 - val_VH_attention_linear_output_acc: 0.3822\n",
      "Epoch 970/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7918 - VL_attention_linear_output_loss: 1.8042 - VH_attention_linear_output_loss: 1.9876 - VL_attention_linear_output_acc: 0.4721 - VH_attention_linear_output_acc: 0.3893 - val_loss: 3.8344 - val_VL_attention_linear_output_loss: 1.8486 - val_VH_attention_linear_output_loss: 1.9859 - val_VL_attention_linear_output_acc: 0.4560 - val_VH_attention_linear_output_acc: 0.3896\n",
      "Epoch 971/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7779 - VL_attention_linear_output_loss: 1.7921 - VH_attention_linear_output_loss: 1.9858 - VL_attention_linear_output_acc: 0.4761 - VH_attention_linear_output_acc: 0.3907 - val_loss: 3.8002 - val_VL_attention_linear_output_loss: 1.8145 - val_VH_attention_linear_output_loss: 1.9857 - val_VL_attention_linear_output_acc: 0.4711 - val_VH_attention_linear_output_acc: 0.3915\n",
      "Epoch 972/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7826 - VL_attention_linear_output_loss: 1.7884 - VH_attention_linear_output_loss: 1.9942 - VL_attention_linear_output_acc: 0.4780 - VH_attention_linear_output_acc: 0.3868 - val_loss: 3.8060 - val_VL_attention_linear_output_loss: 1.8244 - val_VH_attention_linear_output_loss: 1.9816 - val_VL_attention_linear_output_acc: 0.4664 - val_VH_attention_linear_output_acc: 0.3922\n",
      "Epoch 973/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7848 - VL_attention_linear_output_loss: 1.8031 - VH_attention_linear_output_loss: 1.9817 - VL_attention_linear_output_acc: 0.4717 - VH_attention_linear_output_acc: 0.3921 - val_loss: 3.7979 - val_VL_attention_linear_output_loss: 1.8164 - val_VH_attention_linear_output_loss: 1.9815 - val_VL_attention_linear_output_acc: 0.4734 - val_VH_attention_linear_output_acc: 0.3911\n",
      "Epoch 974/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7787 - VL_attention_linear_output_loss: 1.7889 - VH_attention_linear_output_loss: 1.9897 - VL_attention_linear_output_acc: 0.4762 - VH_attention_linear_output_acc: 0.3894 - val_loss: 3.8201 - val_VL_attention_linear_output_loss: 1.8174 - val_VH_attention_linear_output_loss: 2.0027 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.3825\n",
      "Epoch 975/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7967 - VL_attention_linear_output_loss: 1.8052 - VH_attention_linear_output_loss: 1.9916 - VL_attention_linear_output_acc: 0.4702 - VH_attention_linear_output_acc: 0.3890 - val_loss: 3.8311 - val_VL_attention_linear_output_loss: 1.8474 - val_VH_attention_linear_output_loss: 1.9836 - val_VL_attention_linear_output_acc: 0.4581 - val_VH_attention_linear_output_acc: 0.3902\n",
      "Epoch 976/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7887 - VL_attention_linear_output_loss: 1.7948 - VH_attention_linear_output_loss: 1.9938 - VL_attention_linear_output_acc: 0.4754 - VH_attention_linear_output_acc: 0.3865 - val_loss: 3.8832 - val_VL_attention_linear_output_loss: 1.8511 - val_VH_attention_linear_output_loss: 2.0321 - val_VL_attention_linear_output_acc: 0.4549 - val_VH_attention_linear_output_acc: 0.3702\n",
      "Epoch 977/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7944 - VL_attention_linear_output_loss: 1.8077 - VH_attention_linear_output_loss: 1.9867 - VL_attention_linear_output_acc: 0.4675 - VH_attention_linear_output_acc: 0.3906 - val_loss: 3.8194 - val_VL_attention_linear_output_loss: 1.8180 - val_VH_attention_linear_output_loss: 2.0014 - val_VL_attention_linear_output_acc: 0.4684 - val_VH_attention_linear_output_acc: 0.3824\n",
      "Epoch 978/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7861 - VL_attention_linear_output_loss: 1.7918 - VH_attention_linear_output_loss: 1.9944 - VL_attention_linear_output_acc: 0.4769 - VH_attention_linear_output_acc: 0.3859 - val_loss: 3.8080 - val_VL_attention_linear_output_loss: 1.8098 - val_VH_attention_linear_output_loss: 1.9983 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.3848\n",
      "Epoch 979/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7799 - VL_attention_linear_output_loss: 1.7912 - VH_attention_linear_output_loss: 1.9887 - VL_attention_linear_output_acc: 0.4762 - VH_attention_linear_output_acc: 0.3896 - val_loss: 3.8444 - val_VL_attention_linear_output_loss: 1.8133 - val_VH_attention_linear_output_loss: 2.0312 - val_VL_attention_linear_output_acc: 0.4764 - val_VH_attention_linear_output_acc: 0.3697\n",
      "Epoch 980/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7838 - VL_attention_linear_output_loss: 1.7976 - VH_attention_linear_output_loss: 1.9862 - VL_attention_linear_output_acc: 0.4752 - VH_attention_linear_output_acc: 0.3899 - val_loss: 3.8201 - val_VL_attention_linear_output_loss: 1.8260 - val_VH_attention_linear_output_loss: 1.9941 - val_VL_attention_linear_output_acc: 0.4640 - val_VH_attention_linear_output_acc: 0.3879\n",
      "Epoch 981/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7965 - VL_attention_linear_output_loss: 1.8039 - VH_attention_linear_output_loss: 1.9926 - VL_attention_linear_output_acc: 0.4705 - VH_attention_linear_output_acc: 0.3875 - val_loss: 3.8171 - val_VL_attention_linear_output_loss: 1.8364 - val_VH_attention_linear_output_loss: 1.9807 - val_VL_attention_linear_output_acc: 0.4665 - val_VH_attention_linear_output_acc: 0.3949\n",
      "Epoch 982/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.8089 - VL_attention_linear_output_loss: 1.8205 - VH_attention_linear_output_loss: 1.9884 - VL_attention_linear_output_acc: 0.4641 - VH_attention_linear_output_acc: 0.3900 - val_loss: 3.8490 - val_VL_attention_linear_output_loss: 1.8187 - val_VH_attention_linear_output_loss: 2.0303 - val_VL_attention_linear_output_acc: 0.4640 - val_VH_attention_linear_output_acc: 0.3626\n",
      "Epoch 983/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7847 - VL_attention_linear_output_loss: 1.7950 - VH_attention_linear_output_loss: 1.9898 - VL_attention_linear_output_acc: 0.4765 - VH_attention_linear_output_acc: 0.3878 - val_loss: 3.8325 - val_VL_attention_linear_output_loss: 1.8448 - val_VH_attention_linear_output_loss: 1.9876 - val_VL_attention_linear_output_acc: 0.4529 - val_VH_attention_linear_output_acc: 0.3897\n",
      "Epoch 984/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7854 - VL_attention_linear_output_loss: 1.8010 - VH_attention_linear_output_loss: 1.9845 - VL_attention_linear_output_acc: 0.4707 - VH_attention_linear_output_acc: 0.3918 - val_loss: 3.8267 - val_VL_attention_linear_output_loss: 1.8360 - val_VH_attention_linear_output_loss: 1.9907 - val_VL_attention_linear_output_acc: 0.4603 - val_VH_attention_linear_output_acc: 0.3925\n",
      "Epoch 985/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7853 - VL_attention_linear_output_loss: 1.7939 - VH_attention_linear_output_loss: 1.9914 - VL_attention_linear_output_acc: 0.4738 - VH_attention_linear_output_acc: 0.3869 - val_loss: 3.8033 - val_VL_attention_linear_output_loss: 1.8163 - val_VH_attention_linear_output_loss: 1.9870 - val_VL_attention_linear_output_acc: 0.4656 - val_VH_attention_linear_output_acc: 0.3900\n",
      "Epoch 986/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7837 - VL_attention_linear_output_loss: 1.7995 - VH_attention_linear_output_loss: 1.9842 - VL_attention_linear_output_acc: 0.4732 - VH_attention_linear_output_acc: 0.3909 - val_loss: 3.7976 - val_VL_attention_linear_output_loss: 1.8102 - val_VH_attention_linear_output_loss: 1.9875 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.3930\n",
      "Epoch 987/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7728 - VL_attention_linear_output_loss: 1.7895 - VH_attention_linear_output_loss: 1.9833 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.3918 - val_loss: 3.8021 - val_VL_attention_linear_output_loss: 1.8160 - val_VH_attention_linear_output_loss: 1.9861 - val_VL_attention_linear_output_acc: 0.4774 - val_VH_attention_linear_output_acc: 0.3911\n",
      "Epoch 988/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7823 - VL_attention_linear_output_loss: 1.7945 - VH_attention_linear_output_loss: 1.9878 - VL_attention_linear_output_acc: 0.4759 - VH_attention_linear_output_acc: 0.3904 - val_loss: 3.8082 - val_VL_attention_linear_output_loss: 1.8133 - val_VH_attention_linear_output_loss: 1.9949 - val_VL_attention_linear_output_acc: 0.4768 - val_VH_attention_linear_output_acc: 0.3889\n",
      "Epoch 989/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7817 - VL_attention_linear_output_loss: 1.7971 - VH_attention_linear_output_loss: 1.9846 - VL_attention_linear_output_acc: 0.4735 - VH_attention_linear_output_acc: 0.3908 - val_loss: 3.8443 - val_VL_attention_linear_output_loss: 1.8480 - val_VH_attention_linear_output_loss: 1.9964 - val_VL_attention_linear_output_acc: 0.4534 - val_VH_attention_linear_output_acc: 0.3903\n",
      "Epoch 990/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7651 - VL_attention_linear_output_loss: 1.7873 - VH_attention_linear_output_loss: 1.9778 - VL_attention_linear_output_acc: 0.4779 - VH_attention_linear_output_acc: 0.3949 - val_loss: 3.8127 - val_VL_attention_linear_output_loss: 1.8126 - val_VH_attention_linear_output_loss: 2.0001 - val_VL_attention_linear_output_acc: 0.4755 - val_VH_attention_linear_output_acc: 0.3896\n",
      "Epoch 991/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7704 - VL_attention_linear_output_loss: 1.7889 - VH_attention_linear_output_loss: 1.9815 - VL_attention_linear_output_acc: 0.4764 - VH_attention_linear_output_acc: 0.3932 - val_loss: 3.7973 - val_VL_attention_linear_output_loss: 1.8173 - val_VH_attention_linear_output_loss: 1.9800 - val_VL_attention_linear_output_acc: 0.4742 - val_VH_attention_linear_output_acc: 0.3927\n",
      "Epoch 992/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7678 - VL_attention_linear_output_loss: 1.7907 - VH_attention_linear_output_loss: 1.9771 - VL_attention_linear_output_acc: 0.4760 - VH_attention_linear_output_acc: 0.3949 - val_loss: 3.7925 - val_VL_attention_linear_output_loss: 1.8125 - val_VH_attention_linear_output_loss: 1.9800 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.3928\n",
      "Epoch 993/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7887 - VL_attention_linear_output_loss: 1.7997 - VH_attention_linear_output_loss: 1.9890 - VL_attention_linear_output_acc: 0.4733 - VH_attention_linear_output_acc: 0.3900 - val_loss: 3.7841 - val_VL_attention_linear_output_loss: 1.8077 - val_VH_attention_linear_output_loss: 1.9764 - val_VL_attention_linear_output_acc: 0.4717 - val_VH_attention_linear_output_acc: 0.3951\n",
      "Epoch 994/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7608 - VL_attention_linear_output_loss: 1.7899 - VH_attention_linear_output_loss: 1.9709 - VL_attention_linear_output_acc: 0.4761 - VH_attention_linear_output_acc: 0.3977 - val_loss: 3.7892 - val_VL_attention_linear_output_loss: 1.8115 - val_VH_attention_linear_output_loss: 1.9777 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.3973\n",
      "Epoch 995/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7681 - VL_attention_linear_output_loss: 1.7941 - VH_attention_linear_output_loss: 1.9741 - VL_attention_linear_output_acc: 0.4755 - VH_attention_linear_output_acc: 0.3958 - val_loss: 3.8001 - val_VL_attention_linear_output_loss: 1.8170 - val_VH_attention_linear_output_loss: 1.9831 - val_VL_attention_linear_output_acc: 0.4707 - val_VH_attention_linear_output_acc: 0.3922\n",
      "Epoch 996/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7731 - VL_attention_linear_output_loss: 1.7957 - VH_attention_linear_output_loss: 1.9774 - VL_attention_linear_output_acc: 0.4749 - VH_attention_linear_output_acc: 0.3943 - val_loss: 3.7917 - val_VL_attention_linear_output_loss: 1.8124 - val_VH_attention_linear_output_loss: 1.9793 - val_VL_attention_linear_output_acc: 0.4754 - val_VH_attention_linear_output_acc: 0.3942\n",
      "Epoch 997/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7662 - VL_attention_linear_output_loss: 1.7934 - VH_attention_linear_output_loss: 1.9728 - VL_attention_linear_output_acc: 0.4750 - VH_attention_linear_output_acc: 0.3963 - val_loss: 3.8013 - val_VL_attention_linear_output_loss: 1.8161 - val_VH_attention_linear_output_loss: 1.9852 - val_VL_attention_linear_output_acc: 0.4699 - val_VH_attention_linear_output_acc: 0.3932\n",
      "Epoch 998/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7662 - VL_attention_linear_output_loss: 1.7888 - VH_attention_linear_output_loss: 1.9773 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.3945 - val_loss: 3.7937 - val_VL_attention_linear_output_loss: 1.8104 - val_VH_attention_linear_output_loss: 1.9833 - val_VL_attention_linear_output_acc: 0.4690 - val_VH_attention_linear_output_acc: 0.3924\n",
      "Epoch 999/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7883 - VL_attention_linear_output_loss: 1.8038 - VH_attention_linear_output_loss: 1.9845 - VL_attention_linear_output_acc: 0.4699 - VH_attention_linear_output_acc: 0.3914 - val_loss: 3.7940 - val_VL_attention_linear_output_loss: 1.8147 - val_VH_attention_linear_output_loss: 1.9794 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.3973\n",
      "Epoch 1000/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7594 - VL_attention_linear_output_loss: 1.7853 - VH_attention_linear_output_loss: 1.9741 - VL_attention_linear_output_acc: 0.4786 - VH_attention_linear_output_acc: 0.3968 - val_loss: 3.7933 - val_VL_attention_linear_output_loss: 1.8107 - val_VH_attention_linear_output_loss: 1.9826 - val_VL_attention_linear_output_acc: 0.4743 - val_VH_attention_linear_output_acc: 0.3963\n",
      "Epoch 1001/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7688 - VL_attention_linear_output_loss: 1.7935 - VH_attention_linear_output_loss: 1.9753 - VL_attention_linear_output_acc: 0.4735 - VH_attention_linear_output_acc: 0.3959 - val_loss: 3.8270 - val_VL_attention_linear_output_loss: 1.8150 - val_VH_attention_linear_output_loss: 2.0120 - val_VL_attention_linear_output_acc: 0.4705 - val_VH_attention_linear_output_acc: 0.3772\n",
      "Epoch 1002/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7733 - VL_attention_linear_output_loss: 1.7967 - VH_attention_linear_output_loss: 1.9766 - VL_attention_linear_output_acc: 0.4738 - VH_attention_linear_output_acc: 0.3955 - val_loss: 3.7845 - val_VL_attention_linear_output_loss: 1.8084 - val_VH_attention_linear_output_loss: 1.9761 - val_VL_attention_linear_output_acc: 0.4748 - val_VH_attention_linear_output_acc: 0.3977\n",
      "Epoch 1003/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7768 - VL_attention_linear_output_loss: 1.8007 - VH_attention_linear_output_loss: 1.9761 - VL_attention_linear_output_acc: 0.4737 - VH_attention_linear_output_acc: 0.3951 - val_loss: 3.8210 - val_VL_attention_linear_output_loss: 1.8452 - val_VH_attention_linear_output_loss: 1.9758 - val_VL_attention_linear_output_acc: 0.4627 - val_VH_attention_linear_output_acc: 0.3966\n",
      "Epoch 1004/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7656 - VL_attention_linear_output_loss: 1.7901 - VH_attention_linear_output_loss: 1.9755 - VL_attention_linear_output_acc: 0.4770 - VH_attention_linear_output_acc: 0.3956 - val_loss: 3.7858 - val_VL_attention_linear_output_loss: 1.8096 - val_VH_attention_linear_output_loss: 1.9763 - val_VL_attention_linear_output_acc: 0.4694 - val_VH_attention_linear_output_acc: 0.3949\n",
      "Epoch 1005/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7732 - VL_attention_linear_output_loss: 1.7894 - VH_attention_linear_output_loss: 1.9837 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.3914 - val_loss: 3.9260 - val_VL_attention_linear_output_loss: 1.8136 - val_VH_attention_linear_output_loss: 2.1124 - val_VL_attention_linear_output_acc: 0.4688 - val_VH_attention_linear_output_acc: 0.3364\n",
      "Epoch 1006/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7788 - VL_attention_linear_output_loss: 1.8035 - VH_attention_linear_output_loss: 1.9753 - VL_attention_linear_output_acc: 0.4699 - VH_attention_linear_output_acc: 0.3959 - val_loss: 3.8132 - val_VL_attention_linear_output_loss: 1.8128 - val_VH_attention_linear_output_loss: 2.0003 - val_VL_attention_linear_output_acc: 0.4766 - val_VH_attention_linear_output_acc: 0.3858\n",
      "Epoch 1007/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7796 - VL_attention_linear_output_loss: 1.8012 - VH_attention_linear_output_loss: 1.9784 - VL_attention_linear_output_acc: 0.4715 - VH_attention_linear_output_acc: 0.3945 - val_loss: 3.8220 - val_VL_attention_linear_output_loss: 1.8357 - val_VH_attention_linear_output_loss: 1.9863 - val_VL_attention_linear_output_acc: 0.4612 - val_VH_attention_linear_output_acc: 0.3947\n",
      "Epoch 1008/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7900 - VL_attention_linear_output_loss: 1.8060 - VH_attention_linear_output_loss: 1.9840 - VL_attention_linear_output_acc: 0.4693 - VH_attention_linear_output_acc: 0.3922 - val_loss: 3.7797 - val_VL_attention_linear_output_loss: 1.8084 - val_VH_attention_linear_output_loss: 1.9713 - val_VL_attention_linear_output_acc: 0.4707 - val_VH_attention_linear_output_acc: 0.3977\n",
      "Epoch 1009/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7645 - VL_attention_linear_output_loss: 1.7875 - VH_attention_linear_output_loss: 1.9770 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.3950 - val_loss: 3.8077 - val_VL_attention_linear_output_loss: 1.8156 - val_VH_attention_linear_output_loss: 1.9921 - val_VL_attention_linear_output_acc: 0.4685 - val_VH_attention_linear_output_acc: 0.3913\n",
      "Epoch 1010/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7710 - VL_attention_linear_output_loss: 1.7883 - VH_attention_linear_output_loss: 1.9827 - VL_attention_linear_output_acc: 0.4763 - VH_attention_linear_output_acc: 0.3917 - val_loss: 3.7836 - val_VL_attention_linear_output_loss: 1.8089 - val_VH_attention_linear_output_loss: 1.9747 - val_VL_attention_linear_output_acc: 0.4704 - val_VH_attention_linear_output_acc: 0.3976\n",
      "Epoch 1011/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7768 - VL_attention_linear_output_loss: 1.8039 - VH_attention_linear_output_loss: 1.9729 - VL_attention_linear_output_acc: 0.4702 - VH_attention_linear_output_acc: 0.3970 - val_loss: 3.7992 - val_VL_attention_linear_output_loss: 1.8144 - val_VH_attention_linear_output_loss: 1.9847 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.3904\n",
      "Epoch 1012/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7686 - VL_attention_linear_output_loss: 1.7948 - VH_attention_linear_output_loss: 1.9738 - VL_attention_linear_output_acc: 0.4752 - VH_attention_linear_output_acc: 0.3962 - val_loss: 3.8322 - val_VL_attention_linear_output_loss: 1.8150 - val_VH_attention_linear_output_loss: 2.0171 - val_VL_attention_linear_output_acc: 0.4724 - val_VH_attention_linear_output_acc: 0.3815\n",
      "Epoch 1013/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7689 - VL_attention_linear_output_loss: 1.7880 - VH_attention_linear_output_loss: 1.9809 - VL_attention_linear_output_acc: 0.4776 - VH_attention_linear_output_acc: 0.3938 - val_loss: 3.7848 - val_VL_attention_linear_output_loss: 1.8074 - val_VH_attention_linear_output_loss: 1.9774 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.3956\n",
      "Epoch 1014/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7700 - VL_attention_linear_output_loss: 1.7958 - VH_attention_linear_output_loss: 1.9743 - VL_attention_linear_output_acc: 0.4736 - VH_attention_linear_output_acc: 0.3966 - val_loss: 3.8896 - val_VL_attention_linear_output_loss: 1.8975 - val_VH_attention_linear_output_loss: 1.9922 - val_VL_attention_linear_output_acc: 0.4366 - val_VH_attention_linear_output_acc: 0.3906\n",
      "Epoch 1015/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7900 - VL_attention_linear_output_loss: 1.8013 - VH_attention_linear_output_loss: 1.9887 - VL_attention_linear_output_acc: 0.4715 - VH_attention_linear_output_acc: 0.3903 - val_loss: 3.8455 - val_VL_attention_linear_output_loss: 1.8156 - val_VH_attention_linear_output_loss: 2.0299 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.3727\n",
      "Epoch 1016/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7767 - VL_attention_linear_output_loss: 1.8002 - VH_attention_linear_output_loss: 1.9764 - VL_attention_linear_output_acc: 0.4717 - VH_attention_linear_output_acc: 0.3965 - val_loss: 3.7823 - val_VL_attention_linear_output_loss: 1.8086 - val_VH_attention_linear_output_loss: 1.9736 - val_VL_attention_linear_output_acc: 0.4673 - val_VH_attention_linear_output_acc: 0.3952\n",
      "Epoch 1017/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7727 - VL_attention_linear_output_loss: 1.7887 - VH_attention_linear_output_loss: 1.9840 - VL_attention_linear_output_acc: 0.4770 - VH_attention_linear_output_acc: 0.3929 - val_loss: 3.8147 - val_VL_attention_linear_output_loss: 1.8141 - val_VH_attention_linear_output_loss: 2.0005 - val_VL_attention_linear_output_acc: 0.4710 - val_VH_attention_linear_output_acc: 0.3864\n",
      "Epoch 1018/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7801 - VL_attention_linear_output_loss: 1.7953 - VH_attention_linear_output_loss: 1.9848 - VL_attention_linear_output_acc: 0.4736 - VH_attention_linear_output_acc: 0.3929 - val_loss: 3.8041 - val_VL_attention_linear_output_loss: 1.8262 - val_VH_attention_linear_output_loss: 1.9779 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.3950\n",
      "Epoch 1019/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7922 - VL_attention_linear_output_loss: 1.8087 - VH_attention_linear_output_loss: 1.9836 - VL_attention_linear_output_acc: 0.4665 - VH_attention_linear_output_acc: 0.3937 - val_loss: 3.8233 - val_VL_attention_linear_output_loss: 1.8363 - val_VH_attention_linear_output_loss: 1.9870 - val_VL_attention_linear_output_acc: 0.4578 - val_VH_attention_linear_output_acc: 0.3948\n",
      "Epoch 1020/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7808 - VL_attention_linear_output_loss: 1.7942 - VH_attention_linear_output_loss: 1.9865 - VL_attention_linear_output_acc: 0.4740 - VH_attention_linear_output_acc: 0.3934 - val_loss: 3.8080 - val_VL_attention_linear_output_loss: 1.8309 - val_VH_attention_linear_output_loss: 1.9771 - val_VL_attention_linear_output_acc: 0.4639 - val_VH_attention_linear_output_acc: 0.3991\n",
      "Epoch 1021/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7753 - VL_attention_linear_output_loss: 1.7942 - VH_attention_linear_output_loss: 1.9811 - VL_attention_linear_output_acc: 0.4735 - VH_attention_linear_output_acc: 0.3948 - val_loss: 3.7896 - val_VL_attention_linear_output_loss: 1.8112 - val_VH_attention_linear_output_loss: 1.9784 - val_VL_attention_linear_output_acc: 0.4730 - val_VH_attention_linear_output_acc: 0.3961\n",
      "Epoch 1022/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7654 - VL_attention_linear_output_loss: 1.7934 - VH_attention_linear_output_loss: 1.9720 - VL_attention_linear_output_acc: 0.4744 - VH_attention_linear_output_acc: 0.3983 - val_loss: 3.8558 - val_VL_attention_linear_output_loss: 1.8683 - val_VH_attention_linear_output_loss: 1.9876 - val_VL_attention_linear_output_acc: 0.4536 - val_VH_attention_linear_output_acc: 0.3949\n",
      "Epoch 1023/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7819 - VL_attention_linear_output_loss: 1.8029 - VH_attention_linear_output_loss: 1.9790 - VL_attention_linear_output_acc: 0.4708 - VH_attention_linear_output_acc: 0.3942 - val_loss: 3.8200 - val_VL_attention_linear_output_loss: 1.8375 - val_VH_attention_linear_output_loss: 1.9825 - val_VL_attention_linear_output_acc: 0.4697 - val_VH_attention_linear_output_acc: 0.3987\n",
      "Epoch 1024/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7799 - VL_attention_linear_output_loss: 1.8033 - VH_attention_linear_output_loss: 1.9766 - VL_attention_linear_output_acc: 0.4704 - VH_attention_linear_output_acc: 0.3960 - val_loss: 3.7863 - val_VL_attention_linear_output_loss: 1.8115 - val_VH_attention_linear_output_loss: 1.9748 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.4001\n",
      "Epoch 1025/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7637 - VL_attention_linear_output_loss: 1.7908 - VH_attention_linear_output_loss: 1.9729 - VL_attention_linear_output_acc: 0.4748 - VH_attention_linear_output_acc: 0.3982 - val_loss: 3.8042 - val_VL_attention_linear_output_loss: 1.8227 - val_VH_attention_linear_output_loss: 1.9815 - val_VL_attention_linear_output_acc: 0.4632 - val_VH_attention_linear_output_acc: 0.3959\n",
      "Epoch 1026/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7772 - VL_attention_linear_output_loss: 1.7999 - VH_attention_linear_output_loss: 1.9773 - VL_attention_linear_output_acc: 0.4717 - VH_attention_linear_output_acc: 0.3971 - val_loss: 3.8380 - val_VL_attention_linear_output_loss: 1.8434 - val_VH_attention_linear_output_loss: 1.9946 - val_VL_attention_linear_output_acc: 0.4649 - val_VH_attention_linear_output_acc: 0.3929\n",
      "Epoch 1027/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7814 - VL_attention_linear_output_loss: 1.8051 - VH_attention_linear_output_loss: 1.9764 - VL_attention_linear_output_acc: 0.4698 - VH_attention_linear_output_acc: 0.3982 - val_loss: 3.8120 - val_VL_attention_linear_output_loss: 1.8142 - val_VH_attention_linear_output_loss: 1.9977 - val_VL_attention_linear_output_acc: 0.4689 - val_VH_attention_linear_output_acc: 0.3898\n",
      "Epoch 1028/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7532 - VL_attention_linear_output_loss: 1.7838 - VH_attention_linear_output_loss: 1.9694 - VL_attention_linear_output_acc: 0.4795 - VH_attention_linear_output_acc: 0.3994 - val_loss: 3.8066 - val_VL_attention_linear_output_loss: 1.8098 - val_VH_attention_linear_output_loss: 1.9968 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.3883\n",
      "Epoch 1029/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7623 - VL_attention_linear_output_loss: 1.7846 - VH_attention_linear_output_loss: 1.9777 - VL_attention_linear_output_acc: 0.4798 - VH_attention_linear_output_acc: 0.3970 - val_loss: 3.8019 - val_VL_attention_linear_output_loss: 1.8215 - val_VH_attention_linear_output_loss: 1.9804 - val_VL_attention_linear_output_acc: 0.4714 - val_VH_attention_linear_output_acc: 0.3954\n",
      "Epoch 1030/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7707 - VL_attention_linear_output_loss: 1.7999 - VH_attention_linear_output_loss: 1.9709 - VL_attention_linear_output_acc: 0.4703 - VH_attention_linear_output_acc: 0.3996 - val_loss: 3.8110 - val_VL_attention_linear_output_loss: 1.8138 - val_VH_attention_linear_output_loss: 1.9971 - val_VL_attention_linear_output_acc: 0.4694 - val_VH_attention_linear_output_acc: 0.3871\n",
      "Epoch 1031/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7773 - VL_attention_linear_output_loss: 1.8003 - VH_attention_linear_output_loss: 1.9770 - VL_attention_linear_output_acc: 0.4717 - VH_attention_linear_output_acc: 0.3971 - val_loss: 3.8723 - val_VL_attention_linear_output_loss: 1.8963 - val_VH_attention_linear_output_loss: 1.9760 - val_VL_attention_linear_output_acc: 0.4305 - val_VH_attention_linear_output_acc: 0.3998\n",
      "Epoch 1032/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7603 - VL_attention_linear_output_loss: 1.7883 - VH_attention_linear_output_loss: 1.9720 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.3985 - val_loss: 3.7745 - val_VL_attention_linear_output_loss: 1.8062 - val_VH_attention_linear_output_loss: 1.9683 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4027\n",
      "Epoch 1033/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7476 - VL_attention_linear_output_loss: 1.7841 - VH_attention_linear_output_loss: 1.9635 - VL_attention_linear_output_acc: 0.4792 - VH_attention_linear_output_acc: 0.4025 - val_loss: 3.7766 - val_VL_attention_linear_output_loss: 1.8056 - val_VH_attention_linear_output_loss: 1.9709 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4007\n",
      "Epoch 1034/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7699 - VL_attention_linear_output_loss: 1.7890 - VH_attention_linear_output_loss: 1.9809 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.3957 - val_loss: 3.8022 - val_VL_attention_linear_output_loss: 1.8121 - val_VH_attention_linear_output_loss: 1.9900 - val_VL_attention_linear_output_acc: 0.4751 - val_VH_attention_linear_output_acc: 0.3956\n",
      "Epoch 1035/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7607 - VL_attention_linear_output_loss: 1.7852 - VH_attention_linear_output_loss: 1.9755 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.4014 - val_loss: 3.8055 - val_VL_attention_linear_output_loss: 1.8170 - val_VH_attention_linear_output_loss: 1.9885 - val_VL_attention_linear_output_acc: 0.4726 - val_VH_attention_linear_output_acc: 0.3937\n",
      "Epoch 1036/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7585 - VL_attention_linear_output_loss: 1.7886 - VH_attention_linear_output_loss: 1.9700 - VL_attention_linear_output_acc: 0.4768 - VH_attention_linear_output_acc: 0.4026 - val_loss: 3.7921 - val_VL_attention_linear_output_loss: 1.8046 - val_VH_attention_linear_output_loss: 1.9875 - val_VL_attention_linear_output_acc: 0.4775 - val_VH_attention_linear_output_acc: 0.3954\n",
      "Epoch 1037/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7560 - VL_attention_linear_output_loss: 1.7855 - VH_attention_linear_output_loss: 1.9705 - VL_attention_linear_output_acc: 0.4778 - VH_attention_linear_output_acc: 0.4021 - val_loss: 3.8278 - val_VL_attention_linear_output_loss: 1.8512 - val_VH_attention_linear_output_loss: 1.9766 - val_VL_attention_linear_output_acc: 0.4555 - val_VH_attention_linear_output_acc: 0.4001\n",
      "Epoch 1038/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7670 - VL_attention_linear_output_loss: 1.7948 - VH_attention_linear_output_loss: 1.9721 - VL_attention_linear_output_acc: 0.4739 - VH_attention_linear_output_acc: 0.4005 - val_loss: 3.8003 - val_VL_attention_linear_output_loss: 1.8197 - val_VH_attention_linear_output_loss: 1.9806 - val_VL_attention_linear_output_acc: 0.4724 - val_VH_attention_linear_output_acc: 0.3998\n",
      "Epoch 1039/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7693 - VL_attention_linear_output_loss: 1.7983 - VH_attention_linear_output_loss: 1.9710 - VL_attention_linear_output_acc: 0.4723 - VH_attention_linear_output_acc: 0.4005 - val_loss: 3.8010 - val_VL_attention_linear_output_loss: 1.8149 - val_VH_attention_linear_output_loss: 1.9862 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.3966\n",
      "Epoch 1040/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7516 - VL_attention_linear_output_loss: 1.7854 - VH_attention_linear_output_loss: 1.9662 - VL_attention_linear_output_acc: 0.4793 - VH_attention_linear_output_acc: 0.4033 - val_loss: 3.7918 - val_VL_attention_linear_output_loss: 1.8169 - val_VH_attention_linear_output_loss: 1.9749 - val_VL_attention_linear_output_acc: 0.4718 - val_VH_attention_linear_output_acc: 0.4005\n",
      "Epoch 1041/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7626 - VL_attention_linear_output_loss: 1.7931 - VH_attention_linear_output_loss: 1.9695 - VL_attention_linear_output_acc: 0.4759 - VH_attention_linear_output_acc: 0.4014 - val_loss: 3.7886 - val_VL_attention_linear_output_loss: 1.8089 - val_VH_attention_linear_output_loss: 1.9797 - val_VL_attention_linear_output_acc: 0.4739 - val_VH_attention_linear_output_acc: 0.3991\n",
      "Epoch 1042/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7555 - VL_attention_linear_output_loss: 1.7857 - VH_attention_linear_output_loss: 1.9699 - VL_attention_linear_output_acc: 0.4779 - VH_attention_linear_output_acc: 0.4010 - val_loss: 3.8317 - val_VL_attention_linear_output_loss: 1.8371 - val_VH_attention_linear_output_loss: 1.9947 - val_VL_attention_linear_output_acc: 0.4596 - val_VH_attention_linear_output_acc: 0.3916\n",
      "Epoch 1043/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7591 - VL_attention_linear_output_loss: 1.7891 - VH_attention_linear_output_loss: 1.9700 - VL_attention_linear_output_acc: 0.4765 - VH_attention_linear_output_acc: 0.4009 - val_loss: 3.8076 - val_VL_attention_linear_output_loss: 1.8288 - val_VH_attention_linear_output_loss: 1.9788 - val_VL_attention_linear_output_acc: 0.4609 - val_VH_attention_linear_output_acc: 0.4001\n",
      "Epoch 1044/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7759 - VL_attention_linear_output_loss: 1.8058 - VH_attention_linear_output_loss: 1.9701 - VL_attention_linear_output_acc: 0.4687 - VH_attention_linear_output_acc: 0.4011 - val_loss: 3.7909 - val_VL_attention_linear_output_loss: 1.8082 - val_VH_attention_linear_output_loss: 1.9828 - val_VL_attention_linear_output_acc: 0.4795 - val_VH_attention_linear_output_acc: 0.3973\n",
      "Epoch 1045/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7602 - VL_attention_linear_output_loss: 1.7888 - VH_attention_linear_output_loss: 1.9714 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.4001 - val_loss: 3.9094 - val_VL_attention_linear_output_loss: 1.9431 - val_VH_attention_linear_output_loss: 1.9663 - val_VL_attention_linear_output_acc: 0.4157 - val_VH_attention_linear_output_acc: 0.4042\n",
      "Epoch 1046/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7659 - VL_attention_linear_output_loss: 1.7942 - VH_attention_linear_output_loss: 1.9717 - VL_attention_linear_output_acc: 0.4731 - VH_attention_linear_output_acc: 0.4011 - val_loss: 3.8209 - val_VL_attention_linear_output_loss: 1.8361 - val_VH_attention_linear_output_loss: 1.9848 - val_VL_attention_linear_output_acc: 0.4662 - val_VH_attention_linear_output_acc: 0.3929\n",
      "Epoch 1047/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7518 - VL_attention_linear_output_loss: 1.7854 - VH_attention_linear_output_loss: 1.9665 - VL_attention_linear_output_acc: 0.4790 - VH_attention_linear_output_acc: 0.4023 - val_loss: 3.7829 - val_VL_attention_linear_output_loss: 1.8198 - val_VH_attention_linear_output_loss: 1.9631 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.4050\n",
      "Epoch 1048/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7669 - VL_attention_linear_output_loss: 1.7981 - VH_attention_linear_output_loss: 1.9688 - VL_attention_linear_output_acc: 0.4714 - VH_attention_linear_output_acc: 0.4012 - val_loss: 3.7736 - val_VL_attention_linear_output_loss: 1.8088 - val_VH_attention_linear_output_loss: 1.9647 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.4020\n",
      "Epoch 1049/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7612 - VL_attention_linear_output_loss: 1.7879 - VH_attention_linear_output_loss: 1.9733 - VL_attention_linear_output_acc: 0.4775 - VH_attention_linear_output_acc: 0.3984 - val_loss: 3.7907 - val_VL_attention_linear_output_loss: 1.8090 - val_VH_attention_linear_output_loss: 1.9817 - val_VL_attention_linear_output_acc: 0.4734 - val_VH_attention_linear_output_acc: 0.3984\n",
      "Epoch 1050/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7670 - VL_attention_linear_output_loss: 1.7970 - VH_attention_linear_output_loss: 1.9700 - VL_attention_linear_output_acc: 0.4722 - VH_attention_linear_output_acc: 0.4004 - val_loss: 3.8287 - val_VL_attention_linear_output_loss: 1.8223 - val_VH_attention_linear_output_loss: 2.0063 - val_VL_attention_linear_output_acc: 0.4683 - val_VH_attention_linear_output_acc: 0.3827\n",
      "Epoch 1051/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7647 - VL_attention_linear_output_loss: 1.7945 - VH_attention_linear_output_loss: 1.9702 - VL_attention_linear_output_acc: 0.4739 - VH_attention_linear_output_acc: 0.4005 - val_loss: 3.8028 - val_VL_attention_linear_output_loss: 1.8259 - val_VH_attention_linear_output_loss: 1.9769 - val_VL_attention_linear_output_acc: 0.4678 - val_VH_attention_linear_output_acc: 0.3982\n",
      "Epoch 1052/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7597 - VL_attention_linear_output_loss: 1.7961 - VH_attention_linear_output_loss: 1.9636 - VL_attention_linear_output_acc: 0.4723 - VH_attention_linear_output_acc: 0.4028 - val_loss: 3.7978 - val_VL_attention_linear_output_loss: 1.8233 - val_VH_attention_linear_output_loss: 1.9745 - val_VL_attention_linear_output_acc: 0.4689 - val_VH_attention_linear_output_acc: 0.3995\n",
      "Epoch 1053/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7727 - VL_attention_linear_output_loss: 1.8016 - VH_attention_linear_output_loss: 1.9711 - VL_attention_linear_output_acc: 0.4698 - VH_attention_linear_output_acc: 0.4000 - val_loss: 3.7869 - val_VL_attention_linear_output_loss: 1.8137 - val_VH_attention_linear_output_loss: 1.9732 - val_VL_attention_linear_output_acc: 0.4726 - val_VH_attention_linear_output_acc: 0.4007\n",
      "Epoch 1054/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7697 - VL_attention_linear_output_loss: 1.8008 - VH_attention_linear_output_loss: 1.9689 - VL_attention_linear_output_acc: 0.4706 - VH_attention_linear_output_acc: 0.4011 - val_loss: 3.8323 - val_VL_attention_linear_output_loss: 1.8596 - val_VH_attention_linear_output_loss: 1.9727 - val_VL_attention_linear_output_acc: 0.4530 - val_VH_attention_linear_output_acc: 0.4009\n",
      "Epoch 1055/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7719 - VL_attention_linear_output_loss: 1.8003 - VH_attention_linear_output_loss: 1.9717 - VL_attention_linear_output_acc: 0.4699 - VH_attention_linear_output_acc: 0.3997 - val_loss: 3.7928 - val_VL_attention_linear_output_loss: 1.8083 - val_VH_attention_linear_output_loss: 1.9844 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.3928\n",
      "Epoch 1056/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7653 - VL_attention_linear_output_loss: 1.7965 - VH_attention_linear_output_loss: 1.9689 - VL_attention_linear_output_acc: 0.4733 - VH_attention_linear_output_acc: 0.4003 - val_loss: 3.8670 - val_VL_attention_linear_output_loss: 1.8809 - val_VH_attention_linear_output_loss: 1.9861 - val_VL_attention_linear_output_acc: 0.4380 - val_VH_attention_linear_output_acc: 0.3927\n",
      "Epoch 1057/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7676 - VL_attention_linear_output_loss: 1.7926 - VH_attention_linear_output_loss: 1.9750 - VL_attention_linear_output_acc: 0.4739 - VH_attention_linear_output_acc: 0.3984 - val_loss: 3.7865 - val_VL_attention_linear_output_loss: 1.8012 - val_VH_attention_linear_output_loss: 1.9853 - val_VL_attention_linear_output_acc: 0.4736 - val_VH_attention_linear_output_acc: 0.3940\n",
      "Epoch 1058/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7457 - VL_attention_linear_output_loss: 1.7840 - VH_attention_linear_output_loss: 1.9617 - VL_attention_linear_output_acc: 0.4786 - VH_attention_linear_output_acc: 0.4038 - val_loss: 3.7787 - val_VL_attention_linear_output_loss: 1.8072 - val_VH_attention_linear_output_loss: 1.9714 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.4023\n",
      "Epoch 1059/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7766 - VL_attention_linear_output_loss: 1.7986 - VH_attention_linear_output_loss: 1.9780 - VL_attention_linear_output_acc: 0.4728 - VH_attention_linear_output_acc: 0.3988 - val_loss: 3.7822 - val_VL_attention_linear_output_loss: 1.8180 - val_VH_attention_linear_output_loss: 1.9642 - val_VL_attention_linear_output_acc: 0.4677 - val_VH_attention_linear_output_acc: 0.4047\n",
      "Epoch 1060/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7642 - VL_attention_linear_output_loss: 1.7923 - VH_attention_linear_output_loss: 1.9719 - VL_attention_linear_output_acc: 0.4740 - VH_attention_linear_output_acc: 0.4003 - val_loss: 3.7950 - val_VL_attention_linear_output_loss: 1.8076 - val_VH_attention_linear_output_loss: 1.9874 - val_VL_attention_linear_output_acc: 0.4779 - val_VH_attention_linear_output_acc: 0.3911\n",
      "Epoch 1061/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7648 - VL_attention_linear_output_loss: 1.8002 - VH_attention_linear_output_loss: 1.9646 - VL_attention_linear_output_acc: 0.4714 - VH_attention_linear_output_acc: 0.4020 - val_loss: 3.8024 - val_VL_attention_linear_output_loss: 1.8056 - val_VH_attention_linear_output_loss: 1.9969 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.3891\n",
      "Epoch 1062/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7529 - VL_attention_linear_output_loss: 1.7887 - VH_attention_linear_output_loss: 1.9642 - VL_attention_linear_output_acc: 0.4759 - VH_attention_linear_output_acc: 0.4027 - val_loss: 3.8211 - val_VL_attention_linear_output_loss: 1.8084 - val_VH_attention_linear_output_loss: 2.0126 - val_VL_attention_linear_output_acc: 0.4794 - val_VH_attention_linear_output_acc: 0.3804\n",
      "Epoch 1063/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7679 - VL_attention_linear_output_loss: 1.8037 - VH_attention_linear_output_loss: 1.9642 - VL_attention_linear_output_acc: 0.4679 - VH_attention_linear_output_acc: 0.4024 - val_loss: 3.7894 - val_VL_attention_linear_output_loss: 1.8219 - val_VH_attention_linear_output_loss: 1.9675 - val_VL_attention_linear_output_acc: 0.4683 - val_VH_attention_linear_output_acc: 0.4026\n",
      "Epoch 1064/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7416 - VL_attention_linear_output_loss: 1.7816 - VH_attention_linear_output_loss: 1.9599 - VL_attention_linear_output_acc: 0.4796 - VH_attention_linear_output_acc: 0.4044 - val_loss: 3.7687 - val_VL_attention_linear_output_loss: 1.8034 - val_VH_attention_linear_output_loss: 1.9653 - val_VL_attention_linear_output_acc: 0.4781 - val_VH_attention_linear_output_acc: 0.4028\n",
      "Epoch 1065/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7550 - VL_attention_linear_output_loss: 1.7839 - VH_attention_linear_output_loss: 1.9711 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.3988 - val_loss: 3.7713 - val_VL_attention_linear_output_loss: 1.8048 - val_VH_attention_linear_output_loss: 1.9664 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.4040\n",
      "Epoch 1066/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7550 - VL_attention_linear_output_loss: 1.7906 - VH_attention_linear_output_loss: 1.9644 - VL_attention_linear_output_acc: 0.4754 - VH_attention_linear_output_acc: 0.4028 - val_loss: 3.7811 - val_VL_attention_linear_output_loss: 1.8074 - val_VH_attention_linear_output_loss: 1.9738 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4007\n",
      "Epoch 1067/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7678 - VL_attention_linear_output_loss: 1.7962 - VH_attention_linear_output_loss: 1.9716 - VL_attention_linear_output_acc: 0.4742 - VH_attention_linear_output_acc: 0.3995 - val_loss: 3.8016 - val_VL_attention_linear_output_loss: 1.8199 - val_VH_attention_linear_output_loss: 1.9817 - val_VL_attention_linear_output_acc: 0.4676 - val_VH_attention_linear_output_acc: 0.3980\n",
      "Epoch 1068/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7603 - VL_attention_linear_output_loss: 1.7932 - VH_attention_linear_output_loss: 1.9671 - VL_attention_linear_output_acc: 0.4733 - VH_attention_linear_output_acc: 0.4021 - val_loss: 3.7725 - val_VL_attention_linear_output_loss: 1.8060 - val_VH_attention_linear_output_loss: 1.9665 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4023\n",
      "Epoch 1069/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7481 - VL_attention_linear_output_loss: 1.7855 - VH_attention_linear_output_loss: 1.9627 - VL_attention_linear_output_acc: 0.4775 - VH_attention_linear_output_acc: 0.4029 - val_loss: 3.8329 - val_VL_attention_linear_output_loss: 1.8583 - val_VH_attention_linear_output_loss: 1.9746 - val_VL_attention_linear_output_acc: 0.4536 - val_VH_attention_linear_output_acc: 0.4001\n",
      "Epoch 1070/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7680 - VL_attention_linear_output_loss: 1.8035 - VH_attention_linear_output_loss: 1.9645 - VL_attention_linear_output_acc: 0.4697 - VH_attention_linear_output_acc: 0.4023 - val_loss: 3.8278 - val_VL_attention_linear_output_loss: 1.8349 - val_VH_attention_linear_output_loss: 1.9928 - val_VL_attention_linear_output_acc: 0.4570 - val_VH_attention_linear_output_acc: 0.3873\n",
      "Epoch 1071/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7641 - VL_attention_linear_output_loss: 1.7973 - VH_attention_linear_output_loss: 1.9668 - VL_attention_linear_output_acc: 0.4716 - VH_attention_linear_output_acc: 0.4006 - val_loss: 3.7977 - val_VL_attention_linear_output_loss: 1.8055 - val_VH_attention_linear_output_loss: 1.9922 - val_VL_attention_linear_output_acc: 0.4700 - val_VH_attention_linear_output_acc: 0.3902\n",
      "Epoch 1072/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7715 - VL_attention_linear_output_loss: 1.8035 - VH_attention_linear_output_loss: 1.9680 - VL_attention_linear_output_acc: 0.4689 - VH_attention_linear_output_acc: 0.4005 - val_loss: 3.8044 - val_VL_attention_linear_output_loss: 1.8351 - val_VH_attention_linear_output_loss: 1.9692 - val_VL_attention_linear_output_acc: 0.4623 - val_VH_attention_linear_output_acc: 0.3993\n",
      "Epoch 1073/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7545 - VL_attention_linear_output_loss: 1.7859 - VH_attention_linear_output_loss: 1.9686 - VL_attention_linear_output_acc: 0.4768 - VH_attention_linear_output_acc: 0.3999 - val_loss: 3.8133 - val_VL_attention_linear_output_loss: 1.8468 - val_VH_attention_linear_output_loss: 1.9665 - val_VL_attention_linear_output_acc: 0.4496 - val_VH_attention_linear_output_acc: 0.4048\n",
      "Epoch 1074/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7514 - VL_attention_linear_output_loss: 1.7876 - VH_attention_linear_output_loss: 1.9638 - VL_attention_linear_output_acc: 0.4756 - VH_attention_linear_output_acc: 0.4027 - val_loss: 3.7719 - val_VL_attention_linear_output_loss: 1.8126 - val_VH_attention_linear_output_loss: 1.9594 - val_VL_attention_linear_output_acc: 0.4726 - val_VH_attention_linear_output_acc: 0.4065\n",
      "Epoch 1075/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7662 - VL_attention_linear_output_loss: 1.8050 - VH_attention_linear_output_loss: 1.9612 - VL_attention_linear_output_acc: 0.4682 - VH_attention_linear_output_acc: 0.4037 - val_loss: 3.7904 - val_VL_attention_linear_output_loss: 1.8159 - val_VH_attention_linear_output_loss: 1.9745 - val_VL_attention_linear_output_acc: 0.4724 - val_VH_attention_linear_output_acc: 0.4023\n",
      "Epoch 1076/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7587 - VL_attention_linear_output_loss: 1.7871 - VH_attention_linear_output_loss: 1.9716 - VL_attention_linear_output_acc: 0.4764 - VH_attention_linear_output_acc: 0.3988 - val_loss: 3.7791 - val_VL_attention_linear_output_loss: 1.8111 - val_VH_attention_linear_output_loss: 1.9680 - val_VL_attention_linear_output_acc: 0.4699 - val_VH_attention_linear_output_acc: 0.4010\n",
      "Epoch 1077/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7521 - VL_attention_linear_output_loss: 1.7947 - VH_attention_linear_output_loss: 1.9575 - VL_attention_linear_output_acc: 0.4742 - VH_attention_linear_output_acc: 0.4056 - val_loss: 3.7857 - val_VL_attention_linear_output_loss: 1.8261 - val_VH_attention_linear_output_loss: 1.9596 - val_VL_attention_linear_output_acc: 0.4624 - val_VH_attention_linear_output_acc: 0.4062\n",
      "Epoch 1078/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7523 - VL_attention_linear_output_loss: 1.7884 - VH_attention_linear_output_loss: 1.9639 - VL_attention_linear_output_acc: 0.4771 - VH_attention_linear_output_acc: 0.4018 - val_loss: 3.8091 - val_VL_attention_linear_output_loss: 1.8436 - val_VH_attention_linear_output_loss: 1.9655 - val_VL_attention_linear_output_acc: 0.4581 - val_VH_attention_linear_output_acc: 0.4048\n",
      "Epoch 1079/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7647 - VL_attention_linear_output_loss: 1.8033 - VH_attention_linear_output_loss: 1.9614 - VL_attention_linear_output_acc: 0.4689 - VH_attention_linear_output_acc: 0.4034 - val_loss: 3.7721 - val_VL_attention_linear_output_loss: 1.8027 - val_VH_attention_linear_output_loss: 1.9694 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4019\n",
      "Epoch 1080/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7460 - VL_attention_linear_output_loss: 1.7845 - VH_attention_linear_output_loss: 1.9615 - VL_attention_linear_output_acc: 0.4776 - VH_attention_linear_output_acc: 0.4038 - val_loss: 3.8065 - val_VL_attention_linear_output_loss: 1.8186 - val_VH_attention_linear_output_loss: 1.9879 - val_VL_attention_linear_output_acc: 0.4701 - val_VH_attention_linear_output_acc: 0.3962\n",
      "Epoch 1081/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7397 - VL_attention_linear_output_loss: 1.7819 - VH_attention_linear_output_loss: 1.9578 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4045 - val_loss: 3.7744 - val_VL_attention_linear_output_loss: 1.8087 - val_VH_attention_linear_output_loss: 1.9657 - val_VL_attention_linear_output_acc: 0.4784 - val_VH_attention_linear_output_acc: 0.4053\n",
      "Epoch 1082/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7417 - VL_attention_linear_output_loss: 1.7866 - VH_attention_linear_output_loss: 1.9551 - VL_attention_linear_output_acc: 0.4771 - VH_attention_linear_output_acc: 0.4067 - val_loss: 3.7827 - val_VL_attention_linear_output_loss: 1.8186 - val_VH_attention_linear_output_loss: 1.9642 - val_VL_attention_linear_output_acc: 0.4661 - val_VH_attention_linear_output_acc: 0.4022\n",
      "Epoch 1083/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7482 - VL_attention_linear_output_loss: 1.7903 - VH_attention_linear_output_loss: 1.9579 - VL_attention_linear_output_acc: 0.4755 - VH_attention_linear_output_acc: 0.4044 - val_loss: 3.7726 - val_VL_attention_linear_output_loss: 1.8061 - val_VH_attention_linear_output_loss: 1.9665 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4061\n",
      "Epoch 1084/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7601 - VL_attention_linear_output_loss: 1.7928 - VH_attention_linear_output_loss: 1.9673 - VL_attention_linear_output_acc: 0.4751 - VH_attention_linear_output_acc: 0.4011 - val_loss: 3.7885 - val_VL_attention_linear_output_loss: 1.8171 - val_VH_attention_linear_output_loss: 1.9714 - val_VL_attention_linear_output_acc: 0.4703 - val_VH_attention_linear_output_acc: 0.4027\n",
      "Epoch 1085/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7507 - VL_attention_linear_output_loss: 1.7878 - VH_attention_linear_output_loss: 1.9629 - VL_attention_linear_output_acc: 0.4758 - VH_attention_linear_output_acc: 0.4028 - val_loss: 3.7709 - val_VL_attention_linear_output_loss: 1.8068 - val_VH_attention_linear_output_loss: 1.9641 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4060\n",
      "Epoch 1086/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7509 - VL_attention_linear_output_loss: 1.7913 - VH_attention_linear_output_loss: 1.9597 - VL_attention_linear_output_acc: 0.4748 - VH_attention_linear_output_acc: 0.4041 - val_loss: 3.7654 - val_VL_attention_linear_output_loss: 1.8014 - val_VH_attention_linear_output_loss: 1.9639 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4012\n",
      "Epoch 1087/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7368 - VL_attention_linear_output_loss: 1.7825 - VH_attention_linear_output_loss: 1.9544 - VL_attention_linear_output_acc: 0.4792 - VH_attention_linear_output_acc: 0.4063 - val_loss: 3.7836 - val_VL_attention_linear_output_loss: 1.8099 - val_VH_attention_linear_output_loss: 1.9738 - val_VL_attention_linear_output_acc: 0.4736 - val_VH_attention_linear_output_acc: 0.3994\n",
      "Epoch 1088/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7447 - VL_attention_linear_output_loss: 1.7884 - VH_attention_linear_output_loss: 1.9563 - VL_attention_linear_output_acc: 0.4769 - VH_attention_linear_output_acc: 0.4055 - val_loss: 3.7848 - val_VL_attention_linear_output_loss: 1.8217 - val_VH_attention_linear_output_loss: 1.9632 - val_VL_attention_linear_output_acc: 0.4664 - val_VH_attention_linear_output_acc: 0.4021\n",
      "Epoch 1089/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7575 - VL_attention_linear_output_loss: 1.8007 - VH_attention_linear_output_loss: 1.9568 - VL_attention_linear_output_acc: 0.4703 - VH_attention_linear_output_acc: 0.4055 - val_loss: 3.7763 - val_VL_attention_linear_output_loss: 1.8069 - val_VH_attention_linear_output_loss: 1.9694 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.4020\n",
      "Epoch 1090/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7659 - VL_attention_linear_output_loss: 1.8008 - VH_attention_linear_output_loss: 1.9651 - VL_attention_linear_output_acc: 0.4704 - VH_attention_linear_output_acc: 0.4010 - val_loss: 3.7732 - val_VL_attention_linear_output_loss: 1.8147 - val_VH_attention_linear_output_loss: 1.9585 - val_VL_attention_linear_output_acc: 0.4682 - val_VH_attention_linear_output_acc: 0.4069\n",
      "Epoch 1091/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7508 - VL_attention_linear_output_loss: 1.7886 - VH_attention_linear_output_loss: 1.9622 - VL_attention_linear_output_acc: 0.4750 - VH_attention_linear_output_acc: 0.4018 - val_loss: 3.9084 - val_VL_attention_linear_output_loss: 1.9406 - val_VH_attention_linear_output_loss: 1.9677 - val_VL_attention_linear_output_acc: 0.4138 - val_VH_attention_linear_output_acc: 0.4004\n",
      "Epoch 1092/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7564 - VL_attention_linear_output_loss: 1.8013 - VH_attention_linear_output_loss: 1.9551 - VL_attention_linear_output_acc: 0.4702 - VH_attention_linear_output_acc: 0.4058 - val_loss: 3.8228 - val_VL_attention_linear_output_loss: 1.8043 - val_VH_attention_linear_output_loss: 2.0185 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.3791\n",
      "Epoch 1093/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7447 - VL_attention_linear_output_loss: 1.7823 - VH_attention_linear_output_loss: 1.9624 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4023 - val_loss: 3.7866 - val_VL_attention_linear_output_loss: 1.8068 - val_VH_attention_linear_output_loss: 1.9799 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.3964\n",
      "Epoch 1094/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7391 - VL_attention_linear_output_loss: 1.7842 - VH_attention_linear_output_loss: 1.9549 - VL_attention_linear_output_acc: 0.4781 - VH_attention_linear_output_acc: 0.4058 - val_loss: 3.7780 - val_VL_attention_linear_output_loss: 1.8103 - val_VH_attention_linear_output_loss: 1.9677 - val_VL_attention_linear_output_acc: 0.4705 - val_VH_attention_linear_output_acc: 0.4021\n",
      "Epoch 1095/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7722 - VL_attention_linear_output_loss: 1.8071 - VH_attention_linear_output_loss: 1.9651 - VL_attention_linear_output_acc: 0.4674 - VH_attention_linear_output_acc: 0.4010 - val_loss: 3.8215 - val_VL_attention_linear_output_loss: 1.8092 - val_VH_attention_linear_output_loss: 2.0123 - val_VL_attention_linear_output_acc: 0.4729 - val_VH_attention_linear_output_acc: 0.3802\n",
      "Epoch 1096/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7503 - VL_attention_linear_output_loss: 1.7943 - VH_attention_linear_output_loss: 1.9559 - VL_attention_linear_output_acc: 0.4726 - VH_attention_linear_output_acc: 0.4059 - val_loss: 3.7859 - val_VL_attention_linear_output_loss: 1.8207 - val_VH_attention_linear_output_loss: 1.9652 - val_VL_attention_linear_output_acc: 0.4610 - val_VH_attention_linear_output_acc: 0.4007\n",
      "Epoch 1097/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7565 - VL_attention_linear_output_loss: 1.7947 - VH_attention_linear_output_loss: 1.9618 - VL_attention_linear_output_acc: 0.4728 - VH_attention_linear_output_acc: 0.4029 - val_loss: 3.7749 - val_VL_attention_linear_output_loss: 1.8159 - val_VH_attention_linear_output_loss: 1.9590 - val_VL_attention_linear_output_acc: 0.4715 - val_VH_attention_linear_output_acc: 0.4055\n",
      "Epoch 1098/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7447 - VL_attention_linear_output_loss: 1.7879 - VH_attention_linear_output_loss: 1.9568 - VL_attention_linear_output_acc: 0.4767 - VH_attention_linear_output_acc: 0.4051 - val_loss: 3.8937 - val_VL_attention_linear_output_loss: 1.9190 - val_VH_attention_linear_output_loss: 1.9747 - val_VL_attention_linear_output_acc: 0.4178 - val_VH_attention_linear_output_acc: 0.3989\n",
      "Epoch 1099/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7704 - VL_attention_linear_output_loss: 1.8054 - VH_attention_linear_output_loss: 1.9650 - VL_attention_linear_output_acc: 0.4672 - VH_attention_linear_output_acc: 0.4024 - val_loss: 3.8563 - val_VL_attention_linear_output_loss: 1.8855 - val_VH_attention_linear_output_loss: 1.9708 - val_VL_attention_linear_output_acc: 0.4385 - val_VH_attention_linear_output_acc: 0.3993\n",
      "Epoch 1100/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7472 - VL_attention_linear_output_loss: 1.7874 - VH_attention_linear_output_loss: 1.9598 - VL_attention_linear_output_acc: 0.4759 - VH_attention_linear_output_acc: 0.4035 - val_loss: 3.7553 - val_VL_attention_linear_output_loss: 1.8002 - val_VH_attention_linear_output_loss: 1.9551 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4067\n",
      "Epoch 1101/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7388 - VL_attention_linear_output_loss: 1.7840 - VH_attention_linear_output_loss: 1.9548 - VL_attention_linear_output_acc: 0.4782 - VH_attention_linear_output_acc: 0.4056 - val_loss: 3.7849 - val_VL_attention_linear_output_loss: 1.8111 - val_VH_attention_linear_output_loss: 1.9738 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.3998\n",
      "Epoch 1102/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7423 - VL_attention_linear_output_loss: 1.7887 - VH_attention_linear_output_loss: 1.9536 - VL_attention_linear_output_acc: 0.4759 - VH_attention_linear_output_acc: 0.4053 - val_loss: 3.7843 - val_VL_attention_linear_output_loss: 1.8137 - val_VH_attention_linear_output_loss: 1.9706 - val_VL_attention_linear_output_acc: 0.4670 - val_VH_attention_linear_output_acc: 0.4020\n",
      "Epoch 1103/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7379 - VL_attention_linear_output_loss: 1.7784 - VH_attention_linear_output_loss: 1.9595 - VL_attention_linear_output_acc: 0.4799 - VH_attention_linear_output_acc: 0.4034 - val_loss: 3.8126 - val_VL_attention_linear_output_loss: 1.8053 - val_VH_attention_linear_output_loss: 2.0072 - val_VL_attention_linear_output_acc: 0.4758 - val_VH_attention_linear_output_acc: 0.3828\n",
      "Epoch 1104/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7519 - VL_attention_linear_output_loss: 1.7917 - VH_attention_linear_output_loss: 1.9602 - VL_attention_linear_output_acc: 0.4738 - VH_attention_linear_output_acc: 0.4035 - val_loss: 3.8204 - val_VL_attention_linear_output_loss: 1.8077 - val_VH_attention_linear_output_loss: 2.0127 - val_VL_attention_linear_output_acc: 0.4735 - val_VH_attention_linear_output_acc: 0.3808\n",
      "Epoch 1105/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7515 - VL_attention_linear_output_loss: 1.7910 - VH_attention_linear_output_loss: 1.9606 - VL_attention_linear_output_acc: 0.4746 - VH_attention_linear_output_acc: 0.4036 - val_loss: 3.7890 - val_VL_attention_linear_output_loss: 1.8215 - val_VH_attention_linear_output_loss: 1.9675 - val_VL_attention_linear_output_acc: 0.4689 - val_VH_attention_linear_output_acc: 0.3989\n",
      "Epoch 1106/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7453 - VL_attention_linear_output_loss: 1.7893 - VH_attention_linear_output_loss: 1.9560 - VL_attention_linear_output_acc: 0.4748 - VH_attention_linear_output_acc: 0.4049 - val_loss: 3.7772 - val_VL_attention_linear_output_loss: 1.8171 - val_VH_attention_linear_output_loss: 1.9601 - val_VL_attention_linear_output_acc: 0.4717 - val_VH_attention_linear_output_acc: 0.4054\n",
      "Epoch 1107/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7373 - VL_attention_linear_output_loss: 1.7798 - VH_attention_linear_output_loss: 1.9576 - VL_attention_linear_output_acc: 0.4795 - VH_attention_linear_output_acc: 0.4048 - val_loss: 3.7616 - val_VL_attention_linear_output_loss: 1.8100 - val_VH_attention_linear_output_loss: 1.9516 - val_VL_attention_linear_output_acc: 0.4708 - val_VH_attention_linear_output_acc: 0.4054\n",
      "Epoch 1108/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7295 - VL_attention_linear_output_loss: 1.7840 - VH_attention_linear_output_loss: 1.9455 - VL_attention_linear_output_acc: 0.4770 - VH_attention_linear_output_acc: 0.4090 - val_loss: 3.7884 - val_VL_attention_linear_output_loss: 1.8314 - val_VH_attention_linear_output_loss: 1.9570 - val_VL_attention_linear_output_acc: 0.4568 - val_VH_attention_linear_output_acc: 0.4068\n",
      "Epoch 1109/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7487 - VL_attention_linear_output_loss: 1.7944 - VH_attention_linear_output_loss: 1.9544 - VL_attention_linear_output_acc: 0.4724 - VH_attention_linear_output_acc: 0.4055 - val_loss: 3.7963 - val_VL_attention_linear_output_loss: 1.8317 - val_VH_attention_linear_output_loss: 1.9645 - val_VL_attention_linear_output_acc: 0.4674 - val_VH_attention_linear_output_acc: 0.4024\n",
      "Epoch 1110/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7465 - VL_attention_linear_output_loss: 1.7912 - VH_attention_linear_output_loss: 1.9552 - VL_attention_linear_output_acc: 0.4744 - VH_attention_linear_output_acc: 0.4050 - val_loss: 3.7758 - val_VL_attention_linear_output_loss: 1.8066 - val_VH_attention_linear_output_loss: 1.9692 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4016\n",
      "Epoch 1111/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7534 - VL_attention_linear_output_loss: 1.7909 - VH_attention_linear_output_loss: 1.9625 - VL_attention_linear_output_acc: 0.4737 - VH_attention_linear_output_acc: 0.4028 - val_loss: 3.7640 - val_VL_attention_linear_output_loss: 1.8078 - val_VH_attention_linear_output_loss: 1.9561 - val_VL_attention_linear_output_acc: 0.4742 - val_VH_attention_linear_output_acc: 0.4057\n",
      "Epoch 1112/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7352 - VL_attention_linear_output_loss: 1.7804 - VH_attention_linear_output_loss: 1.9548 - VL_attention_linear_output_acc: 0.4799 - VH_attention_linear_output_acc: 0.4054 - val_loss: 3.7636 - val_VL_attention_linear_output_loss: 1.8078 - val_VH_attention_linear_output_loss: 1.9558 - val_VL_attention_linear_output_acc: 0.4723 - val_VH_attention_linear_output_acc: 0.4077\n",
      "Epoch 1113/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7440 - VL_attention_linear_output_loss: 1.7920 - VH_attention_linear_output_loss: 1.9520 - VL_attention_linear_output_acc: 0.4730 - VH_attention_linear_output_acc: 0.4067 - val_loss: 3.7645 - val_VL_attention_linear_output_loss: 1.8098 - val_VH_attention_linear_output_loss: 1.9547 - val_VL_attention_linear_output_acc: 0.4704 - val_VH_attention_linear_output_acc: 0.4091\n",
      "Epoch 1114/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7302 - VL_attention_linear_output_loss: 1.7790 - VH_attention_linear_output_loss: 1.9512 - VL_attention_linear_output_acc: 0.4802 - VH_attention_linear_output_acc: 0.4072 - val_loss: 3.7832 - val_VL_attention_linear_output_loss: 1.8014 - val_VH_attention_linear_output_loss: 1.9818 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.3948\n",
      "Epoch 1115/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7553 - VL_attention_linear_output_loss: 1.8019 - VH_attention_linear_output_loss: 1.9534 - VL_attention_linear_output_acc: 0.4682 - VH_attention_linear_output_acc: 0.4059 - val_loss: 3.7550 - val_VL_attention_linear_output_loss: 1.8023 - val_VH_attention_linear_output_loss: 1.9527 - val_VL_attention_linear_output_acc: 0.4703 - val_VH_attention_linear_output_acc: 0.4075\n",
      "Epoch 1116/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7443 - VL_attention_linear_output_loss: 1.7819 - VH_attention_linear_output_loss: 1.9624 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.4019 - val_loss: 3.7854 - val_VL_attention_linear_output_loss: 1.8034 - val_VH_attention_linear_output_loss: 1.9820 - val_VL_attention_linear_output_acc: 0.4793 - val_VH_attention_linear_output_acc: 0.3933\n",
      "Epoch 1117/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7392 - VL_attention_linear_output_loss: 1.7831 - VH_attention_linear_output_loss: 1.9561 - VL_attention_linear_output_acc: 0.4770 - VH_attention_linear_output_acc: 0.4047 - val_loss: 3.7792 - val_VL_attention_linear_output_loss: 1.8145 - val_VH_attention_linear_output_loss: 1.9647 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4031\n",
      "Epoch 1118/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7474 - VL_attention_linear_output_loss: 1.7924 - VH_attention_linear_output_loss: 1.9550 - VL_attention_linear_output_acc: 0.4732 - VH_attention_linear_output_acc: 0.4046 - val_loss: 3.8048 - val_VL_attention_linear_output_loss: 1.8487 - val_VH_attention_linear_output_loss: 1.9561 - val_VL_attention_linear_output_acc: 0.4574 - val_VH_attention_linear_output_acc: 0.4044\n",
      "Epoch 1119/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7349 - VL_attention_linear_output_loss: 1.7868 - VH_attention_linear_output_loss: 1.9482 - VL_attention_linear_output_acc: 0.4763 - VH_attention_linear_output_acc: 0.4079 - val_loss: 3.7768 - val_VL_attention_linear_output_loss: 1.8103 - val_VH_attention_linear_output_loss: 1.9665 - val_VL_attention_linear_output_acc: 0.4729 - val_VH_attention_linear_output_acc: 0.4026\n",
      "Epoch 1120/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7347 - VL_attention_linear_output_loss: 1.7829 - VH_attention_linear_output_loss: 1.9518 - VL_attention_linear_output_acc: 0.4776 - VH_attention_linear_output_acc: 0.4068 - val_loss: 3.7860 - val_VL_attention_linear_output_loss: 1.8038 - val_VH_attention_linear_output_loss: 1.9822 - val_VL_attention_linear_output_acc: 0.4750 - val_VH_attention_linear_output_acc: 0.3950\n",
      "Epoch 1121/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7454 - VL_attention_linear_output_loss: 1.7900 - VH_attention_linear_output_loss: 1.9554 - VL_attention_linear_output_acc: 0.4735 - VH_attention_linear_output_acc: 0.4042 - val_loss: 3.7717 - val_VL_attention_linear_output_loss: 1.8007 - val_VH_attention_linear_output_loss: 1.9710 - val_VL_attention_linear_output_acc: 0.4781 - val_VH_attention_linear_output_acc: 0.4011\n",
      "Epoch 1122/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7463 - VL_attention_linear_output_loss: 1.7951 - VH_attention_linear_output_loss: 1.9512 - VL_attention_linear_output_acc: 0.4714 - VH_attention_linear_output_acc: 0.4059 - val_loss: 3.7632 - val_VL_attention_linear_output_loss: 1.8040 - val_VH_attention_linear_output_loss: 1.9592 - val_VL_attention_linear_output_acc: 0.4711 - val_VH_attention_linear_output_acc: 0.4035\n",
      "Epoch 1123/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7412 - VL_attention_linear_output_loss: 1.7884 - VH_attention_linear_output_loss: 1.9529 - VL_attention_linear_output_acc: 0.4766 - VH_attention_linear_output_acc: 0.4055 - val_loss: 3.7691 - val_VL_attention_linear_output_loss: 1.8188 - val_VH_attention_linear_output_loss: 1.9504 - val_VL_attention_linear_output_acc: 0.4705 - val_VH_attention_linear_output_acc: 0.4072\n",
      "Epoch 1124/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7321 - VL_attention_linear_output_loss: 1.7835 - VH_attention_linear_output_loss: 1.9486 - VL_attention_linear_output_acc: 0.4768 - VH_attention_linear_output_acc: 0.4076 - val_loss: 3.7583 - val_VL_attention_linear_output_loss: 1.8071 - val_VH_attention_linear_output_loss: 1.9512 - val_VL_attention_linear_output_acc: 0.4675 - val_VH_attention_linear_output_acc: 0.4054\n",
      "Epoch 1125/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7463 - VL_attention_linear_output_loss: 1.7917 - VH_attention_linear_output_loss: 1.9546 - VL_attention_linear_output_acc: 0.4750 - VH_attention_linear_output_acc: 0.4050 - val_loss: 3.7631 - val_VL_attention_linear_output_loss: 1.8129 - val_VH_attention_linear_output_loss: 1.9501 - val_VL_attention_linear_output_acc: 0.4654 - val_VH_attention_linear_output_acc: 0.4088\n",
      "Epoch 1126/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7389 - VL_attention_linear_output_loss: 1.7858 - VH_attention_linear_output_loss: 1.9531 - VL_attention_linear_output_acc: 0.4780 - VH_attention_linear_output_acc: 0.4062 - val_loss: 3.7890 - val_VL_attention_linear_output_loss: 1.8210 - val_VH_attention_linear_output_loss: 1.9680 - val_VL_attention_linear_output_acc: 0.4716 - val_VH_attention_linear_output_acc: 0.4006\n",
      "Epoch 1127/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7343 - VL_attention_linear_output_loss: 1.7841 - VH_attention_linear_output_loss: 1.9502 - VL_attention_linear_output_acc: 0.4773 - VH_attention_linear_output_acc: 0.4070 - val_loss: 3.7724 - val_VL_attention_linear_output_loss: 1.8097 - val_VH_attention_linear_output_loss: 1.9627 - val_VL_attention_linear_output_acc: 0.4661 - val_VH_attention_linear_output_acc: 0.4049\n",
      "Epoch 1128/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7480 - VL_attention_linear_output_loss: 1.8036 - VH_attention_linear_output_loss: 1.9445 - VL_attention_linear_output_acc: 0.4675 - VH_attention_linear_output_acc: 0.4091 - val_loss: 3.7829 - val_VL_attention_linear_output_loss: 1.8053 - val_VH_attention_linear_output_loss: 1.9776 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.3939\n",
      "Epoch 1129/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7279 - VL_attention_linear_output_loss: 1.7790 - VH_attention_linear_output_loss: 1.9489 - VL_attention_linear_output_acc: 0.4802 - VH_attention_linear_output_acc: 0.4068 - val_loss: 3.8041 - val_VL_attention_linear_output_loss: 1.8461 - val_VH_attention_linear_output_loss: 1.9580 - val_VL_attention_linear_output_acc: 0.4546 - val_VH_attention_linear_output_acc: 0.4050\n",
      "Epoch 1130/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7527 - VL_attention_linear_output_loss: 1.7891 - VH_attention_linear_output_loss: 1.9636 - VL_attention_linear_output_acc: 0.4744 - VH_attention_linear_output_acc: 0.4012 - val_loss: 3.7659 - val_VL_attention_linear_output_loss: 1.8051 - val_VH_attention_linear_output_loss: 1.9609 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4062\n",
      "Epoch 1131/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7404 - VL_attention_linear_output_loss: 1.7901 - VH_attention_linear_output_loss: 1.9503 - VL_attention_linear_output_acc: 0.4739 - VH_attention_linear_output_acc: 0.4068 - val_loss: 3.7693 - val_VL_attention_linear_output_loss: 1.8106 - val_VH_attention_linear_output_loss: 1.9587 - val_VL_attention_linear_output_acc: 0.4748 - val_VH_attention_linear_output_acc: 0.4076\n",
      "Epoch 1132/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7523 - VL_attention_linear_output_loss: 1.8034 - VH_attention_linear_output_loss: 1.9489 - VL_attention_linear_output_acc: 0.4681 - VH_attention_linear_output_acc: 0.4074 - val_loss: 3.7849 - val_VL_attention_linear_output_loss: 1.8182 - val_VH_attention_linear_output_loss: 1.9667 - val_VL_attention_linear_output_acc: 0.4714 - val_VH_attention_linear_output_acc: 0.4016\n",
      "Epoch 1133/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7291 - VL_attention_linear_output_loss: 1.7792 - VH_attention_linear_output_loss: 1.9499 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.4069 - val_loss: 3.7658 - val_VL_attention_linear_output_loss: 1.8027 - val_VH_attention_linear_output_loss: 1.9631 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.4055\n",
      "Epoch 1134/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7356 - VL_attention_linear_output_loss: 1.7869 - VH_attention_linear_output_loss: 1.9487 - VL_attention_linear_output_acc: 0.4755 - VH_attention_linear_output_acc: 0.4072 - val_loss: 3.7826 - val_VL_attention_linear_output_loss: 1.8297 - val_VH_attention_linear_output_loss: 1.9529 - val_VL_attention_linear_output_acc: 0.4652 - val_VH_attention_linear_output_acc: 0.4071\n",
      "Epoch 1135/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7281 - VL_attention_linear_output_loss: 1.7831 - VH_attention_linear_output_loss: 1.9450 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.4091 - val_loss: 3.7831 - val_VL_attention_linear_output_loss: 1.8091 - val_VH_attention_linear_output_loss: 1.9739 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.3974\n",
      "Epoch 1136/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7409 - VL_attention_linear_output_loss: 1.7876 - VH_attention_linear_output_loss: 1.9533 - VL_attention_linear_output_acc: 0.4770 - VH_attention_linear_output_acc: 0.4053 - val_loss: 3.8300 - val_VL_attention_linear_output_loss: 1.8118 - val_VH_attention_linear_output_loss: 2.0182 - val_VL_attention_linear_output_acc: 0.4718 - val_VH_attention_linear_output_acc: 0.3792\n",
      "Epoch 1137/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7380 - VL_attention_linear_output_loss: 1.7880 - VH_attention_linear_output_loss: 1.9500 - VL_attention_linear_output_acc: 0.4740 - VH_attention_linear_output_acc: 0.4069 - val_loss: 3.7817 - val_VL_attention_linear_output_loss: 1.8214 - val_VH_attention_linear_output_loss: 1.9603 - val_VL_attention_linear_output_acc: 0.4712 - val_VH_attention_linear_output_acc: 0.4047\n",
      "Epoch 1138/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7387 - VL_attention_linear_output_loss: 1.7844 - VH_attention_linear_output_loss: 1.9543 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.4045 - val_loss: 3.7976 - val_VL_attention_linear_output_loss: 1.8465 - val_VH_attention_linear_output_loss: 1.9511 - val_VL_attention_linear_output_acc: 0.4529 - val_VH_attention_linear_output_acc: 0.4058\n",
      "Epoch 1139/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7479 - VL_attention_linear_output_loss: 1.8036 - VH_attention_linear_output_loss: 1.9443 - VL_attention_linear_output_acc: 0.4686 - VH_attention_linear_output_acc: 0.4087 - val_loss: 3.7627 - val_VL_attention_linear_output_loss: 1.8097 - val_VH_attention_linear_output_loss: 1.9529 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.4050\n",
      "Epoch 1140/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7247 - VL_attention_linear_output_loss: 1.7737 - VH_attention_linear_output_loss: 1.9511 - VL_attention_linear_output_acc: 0.4814 - VH_attention_linear_output_acc: 0.4061 - val_loss: 3.7585 - val_VL_attention_linear_output_loss: 1.8044 - val_VH_attention_linear_output_loss: 1.9541 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4075\n",
      "Epoch 1141/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7363 - VL_attention_linear_output_loss: 1.7842 - VH_attention_linear_output_loss: 1.9520 - VL_attention_linear_output_acc: 0.4786 - VH_attention_linear_output_acc: 0.4056 - val_loss: 3.7671 - val_VL_attention_linear_output_loss: 1.8140 - val_VH_attention_linear_output_loss: 1.9532 - val_VL_attention_linear_output_acc: 0.4708 - val_VH_attention_linear_output_acc: 0.4071\n",
      "Epoch 1142/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7388 - VL_attention_linear_output_loss: 1.7901 - VH_attention_linear_output_loss: 1.9488 - VL_attention_linear_output_acc: 0.4745 - VH_attention_linear_output_acc: 0.4079 - val_loss: 3.7893 - val_VL_attention_linear_output_loss: 1.8273 - val_VH_attention_linear_output_loss: 1.9620 - val_VL_attention_linear_output_acc: 0.4668 - val_VH_attention_linear_output_acc: 0.4024\n",
      "Epoch 1143/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7308 - VL_attention_linear_output_loss: 1.7836 - VH_attention_linear_output_loss: 1.9472 - VL_attention_linear_output_acc: 0.4769 - VH_attention_linear_output_acc: 0.4074 - val_loss: 3.7627 - val_VL_attention_linear_output_loss: 1.8067 - val_VH_attention_linear_output_loss: 1.9560 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.4075\n",
      "Epoch 1144/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7419 - VL_attention_linear_output_loss: 1.7874 - VH_attention_linear_output_loss: 1.9546 - VL_attention_linear_output_acc: 0.4757 - VH_attention_linear_output_acc: 0.4065 - val_loss: 3.7764 - val_VL_attention_linear_output_loss: 1.8142 - val_VH_attention_linear_output_loss: 1.9621 - val_VL_attention_linear_output_acc: 0.4726 - val_VH_attention_linear_output_acc: 0.4030\n",
      "Epoch 1145/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7573 - VL_attention_linear_output_loss: 1.7994 - VH_attention_linear_output_loss: 1.9579 - VL_attention_linear_output_acc: 0.4699 - VH_attention_linear_output_acc: 0.4048 - val_loss: 3.7818 - val_VL_attention_linear_output_loss: 1.8163 - val_VH_attention_linear_output_loss: 1.9655 - val_VL_attention_linear_output_acc: 0.4670 - val_VH_attention_linear_output_acc: 0.4023\n",
      "Epoch 1146/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7443 - VL_attention_linear_output_loss: 1.7889 - VH_attention_linear_output_loss: 1.9554 - VL_attention_linear_output_acc: 0.4737 - VH_attention_linear_output_acc: 0.4048 - val_loss: 3.7555 - val_VL_attention_linear_output_loss: 1.8073 - val_VH_attention_linear_output_loss: 1.9482 - val_VL_attention_linear_output_acc: 0.4739 - val_VH_attention_linear_output_acc: 0.4095\n",
      "Epoch 1147/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7302 - VL_attention_linear_output_loss: 1.7792 - VH_attention_linear_output_loss: 1.9509 - VL_attention_linear_output_acc: 0.4793 - VH_attention_linear_output_acc: 0.4061 - val_loss: 3.7726 - val_VL_attention_linear_output_loss: 1.8099 - val_VH_attention_linear_output_loss: 1.9627 - val_VL_attention_linear_output_acc: 0.4715 - val_VH_attention_linear_output_acc: 0.4032\n",
      "Epoch 1148/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7475 - VL_attention_linear_output_loss: 1.8004 - VH_attention_linear_output_loss: 1.9471 - VL_attention_linear_output_acc: 0.4692 - VH_attention_linear_output_acc: 0.4078 - val_loss: 3.7511 - val_VL_attention_linear_output_loss: 1.8066 - val_VH_attention_linear_output_loss: 1.9445 - val_VL_attention_linear_output_acc: 0.4729 - val_VH_attention_linear_output_acc: 0.4087\n",
      "Epoch 1149/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7256 - VL_attention_linear_output_loss: 1.7809 - VH_attention_linear_output_loss: 1.9447 - VL_attention_linear_output_acc: 0.4780 - VH_attention_linear_output_acc: 0.4082 - val_loss: 3.7833 - val_VL_attention_linear_output_loss: 1.8062 - val_VH_attention_linear_output_loss: 1.9770 - val_VL_attention_linear_output_acc: 0.4748 - val_VH_attention_linear_output_acc: 0.3975\n",
      "Epoch 1150/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7330 - VL_attention_linear_output_loss: 1.7829 - VH_attention_linear_output_loss: 1.9501 - VL_attention_linear_output_acc: 0.4771 - VH_attention_linear_output_acc: 0.4066 - val_loss: 3.7707 - val_VL_attention_linear_output_loss: 1.8058 - val_VH_attention_linear_output_loss: 1.9650 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4011\n",
      "Epoch 1151/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7359 - VL_attention_linear_output_loss: 1.7840 - VH_attention_linear_output_loss: 1.9519 - VL_attention_linear_output_acc: 0.4780 - VH_attention_linear_output_acc: 0.4067 - val_loss: 3.8098 - val_VL_attention_linear_output_loss: 1.8601 - val_VH_attention_linear_output_loss: 1.9497 - val_VL_attention_linear_output_acc: 0.4483 - val_VH_attention_linear_output_acc: 0.4095\n",
      "Epoch 1152/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7389 - VL_attention_linear_output_loss: 1.7918 - VH_attention_linear_output_loss: 1.9471 - VL_attention_linear_output_acc: 0.4723 - VH_attention_linear_output_acc: 0.4075 - val_loss: 3.7543 - val_VL_attention_linear_output_loss: 1.8047 - val_VH_attention_linear_output_loss: 1.9496 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4122\n",
      "Epoch 1153/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7431 - VL_attention_linear_output_loss: 1.7932 - VH_attention_linear_output_loss: 1.9499 - VL_attention_linear_output_acc: 0.4735 - VH_attention_linear_output_acc: 0.4062 - val_loss: 3.7561 - val_VL_attention_linear_output_loss: 1.8099 - val_VH_attention_linear_output_loss: 1.9462 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4105\n",
      "Epoch 1154/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7410 - VL_attention_linear_output_loss: 1.7974 - VH_attention_linear_output_loss: 1.9436 - VL_attention_linear_output_acc: 0.4718 - VH_attention_linear_output_acc: 0.4094 - val_loss: 3.7694 - val_VL_attention_linear_output_loss: 1.8203 - val_VH_attention_linear_output_loss: 1.9491 - val_VL_attention_linear_output_acc: 0.4694 - val_VH_attention_linear_output_acc: 0.4096\n",
      "Epoch 1155/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7159 - VL_attention_linear_output_loss: 1.7781 - VH_attention_linear_output_loss: 1.9378 - VL_attention_linear_output_acc: 0.4792 - VH_attention_linear_output_acc: 0.4107 - val_loss: 3.7553 - val_VL_attention_linear_output_loss: 1.8085 - val_VH_attention_linear_output_loss: 1.9468 - val_VL_attention_linear_output_acc: 0.4767 - val_VH_attention_linear_output_acc: 0.4103\n",
      "Epoch 1156/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7335 - VL_attention_linear_output_loss: 1.7887 - VH_attention_linear_output_loss: 1.9447 - VL_attention_linear_output_acc: 0.4746 - VH_attention_linear_output_acc: 0.4081 - val_loss: 3.7514 - val_VL_attention_linear_output_loss: 1.8076 - val_VH_attention_linear_output_loss: 1.9438 - val_VL_attention_linear_output_acc: 0.4681 - val_VH_attention_linear_output_acc: 0.4112\n",
      "Epoch 1157/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7227 - VL_attention_linear_output_loss: 1.7823 - VH_attention_linear_output_loss: 1.9404 - VL_attention_linear_output_acc: 0.4774 - VH_attention_linear_output_acc: 0.4101 - val_loss: 3.7689 - val_VL_attention_linear_output_loss: 1.8056 - val_VH_attention_linear_output_loss: 1.9633 - val_VL_attention_linear_output_acc: 0.4784 - val_VH_attention_linear_output_acc: 0.4034\n",
      "Epoch 1158/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7494 - VL_attention_linear_output_loss: 1.8018 - VH_attention_linear_output_loss: 1.9476 - VL_attention_linear_output_acc: 0.4691 - VH_attention_linear_output_acc: 0.4069 - val_loss: 3.7717 - val_VL_attention_linear_output_loss: 1.8037 - val_VH_attention_linear_output_loss: 1.9680 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.4005\n",
      "Epoch 1159/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7331 - VL_attention_linear_output_loss: 1.7823 - VH_attention_linear_output_loss: 1.9508 - VL_attention_linear_output_acc: 0.4762 - VH_attention_linear_output_acc: 0.4049 - val_loss: 3.7760 - val_VL_attention_linear_output_loss: 1.8015 - val_VH_attention_linear_output_loss: 1.9746 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.3938\n",
      "Epoch 1160/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7222 - VL_attention_linear_output_loss: 1.7812 - VH_attention_linear_output_loss: 1.9410 - VL_attention_linear_output_acc: 0.4793 - VH_attention_linear_output_acc: 0.4097 - val_loss: 3.7505 - val_VL_attention_linear_output_loss: 1.8020 - val_VH_attention_linear_output_loss: 1.9484 - val_VL_attention_linear_output_acc: 0.4754 - val_VH_attention_linear_output_acc: 0.4116\n",
      "Epoch 1161/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7435 - VL_attention_linear_output_loss: 1.8015 - VH_attention_linear_output_loss: 1.9421 - VL_attention_linear_output_acc: 0.4686 - VH_attention_linear_output_acc: 0.4094 - val_loss: 3.7519 - val_VL_attention_linear_output_loss: 1.8032 - val_VH_attention_linear_output_loss: 1.9487 - val_VL_attention_linear_output_acc: 0.4718 - val_VH_attention_linear_output_acc: 0.4080\n",
      "Epoch 1162/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7214 - VL_attention_linear_output_loss: 1.7781 - VH_attention_linear_output_loss: 1.9434 - VL_attention_linear_output_acc: 0.4793 - VH_attention_linear_output_acc: 0.4090 - val_loss: 3.7485 - val_VL_attention_linear_output_loss: 1.7996 - val_VH_attention_linear_output_loss: 1.9490 - val_VL_attention_linear_output_acc: 0.4775 - val_VH_attention_linear_output_acc: 0.4065\n",
      "Epoch 1163/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7187 - VL_attention_linear_output_loss: 1.7774 - VH_attention_linear_output_loss: 1.9413 - VL_attention_linear_output_acc: 0.4791 - VH_attention_linear_output_acc: 0.4098 - val_loss: 3.7874 - val_VL_attention_linear_output_loss: 1.8360 - val_VH_attention_linear_output_loss: 1.9514 - val_VL_attention_linear_output_acc: 0.4621 - val_VH_attention_linear_output_acc: 0.4116\n",
      "Epoch 1164/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7309 - VL_attention_linear_output_loss: 1.7817 - VH_attention_linear_output_loss: 1.9492 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.4057 - val_loss: 3.8565 - val_VL_attention_linear_output_loss: 1.8340 - val_VH_attention_linear_output_loss: 2.0225 - val_VL_attention_linear_output_acc: 0.4651 - val_VH_attention_linear_output_acc: 0.3785\n",
      "Epoch 1165/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7346 - VL_attention_linear_output_loss: 1.7891 - VH_attention_linear_output_loss: 1.9455 - VL_attention_linear_output_acc: 0.4747 - VH_attention_linear_output_acc: 0.4082 - val_loss: 3.8463 - val_VL_attention_linear_output_loss: 1.8692 - val_VH_attention_linear_output_loss: 1.9771 - val_VL_attention_linear_output_acc: 0.4410 - val_VH_attention_linear_output_acc: 0.3977\n",
      "Epoch 1166/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7226 - VL_attention_linear_output_loss: 1.7821 - VH_attention_linear_output_loss: 1.9406 - VL_attention_linear_output_acc: 0.4776 - VH_attention_linear_output_acc: 0.4098 - val_loss: 3.7554 - val_VL_attention_linear_output_loss: 1.8160 - val_VH_attention_linear_output_loss: 1.9395 - val_VL_attention_linear_output_acc: 0.4699 - val_VH_attention_linear_output_acc: 0.4116\n",
      "Epoch 1167/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7226 - VL_attention_linear_output_loss: 1.7806 - VH_attention_linear_output_loss: 1.9420 - VL_attention_linear_output_acc: 0.4792 - VH_attention_linear_output_acc: 0.4093 - val_loss: 3.7458 - val_VL_attention_linear_output_loss: 1.8012 - val_VH_attention_linear_output_loss: 1.9445 - val_VL_attention_linear_output_acc: 0.4788 - val_VH_attention_linear_output_acc: 0.4113\n",
      "Epoch 1168/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7234 - VL_attention_linear_output_loss: 1.7835 - VH_attention_linear_output_loss: 1.9399 - VL_attention_linear_output_acc: 0.4774 - VH_attention_linear_output_acc: 0.4101 - val_loss: 3.7636 - val_VL_attention_linear_output_loss: 1.8153 - val_VH_attention_linear_output_loss: 1.9483 - val_VL_attention_linear_output_acc: 0.4744 - val_VH_attention_linear_output_acc: 0.4092\n",
      "Epoch 1169/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7559 - VL_attention_linear_output_loss: 1.8006 - VH_attention_linear_output_loss: 1.9553 - VL_attention_linear_output_acc: 0.4693 - VH_attention_linear_output_acc: 0.4037 - val_loss: 3.7419 - val_VL_attention_linear_output_loss: 1.8000 - val_VH_attention_linear_output_loss: 1.9419 - val_VL_attention_linear_output_acc: 0.4740 - val_VH_attention_linear_output_acc: 0.4119\n",
      "Epoch 1170/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7170 - VL_attention_linear_output_loss: 1.7787 - VH_attention_linear_output_loss: 1.9384 - VL_attention_linear_output_acc: 0.4795 - VH_attention_linear_output_acc: 0.4099 - val_loss: 3.7635 - val_VL_attention_linear_output_loss: 1.8109 - val_VH_attention_linear_output_loss: 1.9526 - val_VL_attention_linear_output_acc: 0.4700 - val_VH_attention_linear_output_acc: 0.4062\n",
      "Epoch 1171/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7260 - VL_attention_linear_output_loss: 1.7813 - VH_attention_linear_output_loss: 1.9447 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.4074 - val_loss: 3.7884 - val_VL_attention_linear_output_loss: 1.8174 - val_VH_attention_linear_output_loss: 1.9710 - val_VL_attention_linear_output_acc: 0.4662 - val_VH_attention_linear_output_acc: 0.4003\n",
      "Epoch 1172/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7595 - VL_attention_linear_output_loss: 1.8067 - VH_attention_linear_output_loss: 1.9528 - VL_attention_linear_output_acc: 0.4663 - VH_attention_linear_output_acc: 0.4046 - val_loss: 3.7677 - val_VL_attention_linear_output_loss: 1.8009 - val_VH_attention_linear_output_loss: 1.9668 - val_VL_attention_linear_output_acc: 0.4746 - val_VH_attention_linear_output_acc: 0.4005\n",
      "Epoch 1173/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7091 - VL_attention_linear_output_loss: 1.7741 - VH_attention_linear_output_loss: 1.9350 - VL_attention_linear_output_acc: 0.4807 - VH_attention_linear_output_acc: 0.4113 - val_loss: 3.7523 - val_VL_attention_linear_output_loss: 1.8100 - val_VH_attention_linear_output_loss: 1.9422 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4104\n",
      "Epoch 1174/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7141 - VL_attention_linear_output_loss: 1.7802 - VH_attention_linear_output_loss: 1.9339 - VL_attention_linear_output_acc: 0.4789 - VH_attention_linear_output_acc: 0.4113 - val_loss: 3.7542 - val_VL_attention_linear_output_loss: 1.8075 - val_VH_attention_linear_output_loss: 1.9467 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.4065\n",
      "Epoch 1175/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7302 - VL_attention_linear_output_loss: 1.7899 - VH_attention_linear_output_loss: 1.9403 - VL_attention_linear_output_acc: 0.4727 - VH_attention_linear_output_acc: 0.4083 - val_loss: 3.7617 - val_VL_attention_linear_output_loss: 1.8228 - val_VH_attention_linear_output_loss: 1.9389 - val_VL_attention_linear_output_acc: 0.4657 - val_VH_attention_linear_output_acc: 0.4141\n",
      "Epoch 1176/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7252 - VL_attention_linear_output_loss: 1.7883 - VH_attention_linear_output_loss: 1.9370 - VL_attention_linear_output_acc: 0.4745 - VH_attention_linear_output_acc: 0.4101 - val_loss: 3.7538 - val_VL_attention_linear_output_loss: 1.8084 - val_VH_attention_linear_output_loss: 1.9454 - val_VL_attention_linear_output_acc: 0.4744 - val_VH_attention_linear_output_acc: 0.4067\n",
      "Epoch 1177/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7119 - VL_attention_linear_output_loss: 1.7750 - VH_attention_linear_output_loss: 1.9369 - VL_attention_linear_output_acc: 0.4807 - VH_attention_linear_output_acc: 0.4096 - val_loss: 3.8288 - val_VL_attention_linear_output_loss: 1.8043 - val_VH_attention_linear_output_loss: 2.0245 - val_VL_attention_linear_output_acc: 0.4768 - val_VH_attention_linear_output_acc: 0.3737\n",
      "Epoch 1178/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7254 - VL_attention_linear_output_loss: 1.7837 - VH_attention_linear_output_loss: 1.9416 - VL_attention_linear_output_acc: 0.4765 - VH_attention_linear_output_acc: 0.4087 - val_loss: 3.7498 - val_VL_attention_linear_output_loss: 1.8103 - val_VH_attention_linear_output_loss: 1.9394 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.4117\n",
      "Epoch 1179/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7342 - VL_attention_linear_output_loss: 1.7990 - VH_attention_linear_output_loss: 1.9352 - VL_attention_linear_output_acc: 0.4690 - VH_attention_linear_output_acc: 0.4108 - val_loss: 3.8416 - val_VL_attention_linear_output_loss: 1.8452 - val_VH_attention_linear_output_loss: 1.9964 - val_VL_attention_linear_output_acc: 0.4547 - val_VH_attention_linear_output_acc: 0.3848\n",
      "Epoch 1180/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7241 - VL_attention_linear_output_loss: 1.7816 - VH_attention_linear_output_loss: 1.9426 - VL_attention_linear_output_acc: 0.4778 - VH_attention_linear_output_acc: 0.4072 - val_loss: 3.7774 - val_VL_attention_linear_output_loss: 1.8193 - val_VH_attention_linear_output_loss: 1.9581 - val_VL_attention_linear_output_acc: 0.4664 - val_VH_attention_linear_output_acc: 0.4059\n",
      "Epoch 1181/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7325 - VL_attention_linear_output_loss: 1.7908 - VH_attention_linear_output_loss: 1.9417 - VL_attention_linear_output_acc: 0.4736 - VH_attention_linear_output_acc: 0.4083 - val_loss: 3.7722 - val_VL_attention_linear_output_loss: 1.8144 - val_VH_attention_linear_output_loss: 1.9578 - val_VL_attention_linear_output_acc: 0.4705 - val_VH_attention_linear_output_acc: 0.4030\n",
      "Epoch 1182/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7225 - VL_attention_linear_output_loss: 1.7823 - VH_attention_linear_output_loss: 1.9402 - VL_attention_linear_output_acc: 0.4768 - VH_attention_linear_output_acc: 0.4079 - val_loss: 3.7713 - val_VL_attention_linear_output_loss: 1.8001 - val_VH_attention_linear_output_loss: 1.9712 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.4016\n",
      "Epoch 1183/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7200 - VL_attention_linear_output_loss: 1.7808 - VH_attention_linear_output_loss: 1.9392 - VL_attention_linear_output_acc: 0.4790 - VH_attention_linear_output_acc: 0.4082 - val_loss: 3.7453 - val_VL_attention_linear_output_loss: 1.8077 - val_VH_attention_linear_output_loss: 1.9376 - val_VL_attention_linear_output_acc: 0.4730 - val_VH_attention_linear_output_acc: 0.4106\n",
      "Epoch 1184/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7202 - VL_attention_linear_output_loss: 1.7840 - VH_attention_linear_output_loss: 1.9362 - VL_attention_linear_output_acc: 0.4776 - VH_attention_linear_output_acc: 0.4098 - val_loss: 3.7516 - val_VL_attention_linear_output_loss: 1.8088 - val_VH_attention_linear_output_loss: 1.9427 - val_VL_attention_linear_output_acc: 0.4746 - val_VH_attention_linear_output_acc: 0.4101\n",
      "Epoch 1185/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7173 - VL_attention_linear_output_loss: 1.7794 - VH_attention_linear_output_loss: 1.9379 - VL_attention_linear_output_acc: 0.4786 - VH_attention_linear_output_acc: 0.4089 - val_loss: 3.7629 - val_VL_attention_linear_output_loss: 1.8085 - val_VH_attention_linear_output_loss: 1.9545 - val_VL_attention_linear_output_acc: 0.4675 - val_VH_attention_linear_output_acc: 0.4066\n",
      "Epoch 1186/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7199 - VL_attention_linear_output_loss: 1.7861 - VH_attention_linear_output_loss: 1.9338 - VL_attention_linear_output_acc: 0.4751 - VH_attention_linear_output_acc: 0.4106 - val_loss: 3.7636 - val_VL_attention_linear_output_loss: 1.8140 - val_VH_attention_linear_output_loss: 1.9496 - val_VL_attention_linear_output_acc: 0.4707 - val_VH_attention_linear_output_acc: 0.4089\n",
      "Epoch 1187/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7155 - VL_attention_linear_output_loss: 1.7816 - VH_attention_linear_output_loss: 1.9339 - VL_attention_linear_output_acc: 0.4779 - VH_attention_linear_output_acc: 0.4103 - val_loss: 3.7782 - val_VL_attention_linear_output_loss: 1.8075 - val_VH_attention_linear_output_loss: 1.9707 - val_VL_attention_linear_output_acc: 0.4717 - val_VH_attention_linear_output_acc: 0.3957\n",
      "Epoch 1188/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7188 - VL_attention_linear_output_loss: 1.7836 - VH_attention_linear_output_loss: 1.9352 - VL_attention_linear_output_acc: 0.4762 - VH_attention_linear_output_acc: 0.4096 - val_loss: 3.8290 - val_VL_attention_linear_output_loss: 1.8854 - val_VH_attention_linear_output_loss: 1.9437 - val_VL_attention_linear_output_acc: 0.4346 - val_VH_attention_linear_output_acc: 0.4071\n",
      "Epoch 1189/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7314 - VL_attention_linear_output_loss: 1.7909 - VH_attention_linear_output_loss: 1.9405 - VL_attention_linear_output_acc: 0.4731 - VH_attention_linear_output_acc: 0.4077 - val_loss: 3.7943 - val_VL_attention_linear_output_loss: 1.8144 - val_VH_attention_linear_output_loss: 1.9799 - val_VL_attention_linear_output_acc: 0.4668 - val_VH_attention_linear_output_acc: 0.3909\n",
      "Epoch 1190/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7209 - VL_attention_linear_output_loss: 1.7866 - VH_attention_linear_output_loss: 1.9343 - VL_attention_linear_output_acc: 0.4755 - VH_attention_linear_output_acc: 0.4101 - val_loss: 3.7941 - val_VL_attention_linear_output_loss: 1.8517 - val_VH_attention_linear_output_loss: 1.9425 - val_VL_attention_linear_output_acc: 0.4599 - val_VH_attention_linear_output_acc: 0.4089\n",
      "Epoch 1191/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7347 - VL_attention_linear_output_loss: 1.7922 - VH_attention_linear_output_loss: 1.9426 - VL_attention_linear_output_acc: 0.4733 - VH_attention_linear_output_acc: 0.4068 - val_loss: 3.7751 - val_VL_attention_linear_output_loss: 1.8053 - val_VH_attention_linear_output_loss: 1.9698 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.3970\n",
      "Epoch 1192/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7124 - VL_attention_linear_output_loss: 1.7785 - VH_attention_linear_output_loss: 1.9339 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4102 - val_loss: 3.7663 - val_VL_attention_linear_output_loss: 1.7987 - val_VH_attention_linear_output_loss: 1.9676 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.3979\n",
      "Epoch 1193/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7215 - VL_attention_linear_output_loss: 1.7768 - VH_attention_linear_output_loss: 1.9447 - VL_attention_linear_output_acc: 0.4799 - VH_attention_linear_output_acc: 0.4057 - val_loss: 3.7619 - val_VL_attention_linear_output_loss: 1.7964 - val_VH_attention_linear_output_loss: 1.9655 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4037\n",
      "Epoch 1194/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7193 - VL_attention_linear_output_loss: 1.7890 - VH_attention_linear_output_loss: 1.9303 - VL_attention_linear_output_acc: 0.4736 - VH_attention_linear_output_acc: 0.4122 - val_loss: 3.7444 - val_VL_attention_linear_output_loss: 1.8064 - val_VH_attention_linear_output_loss: 1.9380 - val_VL_attention_linear_output_acc: 0.4757 - val_VH_attention_linear_output_acc: 0.4133\n",
      "Epoch 1195/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7115 - VL_attention_linear_output_loss: 1.7787 - VH_attention_linear_output_loss: 1.9328 - VL_attention_linear_output_acc: 0.4783 - VH_attention_linear_output_acc: 0.4101 - val_loss: 3.7571 - val_VL_attention_linear_output_loss: 1.8009 - val_VH_attention_linear_output_loss: 1.9562 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4048\n",
      "Epoch 1196/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7164 - VL_attention_linear_output_loss: 1.7741 - VH_attention_linear_output_loss: 1.9423 - VL_attention_linear_output_acc: 0.4811 - VH_attention_linear_output_acc: 0.4068 - val_loss: 3.7385 - val_VL_attention_linear_output_loss: 1.8045 - val_VH_attention_linear_output_loss: 1.9340 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.4139\n",
      "Epoch 1197/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7249 - VL_attention_linear_output_loss: 1.7922 - VH_attention_linear_output_loss: 1.9327 - VL_attention_linear_output_acc: 0.4730 - VH_attention_linear_output_acc: 0.4106 - val_loss: 3.7798 - val_VL_attention_linear_output_loss: 1.8277 - val_VH_attention_linear_output_loss: 1.9521 - val_VL_attention_linear_output_acc: 0.4641 - val_VH_attention_linear_output_acc: 0.4067\n",
      "Epoch 1198/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7251 - VL_attention_linear_output_loss: 1.7786 - VH_attention_linear_output_loss: 1.9465 - VL_attention_linear_output_acc: 0.4789 - VH_attention_linear_output_acc: 0.4044 - val_loss: 3.7408 - val_VL_attention_linear_output_loss: 1.7988 - val_VH_attention_linear_output_loss: 1.9420 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4105\n",
      "Epoch 1199/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7280 - VL_attention_linear_output_loss: 1.7954 - VH_attention_linear_output_loss: 1.9326 - VL_attention_linear_output_acc: 0.4701 - VH_attention_linear_output_acc: 0.4105 - val_loss: 3.8548 - val_VL_attention_linear_output_loss: 1.9030 - val_VH_attention_linear_output_loss: 1.9518 - val_VL_attention_linear_output_acc: 0.4243 - val_VH_attention_linear_output_acc: 0.4060\n",
      "Epoch 1200/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7080 - VL_attention_linear_output_loss: 1.7796 - VH_attention_linear_output_loss: 1.9284 - VL_attention_linear_output_acc: 0.4778 - VH_attention_linear_output_acc: 0.4125 - val_loss: 3.7403 - val_VL_attention_linear_output_loss: 1.7964 - val_VH_attention_linear_output_loss: 1.9439 - val_VL_attention_linear_output_acc: 0.4721 - val_VH_attention_linear_output_acc: 0.4106\n",
      "Epoch 1201/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7166 - VL_attention_linear_output_loss: 1.7772 - VH_attention_linear_output_loss: 1.9394 - VL_attention_linear_output_acc: 0.4802 - VH_attention_linear_output_acc: 0.4081 - val_loss: 3.8120 - val_VL_attention_linear_output_loss: 1.8183 - val_VH_attention_linear_output_loss: 1.9937 - val_VL_attention_linear_output_acc: 0.4662 - val_VH_attention_linear_output_acc: 0.3810\n",
      "Epoch 1202/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7200 - VL_attention_linear_output_loss: 1.7794 - VH_attention_linear_output_loss: 1.9406 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4068 - val_loss: 3.7499 - val_VL_attention_linear_output_loss: 1.8034 - val_VH_attention_linear_output_loss: 1.9465 - val_VL_attention_linear_output_acc: 0.4752 - val_VH_attention_linear_output_acc: 0.4089\n",
      "Epoch 1203/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7139 - VL_attention_linear_output_loss: 1.7782 - VH_attention_linear_output_loss: 1.9357 - VL_attention_linear_output_acc: 0.4802 - VH_attention_linear_output_acc: 0.4092 - val_loss: 3.7417 - val_VL_attention_linear_output_loss: 1.8011 - val_VH_attention_linear_output_loss: 1.9405 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4097\n",
      "Epoch 1204/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7116 - VL_attention_linear_output_loss: 1.7798 - VH_attention_linear_output_loss: 1.9318 - VL_attention_linear_output_acc: 0.4788 - VH_attention_linear_output_acc: 0.4113 - val_loss: 3.7615 - val_VL_attention_linear_output_loss: 1.8252 - val_VH_attention_linear_output_loss: 1.9363 - val_VL_attention_linear_output_acc: 0.4715 - val_VH_attention_linear_output_acc: 0.4108\n",
      "Epoch 1205/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7145 - VL_attention_linear_output_loss: 1.7826 - VH_attention_linear_output_loss: 1.9319 - VL_attention_linear_output_acc: 0.4769 - VH_attention_linear_output_acc: 0.4110 - val_loss: 3.7470 - val_VL_attention_linear_output_loss: 1.8166 - val_VH_attention_linear_output_loss: 1.9304 - val_VL_attention_linear_output_acc: 0.4684 - val_VH_attention_linear_output_acc: 0.4150\n",
      "Epoch 1206/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7307 - VL_attention_linear_output_loss: 1.7891 - VH_attention_linear_output_loss: 1.9416 - VL_attention_linear_output_acc: 0.4732 - VH_attention_linear_output_acc: 0.4079 - val_loss: 3.7421 - val_VL_attention_linear_output_loss: 1.8078 - val_VH_attention_linear_output_loss: 1.9343 - val_VL_attention_linear_output_acc: 0.4740 - val_VH_attention_linear_output_acc: 0.4116\n",
      "Epoch 1207/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7211 - VL_attention_linear_output_loss: 1.7885 - VH_attention_linear_output_loss: 1.9326 - VL_attention_linear_output_acc: 0.4743 - VH_attention_linear_output_acc: 0.4097 - val_loss: 3.7440 - val_VL_attention_linear_output_loss: 1.8053 - val_VH_attention_linear_output_loss: 1.9387 - val_VL_attention_linear_output_acc: 0.4718 - val_VH_attention_linear_output_acc: 0.4115\n",
      "Epoch 1208/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7109 - VL_attention_linear_output_loss: 1.7820 - VH_attention_linear_output_loss: 1.9288 - VL_attention_linear_output_acc: 0.4767 - VH_attention_linear_output_acc: 0.4121 - val_loss: 3.7623 - val_VL_attention_linear_output_loss: 1.8003 - val_VH_attention_linear_output_loss: 1.9620 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.3950\n",
      "Epoch 1209/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7228 - VL_attention_linear_output_loss: 1.7957 - VH_attention_linear_output_loss: 1.9271 - VL_attention_linear_output_acc: 0.4708 - VH_attention_linear_output_acc: 0.4122 - val_loss: 3.7517 - val_VL_attention_linear_output_loss: 1.8106 - val_VH_attention_linear_output_loss: 1.9411 - val_VL_attention_linear_output_acc: 0.4767 - val_VH_attention_linear_output_acc: 0.4052\n",
      "Epoch 1210/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7050 - VL_attention_linear_output_loss: 1.7759 - VH_attention_linear_output_loss: 1.9291 - VL_attention_linear_output_acc: 0.4795 - VH_attention_linear_output_acc: 0.4107 - val_loss: 3.7414 - val_VL_attention_linear_output_loss: 1.8087 - val_VH_attention_linear_output_loss: 1.9327 - val_VL_attention_linear_output_acc: 0.4703 - val_VH_attention_linear_output_acc: 0.4128\n",
      "Epoch 1211/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7059 - VL_attention_linear_output_loss: 1.7799 - VH_attention_linear_output_loss: 1.9259 - VL_attention_linear_output_acc: 0.4782 - VH_attention_linear_output_acc: 0.4134 - val_loss: 3.7848 - val_VL_attention_linear_output_loss: 1.8444 - val_VH_attention_linear_output_loss: 1.9404 - val_VL_attention_linear_output_acc: 0.4620 - val_VH_attention_linear_output_acc: 0.4068\n",
      "Epoch 1212/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7274 - VL_attention_linear_output_loss: 1.7913 - VH_attention_linear_output_loss: 1.9361 - VL_attention_linear_output_acc: 0.4728 - VH_attention_linear_output_acc: 0.4083 - val_loss: 3.7436 - val_VL_attention_linear_output_loss: 1.8068 - val_VH_attention_linear_output_loss: 1.9368 - val_VL_attention_linear_output_acc: 0.4701 - val_VH_attention_linear_output_acc: 0.4104\n",
      "Epoch 1213/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7125 - VL_attention_linear_output_loss: 1.7808 - VH_attention_linear_output_loss: 1.9318 - VL_attention_linear_output_acc: 0.4762 - VH_attention_linear_output_acc: 0.4105 - val_loss: 3.7585 - val_VL_attention_linear_output_loss: 1.8078 - val_VH_attention_linear_output_loss: 1.9507 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4032\n",
      "Epoch 1214/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7212 - VL_attention_linear_output_loss: 1.7868 - VH_attention_linear_output_loss: 1.9344 - VL_attention_linear_output_acc: 0.4755 - VH_attention_linear_output_acc: 0.4093 - val_loss: 3.7972 - val_VL_attention_linear_output_loss: 1.8456 - val_VH_attention_linear_output_loss: 1.9516 - val_VL_attention_linear_output_acc: 0.4559 - val_VH_attention_linear_output_acc: 0.4060\n",
      "Epoch 1215/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7249 - VL_attention_linear_output_loss: 1.7909 - VH_attention_linear_output_loss: 1.9340 - VL_attention_linear_output_acc: 0.4732 - VH_attention_linear_output_acc: 0.4097 - val_loss: 3.7454 - val_VL_attention_linear_output_loss: 1.8061 - val_VH_attention_linear_output_loss: 1.9394 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4113\n",
      "Epoch 1216/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7136 - VL_attention_linear_output_loss: 1.7751 - VH_attention_linear_output_loss: 1.9385 - VL_attention_linear_output_acc: 0.4800 - VH_attention_linear_output_acc: 0.4078 - val_loss: 3.7493 - val_VL_attention_linear_output_loss: 1.7972 - val_VH_attention_linear_output_loss: 1.9521 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4036\n",
      "Epoch 1217/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7209 - VL_attention_linear_output_loss: 1.7817 - VH_attention_linear_output_loss: 1.9392 - VL_attention_linear_output_acc: 0.4773 - VH_attention_linear_output_acc: 0.4074 - val_loss: 3.7514 - val_VL_attention_linear_output_loss: 1.8054 - val_VH_attention_linear_output_loss: 1.9460 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.4066\n",
      "Epoch 1218/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7194 - VL_attention_linear_output_loss: 1.7929 - VH_attention_linear_output_loss: 1.9265 - VL_attention_linear_output_acc: 0.4728 - VH_attention_linear_output_acc: 0.4124 - val_loss: 3.7974 - val_VL_attention_linear_output_loss: 1.8038 - val_VH_attention_linear_output_loss: 1.9936 - val_VL_attention_linear_output_acc: 0.4757 - val_VH_attention_linear_output_acc: 0.3832\n",
      "Epoch 1219/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7217 - VL_attention_linear_output_loss: 1.7924 - VH_attention_linear_output_loss: 1.9293 - VL_attention_linear_output_acc: 0.4732 - VH_attention_linear_output_acc: 0.4116 - val_loss: 3.7463 - val_VL_attention_linear_output_loss: 1.8075 - val_VH_attention_linear_output_loss: 1.9388 - val_VL_attention_linear_output_acc: 0.4736 - val_VH_attention_linear_output_acc: 0.4104\n",
      "Epoch 1220/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7130 - VL_attention_linear_output_loss: 1.7821 - VH_attention_linear_output_loss: 1.9308 - VL_attention_linear_output_acc: 0.4776 - VH_attention_linear_output_acc: 0.4106 - val_loss: 3.7413 - val_VL_attention_linear_output_loss: 1.8006 - val_VH_attention_linear_output_loss: 1.9406 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4092\n",
      "Epoch 1221/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7080 - VL_attention_linear_output_loss: 1.7803 - VH_attention_linear_output_loss: 1.9278 - VL_attention_linear_output_acc: 0.4780 - VH_attention_linear_output_acc: 0.4120 - val_loss: 3.7438 - val_VL_attention_linear_output_loss: 1.8073 - val_VH_attention_linear_output_loss: 1.9365 - val_VL_attention_linear_output_acc: 0.4739 - val_VH_attention_linear_output_acc: 0.4112\n",
      "Epoch 1222/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7062 - VL_attention_linear_output_loss: 1.7792 - VH_attention_linear_output_loss: 1.9270 - VL_attention_linear_output_acc: 0.4779 - VH_attention_linear_output_acc: 0.4117 - val_loss: 3.7452 - val_VL_attention_linear_output_loss: 1.8134 - val_VH_attention_linear_output_loss: 1.9319 - val_VL_attention_linear_output_acc: 0.4695 - val_VH_attention_linear_output_acc: 0.4115\n",
      "Epoch 1223/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7071 - VL_attention_linear_output_loss: 1.7784 - VH_attention_linear_output_loss: 1.9287 - VL_attention_linear_output_acc: 0.4790 - VH_attention_linear_output_acc: 0.4107 - val_loss: 3.7343 - val_VL_attention_linear_output_loss: 1.8058 - val_VH_attention_linear_output_loss: 1.9286 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.4149\n",
      "Epoch 1224/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7264 - VL_attention_linear_output_loss: 1.7926 - VH_attention_linear_output_loss: 1.9338 - VL_attention_linear_output_acc: 0.4739 - VH_attention_linear_output_acc: 0.4104 - val_loss: 3.7567 - val_VL_attention_linear_output_loss: 1.8039 - val_VH_attention_linear_output_loss: 1.9527 - val_VL_attention_linear_output_acc: 0.4755 - val_VH_attention_linear_output_acc: 0.4053\n",
      "Epoch 1225/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7074 - VL_attention_linear_output_loss: 1.7763 - VH_attention_linear_output_loss: 1.9311 - VL_attention_linear_output_acc: 0.4801 - VH_attention_linear_output_acc: 0.4116 - val_loss: 3.7427 - val_VL_attention_linear_output_loss: 1.7989 - val_VH_attention_linear_output_loss: 1.9438 - val_VL_attention_linear_output_acc: 0.4735 - val_VH_attention_linear_output_acc: 0.4063\n",
      "Epoch 1226/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7132 - VL_attention_linear_output_loss: 1.7819 - VH_attention_linear_output_loss: 1.9314 - VL_attention_linear_output_acc: 0.4776 - VH_attention_linear_output_acc: 0.4103 - val_loss: 3.7495 - val_VL_attention_linear_output_loss: 1.8057 - val_VH_attention_linear_output_loss: 1.9438 - val_VL_attention_linear_output_acc: 0.4744 - val_VH_attention_linear_output_acc: 0.4080\n",
      "Epoch 1227/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7147 - VL_attention_linear_output_loss: 1.7893 - VH_attention_linear_output_loss: 1.9254 - VL_attention_linear_output_acc: 0.4743 - VH_attention_linear_output_acc: 0.4128 - val_loss: 3.7751 - val_VL_attention_linear_output_loss: 1.8061 - val_VH_attention_linear_output_loss: 1.9690 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.3967\n",
      "Epoch 1228/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7087 - VL_attention_linear_output_loss: 1.7801 - VH_attention_linear_output_loss: 1.9287 - VL_attention_linear_output_acc: 0.4779 - VH_attention_linear_output_acc: 0.4114 - val_loss: 3.7557 - val_VL_attention_linear_output_loss: 1.8009 - val_VH_attention_linear_output_loss: 1.9548 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4074\n",
      "Epoch 1229/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7117 - VL_attention_linear_output_loss: 1.7801 - VH_attention_linear_output_loss: 1.9316 - VL_attention_linear_output_acc: 0.4782 - VH_attention_linear_output_acc: 0.4109 - val_loss: 3.7817 - val_VL_attention_linear_output_loss: 1.7997 - val_VH_attention_linear_output_loss: 1.9819 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.3930\n",
      "Epoch 1230/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6962 - VL_attention_linear_output_loss: 1.7742 - VH_attention_linear_output_loss: 1.9220 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4139 - val_loss: 3.7419 - val_VL_attention_linear_output_loss: 1.8139 - val_VH_attention_linear_output_loss: 1.9279 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.4142\n",
      "Epoch 1231/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7087 - VL_attention_linear_output_loss: 1.7822 - VH_attention_linear_output_loss: 1.9265 - VL_attention_linear_output_acc: 0.4759 - VH_attention_linear_output_acc: 0.4122 - val_loss: 3.7223 - val_VL_attention_linear_output_loss: 1.7988 - val_VH_attention_linear_output_loss: 1.9235 - val_VL_attention_linear_output_acc: 0.4743 - val_VH_attention_linear_output_acc: 0.4157\n",
      "Epoch 1232/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7077 - VL_attention_linear_output_loss: 1.7766 - VH_attention_linear_output_loss: 1.9311 - VL_attention_linear_output_acc: 0.4790 - VH_attention_linear_output_acc: 0.4104 - val_loss: 3.7982 - val_VL_attention_linear_output_loss: 1.8096 - val_VH_attention_linear_output_loss: 1.9886 - val_VL_attention_linear_output_acc: 0.4713 - val_VH_attention_linear_output_acc: 0.3929\n",
      "Epoch 1233/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7027 - VL_attention_linear_output_loss: 1.7791 - VH_attention_linear_output_loss: 1.9235 - VL_attention_linear_output_acc: 0.4786 - VH_attention_linear_output_acc: 0.4131 - val_loss: 3.7379 - val_VL_attention_linear_output_loss: 1.7998 - val_VH_attention_linear_output_loss: 1.9381 - val_VL_attention_linear_output_acc: 0.4743 - val_VH_attention_linear_output_acc: 0.4083\n",
      "Epoch 1234/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7118 - VL_attention_linear_output_loss: 1.7909 - VH_attention_linear_output_loss: 1.9209 - VL_attention_linear_output_acc: 0.4735 - VH_attention_linear_output_acc: 0.4146 - val_loss: 3.7389 - val_VL_attention_linear_output_loss: 1.7967 - val_VH_attention_linear_output_loss: 1.9422 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4072\n",
      "Epoch 1235/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6946 - VL_attention_linear_output_loss: 1.7686 - VH_attention_linear_output_loss: 1.9259 - VL_attention_linear_output_acc: 0.4832 - VH_attention_linear_output_acc: 0.4119 - val_loss: 3.7250 - val_VL_attention_linear_output_loss: 1.7975 - val_VH_attention_linear_output_loss: 1.9275 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4139\n",
      "Epoch 1236/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7026 - VL_attention_linear_output_loss: 1.7754 - VH_attention_linear_output_loss: 1.9271 - VL_attention_linear_output_acc: 0.4805 - VH_attention_linear_output_acc: 0.4121 - val_loss: 3.7764 - val_VL_attention_linear_output_loss: 1.8113 - val_VH_attention_linear_output_loss: 1.9650 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.3961\n",
      "Epoch 1237/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7043 - VL_attention_linear_output_loss: 1.7788 - VH_attention_linear_output_loss: 1.9255 - VL_attention_linear_output_acc: 0.4782 - VH_attention_linear_output_acc: 0.4121 - val_loss: 3.7456 - val_VL_attention_linear_output_loss: 1.8077 - val_VH_attention_linear_output_loss: 1.9379 - val_VL_attention_linear_output_acc: 0.4761 - val_VH_attention_linear_output_acc: 0.4082\n",
      "Epoch 1238/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7173 - VL_attention_linear_output_loss: 1.7887 - VH_attention_linear_output_loss: 1.9286 - VL_attention_linear_output_acc: 0.4729 - VH_attention_linear_output_acc: 0.4111 - val_loss: 3.8131 - val_VL_attention_linear_output_loss: 1.8687 - val_VH_attention_linear_output_loss: 1.9445 - val_VL_attention_linear_output_acc: 0.4450 - val_VH_attention_linear_output_acc: 0.4080\n",
      "Epoch 1239/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7000 - VL_attention_linear_output_loss: 1.7795 - VH_attention_linear_output_loss: 1.9205 - VL_attention_linear_output_acc: 0.4788 - VH_attention_linear_output_acc: 0.4143 - val_loss: 3.7322 - val_VL_attention_linear_output_loss: 1.7984 - val_VH_attention_linear_output_loss: 1.9338 - val_VL_attention_linear_output_acc: 0.4713 - val_VH_attention_linear_output_acc: 0.4110\n",
      "Epoch 1240/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7140 - VL_attention_linear_output_loss: 1.7865 - VH_attention_linear_output_loss: 1.9275 - VL_attention_linear_output_acc: 0.4748 - VH_attention_linear_output_acc: 0.4119 - val_loss: 3.7387 - val_VL_attention_linear_output_loss: 1.7971 - val_VH_attention_linear_output_loss: 1.9416 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4086\n",
      "Epoch 1241/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7211 - VL_attention_linear_output_loss: 1.7869 - VH_attention_linear_output_loss: 1.9342 - VL_attention_linear_output_acc: 0.4749 - VH_attention_linear_output_acc: 0.4088 - val_loss: 3.7386 - val_VL_attention_linear_output_loss: 1.7989 - val_VH_attention_linear_output_loss: 1.9398 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.4100\n",
      "Epoch 1242/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7144 - VL_attention_linear_output_loss: 1.7881 - VH_attention_linear_output_loss: 1.9263 - VL_attention_linear_output_acc: 0.4731 - VH_attention_linear_output_acc: 0.4122 - val_loss: 3.7681 - val_VL_attention_linear_output_loss: 1.8118 - val_VH_attention_linear_output_loss: 1.9564 - val_VL_attention_linear_output_acc: 0.4728 - val_VH_attention_linear_output_acc: 0.3990\n",
      "Epoch 1243/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7193 - VL_attention_linear_output_loss: 1.7933 - VH_attention_linear_output_loss: 1.9260 - VL_attention_linear_output_acc: 0.4717 - VH_attention_linear_output_acc: 0.4120 - val_loss: 3.7376 - val_VL_attention_linear_output_loss: 1.8074 - val_VH_attention_linear_output_loss: 1.9302 - val_VL_attention_linear_output_acc: 0.4710 - val_VH_attention_linear_output_acc: 0.4123\n",
      "Epoch 1244/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6984 - VL_attention_linear_output_loss: 1.7772 - VH_attention_linear_output_loss: 1.9213 - VL_attention_linear_output_acc: 0.4783 - VH_attention_linear_output_acc: 0.4139 - val_loss: 3.7333 - val_VL_attention_linear_output_loss: 1.7996 - val_VH_attention_linear_output_loss: 1.9337 - val_VL_attention_linear_output_acc: 0.4773 - val_VH_attention_linear_output_acc: 0.4106\n",
      "Epoch 1245/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7033 - VL_attention_linear_output_loss: 1.7791 - VH_attention_linear_output_loss: 1.9242 - VL_attention_linear_output_acc: 0.4776 - VH_attention_linear_output_acc: 0.4130 - val_loss: 3.7319 - val_VL_attention_linear_output_loss: 1.8067 - val_VH_attention_linear_output_loss: 1.9251 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.4166\n",
      "Epoch 1246/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7097 - VL_attention_linear_output_loss: 1.7837 - VH_attention_linear_output_loss: 1.9261 - VL_attention_linear_output_acc: 0.4761 - VH_attention_linear_output_acc: 0.4136 - val_loss: 3.7708 - val_VL_attention_linear_output_loss: 1.8325 - val_VH_attention_linear_output_loss: 1.9382 - val_VL_attention_linear_output_acc: 0.4653 - val_VH_attention_linear_output_acc: 0.4102\n",
      "Epoch 1247/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7039 - VL_attention_linear_output_loss: 1.7785 - VH_attention_linear_output_loss: 1.9254 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4124 - val_loss: 3.7511 - val_VL_attention_linear_output_loss: 1.8011 - val_VH_attention_linear_output_loss: 1.9499 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4049\n",
      "Epoch 1248/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7138 - VL_attention_linear_output_loss: 1.7913 - VH_attention_linear_output_loss: 1.9225 - VL_attention_linear_output_acc: 0.4729 - VH_attention_linear_output_acc: 0.4141 - val_loss: 3.7325 - val_VL_attention_linear_output_loss: 1.7950 - val_VH_attention_linear_output_loss: 1.9375 - val_VL_attention_linear_output_acc: 0.4780 - val_VH_attention_linear_output_acc: 0.4073\n",
      "Epoch 1249/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7045 - VL_attention_linear_output_loss: 1.7743 - VH_attention_linear_output_loss: 1.9302 - VL_attention_linear_output_acc: 0.4807 - VH_attention_linear_output_acc: 0.4106 - val_loss: 3.7661 - val_VL_attention_linear_output_loss: 1.8208 - val_VH_attention_linear_output_loss: 1.9454 - val_VL_attention_linear_output_acc: 0.4657 - val_VH_attention_linear_output_acc: 0.4085\n",
      "Epoch 1250/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7054 - VL_attention_linear_output_loss: 1.7806 - VH_attention_linear_output_loss: 1.9248 - VL_attention_linear_output_acc: 0.4789 - VH_attention_linear_output_acc: 0.4120 - val_loss: 3.7307 - val_VL_attention_linear_output_loss: 1.7962 - val_VH_attention_linear_output_loss: 1.9345 - val_VL_attention_linear_output_acc: 0.4795 - val_VH_attention_linear_output_acc: 0.4103\n",
      "Epoch 1251/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6920 - VL_attention_linear_output_loss: 1.7724 - VH_attention_linear_output_loss: 1.9196 - VL_attention_linear_output_acc: 0.4815 - VH_attention_linear_output_acc: 0.4142 - val_loss: 3.7635 - val_VL_attention_linear_output_loss: 1.8405 - val_VH_attention_linear_output_loss: 1.9230 - val_VL_attention_linear_output_acc: 0.4552 - val_VH_attention_linear_output_acc: 0.4168\n",
      "Epoch 1252/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6941 - VL_attention_linear_output_loss: 1.7788 - VH_attention_linear_output_loss: 1.9153 - VL_attention_linear_output_acc: 0.4780 - VH_attention_linear_output_acc: 0.4162 - val_loss: 3.7426 - val_VL_attention_linear_output_loss: 1.8014 - val_VH_attention_linear_output_loss: 1.9413 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.4055\n",
      "Epoch 1253/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6911 - VL_attention_linear_output_loss: 1.7728 - VH_attention_linear_output_loss: 1.9183 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4151 - val_loss: 3.7395 - val_VL_attention_linear_output_loss: 1.8084 - val_VH_attention_linear_output_loss: 1.9311 - val_VL_attention_linear_output_acc: 0.4705 - val_VH_attention_linear_output_acc: 0.4132\n",
      "Epoch 1254/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7044 - VL_attention_linear_output_loss: 1.7787 - VH_attention_linear_output_loss: 1.9257 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.4119 - val_loss: 3.7250 - val_VL_attention_linear_output_loss: 1.7977 - val_VH_attention_linear_output_loss: 1.9272 - val_VL_attention_linear_output_acc: 0.4751 - val_VH_attention_linear_output_acc: 0.4131\n",
      "Epoch 1255/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7007 - VL_attention_linear_output_loss: 1.7773 - VH_attention_linear_output_loss: 1.9234 - VL_attention_linear_output_acc: 0.4784 - VH_attention_linear_output_acc: 0.4125 - val_loss: 3.7591 - val_VL_attention_linear_output_loss: 1.8349 - val_VH_attention_linear_output_loss: 1.9242 - val_VL_attention_linear_output_acc: 0.4616 - val_VH_attention_linear_output_acc: 0.4166\n",
      "Epoch 1256/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7019 - VL_attention_linear_output_loss: 1.7807 - VH_attention_linear_output_loss: 1.9212 - VL_attention_linear_output_acc: 0.4759 - VH_attention_linear_output_acc: 0.4135 - val_loss: 3.7220 - val_VL_attention_linear_output_loss: 1.7916 - val_VH_attention_linear_output_loss: 1.9304 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4136\n",
      "Epoch 1257/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6834 - VL_attention_linear_output_loss: 1.7670 - VH_attention_linear_output_loss: 1.9164 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4160 - val_loss: 3.7400 - val_VL_attention_linear_output_loss: 1.7990 - val_VH_attention_linear_output_loss: 1.9410 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4095\n",
      "Epoch 1258/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6932 - VL_attention_linear_output_loss: 1.7740 - VH_attention_linear_output_loss: 1.9192 - VL_attention_linear_output_acc: 0.4805 - VH_attention_linear_output_acc: 0.4148 - val_loss: 3.7342 - val_VL_attention_linear_output_loss: 1.7986 - val_VH_attention_linear_output_loss: 1.9356 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4094\n",
      "Epoch 1259/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7008 - VL_attention_linear_output_loss: 1.7717 - VH_attention_linear_output_loss: 1.9291 - VL_attention_linear_output_acc: 0.4823 - VH_attention_linear_output_acc: 0.4099 - val_loss: 3.7787 - val_VL_attention_linear_output_loss: 1.7990 - val_VH_attention_linear_output_loss: 1.9798 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.3950\n",
      "Epoch 1260/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7002 - VL_attention_linear_output_loss: 1.7761 - VH_attention_linear_output_loss: 1.9241 - VL_attention_linear_output_acc: 0.4784 - VH_attention_linear_output_acc: 0.4121 - val_loss: 3.7424 - val_VL_attention_linear_output_loss: 1.8103 - val_VH_attention_linear_output_loss: 1.9321 - val_VL_attention_linear_output_acc: 0.4774 - val_VH_attention_linear_output_acc: 0.4112\n",
      "Epoch 1261/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7091 - VL_attention_linear_output_loss: 1.7773 - VH_attention_linear_output_loss: 1.9319 - VL_attention_linear_output_acc: 0.4780 - VH_attention_linear_output_acc: 0.4107 - val_loss: 3.7453 - val_VL_attention_linear_output_loss: 1.8120 - val_VH_attention_linear_output_loss: 1.9334 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.4124\n",
      "Epoch 1262/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7085 - VL_attention_linear_output_loss: 1.7884 - VH_attention_linear_output_loss: 1.9201 - VL_attention_linear_output_acc: 0.4743 - VH_attention_linear_output_acc: 0.4143 - val_loss: 3.7365 - val_VL_attention_linear_output_loss: 1.8042 - val_VH_attention_linear_output_loss: 1.9324 - val_VL_attention_linear_output_acc: 0.4814 - val_VH_attention_linear_output_acc: 0.4109\n",
      "Epoch 1263/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7129 - VL_attention_linear_output_loss: 1.7893 - VH_attention_linear_output_loss: 1.9236 - VL_attention_linear_output_acc: 0.4739 - VH_attention_linear_output_acc: 0.4131 - val_loss: 3.7599 - val_VL_attention_linear_output_loss: 1.8101 - val_VH_attention_linear_output_loss: 1.9498 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.4053\n",
      "Epoch 1264/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7099 - VL_attention_linear_output_loss: 1.7750 - VH_attention_linear_output_loss: 1.9349 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4075 - val_loss: 3.7393 - val_VL_attention_linear_output_loss: 1.8001 - val_VH_attention_linear_output_loss: 1.9392 - val_VL_attention_linear_output_acc: 0.4778 - val_VH_attention_linear_output_acc: 0.4123\n",
      "Epoch 1265/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6974 - VL_attention_linear_output_loss: 1.7740 - VH_attention_linear_output_loss: 1.9234 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.4134 - val_loss: 3.7561 - val_VL_attention_linear_output_loss: 1.8028 - val_VH_attention_linear_output_loss: 1.9533 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.4001\n",
      "Epoch 1266/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7270 - VL_attention_linear_output_loss: 1.7974 - VH_attention_linear_output_loss: 1.9296 - VL_attention_linear_output_acc: 0.4730 - VH_attention_linear_output_acc: 0.4110 - val_loss: 3.7428 - val_VL_attention_linear_output_loss: 1.8105 - val_VH_attention_linear_output_loss: 1.9324 - val_VL_attention_linear_output_acc: 0.4738 - val_VH_attention_linear_output_acc: 0.4109\n",
      "Epoch 1267/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6950 - VL_attention_linear_output_loss: 1.7740 - VH_attention_linear_output_loss: 1.9210 - VL_attention_linear_output_acc: 0.4815 - VH_attention_linear_output_acc: 0.4136 - val_loss: 3.7401 - val_VL_attention_linear_output_loss: 1.8027 - val_VH_attention_linear_output_loss: 1.9374 - val_VL_attention_linear_output_acc: 0.4714 - val_VH_attention_linear_output_acc: 0.4131\n",
      "Epoch 1268/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6880 - VL_attention_linear_output_loss: 1.7725 - VH_attention_linear_output_loss: 1.9155 - VL_attention_linear_output_acc: 0.4804 - VH_attention_linear_output_acc: 0.4164 - val_loss: 3.7319 - val_VL_attention_linear_output_loss: 1.8058 - val_VH_attention_linear_output_loss: 1.9261 - val_VL_attention_linear_output_acc: 0.4746 - val_VH_attention_linear_output_acc: 0.4149\n",
      "Epoch 1269/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7048 - VL_attention_linear_output_loss: 1.7814 - VH_attention_linear_output_loss: 1.9234 - VL_attention_linear_output_acc: 0.4774 - VH_attention_linear_output_acc: 0.4125 - val_loss: 3.7192 - val_VL_attention_linear_output_loss: 1.7957 - val_VH_attention_linear_output_loss: 1.9236 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4173\n",
      "Epoch 1270/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7020 - VL_attention_linear_output_loss: 1.7866 - VH_attention_linear_output_loss: 1.9154 - VL_attention_linear_output_acc: 0.4756 - VH_attention_linear_output_acc: 0.4162 - val_loss: 3.7426 - val_VL_attention_linear_output_loss: 1.8120 - val_VH_attention_linear_output_loss: 1.9306 - val_VL_attention_linear_output_acc: 0.4750 - val_VH_attention_linear_output_acc: 0.4149\n",
      "Epoch 1271/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6920 - VL_attention_linear_output_loss: 1.7722 - VH_attention_linear_output_loss: 1.9199 - VL_attention_linear_output_acc: 0.4813 - VH_attention_linear_output_acc: 0.4138 - val_loss: 3.7755 - val_VL_attention_linear_output_loss: 1.7988 - val_VH_attention_linear_output_loss: 1.9767 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.3890\n",
      "Epoch 1272/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7020 - VL_attention_linear_output_loss: 1.7782 - VH_attention_linear_output_loss: 1.9238 - VL_attention_linear_output_acc: 0.4797 - VH_attention_linear_output_acc: 0.4127 - val_loss: 3.7494 - val_VL_attention_linear_output_loss: 1.8108 - val_VH_attention_linear_output_loss: 1.9386 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.4093\n",
      "Epoch 1273/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7115 - VL_attention_linear_output_loss: 1.7918 - VH_attention_linear_output_loss: 1.9196 - VL_attention_linear_output_acc: 0.4711 - VH_attention_linear_output_acc: 0.4142 - val_loss: 3.7398 - val_VL_attention_linear_output_loss: 1.8042 - val_VH_attention_linear_output_loss: 1.9356 - val_VL_attention_linear_output_acc: 0.4739 - val_VH_attention_linear_output_acc: 0.4080\n",
      "Epoch 1274/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6992 - VL_attention_linear_output_loss: 1.7806 - VH_attention_linear_output_loss: 1.9185 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.4149 - val_loss: 3.7282 - val_VL_attention_linear_output_loss: 1.8004 - val_VH_attention_linear_output_loss: 1.9278 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4108\n",
      "Epoch 1275/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6966 - VL_attention_linear_output_loss: 1.7823 - VH_attention_linear_output_loss: 1.9143 - VL_attention_linear_output_acc: 0.4770 - VH_attention_linear_output_acc: 0.4165 - val_loss: 3.7838 - val_VL_attention_linear_output_loss: 1.8638 - val_VH_attention_linear_output_loss: 1.9200 - val_VL_attention_linear_output_acc: 0.4494 - val_VH_attention_linear_output_acc: 0.4161\n",
      "Epoch 1276/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7062 - VL_attention_linear_output_loss: 1.7883 - VH_attention_linear_output_loss: 1.9179 - VL_attention_linear_output_acc: 0.4748 - VH_attention_linear_output_acc: 0.4149 - val_loss: 3.7792 - val_VL_attention_linear_output_loss: 1.8425 - val_VH_attention_linear_output_loss: 1.9367 - val_VL_attention_linear_output_acc: 0.4575 - val_VH_attention_linear_output_acc: 0.4115\n",
      "Epoch 1277/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7101 - VL_attention_linear_output_loss: 1.7906 - VH_attention_linear_output_loss: 1.9194 - VL_attention_linear_output_acc: 0.4725 - VH_attention_linear_output_acc: 0.4141 - val_loss: 3.7412 - val_VL_attention_linear_output_loss: 1.8146 - val_VH_attention_linear_output_loss: 1.9266 - val_VL_attention_linear_output_acc: 0.4624 - val_VH_attention_linear_output_acc: 0.4126\n",
      "Epoch 1278/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6837 - VL_attention_linear_output_loss: 1.7738 - VH_attention_linear_output_loss: 1.9099 - VL_attention_linear_output_acc: 0.4805 - VH_attention_linear_output_acc: 0.4181 - val_loss: 3.7356 - val_VL_attention_linear_output_loss: 1.7952 - val_VH_attention_linear_output_loss: 1.9404 - val_VL_attention_linear_output_acc: 0.4742 - val_VH_attention_linear_output_acc: 0.4059\n",
      "Epoch 1279/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7020 - VL_attention_linear_output_loss: 1.7859 - VH_attention_linear_output_loss: 1.9161 - VL_attention_linear_output_acc: 0.4745 - VH_attention_linear_output_acc: 0.4152 - val_loss: 3.7797 - val_VL_attention_linear_output_loss: 1.8266 - val_VH_attention_linear_output_loss: 1.9530 - val_VL_attention_linear_output_acc: 0.4572 - val_VH_attention_linear_output_acc: 0.4080\n",
      "Epoch 1280/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6950 - VL_attention_linear_output_loss: 1.7759 - VH_attention_linear_output_loss: 1.9191 - VL_attention_linear_output_acc: 0.4800 - VH_attention_linear_output_acc: 0.4141 - val_loss: 3.7324 - val_VL_attention_linear_output_loss: 1.8078 - val_VH_attention_linear_output_loss: 1.9246 - val_VL_attention_linear_output_acc: 0.4717 - val_VH_attention_linear_output_acc: 0.4164\n",
      "Epoch 1281/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6888 - VL_attention_linear_output_loss: 1.7747 - VH_attention_linear_output_loss: 1.9142 - VL_attention_linear_output_acc: 0.4790 - VH_attention_linear_output_acc: 0.4159 - val_loss: 3.7251 - val_VL_attention_linear_output_loss: 1.8015 - val_VH_attention_linear_output_loss: 1.9236 - val_VL_attention_linear_output_acc: 0.4758 - val_VH_attention_linear_output_acc: 0.4148\n",
      "Epoch 1282/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6981 - VL_attention_linear_output_loss: 1.7811 - VH_attention_linear_output_loss: 1.9171 - VL_attention_linear_output_acc: 0.4781 - VH_attention_linear_output_acc: 0.4147 - val_loss: 3.7470 - val_VL_attention_linear_output_loss: 1.8101 - val_VH_attention_linear_output_loss: 1.9369 - val_VL_attention_linear_output_acc: 0.4700 - val_VH_attention_linear_output_acc: 0.4119\n",
      "Epoch 1283/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7026 - VL_attention_linear_output_loss: 1.7848 - VH_attention_linear_output_loss: 1.9179 - VL_attention_linear_output_acc: 0.4750 - VH_attention_linear_output_acc: 0.4147 - val_loss: 3.7129 - val_VL_attention_linear_output_loss: 1.7970 - val_VH_attention_linear_output_loss: 1.9159 - val_VL_attention_linear_output_acc: 0.4773 - val_VH_attention_linear_output_acc: 0.4175\n",
      "Epoch 1284/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6882 - VL_attention_linear_output_loss: 1.7739 - VH_attention_linear_output_loss: 1.9142 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4162 - val_loss: 3.7367 - val_VL_attention_linear_output_loss: 1.8043 - val_VH_attention_linear_output_loss: 1.9324 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.4158\n",
      "Epoch 1285/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7013 - VL_attention_linear_output_loss: 1.7808 - VH_attention_linear_output_loss: 1.9205 - VL_attention_linear_output_acc: 0.4775 - VH_attention_linear_output_acc: 0.4136 - val_loss: 3.7439 - val_VL_attention_linear_output_loss: 1.8165 - val_VH_attention_linear_output_loss: 1.9274 - val_VL_attention_linear_output_acc: 0.4754 - val_VH_attention_linear_output_acc: 0.4164\n",
      "Epoch 1286/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6955 - VL_attention_linear_output_loss: 1.7845 - VH_attention_linear_output_loss: 1.9111 - VL_attention_linear_output_acc: 0.4754 - VH_attention_linear_output_acc: 0.4173 - val_loss: 3.7227 - val_VL_attention_linear_output_loss: 1.7984 - val_VH_attention_linear_output_loss: 1.9243 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4179\n",
      "Epoch 1287/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6879 - VL_attention_linear_output_loss: 1.7736 - VH_attention_linear_output_loss: 1.9143 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4162 - val_loss: 3.7496 - val_VL_attention_linear_output_loss: 1.8040 - val_VH_attention_linear_output_loss: 1.9457 - val_VL_attention_linear_output_acc: 0.4697 - val_VH_attention_linear_output_acc: 0.4077\n",
      "Epoch 1288/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6945 - VL_attention_linear_output_loss: 1.7769 - VH_attention_linear_output_loss: 1.9176 - VL_attention_linear_output_acc: 0.4789 - VH_attention_linear_output_acc: 0.4151 - val_loss: 3.7259 - val_VL_attention_linear_output_loss: 1.8064 - val_VH_attention_linear_output_loss: 1.9195 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4162\n",
      "Epoch 1289/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7046 - VL_attention_linear_output_loss: 1.7915 - VH_attention_linear_output_loss: 1.9132 - VL_attention_linear_output_acc: 0.4735 - VH_attention_linear_output_acc: 0.4162 - val_loss: 3.7389 - val_VL_attention_linear_output_loss: 1.8154 - val_VH_attention_linear_output_loss: 1.9234 - val_VL_attention_linear_output_acc: 0.4688 - val_VH_attention_linear_output_acc: 0.4160\n",
      "Epoch 1290/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6948 - VL_attention_linear_output_loss: 1.7753 - VH_attention_linear_output_loss: 1.9196 - VL_attention_linear_output_acc: 0.4797 - VH_attention_linear_output_acc: 0.4141 - val_loss: 3.7122 - val_VL_attention_linear_output_loss: 1.7945 - val_VH_attention_linear_output_loss: 1.9177 - val_VL_attention_linear_output_acc: 0.4795 - val_VH_attention_linear_output_acc: 0.4174\n",
      "Epoch 1291/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6804 - VL_attention_linear_output_loss: 1.7661 - VH_attention_linear_output_loss: 1.9143 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4165 - val_loss: 3.7495 - val_VL_attention_linear_output_loss: 1.8216 - val_VH_attention_linear_output_loss: 1.9279 - val_VL_attention_linear_output_acc: 0.4689 - val_VH_attention_linear_output_acc: 0.4122\n",
      "Epoch 1292/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6935 - VL_attention_linear_output_loss: 1.7797 - VH_attention_linear_output_loss: 1.9138 - VL_attention_linear_output_acc: 0.4781 - VH_attention_linear_output_acc: 0.4165 - val_loss: 3.7403 - val_VL_attention_linear_output_loss: 1.8004 - val_VH_attention_linear_output_loss: 1.9399 - val_VL_attention_linear_output_acc: 0.4740 - val_VH_attention_linear_output_acc: 0.4122\n",
      "Epoch 1293/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7041 - VL_attention_linear_output_loss: 1.7809 - VH_attention_linear_output_loss: 1.9232 - VL_attention_linear_output_acc: 0.4778 - VH_attention_linear_output_acc: 0.4150 - val_loss: 3.7419 - val_VL_attention_linear_output_loss: 1.8155 - val_VH_attention_linear_output_loss: 1.9264 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.4149\n",
      "Epoch 1294/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6990 - VL_attention_linear_output_loss: 1.7868 - VH_attention_linear_output_loss: 1.9122 - VL_attention_linear_output_acc: 0.4737 - VH_attention_linear_output_acc: 0.4169 - val_loss: 3.7694 - val_VL_attention_linear_output_loss: 1.8320 - val_VH_attention_linear_output_loss: 1.9374 - val_VL_attention_linear_output_acc: 0.4627 - val_VH_attention_linear_output_acc: 0.4104\n",
      "Epoch 1295/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7077 - VL_attention_linear_output_loss: 1.7851 - VH_attention_linear_output_loss: 1.9226 - VL_attention_linear_output_acc: 0.4753 - VH_attention_linear_output_acc: 0.4131 - val_loss: 3.7315 - val_VL_attention_linear_output_loss: 1.8026 - val_VH_attention_linear_output_loss: 1.9289 - val_VL_attention_linear_output_acc: 0.4793 - val_VH_attention_linear_output_acc: 0.4122\n",
      "Epoch 1296/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6890 - VL_attention_linear_output_loss: 1.7745 - VH_attention_linear_output_loss: 1.9144 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4162 - val_loss: 3.7315 - val_VL_attention_linear_output_loss: 1.7992 - val_VH_attention_linear_output_loss: 1.9323 - val_VL_attention_linear_output_acc: 0.4805 - val_VH_attention_linear_output_acc: 0.4117\n",
      "Epoch 1297/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6815 - VL_attention_linear_output_loss: 1.7742 - VH_attention_linear_output_loss: 1.9073 - VL_attention_linear_output_acc: 0.4796 - VH_attention_linear_output_acc: 0.4190 - val_loss: 3.7239 - val_VL_attention_linear_output_loss: 1.8059 - val_VH_attention_linear_output_loss: 1.9180 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.4177\n",
      "Epoch 1298/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6977 - VL_attention_linear_output_loss: 1.7832 - VH_attention_linear_output_loss: 1.9144 - VL_attention_linear_output_acc: 0.4763 - VH_attention_linear_output_acc: 0.4156 - val_loss: 3.7253 - val_VL_attention_linear_output_loss: 1.8056 - val_VH_attention_linear_output_loss: 1.9196 - val_VL_attention_linear_output_acc: 0.4716 - val_VH_attention_linear_output_acc: 0.4176\n",
      "Epoch 1299/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7002 - VL_attention_linear_output_loss: 1.7846 - VH_attention_linear_output_loss: 1.9156 - VL_attention_linear_output_acc: 0.4749 - VH_attention_linear_output_acc: 0.4156 - val_loss: 3.7179 - val_VL_attention_linear_output_loss: 1.8019 - val_VH_attention_linear_output_loss: 1.9161 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4181\n",
      "Epoch 1300/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6902 - VL_attention_linear_output_loss: 1.7814 - VH_attention_linear_output_loss: 1.9088 - VL_attention_linear_output_acc: 0.4767 - VH_attention_linear_output_acc: 0.4183 - val_loss: 3.7636 - val_VL_attention_linear_output_loss: 1.8404 - val_VH_attention_linear_output_loss: 1.9232 - val_VL_attention_linear_output_acc: 0.4617 - val_VH_attention_linear_output_acc: 0.4148\n",
      "Epoch 1301/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6853 - VL_attention_linear_output_loss: 1.7747 - VH_attention_linear_output_loss: 1.9106 - VL_attention_linear_output_acc: 0.4802 - VH_attention_linear_output_acc: 0.4170 - val_loss: 3.7359 - val_VL_attention_linear_output_loss: 1.8205 - val_VH_attention_linear_output_loss: 1.9153 - val_VL_attention_linear_output_acc: 0.4681 - val_VH_attention_linear_output_acc: 0.4179\n",
      "Epoch 1302/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6931 - VL_attention_linear_output_loss: 1.7829 - VH_attention_linear_output_loss: 1.9102 - VL_attention_linear_output_acc: 0.4759 - VH_attention_linear_output_acc: 0.4177 - val_loss: 3.7391 - val_VL_attention_linear_output_loss: 1.7973 - val_VH_attention_linear_output_loss: 1.9418 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4032\n",
      "Epoch 1303/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6804 - VL_attention_linear_output_loss: 1.7678 - VH_attention_linear_output_loss: 1.9126 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4167 - val_loss: 3.7293 - val_VL_attention_linear_output_loss: 1.7963 - val_VH_attention_linear_output_loss: 1.9330 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4068\n",
      "Epoch 1304/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6867 - VL_attention_linear_output_loss: 1.7796 - VH_attention_linear_output_loss: 1.9072 - VL_attention_linear_output_acc: 0.4781 - VH_attention_linear_output_acc: 0.4188 - val_loss: 3.7767 - val_VL_attention_linear_output_loss: 1.8281 - val_VH_attention_linear_output_loss: 1.9486 - val_VL_attention_linear_output_acc: 0.4565 - val_VH_attention_linear_output_acc: 0.3997\n",
      "Epoch 1305/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7011 - VL_attention_linear_output_loss: 1.7842 - VH_attention_linear_output_loss: 1.9169 - VL_attention_linear_output_acc: 0.4754 - VH_attention_linear_output_acc: 0.4148 - val_loss: 3.7374 - val_VL_attention_linear_output_loss: 1.8004 - val_VH_attention_linear_output_loss: 1.9370 - val_VL_attention_linear_output_acc: 0.4768 - val_VH_attention_linear_output_acc: 0.4118\n",
      "Epoch 1306/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6974 - VL_attention_linear_output_loss: 1.7894 - VH_attention_linear_output_loss: 1.9080 - VL_attention_linear_output_acc: 0.4732 - VH_attention_linear_output_acc: 0.4184 - val_loss: 3.7349 - val_VL_attention_linear_output_loss: 1.7961 - val_VH_attention_linear_output_loss: 1.9388 - val_VL_attention_linear_output_acc: 0.4751 - val_VH_attention_linear_output_acc: 0.4045\n",
      "Epoch 1307/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6860 - VL_attention_linear_output_loss: 1.7679 - VH_attention_linear_output_loss: 1.9180 - VL_attention_linear_output_acc: 0.4826 - VH_attention_linear_output_acc: 0.4142 - val_loss: 3.7737 - val_VL_attention_linear_output_loss: 1.8047 - val_VH_attention_linear_output_loss: 1.9689 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4054\n",
      "Epoch 1308/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6964 - VL_attention_linear_output_loss: 1.7775 - VH_attention_linear_output_loss: 1.9188 - VL_attention_linear_output_acc: 0.4782 - VH_attention_linear_output_acc: 0.4154 - val_loss: 3.7302 - val_VL_attention_linear_output_loss: 1.8043 - val_VH_attention_linear_output_loss: 1.9260 - val_VL_attention_linear_output_acc: 0.4752 - val_VH_attention_linear_output_acc: 0.4099\n",
      "Epoch 1309/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6867 - VL_attention_linear_output_loss: 1.7797 - VH_attention_linear_output_loss: 1.9070 - VL_attention_linear_output_acc: 0.4771 - VH_attention_linear_output_acc: 0.4189 - val_loss: 3.7704 - val_VL_attention_linear_output_loss: 1.7982 - val_VH_attention_linear_output_loss: 1.9723 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.3890\n",
      "Epoch 1310/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6989 - VL_attention_linear_output_loss: 1.7874 - VH_attention_linear_output_loss: 1.9115 - VL_attention_linear_output_acc: 0.4743 - VH_attention_linear_output_acc: 0.4171 - val_loss: 3.7260 - val_VL_attention_linear_output_loss: 1.7948 - val_VH_attention_linear_output_loss: 1.9312 - val_VL_attention_linear_output_acc: 0.4781 - val_VH_attention_linear_output_acc: 0.4088\n",
      "Epoch 1311/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6773 - VL_attention_linear_output_loss: 1.7692 - VH_attention_linear_output_loss: 1.9081 - VL_attention_linear_output_acc: 0.4823 - VH_attention_linear_output_acc: 0.4187 - val_loss: 3.7177 - val_VL_attention_linear_output_loss: 1.7990 - val_VH_attention_linear_output_loss: 1.9187 - val_VL_attention_linear_output_acc: 0.4736 - val_VH_attention_linear_output_acc: 0.4178\n",
      "Epoch 1312/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6881 - VL_attention_linear_output_loss: 1.7813 - VH_attention_linear_output_loss: 1.9067 - VL_attention_linear_output_acc: 0.4762 - VH_attention_linear_output_acc: 0.4196 - val_loss: 3.7407 - val_VL_attention_linear_output_loss: 1.7949 - val_VH_attention_linear_output_loss: 1.9458 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4073\n",
      "Epoch 1313/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6806 - VL_attention_linear_output_loss: 1.7695 - VH_attention_linear_output_loss: 1.9110 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4169 - val_loss: 3.7872 - val_VL_attention_linear_output_loss: 1.8539 - val_VH_attention_linear_output_loss: 1.9333 - val_VL_attention_linear_output_acc: 0.4518 - val_VH_attention_linear_output_acc: 0.4148\n",
      "Epoch 1314/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7042 - VL_attention_linear_output_loss: 1.7896 - VH_attention_linear_output_loss: 1.9145 - VL_attention_linear_output_acc: 0.4729 - VH_attention_linear_output_acc: 0.4157 - val_loss: 3.7256 - val_VL_attention_linear_output_loss: 1.7938 - val_VH_attention_linear_output_loss: 1.9318 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4156\n",
      "Epoch 1315/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6835 - VL_attention_linear_output_loss: 1.7689 - VH_attention_linear_output_loss: 1.9146 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4160 - val_loss: 3.7176 - val_VL_attention_linear_output_loss: 1.7974 - val_VH_attention_linear_output_loss: 1.9203 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4185\n",
      "Epoch 1316/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6860 - VL_attention_linear_output_loss: 1.7711 - VH_attention_linear_output_loss: 1.9149 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4157 - val_loss: 3.7644 - val_VL_attention_linear_output_loss: 1.8485 - val_VH_attention_linear_output_loss: 1.9159 - val_VL_attention_linear_output_acc: 0.4527 - val_VH_attention_linear_output_acc: 0.4169\n",
      "Epoch 1317/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6858 - VL_attention_linear_output_loss: 1.7828 - VH_attention_linear_output_loss: 1.9030 - VL_attention_linear_output_acc: 0.4751 - VH_attention_linear_output_acc: 0.4207 - val_loss: 3.7822 - val_VL_attention_linear_output_loss: 1.8358 - val_VH_attention_linear_output_loss: 1.9464 - val_VL_attention_linear_output_acc: 0.4592 - val_VH_attention_linear_output_acc: 0.4075\n",
      "Epoch 1318/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6886 - VL_attention_linear_output_loss: 1.7801 - VH_attention_linear_output_loss: 1.9084 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.4179 - val_loss: 3.7228 - val_VL_attention_linear_output_loss: 1.7971 - val_VH_attention_linear_output_loss: 1.9257 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4187\n",
      "Epoch 1319/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6925 - VL_attention_linear_output_loss: 1.7864 - VH_attention_linear_output_loss: 1.9061 - VL_attention_linear_output_acc: 0.4743 - VH_attention_linear_output_acc: 0.4197 - val_loss: 3.7394 - val_VL_attention_linear_output_loss: 1.8106 - val_VH_attention_linear_output_loss: 1.9287 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4159\n",
      "Epoch 1320/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6948 - VL_attention_linear_output_loss: 1.7845 - VH_attention_linear_output_loss: 1.9103 - VL_attention_linear_output_acc: 0.4760 - VH_attention_linear_output_acc: 0.4181 - val_loss: 3.7373 - val_VL_attention_linear_output_loss: 1.8170 - val_VH_attention_linear_output_loss: 1.9203 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.4149\n",
      "Epoch 1321/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6803 - VL_attention_linear_output_loss: 1.7678 - VH_attention_linear_output_loss: 1.9125 - VL_attention_linear_output_acc: 0.4832 - VH_attention_linear_output_acc: 0.4169 - val_loss: 3.7860 - val_VL_attention_linear_output_loss: 1.8317 - val_VH_attention_linear_output_loss: 1.9543 - val_VL_attention_linear_output_acc: 0.4665 - val_VH_attention_linear_output_acc: 0.4047\n",
      "Epoch 1322/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6884 - VL_attention_linear_output_loss: 1.7772 - VH_attention_linear_output_loss: 1.9112 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4172 - val_loss: 3.7385 - val_VL_attention_linear_output_loss: 1.8038 - val_VH_attention_linear_output_loss: 1.9347 - val_VL_attention_linear_output_acc: 0.4777 - val_VH_attention_linear_output_acc: 0.4105\n",
      "Epoch 1323/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6816 - VL_attention_linear_output_loss: 1.7780 - VH_attention_linear_output_loss: 1.9036 - VL_attention_linear_output_acc: 0.4784 - VH_attention_linear_output_acc: 0.4203 - val_loss: 3.7233 - val_VL_attention_linear_output_loss: 1.8065 - val_VH_attention_linear_output_loss: 1.9168 - val_VL_attention_linear_output_acc: 0.4703 - val_VH_attention_linear_output_acc: 0.4164\n",
      "Epoch 1324/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6789 - VL_attention_linear_output_loss: 1.7729 - VH_attention_linear_output_loss: 1.9060 - VL_attention_linear_output_acc: 0.4801 - VH_attention_linear_output_acc: 0.4198 - val_loss: 3.7282 - val_VL_attention_linear_output_loss: 1.8092 - val_VH_attention_linear_output_loss: 1.9190 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.4161\n",
      "Epoch 1325/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7043 - VL_attention_linear_output_loss: 1.7726 - VH_attention_linear_output_loss: 1.9317 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4086 - val_loss: 3.7184 - val_VL_attention_linear_output_loss: 1.8007 - val_VH_attention_linear_output_loss: 1.9177 - val_VL_attention_linear_output_acc: 0.4710 - val_VH_attention_linear_output_acc: 0.4182\n",
      "Epoch 1326/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6849 - VL_attention_linear_output_loss: 1.7796 - VH_attention_linear_output_loss: 1.9053 - VL_attention_linear_output_acc: 0.4773 - VH_attention_linear_output_acc: 0.4198 - val_loss: 3.7456 - val_VL_attention_linear_output_loss: 1.8047 - val_VH_attention_linear_output_loss: 1.9410 - val_VL_attention_linear_output_acc: 0.4767 - val_VH_attention_linear_output_acc: 0.4110\n",
      "Epoch 1327/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6966 - VL_attention_linear_output_loss: 1.7758 - VH_attention_linear_output_loss: 1.9207 - VL_attention_linear_output_acc: 0.4790 - VH_attention_linear_output_acc: 0.4133 - val_loss: 3.8195 - val_VL_attention_linear_output_loss: 1.8494 - val_VH_attention_linear_output_loss: 1.9701 - val_VL_attention_linear_output_acc: 0.4491 - val_VH_attention_linear_output_acc: 0.3837\n",
      "Epoch 1328/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6998 - VL_attention_linear_output_loss: 1.7925 - VH_attention_linear_output_loss: 1.9073 - VL_attention_linear_output_acc: 0.4711 - VH_attention_linear_output_acc: 0.4191 - val_loss: 3.7033 - val_VL_attention_linear_output_loss: 1.7938 - val_VH_attention_linear_output_loss: 1.9095 - val_VL_attention_linear_output_acc: 0.4777 - val_VH_attention_linear_output_acc: 0.4209\n",
      "Epoch 1329/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6799 - VL_attention_linear_output_loss: 1.7751 - VH_attention_linear_output_loss: 1.9048 - VL_attention_linear_output_acc: 0.4791 - VH_attention_linear_output_acc: 0.4197 - val_loss: 3.7468 - val_VL_attention_linear_output_loss: 1.8032 - val_VH_attention_linear_output_loss: 1.9436 - val_VL_attention_linear_output_acc: 0.4701 - val_VH_attention_linear_output_acc: 0.4090\n",
      "Epoch 1330/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6898 - VL_attention_linear_output_loss: 1.7749 - VH_attention_linear_output_loss: 1.9148 - VL_attention_linear_output_acc: 0.4788 - VH_attention_linear_output_acc: 0.4158 - val_loss: 3.7169 - val_VL_attention_linear_output_loss: 1.7957 - val_VH_attention_linear_output_loss: 1.9211 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.4194\n",
      "Epoch 1331/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6863 - VL_attention_linear_output_loss: 1.7790 - VH_attention_linear_output_loss: 1.9073 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.4190 - val_loss: 3.7401 - val_VL_attention_linear_output_loss: 1.8107 - val_VH_attention_linear_output_loss: 1.9293 - val_VL_attention_linear_output_acc: 0.4747 - val_VH_attention_linear_output_acc: 0.4101\n",
      "Epoch 1332/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7242 - VL_attention_linear_output_loss: 1.8094 - VH_attention_linear_output_loss: 1.9148 - VL_attention_linear_output_acc: 0.4650 - VH_attention_linear_output_acc: 0.4162 - val_loss: 3.7295 - val_VL_attention_linear_output_loss: 1.8095 - val_VH_attention_linear_output_loss: 1.9200 - val_VL_attention_linear_output_acc: 0.4689 - val_VH_attention_linear_output_acc: 0.4183\n",
      "Epoch 1333/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6799 - VL_attention_linear_output_loss: 1.7693 - VH_attention_linear_output_loss: 1.9106 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4177 - val_loss: 3.7458 - val_VL_attention_linear_output_loss: 1.8096 - val_VH_attention_linear_output_loss: 1.9362 - val_VL_attention_linear_output_acc: 0.4685 - val_VH_attention_linear_output_acc: 0.4069\n",
      "Epoch 1334/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6750 - VL_attention_linear_output_loss: 1.7737 - VH_attention_linear_output_loss: 1.9012 - VL_attention_linear_output_acc: 0.4791 - VH_attention_linear_output_acc: 0.4212 - val_loss: 3.7202 - val_VL_attention_linear_output_loss: 1.7991 - val_VH_attention_linear_output_loss: 1.9211 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4148\n",
      "Epoch 1335/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6706 - VL_attention_linear_output_loss: 1.7656 - VH_attention_linear_output_loss: 1.9050 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4191 - val_loss: 3.7370 - val_VL_attention_linear_output_loss: 1.7954 - val_VH_attention_linear_output_loss: 1.9416 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.3998\n",
      "Epoch 1336/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6776 - VL_attention_linear_output_loss: 1.7728 - VH_attention_linear_output_loss: 1.9048 - VL_attention_linear_output_acc: 0.4814 - VH_attention_linear_output_acc: 0.4197 - val_loss: 3.7326 - val_VL_attention_linear_output_loss: 1.8134 - val_VH_attention_linear_output_loss: 1.9192 - val_VL_attention_linear_output_acc: 0.4662 - val_VH_attention_linear_output_acc: 0.4167\n",
      "Epoch 1337/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6755 - VL_attention_linear_output_loss: 1.7782 - VH_attention_linear_output_loss: 1.8973 - VL_attention_linear_output_acc: 0.4779 - VH_attention_linear_output_acc: 0.4227 - val_loss: 3.7275 - val_VL_attention_linear_output_loss: 1.7942 - val_VH_attention_linear_output_loss: 1.9332 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4161\n",
      "Epoch 1338/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6816 - VL_attention_linear_output_loss: 1.7756 - VH_attention_linear_output_loss: 1.9060 - VL_attention_linear_output_acc: 0.4794 - VH_attention_linear_output_acc: 0.4185 - val_loss: 3.7092 - val_VL_attention_linear_output_loss: 1.7974 - val_VH_attention_linear_output_loss: 1.9119 - val_VL_attention_linear_output_acc: 0.4812 - val_VH_attention_linear_output_acc: 0.4202\n",
      "Epoch 1339/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6735 - VL_attention_linear_output_loss: 1.7721 - VH_attention_linear_output_loss: 1.9015 - VL_attention_linear_output_acc: 0.4817 - VH_attention_linear_output_acc: 0.4204 - val_loss: 3.7764 - val_VL_attention_linear_output_loss: 1.8654 - val_VH_attention_linear_output_loss: 1.9110 - val_VL_attention_linear_output_acc: 0.4468 - val_VH_attention_linear_output_acc: 0.4195\n",
      "Epoch 1340/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6769 - VL_attention_linear_output_loss: 1.7734 - VH_attention_linear_output_loss: 1.9035 - VL_attention_linear_output_acc: 0.4801 - VH_attention_linear_output_acc: 0.4197 - val_loss: 3.7294 - val_VL_attention_linear_output_loss: 1.8012 - val_VH_attention_linear_output_loss: 1.9282 - val_VL_attention_linear_output_acc: 0.4740 - val_VH_attention_linear_output_acc: 0.4162\n",
      "Epoch 1341/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6829 - VL_attention_linear_output_loss: 1.7749 - VH_attention_linear_output_loss: 1.9080 - VL_attention_linear_output_acc: 0.4786 - VH_attention_linear_output_acc: 0.4184 - val_loss: 3.7180 - val_VL_attention_linear_output_loss: 1.7979 - val_VH_attention_linear_output_loss: 1.9201 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4158\n",
      "Epoch 1342/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.7039 - VL_attention_linear_output_loss: 1.7985 - VH_attention_linear_output_loss: 1.9054 - VL_attention_linear_output_acc: 0.4689 - VH_attention_linear_output_acc: 0.4189 - val_loss: 3.7412 - val_VL_attention_linear_output_loss: 1.7980 - val_VH_attention_linear_output_loss: 1.9432 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4008\n",
      "Epoch 1343/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6810 - VL_attention_linear_output_loss: 1.7754 - VH_attention_linear_output_loss: 1.9056 - VL_attention_linear_output_acc: 0.4792 - VH_attention_linear_output_acc: 0.4190 - val_loss: 3.7388 - val_VL_attention_linear_output_loss: 1.7998 - val_VH_attention_linear_output_loss: 1.9389 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4131\n",
      "Epoch 1344/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6679 - VL_attention_linear_output_loss: 1.7671 - VH_attention_linear_output_loss: 1.9008 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4211 - val_loss: 3.7342 - val_VL_attention_linear_output_loss: 1.8093 - val_VH_attention_linear_output_loss: 1.9249 - val_VL_attention_linear_output_acc: 0.4735 - val_VH_attention_linear_output_acc: 0.4129\n",
      "Epoch 1345/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6700 - VL_attention_linear_output_loss: 1.7678 - VH_attention_linear_output_loss: 1.9022 - VL_attention_linear_output_acc: 0.4825 - VH_attention_linear_output_acc: 0.4214 - val_loss: 3.7304 - val_VL_attention_linear_output_loss: 1.7961 - val_VH_attention_linear_output_loss: 1.9343 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4113\n",
      "Epoch 1346/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6723 - VL_attention_linear_output_loss: 1.7715 - VH_attention_linear_output_loss: 1.9008 - VL_attention_linear_output_acc: 0.4812 - VH_attention_linear_output_acc: 0.4208 - val_loss: 3.7841 - val_VL_attention_linear_output_loss: 1.8497 - val_VH_attention_linear_output_loss: 1.9344 - val_VL_attention_linear_output_acc: 0.4510 - val_VH_attention_linear_output_acc: 0.4066\n",
      "Epoch 1347/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6928 - VL_attention_linear_output_loss: 1.7856 - VH_attention_linear_output_loss: 1.9071 - VL_attention_linear_output_acc: 0.4758 - VH_attention_linear_output_acc: 0.4183 - val_loss: 3.7109 - val_VL_attention_linear_output_loss: 1.7952 - val_VH_attention_linear_output_loss: 1.9157 - val_VL_attention_linear_output_acc: 0.4773 - val_VH_attention_linear_output_acc: 0.4175\n",
      "Epoch 1348/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6808 - VL_attention_linear_output_loss: 1.7788 - VH_attention_linear_output_loss: 1.9020 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.4209 - val_loss: 3.7083 - val_VL_attention_linear_output_loss: 1.8000 - val_VH_attention_linear_output_loss: 1.9082 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4190\n",
      "Epoch 1349/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6686 - VL_attention_linear_output_loss: 1.7722 - VH_attention_linear_output_loss: 1.8963 - VL_attention_linear_output_acc: 0.4811 - VH_attention_linear_output_acc: 0.4230 - val_loss: 3.7090 - val_VL_attention_linear_output_loss: 1.7954 - val_VH_attention_linear_output_loss: 1.9136 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4217\n",
      "Epoch 1350/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6796 - VL_attention_linear_output_loss: 1.7715 - VH_attention_linear_output_loss: 1.9081 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4181 - val_loss: 3.7274 - val_VL_attention_linear_output_loss: 1.8113 - val_VH_attention_linear_output_loss: 1.9161 - val_VL_attention_linear_output_acc: 0.4751 - val_VH_attention_linear_output_acc: 0.4175\n",
      "Epoch 1351/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6779 - VL_attention_linear_output_loss: 1.7804 - VH_attention_linear_output_loss: 1.8976 - VL_attention_linear_output_acc: 0.4765 - VH_attention_linear_output_acc: 0.4226 - val_loss: 3.7273 - val_VL_attention_linear_output_loss: 1.7940 - val_VH_attention_linear_output_loss: 1.9333 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4157\n",
      "Epoch 1352/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6723 - VL_attention_linear_output_loss: 1.7660 - VH_attention_linear_output_loss: 1.9063 - VL_attention_linear_output_acc: 0.4817 - VH_attention_linear_output_acc: 0.4192 - val_loss: 3.7321 - val_VL_attention_linear_output_loss: 1.7994 - val_VH_attention_linear_output_loss: 1.9326 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4096\n",
      "Epoch 1353/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6793 - VL_attention_linear_output_loss: 1.7717 - VH_attention_linear_output_loss: 1.9076 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4182 - val_loss: 3.7302 - val_VL_attention_linear_output_loss: 1.8078 - val_VH_attention_linear_output_loss: 1.9224 - val_VL_attention_linear_output_acc: 0.4742 - val_VH_attention_linear_output_acc: 0.4191\n",
      "Epoch 1354/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6699 - VL_attention_linear_output_loss: 1.7730 - VH_attention_linear_output_loss: 1.8970 - VL_attention_linear_output_acc: 0.4804 - VH_attention_linear_output_acc: 0.4227 - val_loss: 3.7212 - val_VL_attention_linear_output_loss: 1.8007 - val_VH_attention_linear_output_loss: 1.9206 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4162\n",
      "Epoch 1355/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6847 - VL_attention_linear_output_loss: 1.7815 - VH_attention_linear_output_loss: 1.9032 - VL_attention_linear_output_acc: 0.4761 - VH_attention_linear_output_acc: 0.4206 - val_loss: 3.7183 - val_VL_attention_linear_output_loss: 1.8071 - val_VH_attention_linear_output_loss: 1.9112 - val_VL_attention_linear_output_acc: 0.4725 - val_VH_attention_linear_output_acc: 0.4202\n",
      "Epoch 1356/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6654 - VL_attention_linear_output_loss: 1.7661 - VH_attention_linear_output_loss: 1.8993 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4221 - val_loss: 3.7049 - val_VL_attention_linear_output_loss: 1.7970 - val_VH_attention_linear_output_loss: 1.9079 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4184\n",
      "Epoch 1357/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6723 - VL_attention_linear_output_loss: 1.7782 - VH_attention_linear_output_loss: 1.8941 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.4242 - val_loss: 3.7549 - val_VL_attention_linear_output_loss: 1.8336 - val_VH_attention_linear_output_loss: 1.9213 - val_VL_attention_linear_output_acc: 0.4569 - val_VH_attention_linear_output_acc: 0.4199\n",
      "Epoch 1358/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6648 - VL_attention_linear_output_loss: 1.7740 - VH_attention_linear_output_loss: 1.8908 - VL_attention_linear_output_acc: 0.4797 - VH_attention_linear_output_acc: 0.4249 - val_loss: 3.7103 - val_VL_attention_linear_output_loss: 1.8007 - val_VH_attention_linear_output_loss: 1.9096 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.4199\n",
      "Epoch 1359/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6691 - VL_attention_linear_output_loss: 1.7673 - VH_attention_linear_output_loss: 1.9018 - VL_attention_linear_output_acc: 0.4814 - VH_attention_linear_output_acc: 0.4211 - val_loss: 3.7312 - val_VL_attention_linear_output_loss: 1.8261 - val_VH_attention_linear_output_loss: 1.9052 - val_VL_attention_linear_output_acc: 0.4619 - val_VH_attention_linear_output_acc: 0.4220\n",
      "Epoch 1360/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6780 - VL_attention_linear_output_loss: 1.7733 - VH_attention_linear_output_loss: 1.9046 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4196 - val_loss: 3.7273 - val_VL_attention_linear_output_loss: 1.8110 - val_VH_attention_linear_output_loss: 1.9163 - val_VL_attention_linear_output_acc: 0.4673 - val_VH_attention_linear_output_acc: 0.4165\n",
      "Epoch 1361/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6777 - VL_attention_linear_output_loss: 1.7829 - VH_attention_linear_output_loss: 1.8948 - VL_attention_linear_output_acc: 0.4760 - VH_attention_linear_output_acc: 0.4239 - val_loss: 3.7452 - val_VL_attention_linear_output_loss: 1.8203 - val_VH_attention_linear_output_loss: 1.9249 - val_VL_attention_linear_output_acc: 0.4667 - val_VH_attention_linear_output_acc: 0.4121\n",
      "Epoch 1362/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6820 - VL_attention_linear_output_loss: 1.7791 - VH_attention_linear_output_loss: 1.9029 - VL_attention_linear_output_acc: 0.4770 - VH_attention_linear_output_acc: 0.4196 - val_loss: 3.7119 - val_VL_attention_linear_output_loss: 1.7952 - val_VH_attention_linear_output_loss: 1.9167 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4217\n",
      "Epoch 1363/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6661 - VL_attention_linear_output_loss: 1.7740 - VH_attention_linear_output_loss: 1.8921 - VL_attention_linear_output_acc: 0.4786 - VH_attention_linear_output_acc: 0.4248 - val_loss: 3.7164 - val_VL_attention_linear_output_loss: 1.7977 - val_VH_attention_linear_output_loss: 1.9187 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4194\n",
      "Epoch 1364/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6755 - VL_attention_linear_output_loss: 1.7712 - VH_attention_linear_output_loss: 1.9043 - VL_attention_linear_output_acc: 0.4811 - VH_attention_linear_output_acc: 0.4195 - val_loss: 3.7259 - val_VL_attention_linear_output_loss: 1.8216 - val_VH_attention_linear_output_loss: 1.9044 - val_VL_attention_linear_output_acc: 0.4664 - val_VH_attention_linear_output_acc: 0.4194\n",
      "Epoch 1365/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6804 - VL_attention_linear_output_loss: 1.7840 - VH_attention_linear_output_loss: 1.8964 - VL_attention_linear_output_acc: 0.4756 - VH_attention_linear_output_acc: 0.4228 - val_loss: 3.7176 - val_VL_attention_linear_output_loss: 1.7941 - val_VH_attention_linear_output_loss: 1.9235 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4113\n",
      "Epoch 1366/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6755 - VL_attention_linear_output_loss: 1.7769 - VH_attention_linear_output_loss: 1.8987 - VL_attention_linear_output_acc: 0.4768 - VH_attention_linear_output_acc: 0.4222 - val_loss: 3.7042 - val_VL_attention_linear_output_loss: 1.7969 - val_VH_attention_linear_output_loss: 1.9073 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4228\n",
      "Epoch 1367/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6748 - VL_attention_linear_output_loss: 1.7767 - VH_attention_linear_output_loss: 1.8981 - VL_attention_linear_output_acc: 0.4784 - VH_attention_linear_output_acc: 0.4220 - val_loss: 3.7214 - val_VL_attention_linear_output_loss: 1.8043 - val_VH_attention_linear_output_loss: 1.9171 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4195\n",
      "Epoch 1368/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6750 - VL_attention_linear_output_loss: 1.7810 - VH_attention_linear_output_loss: 1.8940 - VL_attention_linear_output_acc: 0.4765 - VH_attention_linear_output_acc: 0.4236 - val_loss: 3.7094 - val_VL_attention_linear_output_loss: 1.8022 - val_VH_attention_linear_output_loss: 1.9072 - val_VL_attention_linear_output_acc: 0.4780 - val_VH_attention_linear_output_acc: 0.4219\n",
      "Epoch 1369/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6714 - VL_attention_linear_output_loss: 1.7742 - VH_attention_linear_output_loss: 1.8972 - VL_attention_linear_output_acc: 0.4792 - VH_attention_linear_output_acc: 0.4224 - val_loss: 3.7183 - val_VL_attention_linear_output_loss: 1.7974 - val_VH_attention_linear_output_loss: 1.9209 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4205\n",
      "Epoch 1370/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6590 - VL_attention_linear_output_loss: 1.7701 - VH_attention_linear_output_loss: 1.8889 - VL_attention_linear_output_acc: 0.4826 - VH_attention_linear_output_acc: 0.4259 - val_loss: 3.7082 - val_VL_attention_linear_output_loss: 1.7968 - val_VH_attention_linear_output_loss: 1.9114 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4162\n",
      "Epoch 1371/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6777 - VL_attention_linear_output_loss: 1.7788 - VH_attention_linear_output_loss: 1.8988 - VL_attention_linear_output_acc: 0.4766 - VH_attention_linear_output_acc: 0.4216 - val_loss: 3.7053 - val_VL_attention_linear_output_loss: 1.8007 - val_VH_attention_linear_output_loss: 1.9046 - val_VL_attention_linear_output_acc: 0.4695 - val_VH_attention_linear_output_acc: 0.4238\n",
      "Epoch 1372/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6620 - VL_attention_linear_output_loss: 1.7688 - VH_attention_linear_output_loss: 1.8933 - VL_attention_linear_output_acc: 0.4820 - VH_attention_linear_output_acc: 0.4237 - val_loss: 3.8217 - val_VL_attention_linear_output_loss: 1.9143 - val_VH_attention_linear_output_loss: 1.9073 - val_VL_attention_linear_output_acc: 0.4172 - val_VH_attention_linear_output_acc: 0.4215\n",
      "Epoch 1373/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6693 - VL_attention_linear_output_loss: 1.7808 - VH_attention_linear_output_loss: 1.8885 - VL_attention_linear_output_acc: 0.4765 - VH_attention_linear_output_acc: 0.4259 - val_loss: 3.7058 - val_VL_attention_linear_output_loss: 1.7973 - val_VH_attention_linear_output_loss: 1.9084 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4192\n",
      "Epoch 1374/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6603 - VL_attention_linear_output_loss: 1.7663 - VH_attention_linear_output_loss: 1.8940 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4233 - val_loss: 3.7086 - val_VL_attention_linear_output_loss: 1.7974 - val_VH_attention_linear_output_loss: 1.9111 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4190\n",
      "Epoch 1375/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6636 - VL_attention_linear_output_loss: 1.7675 - VH_attention_linear_output_loss: 1.8961 - VL_attention_linear_output_acc: 0.4822 - VH_attention_linear_output_acc: 0.4235 - val_loss: 3.7776 - val_VL_attention_linear_output_loss: 1.8343 - val_VH_attention_linear_output_loss: 1.9433 - val_VL_attention_linear_output_acc: 0.4630 - val_VH_attention_linear_output_acc: 0.4027\n",
      "Epoch 1376/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6800 - VL_attention_linear_output_loss: 1.7772 - VH_attention_linear_output_loss: 1.9028 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.4203 - val_loss: 3.7063 - val_VL_attention_linear_output_loss: 1.7938 - val_VH_attention_linear_output_loss: 1.9125 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.4183\n",
      "Epoch 1377/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6682 - VL_attention_linear_output_loss: 1.7733 - VH_attention_linear_output_loss: 1.8950 - VL_attention_linear_output_acc: 0.4794 - VH_attention_linear_output_acc: 0.4242 - val_loss: 3.7200 - val_VL_attention_linear_output_loss: 1.7931 - val_VH_attention_linear_output_loss: 1.9269 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4092\n",
      "Epoch 1378/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6856 - VL_attention_linear_output_loss: 1.7742 - VH_attention_linear_output_loss: 1.9114 - VL_attention_linear_output_acc: 0.4796 - VH_attention_linear_output_acc: 0.4172 - val_loss: 3.7447 - val_VL_attention_linear_output_loss: 1.8187 - val_VH_attention_linear_output_loss: 1.9260 - val_VL_attention_linear_output_acc: 0.4657 - val_VH_attention_linear_output_acc: 0.4154\n",
      "Epoch 1379/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6770 - VL_attention_linear_output_loss: 1.7793 - VH_attention_linear_output_loss: 1.8977 - VL_attention_linear_output_acc: 0.4776 - VH_attention_linear_output_acc: 0.4223 - val_loss: 3.7415 - val_VL_attention_linear_output_loss: 1.7949 - val_VH_attention_linear_output_loss: 1.9466 - val_VL_attention_linear_output_acc: 0.4814 - val_VH_attention_linear_output_acc: 0.4041\n",
      "Epoch 1380/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6489 - VL_attention_linear_output_loss: 1.7625 - VH_attention_linear_output_loss: 1.8865 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4266 - val_loss: 3.7166 - val_VL_attention_linear_output_loss: 1.7979 - val_VH_attention_linear_output_loss: 1.9187 - val_VL_attention_linear_output_acc: 0.4781 - val_VH_attention_linear_output_acc: 0.4151\n",
      "Epoch 1381/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6588 - VL_attention_linear_output_loss: 1.7657 - VH_attention_linear_output_loss: 1.8931 - VL_attention_linear_output_acc: 0.4832 - VH_attention_linear_output_acc: 0.4239 - val_loss: 3.7365 - val_VL_attention_linear_output_loss: 1.8023 - val_VH_attention_linear_output_loss: 1.9342 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.4042\n",
      "Epoch 1382/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6720 - VL_attention_linear_output_loss: 1.7776 - VH_attention_linear_output_loss: 1.8944 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.4237 - val_loss: 3.7590 - val_VL_attention_linear_output_loss: 1.8454 - val_VH_attention_linear_output_loss: 1.9136 - val_VL_attention_linear_output_acc: 0.4557 - val_VH_attention_linear_output_acc: 0.4202\n",
      "Epoch 1383/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6785 - VL_attention_linear_output_loss: 1.7799 - VH_attention_linear_output_loss: 1.8986 - VL_attention_linear_output_acc: 0.4767 - VH_attention_linear_output_acc: 0.4224 - val_loss: 3.7010 - val_VL_attention_linear_output_loss: 1.7939 - val_VH_attention_linear_output_loss: 1.9071 - val_VL_attention_linear_output_acc: 0.4781 - val_VH_attention_linear_output_acc: 0.4220\n",
      "Epoch 1384/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6652 - VL_attention_linear_output_loss: 1.7771 - VH_attention_linear_output_loss: 1.8880 - VL_attention_linear_output_acc: 0.4789 - VH_attention_linear_output_acc: 0.4266 - val_loss: 3.7506 - val_VL_attention_linear_output_loss: 1.7971 - val_VH_attention_linear_output_loss: 1.9534 - val_VL_attention_linear_output_acc: 0.4748 - val_VH_attention_linear_output_acc: 0.4055\n",
      "Epoch 1385/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6704 - VL_attention_linear_output_loss: 1.7771 - VH_attention_linear_output_loss: 1.8933 - VL_attention_linear_output_acc: 0.4783 - VH_attention_linear_output_acc: 0.4240 - val_loss: 3.7179 - val_VL_attention_linear_output_loss: 1.8072 - val_VH_attention_linear_output_loss: 1.9107 - val_VL_attention_linear_output_acc: 0.4777 - val_VH_attention_linear_output_acc: 0.4192\n",
      "Epoch 1386/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6901 - VL_attention_linear_output_loss: 1.7826 - VH_attention_linear_output_loss: 1.9076 - VL_attention_linear_output_acc: 0.4757 - VH_attention_linear_output_acc: 0.4190 - val_loss: 3.7093 - val_VL_attention_linear_output_loss: 1.8023 - val_VH_attention_linear_output_loss: 1.9070 - val_VL_attention_linear_output_acc: 0.4782 - val_VH_attention_linear_output_acc: 0.4221\n",
      "Epoch 1387/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6749 - VL_attention_linear_output_loss: 1.7782 - VH_attention_linear_output_loss: 1.8967 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4226 - val_loss: 3.7190 - val_VL_attention_linear_output_loss: 1.8098 - val_VH_attention_linear_output_loss: 1.9092 - val_VL_attention_linear_output_acc: 0.4671 - val_VH_attention_linear_output_acc: 0.4200\n",
      "Epoch 1388/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6886 - VL_attention_linear_output_loss: 1.7949 - VH_attention_linear_output_loss: 1.8938 - VL_attention_linear_output_acc: 0.4690 - VH_attention_linear_output_acc: 0.4236 - val_loss: 3.7138 - val_VL_attention_linear_output_loss: 1.8051 - val_VH_attention_linear_output_loss: 1.9087 - val_VL_attention_linear_output_acc: 0.4742 - val_VH_attention_linear_output_acc: 0.4240\n",
      "Epoch 1389/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6628 - VL_attention_linear_output_loss: 1.7709 - VH_attention_linear_output_loss: 1.8918 - VL_attention_linear_output_acc: 0.4804 - VH_attention_linear_output_acc: 0.4247 - val_loss: 3.7093 - val_VL_attention_linear_output_loss: 1.8092 - val_VH_attention_linear_output_loss: 1.9001 - val_VL_attention_linear_output_acc: 0.4729 - val_VH_attention_linear_output_acc: 0.4222\n",
      "Epoch 1390/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6610 - VL_attention_linear_output_loss: 1.7712 - VH_attention_linear_output_loss: 1.8897 - VL_attention_linear_output_acc: 0.4812 - VH_attention_linear_output_acc: 0.4250 - val_loss: 3.7406 - val_VL_attention_linear_output_loss: 1.8114 - val_VH_attention_linear_output_loss: 1.9292 - val_VL_attention_linear_output_acc: 0.4640 - val_VH_attention_linear_output_acc: 0.4173\n",
      "Epoch 1391/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6664 - VL_attention_linear_output_loss: 1.7769 - VH_attention_linear_output_loss: 1.8894 - VL_attention_linear_output_acc: 0.4779 - VH_attention_linear_output_acc: 0.4260 - val_loss: 3.7023 - val_VL_attention_linear_output_loss: 1.7978 - val_VH_attention_linear_output_loss: 1.9045 - val_VL_attention_linear_output_acc: 0.4784 - val_VH_attention_linear_output_acc: 0.4265\n",
      "Epoch 1392/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6725 - VL_attention_linear_output_loss: 1.7651 - VH_attention_linear_output_loss: 1.9074 - VL_attention_linear_output_acc: 0.4837 - VH_attention_linear_output_acc: 0.4178 - val_loss: 3.7068 - val_VL_attention_linear_output_loss: 1.8025 - val_VH_attention_linear_output_loss: 1.9043 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4241\n",
      "Epoch 1393/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6754 - VL_attention_linear_output_loss: 1.7787 - VH_attention_linear_output_loss: 1.8967 - VL_attention_linear_output_acc: 0.4768 - VH_attention_linear_output_acc: 0.4229 - val_loss: 3.6911 - val_VL_attention_linear_output_loss: 1.7926 - val_VH_attention_linear_output_loss: 1.8985 - val_VL_attention_linear_output_acc: 0.4773 - val_VH_attention_linear_output_acc: 0.4228\n",
      "Epoch 1394/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6565 - VL_attention_linear_output_loss: 1.7633 - VH_attention_linear_output_loss: 1.8932 - VL_attention_linear_output_acc: 0.4849 - VH_attention_linear_output_acc: 0.4242 - val_loss: 3.7212 - val_VL_attention_linear_output_loss: 1.7947 - val_VH_attention_linear_output_loss: 1.9265 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4078\n",
      "Epoch 1395/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6491 - VL_attention_linear_output_loss: 1.7642 - VH_attention_linear_output_loss: 1.8849 - VL_attention_linear_output_acc: 0.4835 - VH_attention_linear_output_acc: 0.4275 - val_loss: 3.7077 - val_VL_attention_linear_output_loss: 1.8007 - val_VH_attention_linear_output_loss: 1.9070 - val_VL_attention_linear_output_acc: 0.4764 - val_VH_attention_linear_output_acc: 0.4191\n",
      "Epoch 1396/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6587 - VL_attention_linear_output_loss: 1.7691 - VH_attention_linear_output_loss: 1.8896 - VL_attention_linear_output_acc: 0.4820 - VH_attention_linear_output_acc: 0.4253 - val_loss: 3.7282 - val_VL_attention_linear_output_loss: 1.8191 - val_VH_attention_linear_output_loss: 1.9091 - val_VL_attention_linear_output_acc: 0.4669 - val_VH_attention_linear_output_acc: 0.4209\n",
      "Epoch 1397/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6835 - VL_attention_linear_output_loss: 1.7827 - VH_attention_linear_output_loss: 1.9008 - VL_attention_linear_output_acc: 0.4747 - VH_attention_linear_output_acc: 0.4210 - val_loss: 3.7088 - val_VL_attention_linear_output_loss: 1.7923 - val_VH_attention_linear_output_loss: 1.9165 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4195\n",
      "Epoch 1398/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6594 - VL_attention_linear_output_loss: 1.7657 - VH_attention_linear_output_loss: 1.8938 - VL_attention_linear_output_acc: 0.4823 - VH_attention_linear_output_acc: 0.4237 - val_loss: 3.7042 - val_VL_attention_linear_output_loss: 1.7957 - val_VH_attention_linear_output_loss: 1.9085 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4201\n",
      "Epoch 1399/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6733 - VL_attention_linear_output_loss: 1.7831 - VH_attention_linear_output_loss: 1.8902 - VL_attention_linear_output_acc: 0.4756 - VH_attention_linear_output_acc: 0.4254 - val_loss: 3.7207 - val_VL_attention_linear_output_loss: 1.7990 - val_VH_attention_linear_output_loss: 1.9217 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4166\n",
      "Epoch 1400/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6756 - VL_attention_linear_output_loss: 1.7766 - VH_attention_linear_output_loss: 1.8990 - VL_attention_linear_output_acc: 0.4774 - VH_attention_linear_output_acc: 0.4222 - val_loss: 3.7436 - val_VL_attention_linear_output_loss: 1.8254 - val_VH_attention_linear_output_loss: 1.9182 - val_VL_attention_linear_output_acc: 0.4669 - val_VH_attention_linear_output_acc: 0.4206\n",
      "Epoch 1401/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6734 - VL_attention_linear_output_loss: 1.7791 - VH_attention_linear_output_loss: 1.8943 - VL_attention_linear_output_acc: 0.4773 - VH_attention_linear_output_acc: 0.4243 - val_loss: 3.7576 - val_VL_attention_linear_output_loss: 1.7992 - val_VH_attention_linear_output_loss: 1.9584 - val_VL_attention_linear_output_acc: 0.4805 - val_VH_attention_linear_output_acc: 0.4002\n",
      "Epoch 1402/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6658 - VL_attention_linear_output_loss: 1.7697 - VH_attention_linear_output_loss: 1.8961 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4244 - val_loss: 3.7058 - val_VL_attention_linear_output_loss: 1.8014 - val_VH_attention_linear_output_loss: 1.9045 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4200\n",
      "Epoch 1403/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6603 - VL_attention_linear_output_loss: 1.7737 - VH_attention_linear_output_loss: 1.8866 - VL_attention_linear_output_acc: 0.4801 - VH_attention_linear_output_acc: 0.4269 - val_loss: 3.7026 - val_VL_attention_linear_output_loss: 1.7935 - val_VH_attention_linear_output_loss: 1.9092 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4242\n",
      "Epoch 1404/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6538 - VL_attention_linear_output_loss: 1.7666 - VH_attention_linear_output_loss: 1.8873 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4266 - val_loss: 3.7135 - val_VL_attention_linear_output_loss: 1.7968 - val_VH_attention_linear_output_loss: 1.9167 - val_VL_attention_linear_output_acc: 0.4747 - val_VH_attention_linear_output_acc: 0.4145\n",
      "Epoch 1405/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6709 - VL_attention_linear_output_loss: 1.7871 - VH_attention_linear_output_loss: 1.8838 - VL_attention_linear_output_acc: 0.4733 - VH_attention_linear_output_acc: 0.4278 - val_loss: 3.7037 - val_VL_attention_linear_output_loss: 1.8000 - val_VH_attention_linear_output_loss: 1.9037 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4246\n",
      "Epoch 1406/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6551 - VL_attention_linear_output_loss: 1.7686 - VH_attention_linear_output_loss: 1.8865 - VL_attention_linear_output_acc: 0.4813 - VH_attention_linear_output_acc: 0.4269 - val_loss: 3.6994 - val_VL_attention_linear_output_loss: 1.7977 - val_VH_attention_linear_output_loss: 1.9017 - val_VL_attention_linear_output_acc: 0.4754 - val_VH_attention_linear_output_acc: 0.4245\n",
      "Epoch 1407/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6590 - VL_attention_linear_output_loss: 1.7650 - VH_attention_linear_output_loss: 1.8940 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4243 - val_loss: 3.7057 - val_VL_attention_linear_output_loss: 1.7985 - val_VH_attention_linear_output_loss: 1.9073 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4183\n",
      "Epoch 1408/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6570 - VL_attention_linear_output_loss: 1.7698 - VH_attention_linear_output_loss: 1.8872 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4269 - val_loss: 3.7033 - val_VL_attention_linear_output_loss: 1.7915 - val_VH_attention_linear_output_loss: 1.9118 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4227\n",
      "Epoch 1409/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6648 - VL_attention_linear_output_loss: 1.7823 - VH_attention_linear_output_loss: 1.8825 - VL_attention_linear_output_acc: 0.4746 - VH_attention_linear_output_acc: 0.4291 - val_loss: 3.7342 - val_VL_attention_linear_output_loss: 1.8304 - val_VH_attention_linear_output_loss: 1.9038 - val_VL_attention_linear_output_acc: 0.4623 - val_VH_attention_linear_output_acc: 0.4220\n",
      "Epoch 1410/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6756 - VL_attention_linear_output_loss: 1.7763 - VH_attention_linear_output_loss: 1.8993 - VL_attention_linear_output_acc: 0.4775 - VH_attention_linear_output_acc: 0.4228 - val_loss: 3.6974 - val_VL_attention_linear_output_loss: 1.7937 - val_VH_attention_linear_output_loss: 1.9037 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4235\n",
      "Epoch 1411/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6441 - VL_attention_linear_output_loss: 1.7616 - VH_attention_linear_output_loss: 1.8825 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4294 - val_loss: 3.7237 - val_VL_attention_linear_output_loss: 1.8133 - val_VH_attention_linear_output_loss: 1.9104 - val_VL_attention_linear_output_acc: 0.4633 - val_VH_attention_linear_output_acc: 0.4190\n",
      "Epoch 1412/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6557 - VL_attention_linear_output_loss: 1.7699 - VH_attention_linear_output_loss: 1.8858 - VL_attention_linear_output_acc: 0.4810 - VH_attention_linear_output_acc: 0.4274 - val_loss: 3.6942 - val_VL_attention_linear_output_loss: 1.7929 - val_VH_attention_linear_output_loss: 1.9013 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4261\n",
      "Epoch 1413/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6554 - VL_attention_linear_output_loss: 1.7709 - VH_attention_linear_output_loss: 1.8845 - VL_attention_linear_output_acc: 0.4817 - VH_attention_linear_output_acc: 0.4280 - val_loss: 3.7328 - val_VL_attention_linear_output_loss: 1.8219 - val_VH_attention_linear_output_loss: 1.9109 - val_VL_attention_linear_output_acc: 0.4704 - val_VH_attention_linear_output_acc: 0.4230\n",
      "Epoch 1414/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6727 - VL_attention_linear_output_loss: 1.7856 - VH_attention_linear_output_loss: 1.8871 - VL_attention_linear_output_acc: 0.4736 - VH_attention_linear_output_acc: 0.4271 - val_loss: 3.7179 - val_VL_attention_linear_output_loss: 1.8069 - val_VH_attention_linear_output_loss: 1.9110 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.4235\n",
      "Epoch 1415/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6612 - VL_attention_linear_output_loss: 1.7695 - VH_attention_linear_output_loss: 1.8917 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4247 - val_loss: 3.7348 - val_VL_attention_linear_output_loss: 1.8150 - val_VH_attention_linear_output_loss: 1.9199 - val_VL_attention_linear_output_acc: 0.4639 - val_VH_attention_linear_output_acc: 0.4213\n",
      "Epoch 1416/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6587 - VL_attention_linear_output_loss: 1.7701 - VH_attention_linear_output_loss: 1.8886 - VL_attention_linear_output_acc: 0.4797 - VH_attention_linear_output_acc: 0.4257 - val_loss: 3.7058 - val_VL_attention_linear_output_loss: 1.8018 - val_VH_attention_linear_output_loss: 1.9040 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.4270\n",
      "Epoch 1417/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6453 - VL_attention_linear_output_loss: 1.7631 - VH_attention_linear_output_loss: 1.8822 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4286 - val_loss: 3.7073 - val_VL_attention_linear_output_loss: 1.7939 - val_VH_attention_linear_output_loss: 1.9134 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4215\n",
      "Epoch 1418/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6583 - VL_attention_linear_output_loss: 1.7740 - VH_attention_linear_output_loss: 1.8843 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.4282 - val_loss: 3.7097 - val_VL_attention_linear_output_loss: 1.7993 - val_VH_attention_linear_output_loss: 1.9104 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4194\n",
      "Epoch 1419/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6566 - VL_attention_linear_output_loss: 1.7724 - VH_attention_linear_output_loss: 1.8842 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.4282 - val_loss: 3.7279 - val_VL_attention_linear_output_loss: 1.8061 - val_VH_attention_linear_output_loss: 1.9218 - val_VL_attention_linear_output_acc: 0.4751 - val_VH_attention_linear_output_acc: 0.4184\n",
      "Epoch 1420/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6550 - VL_attention_linear_output_loss: 1.7705 - VH_attention_linear_output_loss: 1.8845 - VL_attention_linear_output_acc: 0.4804 - VH_attention_linear_output_acc: 0.4274 - val_loss: 3.7063 - val_VL_attention_linear_output_loss: 1.7995 - val_VH_attention_linear_output_loss: 1.9068 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4187\n",
      "Epoch 1421/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6526 - VL_attention_linear_output_loss: 1.7661 - VH_attention_linear_output_loss: 1.8865 - VL_attention_linear_output_acc: 0.4833 - VH_attention_linear_output_acc: 0.4270 - val_loss: 3.7132 - val_VL_attention_linear_output_loss: 1.7969 - val_VH_attention_linear_output_loss: 1.9164 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4192\n",
      "Epoch 1422/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6576 - VL_attention_linear_output_loss: 1.7750 - VH_attention_linear_output_loss: 1.8826 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.4282 - val_loss: 3.7202 - val_VL_attention_linear_output_loss: 1.8184 - val_VH_attention_linear_output_loss: 1.9018 - val_VL_attention_linear_output_acc: 0.4682 - val_VH_attention_linear_output_acc: 0.4278\n",
      "Epoch 1423/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6721 - VL_attention_linear_output_loss: 1.7879 - VH_attention_linear_output_loss: 1.8842 - VL_attention_linear_output_acc: 0.4720 - VH_attention_linear_output_acc: 0.4283 - val_loss: 3.7244 - val_VL_attention_linear_output_loss: 1.7974 - val_VH_attention_linear_output_loss: 1.9270 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.4190\n",
      "Epoch 1424/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6420 - VL_attention_linear_output_loss: 1.7615 - VH_attention_linear_output_loss: 1.8805 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4303 - val_loss: 3.6953 - val_VL_attention_linear_output_loss: 1.7968 - val_VH_attention_linear_output_loss: 1.8985 - val_VL_attention_linear_output_acc: 0.4738 - val_VH_attention_linear_output_acc: 0.4285\n",
      "Epoch 1425/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6436 - VL_attention_linear_output_loss: 1.7640 - VH_attention_linear_output_loss: 1.8797 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4301 - val_loss: 3.7008 - val_VL_attention_linear_output_loss: 1.7959 - val_VH_attention_linear_output_loss: 1.9049 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4263\n",
      "Epoch 1426/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6460 - VL_attention_linear_output_loss: 1.7648 - VH_attention_linear_output_loss: 1.8811 - VL_attention_linear_output_acc: 0.4837 - VH_attention_linear_output_acc: 0.4295 - val_loss: 3.6934 - val_VL_attention_linear_output_loss: 1.7941 - val_VH_attention_linear_output_loss: 1.8993 - val_VL_attention_linear_output_acc: 0.4743 - val_VH_attention_linear_output_acc: 0.4244\n",
      "Epoch 1427/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6440 - VL_attention_linear_output_loss: 1.7663 - VH_attention_linear_output_loss: 1.8777 - VL_attention_linear_output_acc: 0.4817 - VH_attention_linear_output_acc: 0.4307 - val_loss: 3.7230 - val_VL_attention_linear_output_loss: 1.7959 - val_VH_attention_linear_output_loss: 1.9271 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4091\n",
      "Epoch 1428/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6654 - VL_attention_linear_output_loss: 1.7825 - VH_attention_linear_output_loss: 1.8829 - VL_attention_linear_output_acc: 0.4749 - VH_attention_linear_output_acc: 0.4282 - val_loss: 3.7374 - val_VL_attention_linear_output_loss: 1.7974 - val_VH_attention_linear_output_loss: 1.9400 - val_VL_attention_linear_output_acc: 0.4793 - val_VH_attention_linear_output_acc: 0.4135\n",
      "Epoch 1429/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6431 - VL_attention_linear_output_loss: 1.7662 - VH_attention_linear_output_loss: 1.8769 - VL_attention_linear_output_acc: 0.4829 - VH_attention_linear_output_acc: 0.4306 - val_loss: 3.6879 - val_VL_attention_linear_output_loss: 1.7915 - val_VH_attention_linear_output_loss: 1.8964 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4279\n",
      "Epoch 1430/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6390 - VL_attention_linear_output_loss: 1.7594 - VH_attention_linear_output_loss: 1.8795 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4302 - val_loss: 3.7277 - val_VL_attention_linear_output_loss: 1.8159 - val_VH_attention_linear_output_loss: 1.9118 - val_VL_attention_linear_output_acc: 0.4703 - val_VH_attention_linear_output_acc: 0.4185\n",
      "Epoch 1431/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6456 - VL_attention_linear_output_loss: 1.7672 - VH_attention_linear_output_loss: 1.8784 - VL_attention_linear_output_acc: 0.4817 - VH_attention_linear_output_acc: 0.4306 - val_loss: 3.6953 - val_VL_attention_linear_output_loss: 1.7974 - val_VH_attention_linear_output_loss: 1.8979 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4283\n",
      "Epoch 1432/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6492 - VL_attention_linear_output_loss: 1.7648 - VH_attention_linear_output_loss: 1.8843 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4275 - val_loss: 3.6997 - val_VL_attention_linear_output_loss: 1.7977 - val_VH_attention_linear_output_loss: 1.9020 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4223\n",
      "Epoch 1433/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6695 - VL_attention_linear_output_loss: 1.7822 - VH_attention_linear_output_loss: 1.8872 - VL_attention_linear_output_acc: 0.4760 - VH_attention_linear_output_acc: 0.4266 - val_loss: 3.7007 - val_VL_attention_linear_output_loss: 1.7976 - val_VH_attention_linear_output_loss: 1.9032 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4231\n",
      "Epoch 1434/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6468 - VL_attention_linear_output_loss: 1.7642 - VH_attention_linear_output_loss: 1.8827 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4291 - val_loss: 3.7018 - val_VL_attention_linear_output_loss: 1.8080 - val_VH_attention_linear_output_loss: 1.8938 - val_VL_attention_linear_output_acc: 0.4764 - val_VH_attention_linear_output_acc: 0.4285\n",
      "Epoch 1435/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6559 - VL_attention_linear_output_loss: 1.7778 - VH_attention_linear_output_loss: 1.8781 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.4303 - val_loss: 3.7078 - val_VL_attention_linear_output_loss: 1.8090 - val_VH_attention_linear_output_loss: 1.8988 - val_VL_attention_linear_output_acc: 0.4738 - val_VH_attention_linear_output_acc: 0.4275\n",
      "Epoch 1436/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6439 - VL_attention_linear_output_loss: 1.7614 - VH_attention_linear_output_loss: 1.8826 - VL_attention_linear_output_acc: 0.4848 - VH_attention_linear_output_acc: 0.4287 - val_loss: 3.7094 - val_VL_attention_linear_output_loss: 1.7966 - val_VH_attention_linear_output_loss: 1.9129 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4199\n",
      "Epoch 1437/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6501 - VL_attention_linear_output_loss: 1.7644 - VH_attention_linear_output_loss: 1.8857 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4270 - val_loss: 3.6962 - val_VL_attention_linear_output_loss: 1.7947 - val_VH_attention_linear_output_loss: 1.9015 - val_VL_attention_linear_output_acc: 0.4735 - val_VH_attention_linear_output_acc: 0.4238\n",
      "Epoch 1438/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6480 - VL_attention_linear_output_loss: 1.7706 - VH_attention_linear_output_loss: 1.8774 - VL_attention_linear_output_acc: 0.4798 - VH_attention_linear_output_acc: 0.4308 - val_loss: 3.7479 - val_VL_attention_linear_output_loss: 1.7982 - val_VH_attention_linear_output_loss: 1.9497 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4021\n",
      "Epoch 1439/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6585 - VL_attention_linear_output_loss: 1.7735 - VH_attention_linear_output_loss: 1.8850 - VL_attention_linear_output_acc: 0.4794 - VH_attention_linear_output_acc: 0.4280 - val_loss: 3.7020 - val_VL_attention_linear_output_loss: 1.7914 - val_VH_attention_linear_output_loss: 1.9106 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4210\n",
      "Epoch 1440/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6567 - VL_attention_linear_output_loss: 1.7657 - VH_attention_linear_output_loss: 1.8910 - VL_attention_linear_output_acc: 0.4824 - VH_attention_linear_output_acc: 0.4242 - val_loss: 3.7918 - val_VL_attention_linear_output_loss: 1.8055 - val_VH_attention_linear_output_loss: 1.9863 - val_VL_attention_linear_output_acc: 0.4717 - val_VH_attention_linear_output_acc: 0.3819\n",
      "Epoch 1441/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6571 - VL_attention_linear_output_loss: 1.7723 - VH_attention_linear_output_loss: 1.8848 - VL_attention_linear_output_acc: 0.4795 - VH_attention_linear_output_acc: 0.4273 - val_loss: 3.7211 - val_VL_attention_linear_output_loss: 1.7939 - val_VH_attention_linear_output_loss: 1.9272 - val_VL_attention_linear_output_acc: 0.4779 - val_VH_attention_linear_output_acc: 0.4064\n",
      "Epoch 1442/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6580 - VL_attention_linear_output_loss: 1.7715 - VH_attention_linear_output_loss: 1.8865 - VL_attention_linear_output_acc: 0.4813 - VH_attention_linear_output_acc: 0.4271 - val_loss: 3.7081 - val_VL_attention_linear_output_loss: 1.8016 - val_VH_attention_linear_output_loss: 1.9064 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4262\n",
      "Epoch 1443/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6557 - VL_attention_linear_output_loss: 1.7761 - VH_attention_linear_output_loss: 1.8796 - VL_attention_linear_output_acc: 0.4782 - VH_attention_linear_output_acc: 0.4294 - val_loss: 3.7023 - val_VL_attention_linear_output_loss: 1.7987 - val_VH_attention_linear_output_loss: 1.9036 - val_VL_attention_linear_output_acc: 0.4734 - val_VH_attention_linear_output_acc: 0.4224\n",
      "Epoch 1444/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6524 - VL_attention_linear_output_loss: 1.7724 - VH_attention_linear_output_loss: 1.8801 - VL_attention_linear_output_acc: 0.4812 - VH_attention_linear_output_acc: 0.4293 - val_loss: 3.7580 - val_VL_attention_linear_output_loss: 1.8338 - val_VH_attention_linear_output_loss: 1.9242 - val_VL_attention_linear_output_acc: 0.4569 - val_VH_attention_linear_output_acc: 0.4129\n",
      "Epoch 1445/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6568 - VL_attention_linear_output_loss: 1.7705 - VH_attention_linear_output_loss: 1.8863 - VL_attention_linear_output_acc: 0.4811 - VH_attention_linear_output_acc: 0.4272 - val_loss: 3.7026 - val_VL_attention_linear_output_loss: 1.7982 - val_VH_attention_linear_output_loss: 1.9043 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4269\n",
      "Epoch 1446/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6525 - VL_attention_linear_output_loss: 1.7673 - VH_attention_linear_output_loss: 1.8851 - VL_attention_linear_output_acc: 0.4825 - VH_attention_linear_output_acc: 0.4279 - val_loss: 3.7058 - val_VL_attention_linear_output_loss: 1.7990 - val_VH_attention_linear_output_loss: 1.9068 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4191\n",
      "Epoch 1447/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6656 - VL_attention_linear_output_loss: 1.7750 - VH_attention_linear_output_loss: 1.8906 - VL_attention_linear_output_acc: 0.4783 - VH_attention_linear_output_acc: 0.4254 - val_loss: 3.7310 - val_VL_attention_linear_output_loss: 1.7950 - val_VH_attention_linear_output_loss: 1.9361 - val_VL_attention_linear_output_acc: 0.4746 - val_VH_attention_linear_output_acc: 0.4088\n",
      "Epoch 1448/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6578 - VL_attention_linear_output_loss: 1.7741 - VH_attention_linear_output_loss: 1.8837 - VL_attention_linear_output_acc: 0.4801 - VH_attention_linear_output_acc: 0.4273 - val_loss: 3.7023 - val_VL_attention_linear_output_loss: 1.7991 - val_VH_attention_linear_output_loss: 1.9033 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4217\n",
      "Epoch 1449/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6560 - VL_attention_linear_output_loss: 1.7708 - VH_attention_linear_output_loss: 1.8852 - VL_attention_linear_output_acc: 0.4804 - VH_attention_linear_output_acc: 0.4277 - val_loss: 3.7048 - val_VL_attention_linear_output_loss: 1.8099 - val_VH_attention_linear_output_loss: 1.8948 - val_VL_attention_linear_output_acc: 0.4718 - val_VH_attention_linear_output_acc: 0.4220\n",
      "Epoch 1450/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6612 - VL_attention_linear_output_loss: 1.7796 - VH_attention_linear_output_loss: 1.8816 - VL_attention_linear_output_acc: 0.4765 - VH_attention_linear_output_acc: 0.4287 - val_loss: 3.7095 - val_VL_attention_linear_output_loss: 1.8068 - val_VH_attention_linear_output_loss: 1.9027 - val_VL_attention_linear_output_acc: 0.4750 - val_VH_attention_linear_output_acc: 0.4236\n",
      "Epoch 1451/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6471 - VL_attention_linear_output_loss: 1.7671 - VH_attention_linear_output_loss: 1.8800 - VL_attention_linear_output_acc: 0.4826 - VH_attention_linear_output_acc: 0.4292 - val_loss: 3.6894 - val_VL_attention_linear_output_loss: 1.7927 - val_VH_attention_linear_output_loss: 1.8967 - val_VL_attention_linear_output_acc: 0.4761 - val_VH_attention_linear_output_acc: 0.4264\n",
      "Epoch 1452/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6551 - VL_attention_linear_output_loss: 1.7744 - VH_attention_linear_output_loss: 1.8806 - VL_attention_linear_output_acc: 0.4774 - VH_attention_linear_output_acc: 0.4300 - val_loss: 3.6886 - val_VL_attention_linear_output_loss: 1.7983 - val_VH_attention_linear_output_loss: 1.8903 - val_VL_attention_linear_output_acc: 0.4793 - val_VH_attention_linear_output_acc: 0.4288\n",
      "Epoch 1453/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6519 - VL_attention_linear_output_loss: 1.7685 - VH_attention_linear_output_loss: 1.8833 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4283 - val_loss: 3.7653 - val_VL_attention_linear_output_loss: 1.8211 - val_VH_attention_linear_output_loss: 1.9442 - val_VL_attention_linear_output_acc: 0.4666 - val_VH_attention_linear_output_acc: 0.4095\n",
      "Epoch 1454/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6643 - VL_attention_linear_output_loss: 1.7708 - VH_attention_linear_output_loss: 1.8934 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4248 - val_loss: 3.6955 - val_VL_attention_linear_output_loss: 1.7959 - val_VH_attention_linear_output_loss: 1.8997 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4252\n",
      "Epoch 1455/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6387 - VL_attention_linear_output_loss: 1.7678 - VH_attention_linear_output_loss: 1.8710 - VL_attention_linear_output_acc: 0.4813 - VH_attention_linear_output_acc: 0.4333 - val_loss: 3.6880 - val_VL_attention_linear_output_loss: 1.7972 - val_VH_attention_linear_output_loss: 1.8908 - val_VL_attention_linear_output_acc: 0.4777 - val_VH_attention_linear_output_acc: 0.4272\n",
      "Epoch 1456/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6379 - VL_attention_linear_output_loss: 1.7679 - VH_attention_linear_output_loss: 1.8700 - VL_attention_linear_output_acc: 0.4810 - VH_attention_linear_output_acc: 0.4333 - val_loss: 3.7001 - val_VL_attention_linear_output_loss: 1.8108 - val_VH_attention_linear_output_loss: 1.8892 - val_VL_attention_linear_output_acc: 0.4665 - val_VH_attention_linear_output_acc: 0.4292\n",
      "Epoch 1457/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6407 - VL_attention_linear_output_loss: 1.7648 - VH_attention_linear_output_loss: 1.8759 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4307 - val_loss: 3.6936 - val_VL_attention_linear_output_loss: 1.8071 - val_VH_attention_linear_output_loss: 1.8865 - val_VL_attention_linear_output_acc: 0.4746 - val_VH_attention_linear_output_acc: 0.4324\n",
      "Epoch 1458/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6453 - VL_attention_linear_output_loss: 1.7752 - VH_attention_linear_output_loss: 1.8701 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.4334 - val_loss: 3.7371 - val_VL_attention_linear_output_loss: 1.8346 - val_VH_attention_linear_output_loss: 1.9026 - val_VL_attention_linear_output_acc: 0.4590 - val_VH_attention_linear_output_acc: 0.4239\n",
      "Epoch 1459/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6392 - VL_attention_linear_output_loss: 1.7620 - VH_attention_linear_output_loss: 1.8772 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4302 - val_loss: 3.6912 - val_VL_attention_linear_output_loss: 1.7980 - val_VH_attention_linear_output_loss: 1.8932 - val_VL_attention_linear_output_acc: 0.4759 - val_VH_attention_linear_output_acc: 0.4305\n",
      "Epoch 1460/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6354 - VL_attention_linear_output_loss: 1.7584 - VH_attention_linear_output_loss: 1.8770 - VL_attention_linear_output_acc: 0.4852 - VH_attention_linear_output_acc: 0.4297 - val_loss: 3.6975 - val_VL_attention_linear_output_loss: 1.8082 - val_VH_attention_linear_output_loss: 1.8893 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4297\n",
      "Epoch 1461/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6439 - VL_attention_linear_output_loss: 1.7724 - VH_attention_linear_output_loss: 1.8714 - VL_attention_linear_output_acc: 0.4790 - VH_attention_linear_output_acc: 0.4330 - val_loss: 3.6992 - val_VL_attention_linear_output_loss: 1.8077 - val_VH_attention_linear_output_loss: 1.8915 - val_VL_attention_linear_output_acc: 0.4738 - val_VH_attention_linear_output_acc: 0.4271\n",
      "Epoch 1462/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6470 - VL_attention_linear_output_loss: 1.7682 - VH_attention_linear_output_loss: 1.8787 - VL_attention_linear_output_acc: 0.4815 - VH_attention_linear_output_acc: 0.4305 - val_loss: 3.6865 - val_VL_attention_linear_output_loss: 1.7948 - val_VH_attention_linear_output_loss: 1.8918 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4273\n",
      "Epoch 1463/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6475 - VL_attention_linear_output_loss: 1.7702 - VH_attention_linear_output_loss: 1.8773 - VL_attention_linear_output_acc: 0.4804 - VH_attention_linear_output_acc: 0.4306 - val_loss: 3.6934 - val_VL_attention_linear_output_loss: 1.8033 - val_VH_attention_linear_output_loss: 1.8901 - val_VL_attention_linear_output_acc: 0.4708 - val_VH_attention_linear_output_acc: 0.4282\n",
      "Epoch 1464/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6316 - VL_attention_linear_output_loss: 1.7620 - VH_attention_linear_output_loss: 1.8696 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4339 - val_loss: 3.6867 - val_VL_attention_linear_output_loss: 1.7983 - val_VH_attention_linear_output_loss: 1.8883 - val_VL_attention_linear_output_acc: 0.4779 - val_VH_attention_linear_output_acc: 0.4293\n",
      "Epoch 1465/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6535 - VL_attention_linear_output_loss: 1.7747 - VH_attention_linear_output_loss: 1.8787 - VL_attention_linear_output_acc: 0.4769 - VH_attention_linear_output_acc: 0.4301 - val_loss: 3.7119 - val_VL_attention_linear_output_loss: 1.7999 - val_VH_attention_linear_output_loss: 1.9120 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4200\n",
      "Epoch 1466/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6421 - VL_attention_linear_output_loss: 1.7584 - VH_attention_linear_output_loss: 1.8837 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4277 - val_loss: 3.6832 - val_VL_attention_linear_output_loss: 1.7904 - val_VH_attention_linear_output_loss: 1.8928 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4268\n",
      "Epoch 1467/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6403 - VL_attention_linear_output_loss: 1.7595 - VH_attention_linear_output_loss: 1.8808 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4305 - val_loss: 3.6952 - val_VL_attention_linear_output_loss: 1.7975 - val_VH_attention_linear_output_loss: 1.8977 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4304\n",
      "Epoch 1468/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6470 - VL_attention_linear_output_loss: 1.7661 - VH_attention_linear_output_loss: 1.8809 - VL_attention_linear_output_acc: 0.4820 - VH_attention_linear_output_acc: 0.4289 - val_loss: 3.7090 - val_VL_attention_linear_output_loss: 1.7915 - val_VH_attention_linear_output_loss: 1.9175 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4161\n",
      "Epoch 1469/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6383 - VL_attention_linear_output_loss: 1.7629 - VH_attention_linear_output_loss: 1.8754 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4308 - val_loss: 3.7084 - val_VL_attention_linear_output_loss: 1.7979 - val_VH_attention_linear_output_loss: 1.9105 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4166\n",
      "Epoch 1470/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6528 - VL_attention_linear_output_loss: 1.7774 - VH_attention_linear_output_loss: 1.8754 - VL_attention_linear_output_acc: 0.4763 - VH_attention_linear_output_acc: 0.4315 - val_loss: 3.7040 - val_VL_attention_linear_output_loss: 1.8077 - val_VH_attention_linear_output_loss: 1.8962 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.4255\n",
      "Epoch 1471/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6435 - VL_attention_linear_output_loss: 1.7671 - VH_attention_linear_output_loss: 1.8764 - VL_attention_linear_output_acc: 0.4802 - VH_attention_linear_output_acc: 0.4303 - val_loss: 3.6839 - val_VL_attention_linear_output_loss: 1.7930 - val_VH_attention_linear_output_loss: 1.8909 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.4305\n",
      "Epoch 1472/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6349 - VL_attention_linear_output_loss: 1.7635 - VH_attention_linear_output_loss: 1.8715 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4325 - val_loss: 3.6863 - val_VL_attention_linear_output_loss: 1.7956 - val_VH_attention_linear_output_loss: 1.8907 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4280\n",
      "Epoch 1473/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6369 - VL_attention_linear_output_loss: 1.7633 - VH_attention_linear_output_loss: 1.8736 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4318 - val_loss: 3.7625 - val_VL_attention_linear_output_loss: 1.8470 - val_VH_attention_linear_output_loss: 1.9155 - val_VL_attention_linear_output_acc: 0.4494 - val_VH_attention_linear_output_acc: 0.4230\n",
      "Epoch 1474/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6411 - VL_attention_linear_output_loss: 1.7672 - VH_attention_linear_output_loss: 1.8739 - VL_attention_linear_output_acc: 0.4813 - VH_attention_linear_output_acc: 0.4324 - val_loss: 3.6916 - val_VL_attention_linear_output_loss: 1.7977 - val_VH_attention_linear_output_loss: 1.8939 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4278\n",
      "Epoch 1475/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6390 - VL_attention_linear_output_loss: 1.7668 - VH_attention_linear_output_loss: 1.8722 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4324 - val_loss: 3.6924 - val_VL_attention_linear_output_loss: 1.7969 - val_VH_attention_linear_output_loss: 1.8954 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4316\n",
      "Epoch 1476/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6489 - VL_attention_linear_output_loss: 1.7765 - VH_attention_linear_output_loss: 1.8724 - VL_attention_linear_output_acc: 0.4762 - VH_attention_linear_output_acc: 0.4318 - val_loss: 3.6837 - val_VL_attention_linear_output_loss: 1.7919 - val_VH_attention_linear_output_loss: 1.8918 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4287\n",
      "Epoch 1477/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6277 - VL_attention_linear_output_loss: 1.7598 - VH_attention_linear_output_loss: 1.8679 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4339 - val_loss: 3.6878 - val_VL_attention_linear_output_loss: 1.7930 - val_VH_attention_linear_output_loss: 1.8947 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.4299\n",
      "Epoch 1478/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6320 - VL_attention_linear_output_loss: 1.7599 - VH_attention_linear_output_loss: 1.8721 - VL_attention_linear_output_acc: 0.4852 - VH_attention_linear_output_acc: 0.4324 - val_loss: 3.6878 - val_VL_attention_linear_output_loss: 1.7967 - val_VH_attention_linear_output_loss: 1.8910 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4289\n",
      "Epoch 1479/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6404 - VL_attention_linear_output_loss: 1.7635 - VH_attention_linear_output_loss: 1.8769 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4308 - val_loss: 3.7080 - val_VL_attention_linear_output_loss: 1.7946 - val_VH_attention_linear_output_loss: 1.9134 - val_VL_attention_linear_output_acc: 0.4782 - val_VH_attention_linear_output_acc: 0.4116\n",
      "Epoch 1480/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6395 - VL_attention_linear_output_loss: 1.7686 - VH_attention_linear_output_loss: 1.8709 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.4329 - val_loss: 3.6853 - val_VL_attention_linear_output_loss: 1.7897 - val_VH_attention_linear_output_loss: 1.8956 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4284\n",
      "Epoch 1481/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6468 - VL_attention_linear_output_loss: 1.7714 - VH_attention_linear_output_loss: 1.8754 - VL_attention_linear_output_acc: 0.4791 - VH_attention_linear_output_acc: 0.4311 - val_loss: 3.7149 - val_VL_attention_linear_output_loss: 1.8259 - val_VH_attention_linear_output_loss: 1.8891 - val_VL_attention_linear_output_acc: 0.4646 - val_VH_attention_linear_output_acc: 0.4271\n",
      "Epoch 1482/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6444 - VL_attention_linear_output_loss: 1.7745 - VH_attention_linear_output_loss: 1.8699 - VL_attention_linear_output_acc: 0.4774 - VH_attention_linear_output_acc: 0.4327 - val_loss: 3.6822 - val_VL_attention_linear_output_loss: 1.7932 - val_VH_attention_linear_output_loss: 1.8890 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4315\n",
      "Epoch 1483/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6322 - VL_attention_linear_output_loss: 1.7634 - VH_attention_linear_output_loss: 1.8688 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4340 - val_loss: 3.7011 - val_VL_attention_linear_output_loss: 1.8006 - val_VH_attention_linear_output_loss: 1.9005 - val_VL_attention_linear_output_acc: 0.4781 - val_VH_attention_linear_output_acc: 0.4228\n",
      "Epoch 1484/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6551 - VL_attention_linear_output_loss: 1.7709 - VH_attention_linear_output_loss: 1.8842 - VL_attention_linear_output_acc: 0.4794 - VH_attention_linear_output_acc: 0.4269 - val_loss: 3.6957 - val_VL_attention_linear_output_loss: 1.7978 - val_VH_attention_linear_output_loss: 1.8979 - val_VL_attention_linear_output_acc: 0.4780 - val_VH_attention_linear_output_acc: 0.4252\n",
      "Epoch 1485/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6282 - VL_attention_linear_output_loss: 1.7605 - VH_attention_linear_output_loss: 1.8678 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4336 - val_loss: 3.7176 - val_VL_attention_linear_output_loss: 1.8361 - val_VH_attention_linear_output_loss: 1.8814 - val_VL_attention_linear_output_acc: 0.4582 - val_VH_attention_linear_output_acc: 0.4328\n",
      "Epoch 1486/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6472 - VL_attention_linear_output_loss: 1.7747 - VH_attention_linear_output_loss: 1.8725 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.4329 - val_loss: 3.6874 - val_VL_attention_linear_output_loss: 1.7980 - val_VH_attention_linear_output_loss: 1.8894 - val_VL_attention_linear_output_acc: 0.4721 - val_VH_attention_linear_output_acc: 0.4337\n",
      "Epoch 1487/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6298 - VL_attention_linear_output_loss: 1.7644 - VH_attention_linear_output_loss: 1.8653 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4350 - val_loss: 3.6963 - val_VL_attention_linear_output_loss: 1.8071 - val_VH_attention_linear_output_loss: 1.8892 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.4311\n",
      "Epoch 1488/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6496 - VL_attention_linear_output_loss: 1.7795 - VH_attention_linear_output_loss: 1.8701 - VL_attention_linear_output_acc: 0.4756 - VH_attention_linear_output_acc: 0.4330 - val_loss: 3.7240 - val_VL_attention_linear_output_loss: 1.8014 - val_VH_attention_linear_output_loss: 1.9227 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4116\n",
      "Epoch 1489/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6393 - VL_attention_linear_output_loss: 1.7631 - VH_attention_linear_output_loss: 1.8763 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4308 - val_loss: 3.6768 - val_VL_attention_linear_output_loss: 1.7902 - val_VH_attention_linear_output_loss: 1.8867 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4285\n",
      "Epoch 1490/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6206 - VL_attention_linear_output_loss: 1.7574 - VH_attention_linear_output_loss: 1.8633 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4357 - val_loss: 3.6862 - val_VL_attention_linear_output_loss: 1.7943 - val_VH_attention_linear_output_loss: 1.8919 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4337\n",
      "Epoch 1491/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6592 - VL_attention_linear_output_loss: 1.7697 - VH_attention_linear_output_loss: 1.8895 - VL_attention_linear_output_acc: 0.4807 - VH_attention_linear_output_acc: 0.4247 - val_loss: 3.7016 - val_VL_attention_linear_output_loss: 1.8032 - val_VH_attention_linear_output_loss: 1.8984 - val_VL_attention_linear_output_acc: 0.4767 - val_VH_attention_linear_output_acc: 0.4239\n",
      "Epoch 1492/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6356 - VL_attention_linear_output_loss: 1.7669 - VH_attention_linear_output_loss: 1.8687 - VL_attention_linear_output_acc: 0.4814 - VH_attention_linear_output_acc: 0.4332 - val_loss: 3.7066 - val_VL_attention_linear_output_loss: 1.8058 - val_VH_attention_linear_output_loss: 1.9008 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.4257\n",
      "Epoch 1493/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6465 - VL_attention_linear_output_loss: 1.7700 - VH_attention_linear_output_loss: 1.8765 - VL_attention_linear_output_acc: 0.4801 - VH_attention_linear_output_acc: 0.4307 - val_loss: 3.7003 - val_VL_attention_linear_output_loss: 1.8039 - val_VH_attention_linear_output_loss: 1.8963 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4264\n",
      "Epoch 1494/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6380 - VL_attention_linear_output_loss: 1.7720 - VH_attention_linear_output_loss: 1.8660 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.4343 - val_loss: 3.6983 - val_VL_attention_linear_output_loss: 1.8016 - val_VH_attention_linear_output_loss: 1.8967 - val_VL_attention_linear_output_acc: 0.4766 - val_VH_attention_linear_output_acc: 0.4312\n",
      "Epoch 1495/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6406 - VL_attention_linear_output_loss: 1.7702 - VH_attention_linear_output_loss: 1.8704 - VL_attention_linear_output_acc: 0.4797 - VH_attention_linear_output_acc: 0.4336 - val_loss: 3.7373 - val_VL_attention_linear_output_loss: 1.8213 - val_VH_attention_linear_output_loss: 1.9160 - val_VL_attention_linear_output_acc: 0.4662 - val_VH_attention_linear_output_acc: 0.4220\n",
      "Epoch 1496/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6531 - VL_attention_linear_output_loss: 1.7816 - VH_attention_linear_output_loss: 1.8715 - VL_attention_linear_output_acc: 0.4743 - VH_attention_linear_output_acc: 0.4322 - val_loss: 3.6905 - val_VL_attention_linear_output_loss: 1.7897 - val_VH_attention_linear_output_loss: 1.9008 - val_VL_attention_linear_output_acc: 0.4858 - val_VH_attention_linear_output_acc: 0.4213\n",
      "Epoch 1497/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6333 - VL_attention_linear_output_loss: 1.7582 - VH_attention_linear_output_loss: 1.8751 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4308 - val_loss: 3.7073 - val_VL_attention_linear_output_loss: 1.7972 - val_VH_attention_linear_output_loss: 1.9101 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4226\n",
      "Epoch 1498/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6298 - VL_attention_linear_output_loss: 1.7647 - VH_attention_linear_output_loss: 1.8652 - VL_attention_linear_output_acc: 0.4824 - VH_attention_linear_output_acc: 0.4351 - val_loss: 3.6803 - val_VL_attention_linear_output_loss: 1.7956 - val_VH_attention_linear_output_loss: 1.8846 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4306\n",
      "Epoch 1499/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6372 - VL_attention_linear_output_loss: 1.7651 - VH_attention_linear_output_loss: 1.8721 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4321 - val_loss: 3.6906 - val_VL_attention_linear_output_loss: 1.8083 - val_VH_attention_linear_output_loss: 1.8822 - val_VL_attention_linear_output_acc: 0.4714 - val_VH_attention_linear_output_acc: 0.4333\n",
      "Epoch 1500/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6355 - VL_attention_linear_output_loss: 1.7695 - VH_attention_linear_output_loss: 1.8661 - VL_attention_linear_output_acc: 0.4802 - VH_attention_linear_output_acc: 0.4356 - val_loss: 3.6957 - val_VL_attention_linear_output_loss: 1.8083 - val_VH_attention_linear_output_loss: 1.8874 - val_VL_attention_linear_output_acc: 0.4711 - val_VH_attention_linear_output_acc: 0.4316\n",
      "Epoch 1501/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6642 - VL_attention_linear_output_loss: 1.7856 - VH_attention_linear_output_loss: 1.8786 - VL_attention_linear_output_acc: 0.4737 - VH_attention_linear_output_acc: 0.4290 - val_loss: 3.7550 - val_VL_attention_linear_output_loss: 1.8555 - val_VH_attention_linear_output_loss: 1.8995 - val_VL_attention_linear_output_acc: 0.4527 - val_VH_attention_linear_output_acc: 0.4218\n",
      "Epoch 1502/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6325 - VL_attention_linear_output_loss: 1.7613 - VH_attention_linear_output_loss: 1.8712 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4326 - val_loss: 3.7105 - val_VL_attention_linear_output_loss: 1.7965 - val_VH_attention_linear_output_loss: 1.9140 - val_VL_attention_linear_output_acc: 0.4814 - val_VH_attention_linear_output_acc: 0.4219\n",
      "Epoch 1503/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6516 - VL_attention_linear_output_loss: 1.7687 - VH_attention_linear_output_loss: 1.8829 - VL_attention_linear_output_acc: 0.4814 - VH_attention_linear_output_acc: 0.4296 - val_loss: 3.6957 - val_VL_attention_linear_output_loss: 1.8118 - val_VH_attention_linear_output_loss: 1.8839 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.4280\n",
      "Epoch 1504/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6300 - VL_attention_linear_output_loss: 1.7646 - VH_attention_linear_output_loss: 1.8654 - VL_attention_linear_output_acc: 0.4835 - VH_attention_linear_output_acc: 0.4356 - val_loss: 3.7066 - val_VL_attention_linear_output_loss: 1.7933 - val_VH_attention_linear_output_loss: 1.9133 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.4234\n",
      "Epoch 1505/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6391 - VL_attention_linear_output_loss: 1.7672 - VH_attention_linear_output_loss: 1.8720 - VL_attention_linear_output_acc: 0.4811 - VH_attention_linear_output_acc: 0.4322 - val_loss: 3.6907 - val_VL_attention_linear_output_loss: 1.7938 - val_VH_attention_linear_output_loss: 1.8969 - val_VL_attention_linear_output_acc: 0.4751 - val_VH_attention_linear_output_acc: 0.4310\n",
      "Epoch 1506/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6329 - VL_attention_linear_output_loss: 1.7663 - VH_attention_linear_output_loss: 1.8666 - VL_attention_linear_output_acc: 0.4814 - VH_attention_linear_output_acc: 0.4344 - val_loss: 3.6917 - val_VL_attention_linear_output_loss: 1.7905 - val_VH_attention_linear_output_loss: 1.9012 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4215\n",
      "Epoch 1507/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6268 - VL_attention_linear_output_loss: 1.7604 - VH_attention_linear_output_loss: 1.8664 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4345 - val_loss: 3.7004 - val_VL_attention_linear_output_loss: 1.8065 - val_VH_attention_linear_output_loss: 1.8939 - val_VL_attention_linear_output_acc: 0.4730 - val_VH_attention_linear_output_acc: 0.4250\n",
      "Epoch 1508/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6391 - VL_attention_linear_output_loss: 1.7693 - VH_attention_linear_output_loss: 1.8697 - VL_attention_linear_output_acc: 0.4800 - VH_attention_linear_output_acc: 0.4331 - val_loss: 3.6875 - val_VL_attention_linear_output_loss: 1.7968 - val_VH_attention_linear_output_loss: 1.8907 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4254\n",
      "Epoch 1509/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6254 - VL_attention_linear_output_loss: 1.7653 - VH_attention_linear_output_loss: 1.8601 - VL_attention_linear_output_acc: 0.4813 - VH_attention_linear_output_acc: 0.4377 - val_loss: 3.6800 - val_VL_attention_linear_output_loss: 1.7974 - val_VH_attention_linear_output_loss: 1.8826 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4295\n",
      "Epoch 1510/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6426 - VL_attention_linear_output_loss: 1.7765 - VH_attention_linear_output_loss: 1.8662 - VL_attention_linear_output_acc: 0.4776 - VH_attention_linear_output_acc: 0.4352 - val_loss: 3.7054 - val_VL_attention_linear_output_loss: 1.8048 - val_VH_attention_linear_output_loss: 1.9006 - val_VL_attention_linear_output_acc: 0.4775 - val_VH_attention_linear_output_acc: 0.4222\n",
      "Epoch 1511/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6376 - VL_attention_linear_output_loss: 1.7714 - VH_attention_linear_output_loss: 1.8662 - VL_attention_linear_output_acc: 0.4789 - VH_attention_linear_output_acc: 0.4354 - val_loss: 3.6804 - val_VL_attention_linear_output_loss: 1.7997 - val_VH_attention_linear_output_loss: 1.8806 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4354\n",
      "Epoch 1512/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6313 - VL_attention_linear_output_loss: 1.7672 - VH_attention_linear_output_loss: 1.8641 - VL_attention_linear_output_acc: 0.4815 - VH_attention_linear_output_acc: 0.4363 - val_loss: 3.6740 - val_VL_attention_linear_output_loss: 1.7952 - val_VH_attention_linear_output_loss: 1.8788 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4325\n",
      "Epoch 1513/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6429 - VL_attention_linear_output_loss: 1.7732 - VH_attention_linear_output_loss: 1.8697 - VL_attention_linear_output_acc: 0.4776 - VH_attention_linear_output_acc: 0.4332 - val_loss: 3.7135 - val_VL_attention_linear_output_loss: 1.8257 - val_VH_attention_linear_output_loss: 1.8878 - val_VL_attention_linear_output_acc: 0.4615 - val_VH_attention_linear_output_acc: 0.4320\n",
      "Epoch 1514/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6285 - VL_attention_linear_output_loss: 1.7619 - VH_attention_linear_output_loss: 1.8665 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4357 - val_loss: 3.6973 - val_VL_attention_linear_output_loss: 1.7978 - val_VH_attention_linear_output_loss: 1.8996 - val_VL_attention_linear_output_acc: 0.4810 - val_VH_attention_linear_output_acc: 0.4241\n",
      "Epoch 1515/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6547 - VL_attention_linear_output_loss: 1.7820 - VH_attention_linear_output_loss: 1.8727 - VL_attention_linear_output_acc: 0.4749 - VH_attention_linear_output_acc: 0.4316 - val_loss: 3.6782 - val_VL_attention_linear_output_loss: 1.7981 - val_VH_attention_linear_output_loss: 1.8801 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4335\n",
      "Epoch 1516/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6284 - VL_attention_linear_output_loss: 1.7630 - VH_attention_linear_output_loss: 1.8654 - VL_attention_linear_output_acc: 0.4833 - VH_attention_linear_output_acc: 0.4353 - val_loss: 3.7183 - val_VL_attention_linear_output_loss: 1.8028 - val_VH_attention_linear_output_loss: 1.9155 - val_VL_attention_linear_output_acc: 0.4729 - val_VH_attention_linear_output_acc: 0.4197\n",
      "Epoch 1517/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6344 - VL_attention_linear_output_loss: 1.7650 - VH_attention_linear_output_loss: 1.8695 - VL_attention_linear_output_acc: 0.4824 - VH_attention_linear_output_acc: 0.4339 - val_loss: 3.7046 - val_VL_attention_linear_output_loss: 1.7986 - val_VH_attention_linear_output_loss: 1.9060 - val_VL_attention_linear_output_acc: 0.4787 - val_VH_attention_linear_output_acc: 0.4293\n",
      "Epoch 1518/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6276 - VL_attention_linear_output_loss: 1.7586 - VH_attention_linear_output_loss: 1.8690 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4334 - val_loss: 3.6972 - val_VL_attention_linear_output_loss: 1.8021 - val_VH_attention_linear_output_loss: 1.8952 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4337\n",
      "Epoch 1519/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6352 - VL_attention_linear_output_loss: 1.7724 - VH_attention_linear_output_loss: 1.8627 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4374 - val_loss: 3.6765 - val_VL_attention_linear_output_loss: 1.7998 - val_VH_attention_linear_output_loss: 1.8767 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.4330\n",
      "Epoch 1520/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6210 - VL_attention_linear_output_loss: 1.7594 - VH_attention_linear_output_loss: 1.8616 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4371 - val_loss: 3.6774 - val_VL_attention_linear_output_loss: 1.7950 - val_VH_attention_linear_output_loss: 1.8825 - val_VL_attention_linear_output_acc: 0.4777 - val_VH_attention_linear_output_acc: 0.4296\n",
      "Epoch 1521/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6295 - VL_attention_linear_output_loss: 1.7630 - VH_attention_linear_output_loss: 1.8665 - VL_attention_linear_output_acc: 0.4820 - VH_attention_linear_output_acc: 0.4344 - val_loss: 3.7001 - val_VL_attention_linear_output_loss: 1.8081 - val_VH_attention_linear_output_loss: 1.8920 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.4307\n",
      "Epoch 1522/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6198 - VL_attention_linear_output_loss: 1.7577 - VH_attention_linear_output_loss: 1.8620 - VL_attention_linear_output_acc: 0.4863 - VH_attention_linear_output_acc: 0.4368 - val_loss: 3.6995 - val_VL_attention_linear_output_loss: 1.8046 - val_VH_attention_linear_output_loss: 1.8949 - val_VL_attention_linear_output_acc: 0.4787 - val_VH_attention_linear_output_acc: 0.4222\n",
      "Epoch 1523/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6373 - VL_attention_linear_output_loss: 1.7745 - VH_attention_linear_output_loss: 1.8628 - VL_attention_linear_output_acc: 0.4760 - VH_attention_linear_output_acc: 0.4357 - val_loss: 3.6848 - val_VL_attention_linear_output_loss: 1.7922 - val_VH_attention_linear_output_loss: 1.8926 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4330\n",
      "Epoch 1524/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6230 - VL_attention_linear_output_loss: 1.7564 - VH_attention_linear_output_loss: 1.8665 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4361 - val_loss: 3.6825 - val_VL_attention_linear_output_loss: 1.7957 - val_VH_attention_linear_output_loss: 1.8869 - val_VL_attention_linear_output_acc: 0.4755 - val_VH_attention_linear_output_acc: 0.4277\n",
      "Epoch 1525/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6403 - VL_attention_linear_output_loss: 1.7729 - VH_attention_linear_output_loss: 1.8674 - VL_attention_linear_output_acc: 0.4788 - VH_attention_linear_output_acc: 0.4355 - val_loss: 3.6923 - val_VL_attention_linear_output_loss: 1.7975 - val_VH_attention_linear_output_loss: 1.8948 - val_VL_attention_linear_output_acc: 0.4757 - val_VH_attention_linear_output_acc: 0.4300\n",
      "Epoch 1526/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6459 - VL_attention_linear_output_loss: 1.7749 - VH_attention_linear_output_loss: 1.8711 - VL_attention_linear_output_acc: 0.4767 - VH_attention_linear_output_acc: 0.4324 - val_loss: 3.7053 - val_VL_attention_linear_output_loss: 1.8153 - val_VH_attention_linear_output_loss: 1.8901 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.4285\n",
      "Epoch 1527/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6517 - VL_attention_linear_output_loss: 1.7779 - VH_attention_linear_output_loss: 1.8738 - VL_attention_linear_output_acc: 0.4769 - VH_attention_linear_output_acc: 0.4325 - val_loss: 3.7537 - val_VL_attention_linear_output_loss: 1.8191 - val_VH_attention_linear_output_loss: 1.9346 - val_VL_attention_linear_output_acc: 0.4704 - val_VH_attention_linear_output_acc: 0.4092\n",
      "Epoch 1528/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6579 - VL_attention_linear_output_loss: 1.7722 - VH_attention_linear_output_loss: 1.8857 - VL_attention_linear_output_acc: 0.4795 - VH_attention_linear_output_acc: 0.4285 - val_loss: 3.6908 - val_VL_attention_linear_output_loss: 1.7998 - val_VH_attention_linear_output_loss: 1.8910 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4297\n",
      "Epoch 1529/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6385 - VL_attention_linear_output_loss: 1.7683 - VH_attention_linear_output_loss: 1.8702 - VL_attention_linear_output_acc: 0.4811 - VH_attention_linear_output_acc: 0.4344 - val_loss: 3.7952 - val_VL_attention_linear_output_loss: 1.8095 - val_VH_attention_linear_output_loss: 1.9857 - val_VL_attention_linear_output_acc: 0.4769 - val_VH_attention_linear_output_acc: 0.3874\n",
      "Epoch 1530/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6464 - VL_attention_linear_output_loss: 1.7687 - VH_attention_linear_output_loss: 1.8777 - VL_attention_linear_output_acc: 0.4811 - VH_attention_linear_output_acc: 0.4306 - val_loss: 3.6837 - val_VL_attention_linear_output_loss: 1.7992 - val_VH_attention_linear_output_loss: 1.8845 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4325\n",
      "Epoch 1531/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6227 - VL_attention_linear_output_loss: 1.7619 - VH_attention_linear_output_loss: 1.8608 - VL_attention_linear_output_acc: 0.4831 - VH_attention_linear_output_acc: 0.4380 - val_loss: 3.6726 - val_VL_attention_linear_output_loss: 1.7933 - val_VH_attention_linear_output_loss: 1.8793 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4313\n",
      "Epoch 1532/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6331 - VL_attention_linear_output_loss: 1.7687 - VH_attention_linear_output_loss: 1.8644 - VL_attention_linear_output_acc: 0.4802 - VH_attention_linear_output_acc: 0.4362 - val_loss: 3.7081 - val_VL_attention_linear_output_loss: 1.8183 - val_VH_attention_linear_output_loss: 1.8897 - val_VL_attention_linear_output_acc: 0.4715 - val_VH_attention_linear_output_acc: 0.4346\n",
      "Epoch 1533/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6267 - VL_attention_linear_output_loss: 1.7667 - VH_attention_linear_output_loss: 1.8600 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4380 - val_loss: 3.6907 - val_VL_attention_linear_output_loss: 1.8004 - val_VH_attention_linear_output_loss: 1.8904 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4282\n",
      "Epoch 1534/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6387 - VL_attention_linear_output_loss: 1.7660 - VH_attention_linear_output_loss: 1.8726 - VL_attention_linear_output_acc: 0.4824 - VH_attention_linear_output_acc: 0.4323 - val_loss: 3.6731 - val_VL_attention_linear_output_loss: 1.7930 - val_VH_attention_linear_output_loss: 1.8801 - val_VL_attention_linear_output_acc: 0.4828 - val_VH_attention_linear_output_acc: 0.4337\n",
      "Epoch 1535/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6355 - VL_attention_linear_output_loss: 1.7687 - VH_attention_linear_output_loss: 1.8668 - VL_attention_linear_output_acc: 0.4810 - VH_attention_linear_output_acc: 0.4351 - val_loss: 3.6811 - val_VL_attention_linear_output_loss: 1.8004 - val_VH_attention_linear_output_loss: 1.8807 - val_VL_attention_linear_output_acc: 0.4781 - val_VH_attention_linear_output_acc: 0.4326\n",
      "Epoch 1536/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6280 - VL_attention_linear_output_loss: 1.7591 - VH_attention_linear_output_loss: 1.8689 - VL_attention_linear_output_acc: 0.4852 - VH_attention_linear_output_acc: 0.4352 - val_loss: 3.7179 - val_VL_attention_linear_output_loss: 1.7920 - val_VH_attention_linear_output_loss: 1.9259 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4137\n",
      "Epoch 1537/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6348 - VL_attention_linear_output_loss: 1.7705 - VH_attention_linear_output_loss: 1.8644 - VL_attention_linear_output_acc: 0.4793 - VH_attention_linear_output_acc: 0.4366 - val_loss: 3.6831 - val_VL_attention_linear_output_loss: 1.8009 - val_VH_attention_linear_output_loss: 1.8822 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4346\n",
      "Epoch 1538/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6398 - VL_attention_linear_output_loss: 1.7682 - VH_attention_linear_output_loss: 1.8716 - VL_attention_linear_output_acc: 0.4804 - VH_attention_linear_output_acc: 0.4335 - val_loss: 3.6730 - val_VL_attention_linear_output_loss: 1.7924 - val_VH_attention_linear_output_loss: 1.8806 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4371\n",
      "Epoch 1539/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6206 - VL_attention_linear_output_loss: 1.7628 - VH_attention_linear_output_loss: 1.8578 - VL_attention_linear_output_acc: 0.4829 - VH_attention_linear_output_acc: 0.4399 - val_loss: 3.6847 - val_VL_attention_linear_output_loss: 1.7949 - val_VH_attention_linear_output_loss: 1.8899 - val_VL_attention_linear_output_acc: 0.4778 - val_VH_attention_linear_output_acc: 0.4272\n",
      "Epoch 1540/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6237 - VL_attention_linear_output_loss: 1.7651 - VH_attention_linear_output_loss: 1.8586 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4382 - val_loss: 3.6993 - val_VL_attention_linear_output_loss: 1.8103 - val_VH_attention_linear_output_loss: 1.8891 - val_VL_attention_linear_output_acc: 0.4699 - val_VH_attention_linear_output_acc: 0.4369\n",
      "Epoch 1541/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6324 - VL_attention_linear_output_loss: 1.7716 - VH_attention_linear_output_loss: 1.8608 - VL_attention_linear_output_acc: 0.4784 - VH_attention_linear_output_acc: 0.4378 - val_loss: 3.6857 - val_VL_attention_linear_output_loss: 1.8055 - val_VH_attention_linear_output_loss: 1.8801 - val_VL_attention_linear_output_acc: 0.4759 - val_VH_attention_linear_output_acc: 0.4343\n",
      "Epoch 1542/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6261 - VL_attention_linear_output_loss: 1.7611 - VH_attention_linear_output_loss: 1.8650 - VL_attention_linear_output_acc: 0.4838 - VH_attention_linear_output_acc: 0.4363 - val_loss: 3.7421 - val_VL_attention_linear_output_loss: 1.8440 - val_VH_attention_linear_output_loss: 1.8981 - val_VL_attention_linear_output_acc: 0.4521 - val_VH_attention_linear_output_acc: 0.4317\n",
      "Epoch 1543/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6319 - VL_attention_linear_output_loss: 1.7706 - VH_attention_linear_output_loss: 1.8613 - VL_attention_linear_output_acc: 0.4786 - VH_attention_linear_output_acc: 0.4377 - val_loss: 3.6916 - val_VL_attention_linear_output_loss: 1.7947 - val_VH_attention_linear_output_loss: 1.8969 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4254\n",
      "Epoch 1544/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6439 - VL_attention_linear_output_loss: 1.7791 - VH_attention_linear_output_loss: 1.8647 - VL_attention_linear_output_acc: 0.4754 - VH_attention_linear_output_acc: 0.4358 - val_loss: 3.6693 - val_VL_attention_linear_output_loss: 1.7925 - val_VH_attention_linear_output_loss: 1.8768 - val_VL_attention_linear_output_acc: 0.4828 - val_VH_attention_linear_output_acc: 0.4397\n",
      "Epoch 1545/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6279 - VL_attention_linear_output_loss: 1.7640 - VH_attention_linear_output_loss: 1.8639 - VL_attention_linear_output_acc: 0.4826 - VH_attention_linear_output_acc: 0.4361 - val_loss: 3.6917 - val_VL_attention_linear_output_loss: 1.7919 - val_VH_attention_linear_output_loss: 1.8998 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4266\n",
      "Epoch 1546/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6292 - VL_attention_linear_output_loss: 1.7626 - VH_attention_linear_output_loss: 1.8666 - VL_attention_linear_output_acc: 0.4838 - VH_attention_linear_output_acc: 0.4361 - val_loss: 3.7250 - val_VL_attention_linear_output_loss: 1.8462 - val_VH_attention_linear_output_loss: 1.8788 - val_VL_attention_linear_output_acc: 0.4559 - val_VH_attention_linear_output_acc: 0.4301\n",
      "Epoch 1547/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6303 - VL_attention_linear_output_loss: 1.7664 - VH_attention_linear_output_loss: 1.8639 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4361 - val_loss: 3.7106 - val_VL_attention_linear_output_loss: 1.8161 - val_VH_attention_linear_output_loss: 1.8945 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.4280\n",
      "Epoch 1548/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6353 - VL_attention_linear_output_loss: 1.7725 - VH_attention_linear_output_loss: 1.8629 - VL_attention_linear_output_acc: 0.4773 - VH_attention_linear_output_acc: 0.4370 - val_loss: 3.6984 - val_VL_attention_linear_output_loss: 1.8097 - val_VH_attention_linear_output_loss: 1.8887 - val_VL_attention_linear_output_acc: 0.4738 - val_VH_attention_linear_output_acc: 0.4269\n",
      "Epoch 1549/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6418 - VL_attention_linear_output_loss: 1.7758 - VH_attention_linear_output_loss: 1.8661 - VL_attention_linear_output_acc: 0.4764 - VH_attention_linear_output_acc: 0.4357 - val_loss: 3.7138 - val_VL_attention_linear_output_loss: 1.7989 - val_VH_attention_linear_output_loss: 1.9149 - val_VL_attention_linear_output_acc: 0.4748 - val_VH_attention_linear_output_acc: 0.4222\n",
      "Epoch 1550/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6294 - VL_attention_linear_output_loss: 1.7618 - VH_attention_linear_output_loss: 1.8676 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4340 - val_loss: 3.6748 - val_VL_attention_linear_output_loss: 1.7975 - val_VH_attention_linear_output_loss: 1.8774 - val_VL_attention_linear_output_acc: 0.4795 - val_VH_attention_linear_output_acc: 0.4370\n",
      "Epoch 1551/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6217 - VL_attention_linear_output_loss: 1.7628 - VH_attention_linear_output_loss: 1.8589 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4392 - val_loss: 3.6689 - val_VL_attention_linear_output_loss: 1.7954 - val_VH_attention_linear_output_loss: 1.8735 - val_VL_attention_linear_output_acc: 0.4778 - val_VH_attention_linear_output_acc: 0.4339\n",
      "Epoch 1552/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6321 - VL_attention_linear_output_loss: 1.7749 - VH_attention_linear_output_loss: 1.8572 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.4392 - val_loss: 3.7155 - val_VL_attention_linear_output_loss: 1.8335 - val_VH_attention_linear_output_loss: 1.8820 - val_VL_attention_linear_output_acc: 0.4599 - val_VH_attention_linear_output_acc: 0.4313\n",
      "Epoch 1553/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6387 - VL_attention_linear_output_loss: 1.7733 - VH_attention_linear_output_loss: 1.8654 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.4360 - val_loss: 3.6763 - val_VL_attention_linear_output_loss: 1.7949 - val_VH_attention_linear_output_loss: 1.8814 - val_VL_attention_linear_output_acc: 0.4805 - val_VH_attention_linear_output_acc: 0.4301\n",
      "Epoch 1554/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6147 - VL_attention_linear_output_loss: 1.7615 - VH_attention_linear_output_loss: 1.8533 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4408 - val_loss: 3.6702 - val_VL_attention_linear_output_loss: 1.7942 - val_VH_attention_linear_output_loss: 1.8760 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4347\n",
      "Epoch 1555/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6254 - VL_attention_linear_output_loss: 1.7660 - VH_attention_linear_output_loss: 1.8594 - VL_attention_linear_output_acc: 0.4820 - VH_attention_linear_output_acc: 0.4388 - val_loss: 3.6794 - val_VL_attention_linear_output_loss: 1.8070 - val_VH_attention_linear_output_loss: 1.8724 - val_VL_attention_linear_output_acc: 0.4730 - val_VH_attention_linear_output_acc: 0.4337\n",
      "Epoch 1556/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6351 - VL_attention_linear_output_loss: 1.7694 - VH_attention_linear_output_loss: 1.8657 - VL_attention_linear_output_acc: 0.4802 - VH_attention_linear_output_acc: 0.4361 - val_loss: 3.6905 - val_VL_attention_linear_output_loss: 1.8061 - val_VH_attention_linear_output_loss: 1.8844 - val_VL_attention_linear_output_acc: 0.4713 - val_VH_attention_linear_output_acc: 0.4344\n",
      "Epoch 1557/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6392 - VL_attention_linear_output_loss: 1.7823 - VH_attention_linear_output_loss: 1.8568 - VL_attention_linear_output_acc: 0.4731 - VH_attention_linear_output_acc: 0.4394 - val_loss: 3.6680 - val_VL_attention_linear_output_loss: 1.7927 - val_VH_attention_linear_output_loss: 1.8754 - val_VL_attention_linear_output_acc: 0.4810 - val_VH_attention_linear_output_acc: 0.4371\n",
      "Epoch 1558/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6153 - VL_attention_linear_output_loss: 1.7571 - VH_attention_linear_output_loss: 1.8582 - VL_attention_linear_output_acc: 0.4861 - VH_attention_linear_output_acc: 0.4386 - val_loss: 3.6762 - val_VL_attention_linear_output_loss: 1.7964 - val_VH_attention_linear_output_loss: 1.8798 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4312\n",
      "Epoch 1559/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6461 - VL_attention_linear_output_loss: 1.7636 - VH_attention_linear_output_loss: 1.8825 - VL_attention_linear_output_acc: 0.4824 - VH_attention_linear_output_acc: 0.4301 - val_loss: 3.7159 - val_VL_attention_linear_output_loss: 1.7982 - val_VH_attention_linear_output_loss: 1.9177 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4278\n",
      "Epoch 1560/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6234 - VL_attention_linear_output_loss: 1.7654 - VH_attention_linear_output_loss: 1.8580 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4402 - val_loss: 3.6796 - val_VL_attention_linear_output_loss: 1.7964 - val_VH_attention_linear_output_loss: 1.8832 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4309\n",
      "Epoch 1561/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6141 - VL_attention_linear_output_loss: 1.7575 - VH_attention_linear_output_loss: 1.8567 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4397 - val_loss: 3.6727 - val_VL_attention_linear_output_loss: 1.7895 - val_VH_attention_linear_output_loss: 1.8831 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4311\n",
      "Epoch 1562/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6201 - VL_attention_linear_output_loss: 1.7683 - VH_attention_linear_output_loss: 1.8519 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4420 - val_loss: 3.6850 - val_VL_attention_linear_output_loss: 1.8124 - val_VH_attention_linear_output_loss: 1.8726 - val_VL_attention_linear_output_acc: 0.4648 - val_VH_attention_linear_output_acc: 0.4356\n",
      "Epoch 1563/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6134 - VL_attention_linear_output_loss: 1.7664 - VH_attention_linear_output_loss: 1.8469 - VL_attention_linear_output_acc: 0.4796 - VH_attention_linear_output_acc: 0.4446 - val_loss: 3.6767 - val_VL_attention_linear_output_loss: 1.8019 - val_VH_attention_linear_output_loss: 1.8748 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.4356\n",
      "Epoch 1564/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6090 - VL_attention_linear_output_loss: 1.7592 - VH_attention_linear_output_loss: 1.8498 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4424 - val_loss: 3.6677 - val_VL_attention_linear_output_loss: 1.7938 - val_VH_attention_linear_output_loss: 1.8740 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4426\n",
      "Epoch 1565/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6127 - VL_attention_linear_output_loss: 1.7583 - VH_attention_linear_output_loss: 1.8543 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4404 - val_loss: 3.6831 - val_VL_attention_linear_output_loss: 1.7911 - val_VH_attention_linear_output_loss: 1.8921 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4328\n",
      "Epoch 1566/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6192 - VL_attention_linear_output_loss: 1.7694 - VH_attention_linear_output_loss: 1.8498 - VL_attention_linear_output_acc: 0.4781 - VH_attention_linear_output_acc: 0.4430 - val_loss: 3.6781 - val_VL_attention_linear_output_loss: 1.8077 - val_VH_attention_linear_output_loss: 1.8704 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.4384\n",
      "Epoch 1567/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6089 - VL_attention_linear_output_loss: 1.7615 - VH_attention_linear_output_loss: 1.8474 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4432 - val_loss: 3.7129 - val_VL_attention_linear_output_loss: 1.8054 - val_VH_attention_linear_output_loss: 1.9075 - val_VL_attention_linear_output_acc: 0.4758 - val_VH_attention_linear_output_acc: 0.4168\n",
      "Epoch 1568/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6182 - VL_attention_linear_output_loss: 1.7646 - VH_attention_linear_output_loss: 1.8537 - VL_attention_linear_output_acc: 0.4815 - VH_attention_linear_output_acc: 0.4401 - val_loss: 3.6730 - val_VL_attention_linear_output_loss: 1.8006 - val_VH_attention_linear_output_loss: 1.8724 - val_VL_attention_linear_output_acc: 0.4771 - val_VH_attention_linear_output_acc: 0.4383\n",
      "Epoch 1569/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6059 - VL_attention_linear_output_loss: 1.7576 - VH_attention_linear_output_loss: 1.8483 - VL_attention_linear_output_acc: 0.4851 - VH_attention_linear_output_acc: 0.4429 - val_loss: 3.7390 - val_VL_attention_linear_output_loss: 1.8526 - val_VH_attention_linear_output_loss: 1.8864 - val_VL_attention_linear_output_acc: 0.4505 - val_VH_attention_linear_output_acc: 0.4361\n",
      "Epoch 1570/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6289 - VL_attention_linear_output_loss: 1.7734 - VH_attention_linear_output_loss: 1.8555 - VL_attention_linear_output_acc: 0.4773 - VH_attention_linear_output_acc: 0.4404 - val_loss: 3.6737 - val_VL_attention_linear_output_loss: 1.7935 - val_VH_attention_linear_output_loss: 1.8802 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.4325\n",
      "Epoch 1571/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6228 - VL_attention_linear_output_loss: 1.7652 - VH_attention_linear_output_loss: 1.8576 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4388 - val_loss: 3.6826 - val_VL_attention_linear_output_loss: 1.8009 - val_VH_attention_linear_output_loss: 1.8817 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.4385\n",
      "Epoch 1572/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6336 - VL_attention_linear_output_loss: 1.7634 - VH_attention_linear_output_loss: 1.8702 - VL_attention_linear_output_acc: 0.4821 - VH_attention_linear_output_acc: 0.4333 - val_loss: 3.6951 - val_VL_attention_linear_output_loss: 1.8091 - val_VH_attention_linear_output_loss: 1.8860 - val_VL_attention_linear_output_acc: 0.4730 - val_VH_attention_linear_output_acc: 0.4361\n",
      "Epoch 1573/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6134 - VL_attention_linear_output_loss: 1.7668 - VH_attention_linear_output_loss: 1.8466 - VL_attention_linear_output_acc: 0.4795 - VH_attention_linear_output_acc: 0.4438 - val_loss: 3.6752 - val_VL_attention_linear_output_loss: 1.8009 - val_VH_attention_linear_output_loss: 1.8743 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4366\n",
      "Epoch 1574/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6171 - VL_attention_linear_output_loss: 1.7674 - VH_attention_linear_output_loss: 1.8497 - VL_attention_linear_output_acc: 0.4806 - VH_attention_linear_output_acc: 0.4426 - val_loss: 3.6788 - val_VL_attention_linear_output_loss: 1.7931 - val_VH_attention_linear_output_loss: 1.8857 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4276\n",
      "Epoch 1575/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6046 - VL_attention_linear_output_loss: 1.7571 - VH_attention_linear_output_loss: 1.8475 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4435 - val_loss: 3.6919 - val_VL_attention_linear_output_loss: 1.8015 - val_VH_attention_linear_output_loss: 1.8904 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.4316\n",
      "Epoch 1576/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6148 - VL_attention_linear_output_loss: 1.7626 - VH_attention_linear_output_loss: 1.8522 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4417 - val_loss: 3.6755 - val_VL_attention_linear_output_loss: 1.7951 - val_VH_attention_linear_output_loss: 1.8804 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4313\n",
      "Epoch 1577/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6205 - VL_attention_linear_output_loss: 1.7668 - VH_attention_linear_output_loss: 1.8537 - VL_attention_linear_output_acc: 0.4801 - VH_attention_linear_output_acc: 0.4419 - val_loss: 3.6874 - val_VL_attention_linear_output_loss: 1.8172 - val_VH_attention_linear_output_loss: 1.8703 - val_VL_attention_linear_output_acc: 0.4631 - val_VH_attention_linear_output_acc: 0.4394\n",
      "Epoch 1578/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6156 - VL_attention_linear_output_loss: 1.7645 - VH_attention_linear_output_loss: 1.8512 - VL_attention_linear_output_acc: 0.4815 - VH_attention_linear_output_acc: 0.4417 - val_loss: 3.6827 - val_VL_attention_linear_output_loss: 1.8125 - val_VH_attention_linear_output_loss: 1.8702 - val_VL_attention_linear_output_acc: 0.4683 - val_VH_attention_linear_output_acc: 0.4389\n",
      "Epoch 1579/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6288 - VL_attention_linear_output_loss: 1.7709 - VH_attention_linear_output_loss: 1.8579 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4391 - val_loss: 3.6973 - val_VL_attention_linear_output_loss: 1.8020 - val_VH_attention_linear_output_loss: 1.8952 - val_VL_attention_linear_output_acc: 0.4757 - val_VH_attention_linear_output_acc: 0.4216\n",
      "Epoch 1580/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6134 - VL_attention_linear_output_loss: 1.7642 - VH_attention_linear_output_loss: 1.8492 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4429 - val_loss: 3.6730 - val_VL_attention_linear_output_loss: 1.8010 - val_VH_attention_linear_output_loss: 1.8721 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4406\n",
      "Epoch 1581/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6175 - VL_attention_linear_output_loss: 1.7618 - VH_attention_linear_output_loss: 1.8557 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4400 - val_loss: 3.6961 - val_VL_attention_linear_output_loss: 1.8122 - val_VH_attention_linear_output_loss: 1.8839 - val_VL_attention_linear_output_acc: 0.4725 - val_VH_attention_linear_output_acc: 0.4335\n",
      "Epoch 1582/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6340 - VL_attention_linear_output_loss: 1.7759 - VH_attention_linear_output_loss: 1.8581 - VL_attention_linear_output_acc: 0.4769 - VH_attention_linear_output_acc: 0.4393 - val_loss: 3.6876 - val_VL_attention_linear_output_loss: 1.8136 - val_VH_attention_linear_output_loss: 1.8740 - val_VL_attention_linear_output_acc: 0.4661 - val_VH_attention_linear_output_acc: 0.4379\n",
      "Epoch 1583/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6083 - VL_attention_linear_output_loss: 1.7616 - VH_attention_linear_output_loss: 1.8467 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4442 - val_loss: 3.6683 - val_VL_attention_linear_output_loss: 1.7984 - val_VH_attention_linear_output_loss: 1.8700 - val_VL_attention_linear_output_acc: 0.4779 - val_VH_attention_linear_output_acc: 0.4369\n",
      "Epoch 1584/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6089 - VL_attention_linear_output_loss: 1.7604 - VH_attention_linear_output_loss: 1.8484 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4432 - val_loss: 3.6739 - val_VL_attention_linear_output_loss: 1.8019 - val_VH_attention_linear_output_loss: 1.8720 - val_VL_attention_linear_output_acc: 0.4767 - val_VH_attention_linear_output_acc: 0.4388\n",
      "Epoch 1585/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6283 - VL_attention_linear_output_loss: 1.7672 - VH_attention_linear_output_loss: 1.8611 - VL_attention_linear_output_acc: 0.4811 - VH_attention_linear_output_acc: 0.4385 - val_loss: 3.6650 - val_VL_attention_linear_output_loss: 1.7926 - val_VH_attention_linear_output_loss: 1.8723 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4378\n",
      "Epoch 1586/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6198 - VL_attention_linear_output_loss: 1.7605 - VH_attention_linear_output_loss: 1.8594 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4388 - val_loss: 3.6700 - val_VL_attention_linear_output_loss: 1.7991 - val_VH_attention_linear_output_loss: 1.8709 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4389\n",
      "Epoch 1587/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6151 - VL_attention_linear_output_loss: 1.7607 - VH_attention_linear_output_loss: 1.8544 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4409 - val_loss: 3.6807 - val_VL_attention_linear_output_loss: 1.7935 - val_VH_attention_linear_output_loss: 1.8872 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4279\n",
      "Epoch 1588/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6326 - VL_attention_linear_output_loss: 1.7699 - VH_attention_linear_output_loss: 1.8627 - VL_attention_linear_output_acc: 0.4779 - VH_attention_linear_output_acc: 0.4375 - val_loss: 3.6845 - val_VL_attention_linear_output_loss: 1.7975 - val_VH_attention_linear_output_loss: 1.8871 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4343\n",
      "Epoch 1589/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6102 - VL_attention_linear_output_loss: 1.7604 - VH_attention_linear_output_loss: 1.8498 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4432 - val_loss: 3.6993 - val_VL_attention_linear_output_loss: 1.7999 - val_VH_attention_linear_output_loss: 1.8995 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4259\n",
      "Epoch 1590/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6175 - VL_attention_linear_output_loss: 1.7593 - VH_attention_linear_output_loss: 1.8582 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4403 - val_loss: 3.6669 - val_VL_attention_linear_output_loss: 1.7952 - val_VH_attention_linear_output_loss: 1.8717 - val_VL_attention_linear_output_acc: 0.4782 - val_VH_attention_linear_output_acc: 0.4374\n",
      "Epoch 1591/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6342 - VL_attention_linear_output_loss: 1.7686 - VH_attention_linear_output_loss: 1.8656 - VL_attention_linear_output_acc: 0.4810 - VH_attention_linear_output_acc: 0.4385 - val_loss: 3.7067 - val_VL_attention_linear_output_loss: 1.8257 - val_VH_attention_linear_output_loss: 1.8811 - val_VL_attention_linear_output_acc: 0.4599 - val_VH_attention_linear_output_acc: 0.4352\n",
      "Epoch 1592/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6247 - VL_attention_linear_output_loss: 1.7741 - VH_attention_linear_output_loss: 1.8506 - VL_attention_linear_output_acc: 0.4780 - VH_attention_linear_output_acc: 0.4429 - val_loss: 3.6750 - val_VL_attention_linear_output_loss: 1.7972 - val_VH_attention_linear_output_loss: 1.8778 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4383\n",
      "Epoch 1593/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6133 - VL_attention_linear_output_loss: 1.7615 - VH_attention_linear_output_loss: 1.8518 - VL_attention_linear_output_acc: 0.4837 - VH_attention_linear_output_acc: 0.4424 - val_loss: 3.6871 - val_VL_attention_linear_output_loss: 1.8037 - val_VH_attention_linear_output_loss: 1.8834 - val_VL_attention_linear_output_acc: 0.4769 - val_VH_attention_linear_output_acc: 0.4338\n",
      "Epoch 1594/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6087 - VL_attention_linear_output_loss: 1.7576 - VH_attention_linear_output_loss: 1.8510 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4423 - val_loss: 3.7162 - val_VL_attention_linear_output_loss: 1.8133 - val_VH_attention_linear_output_loss: 1.9029 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.4213\n",
      "Epoch 1595/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6217 - VL_attention_linear_output_loss: 1.7672 - VH_attention_linear_output_loss: 1.8545 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.4406 - val_loss: 3.6644 - val_VL_attention_linear_output_loss: 1.7984 - val_VH_attention_linear_output_loss: 1.8660 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.4430\n",
      "Epoch 1596/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6203 - VL_attention_linear_output_loss: 1.7656 - VH_attention_linear_output_loss: 1.8547 - VL_attention_linear_output_acc: 0.4807 - VH_attention_linear_output_acc: 0.4410 - val_loss: 3.6753 - val_VL_attention_linear_output_loss: 1.7917 - val_VH_attention_linear_output_loss: 1.8835 - val_VL_attention_linear_output_acc: 0.4795 - val_VH_attention_linear_output_acc: 0.4363\n",
      "Epoch 1597/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6107 - VL_attention_linear_output_loss: 1.7612 - VH_attention_linear_output_loss: 1.8495 - VL_attention_linear_output_acc: 0.4829 - VH_attention_linear_output_acc: 0.4438 - val_loss: 3.6656 - val_VL_attention_linear_output_loss: 1.8008 - val_VH_attention_linear_output_loss: 1.8648 - val_VL_attention_linear_output_acc: 0.4814 - val_VH_attention_linear_output_acc: 0.4404\n",
      "Epoch 1598/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6181 - VL_attention_linear_output_loss: 1.7633 - VH_attention_linear_output_loss: 1.8548 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4411 - val_loss: 3.6643 - val_VL_attention_linear_output_loss: 1.7951 - val_VH_attention_linear_output_loss: 1.8692 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4409\n",
      "Epoch 1599/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6144 - VL_attention_linear_output_loss: 1.7606 - VH_attention_linear_output_loss: 1.8537 - VL_attention_linear_output_acc: 0.4837 - VH_attention_linear_output_acc: 0.4412 - val_loss: 3.7655 - val_VL_attention_linear_output_loss: 1.8319 - val_VH_attention_linear_output_loss: 1.9335 - val_VL_attention_linear_output_acc: 0.4586 - val_VH_attention_linear_output_acc: 0.4175\n",
      "Epoch 1600/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6360 - VL_attention_linear_output_loss: 1.7750 - VH_attention_linear_output_loss: 1.8610 - VL_attention_linear_output_acc: 0.4761 - VH_attention_linear_output_acc: 0.4389 - val_loss: 3.7042 - val_VL_attention_linear_output_loss: 1.8045 - val_VH_attention_linear_output_loss: 1.8997 - val_VL_attention_linear_output_acc: 0.4773 - val_VH_attention_linear_output_acc: 0.4311\n",
      "Epoch 1601/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6169 - VL_attention_linear_output_loss: 1.7588 - VH_attention_linear_output_loss: 1.8581 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4402 - val_loss: 3.6544 - val_VL_attention_linear_output_loss: 1.7910 - val_VH_attention_linear_output_loss: 1.8634 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4428\n",
      "Epoch 1602/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6019 - VL_attention_linear_output_loss: 1.7582 - VH_attention_linear_output_loss: 1.8437 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4463 - val_loss: 3.6689 - val_VL_attention_linear_output_loss: 1.7934 - val_VH_attention_linear_output_loss: 1.8755 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4343\n",
      "Epoch 1603/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6070 - VL_attention_linear_output_loss: 1.7545 - VH_attention_linear_output_loss: 1.8526 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4423 - val_loss: 3.6994 - val_VL_attention_linear_output_loss: 1.8163 - val_VH_attention_linear_output_loss: 1.8831 - val_VL_attention_linear_output_acc: 0.4678 - val_VH_attention_linear_output_acc: 0.4340\n",
      "Epoch 1604/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6361 - VL_attention_linear_output_loss: 1.7744 - VH_attention_linear_output_loss: 1.8617 - VL_attention_linear_output_acc: 0.4775 - VH_attention_linear_output_acc: 0.4375 - val_loss: 3.7031 - val_VL_attention_linear_output_loss: 1.7958 - val_VH_attention_linear_output_loss: 1.9074 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4199\n",
      "Epoch 1605/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6072 - VL_attention_linear_output_loss: 1.7538 - VH_attention_linear_output_loss: 1.8534 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4412 - val_loss: 3.6651 - val_VL_attention_linear_output_loss: 1.7944 - val_VH_attention_linear_output_loss: 1.8707 - val_VL_attention_linear_output_acc: 0.4854 - val_VH_attention_linear_output_acc: 0.4391\n",
      "Epoch 1606/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6082 - VL_attention_linear_output_loss: 1.7603 - VH_attention_linear_output_loss: 1.8479 - VL_attention_linear_output_acc: 0.4848 - VH_attention_linear_output_acc: 0.4445 - val_loss: 3.6723 - val_VL_attention_linear_output_loss: 1.8012 - val_VH_attention_linear_output_loss: 1.8712 - val_VL_attention_linear_output_acc: 0.4774 - val_VH_attention_linear_output_acc: 0.4418\n",
      "Epoch 1607/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6052 - VL_attention_linear_output_loss: 1.7564 - VH_attention_linear_output_loss: 1.8488 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4447 - val_loss: 3.6903 - val_VL_attention_linear_output_loss: 1.8120 - val_VH_attention_linear_output_loss: 1.8782 - val_VL_attention_linear_output_acc: 0.4682 - val_VH_attention_linear_output_acc: 0.4411\n",
      "Epoch 1608/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6257 - VL_attention_linear_output_loss: 1.7676 - VH_attention_linear_output_loss: 1.8581 - VL_attention_linear_output_acc: 0.4800 - VH_attention_linear_output_acc: 0.4408 - val_loss: 3.7067 - val_VL_attention_linear_output_loss: 1.8084 - val_VH_attention_linear_output_loss: 1.8984 - val_VL_attention_linear_output_acc: 0.4623 - val_VH_attention_linear_output_acc: 0.4253\n",
      "Epoch 1609/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6297 - VL_attention_linear_output_loss: 1.7654 - VH_attention_linear_output_loss: 1.8643 - VL_attention_linear_output_acc: 0.4810 - VH_attention_linear_output_acc: 0.4375 - val_loss: 3.6853 - val_VL_attention_linear_output_loss: 1.8087 - val_VH_attention_linear_output_loss: 1.8766 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.4388\n",
      "Epoch 1610/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6214 - VL_attention_linear_output_loss: 1.7672 - VH_attention_linear_output_loss: 1.8543 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.4422 - val_loss: 3.6645 - val_VL_attention_linear_output_loss: 1.7943 - val_VH_attention_linear_output_loss: 1.8702 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4415\n",
      "Epoch 1611/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6190 - VL_attention_linear_output_loss: 1.7672 - VH_attention_linear_output_loss: 1.8519 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4433 - val_loss: 3.6761 - val_VL_attention_linear_output_loss: 1.7905 - val_VH_attention_linear_output_loss: 1.8856 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4346\n",
      "Epoch 1612/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6021 - VL_attention_linear_output_loss: 1.7623 - VH_attention_linear_output_loss: 1.8398 - VL_attention_linear_output_acc: 0.4826 - VH_attention_linear_output_acc: 0.4484 - val_loss: 3.6555 - val_VL_attention_linear_output_loss: 1.7956 - val_VH_attention_linear_output_loss: 1.8599 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4464\n",
      "Epoch 1613/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6102 - VL_attention_linear_output_loss: 1.7579 - VH_attention_linear_output_loss: 1.8522 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4421 - val_loss: 3.6621 - val_VL_attention_linear_output_loss: 1.7984 - val_VH_attention_linear_output_loss: 1.8638 - val_VL_attention_linear_output_acc: 0.4736 - val_VH_attention_linear_output_acc: 0.4409\n",
      "Epoch 1614/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6121 - VL_attention_linear_output_loss: 1.7679 - VH_attention_linear_output_loss: 1.8442 - VL_attention_linear_output_acc: 0.4794 - VH_attention_linear_output_acc: 0.4461 - val_loss: 3.7293 - val_VL_attention_linear_output_loss: 1.8648 - val_VH_attention_linear_output_loss: 1.8644 - val_VL_attention_linear_output_acc: 0.4446 - val_VH_attention_linear_output_acc: 0.4434\n",
      "Epoch 1615/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5995 - VL_attention_linear_output_loss: 1.7604 - VH_attention_linear_output_loss: 1.8390 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4482 - val_loss: 3.6591 - val_VL_attention_linear_output_loss: 1.7886 - val_VH_attention_linear_output_loss: 1.8706 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4415\n",
      "Epoch 1616/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6076 - VL_attention_linear_output_loss: 1.7548 - VH_attention_linear_output_loss: 1.8528 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4433 - val_loss: 3.6769 - val_VL_attention_linear_output_loss: 1.8035 - val_VH_attention_linear_output_loss: 1.8734 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4367\n",
      "Epoch 1617/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6143 - VL_attention_linear_output_loss: 1.7648 - VH_attention_linear_output_loss: 1.8494 - VL_attention_linear_output_acc: 0.4804 - VH_attention_linear_output_acc: 0.4433 - val_loss: 3.6876 - val_VL_attention_linear_output_loss: 1.8165 - val_VH_attention_linear_output_loss: 1.8711 - val_VL_attention_linear_output_acc: 0.4704 - val_VH_attention_linear_output_acc: 0.4421\n",
      "Epoch 1618/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6119 - VL_attention_linear_output_loss: 1.7663 - VH_attention_linear_output_loss: 1.8455 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4459 - val_loss: 3.6656 - val_VL_attention_linear_output_loss: 1.8000 - val_VH_attention_linear_output_loss: 1.8656 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4438\n",
      "Epoch 1619/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6276 - VL_attention_linear_output_loss: 1.7743 - VH_attention_linear_output_loss: 1.8533 - VL_attention_linear_output_acc: 0.4774 - VH_attention_linear_output_acc: 0.4426 - val_loss: 3.6557 - val_VL_attention_linear_output_loss: 1.7910 - val_VH_attention_linear_output_loss: 1.8647 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4452\n",
      "Epoch 1620/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5966 - VL_attention_linear_output_loss: 1.7528 - VH_attention_linear_output_loss: 1.8438 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4476 - val_loss: 3.6669 - val_VL_attention_linear_output_loss: 1.7947 - val_VH_attention_linear_output_loss: 1.8721 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4394\n",
      "Epoch 1621/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6139 - VL_attention_linear_output_loss: 1.7655 - VH_attention_linear_output_loss: 1.8484 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4448 - val_loss: 3.7353 - val_VL_attention_linear_output_loss: 1.8706 - val_VH_attention_linear_output_loss: 1.8647 - val_VL_attention_linear_output_acc: 0.4443 - val_VH_attention_linear_output_acc: 0.4447\n",
      "Epoch 1622/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6150 - VL_attention_linear_output_loss: 1.7655 - VH_attention_linear_output_loss: 1.8496 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4450 - val_loss: 3.6841 - val_VL_attention_linear_output_loss: 1.7948 - val_VH_attention_linear_output_loss: 1.8893 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4366\n",
      "Epoch 1623/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6129 - VL_attention_linear_output_loss: 1.7606 - VH_attention_linear_output_loss: 1.8522 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4435 - val_loss: 3.6747 - val_VL_attention_linear_output_loss: 1.7958 - val_VH_attention_linear_output_loss: 1.8788 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4388\n",
      "Epoch 1624/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6064 - VL_attention_linear_output_loss: 1.7624 - VH_attention_linear_output_loss: 1.8440 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4466 - val_loss: 3.6528 - val_VL_attention_linear_output_loss: 1.7923 - val_VH_attention_linear_output_loss: 1.8606 - val_VL_attention_linear_output_acc: 0.4867 - val_VH_attention_linear_output_acc: 0.4461\n",
      "Epoch 1625/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6052 - VL_attention_linear_output_loss: 1.7555 - VH_attention_linear_output_loss: 1.8496 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4439 - val_loss: 3.6623 - val_VL_attention_linear_output_loss: 1.7972 - val_VH_attention_linear_output_loss: 1.8651 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4434\n",
      "Epoch 1626/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6126 - VL_attention_linear_output_loss: 1.7649 - VH_attention_linear_output_loss: 1.8477 - VL_attention_linear_output_acc: 0.4810 - VH_attention_linear_output_acc: 0.4452 - val_loss: 3.6806 - val_VL_attention_linear_output_loss: 1.8071 - val_VH_attention_linear_output_loss: 1.8736 - val_VL_attention_linear_output_acc: 0.4723 - val_VH_attention_linear_output_acc: 0.4384\n",
      "Epoch 1627/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6288 - VL_attention_linear_output_loss: 1.7757 - VH_attention_linear_output_loss: 1.8531 - VL_attention_linear_output_acc: 0.4762 - VH_attention_linear_output_acc: 0.4424 - val_loss: 3.6667 - val_VL_attention_linear_output_loss: 1.7922 - val_VH_attention_linear_output_loss: 1.8745 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4355\n",
      "Epoch 1628/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6042 - VL_attention_linear_output_loss: 1.7639 - VH_attention_linear_output_loss: 1.8403 - VL_attention_linear_output_acc: 0.4814 - VH_attention_linear_output_acc: 0.4493 - val_loss: 3.6646 - val_VL_attention_linear_output_loss: 1.7970 - val_VH_attention_linear_output_loss: 1.8676 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4452\n",
      "Epoch 1629/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6083 - VL_attention_linear_output_loss: 1.7631 - VH_attention_linear_output_loss: 1.8452 - VL_attention_linear_output_acc: 0.4823 - VH_attention_linear_output_acc: 0.4480 - val_loss: 3.6634 - val_VL_attention_linear_output_loss: 1.8049 - val_VH_attention_linear_output_loss: 1.8584 - val_VL_attention_linear_output_acc: 0.4752 - val_VH_attention_linear_output_acc: 0.4440\n",
      "Epoch 1630/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6162 - VL_attention_linear_output_loss: 1.7713 - VH_attention_linear_output_loss: 1.8448 - VL_attention_linear_output_acc: 0.4785 - VH_attention_linear_output_acc: 0.4474 - val_loss: 3.7207 - val_VL_attention_linear_output_loss: 1.8449 - val_VH_attention_linear_output_loss: 1.8758 - val_VL_attention_linear_output_acc: 0.4521 - val_VH_attention_linear_output_acc: 0.4351\n",
      "Epoch 1631/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6036 - VL_attention_linear_output_loss: 1.7635 - VH_attention_linear_output_loss: 1.8401 - VL_attention_linear_output_acc: 0.4814 - VH_attention_linear_output_acc: 0.4490 - val_loss: 3.6693 - val_VL_attention_linear_output_loss: 1.7985 - val_VH_attention_linear_output_loss: 1.8707 - val_VL_attention_linear_output_acc: 0.4816 - val_VH_attention_linear_output_acc: 0.4425\n",
      "Epoch 1632/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6083 - VL_attention_linear_output_loss: 1.7656 - VH_attention_linear_output_loss: 1.8427 - VL_attention_linear_output_acc: 0.4805 - VH_attention_linear_output_acc: 0.4486 - val_loss: 3.6732 - val_VL_attention_linear_output_loss: 1.7920 - val_VH_attention_linear_output_loss: 1.8812 - val_VL_attention_linear_output_acc: 0.4804 - val_VH_attention_linear_output_acc: 0.4306\n",
      "Epoch 1633/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6055 - VL_attention_linear_output_loss: 1.7621 - VH_attention_linear_output_loss: 1.8434 - VL_attention_linear_output_acc: 0.4835 - VH_attention_linear_output_acc: 0.4479 - val_loss: 3.6617 - val_VL_attention_linear_output_loss: 1.7944 - val_VH_attention_linear_output_loss: 1.8673 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.4455\n",
      "Epoch 1634/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6056 - VL_attention_linear_output_loss: 1.7647 - VH_attention_linear_output_loss: 1.8409 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4496 - val_loss: 3.6754 - val_VL_attention_linear_output_loss: 1.8007 - val_VH_attention_linear_output_loss: 1.8747 - val_VL_attention_linear_output_acc: 0.4787 - val_VH_attention_linear_output_acc: 0.4399\n",
      "Epoch 1635/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6090 - VL_attention_linear_output_loss: 1.7588 - VH_attention_linear_output_loss: 1.8502 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4456 - val_loss: 3.7352 - val_VL_attention_linear_output_loss: 1.7921 - val_VH_attention_linear_output_loss: 1.9431 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4033\n",
      "Epoch 1636/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6064 - VL_attention_linear_output_loss: 1.7597 - VH_attention_linear_output_loss: 1.8467 - VL_attention_linear_output_acc: 0.4833 - VH_attention_linear_output_acc: 0.4461 - val_loss: 3.6647 - val_VL_attention_linear_output_loss: 1.8004 - val_VH_attention_linear_output_loss: 1.8643 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4431\n",
      "Epoch 1637/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6144 - VL_attention_linear_output_loss: 1.7663 - VH_attention_linear_output_loss: 1.8480 - VL_attention_linear_output_acc: 0.4807 - VH_attention_linear_output_acc: 0.4458 - val_loss: 3.7792 - val_VL_attention_linear_output_loss: 1.9066 - val_VH_attention_linear_output_loss: 1.8726 - val_VL_attention_linear_output_acc: 0.4222 - val_VH_attention_linear_output_acc: 0.4448\n",
      "Epoch 1638/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6107 - VL_attention_linear_output_loss: 1.7638 - VH_attention_linear_output_loss: 1.8469 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4460 - val_loss: 3.6691 - val_VL_attention_linear_output_loss: 1.7970 - val_VH_attention_linear_output_loss: 1.8720 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4439\n",
      "Epoch 1639/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6196 - VL_attention_linear_output_loss: 1.7757 - VH_attention_linear_output_loss: 1.8439 - VL_attention_linear_output_acc: 0.4755 - VH_attention_linear_output_acc: 0.4482 - val_loss: 3.6980 - val_VL_attention_linear_output_loss: 1.7964 - val_VH_attention_linear_output_loss: 1.9016 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4222\n",
      "Epoch 1640/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6043 - VL_attention_linear_output_loss: 1.7614 - VH_attention_linear_output_loss: 1.8429 - VL_attention_linear_output_acc: 0.4833 - VH_attention_linear_output_acc: 0.4472 - val_loss: 3.6753 - val_VL_attention_linear_output_loss: 1.7968 - val_VH_attention_linear_output_loss: 1.8785 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4361\n",
      "Epoch 1641/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6198 - VL_attention_linear_output_loss: 1.7737 - VH_attention_linear_output_loss: 1.8461 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.4472 - val_loss: 3.6653 - val_VL_attention_linear_output_loss: 1.8031 - val_VH_attention_linear_output_loss: 1.8622 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.4457\n",
      "Epoch 1642/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6017 - VL_attention_linear_output_loss: 1.7603 - VH_attention_linear_output_loss: 1.8414 - VL_attention_linear_output_acc: 0.4829 - VH_attention_linear_output_acc: 0.4501 - val_loss: 3.6516 - val_VL_attention_linear_output_loss: 1.7871 - val_VH_attention_linear_output_loss: 1.8645 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4429\n",
      "Epoch 1643/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5944 - VL_attention_linear_output_loss: 1.7540 - VH_attention_linear_output_loss: 1.8404 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4496 - val_loss: 3.6716 - val_VL_attention_linear_output_loss: 1.7957 - val_VH_attention_linear_output_loss: 1.8759 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4394\n",
      "Epoch 1644/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6196 - VL_attention_linear_output_loss: 1.7644 - VH_attention_linear_output_loss: 1.8552 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4430 - val_loss: 3.7758 - val_VL_attention_linear_output_loss: 1.8405 - val_VH_attention_linear_output_loss: 1.9353 - val_VL_attention_linear_output_acc: 0.4547 - val_VH_attention_linear_output_acc: 0.4047\n",
      "Epoch 1645/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6145 - VL_attention_linear_output_loss: 1.7653 - VH_attention_linear_output_loss: 1.8492 - VL_attention_linear_output_acc: 0.4811 - VH_attention_linear_output_acc: 0.4457 - val_loss: 3.6771 - val_VL_attention_linear_output_loss: 1.8004 - val_VH_attention_linear_output_loss: 1.8767 - val_VL_attention_linear_output_acc: 0.4755 - val_VH_attention_linear_output_acc: 0.4359\n",
      "Epoch 1646/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6038 - VL_attention_linear_output_loss: 1.7598 - VH_attention_linear_output_loss: 1.8440 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4476 - val_loss: 3.6712 - val_VL_attention_linear_output_loss: 1.7898 - val_VH_attention_linear_output_loss: 1.8814 - val_VL_attention_linear_output_acc: 0.4782 - val_VH_attention_linear_output_acc: 0.4373\n",
      "Epoch 1647/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6141 - VL_attention_linear_output_loss: 1.7684 - VH_attention_linear_output_loss: 1.8458 - VL_attention_linear_output_acc: 0.4790 - VH_attention_linear_output_acc: 0.4466 - val_loss: 3.6536 - val_VL_attention_linear_output_loss: 1.7917 - val_VH_attention_linear_output_loss: 1.8619 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4413\n",
      "Epoch 1648/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6106 - VL_attention_linear_output_loss: 1.7670 - VH_attention_linear_output_loss: 1.8436 - VL_attention_linear_output_acc: 0.4801 - VH_attention_linear_output_acc: 0.4474 - val_loss: 3.7009 - val_VL_attention_linear_output_loss: 1.8334 - val_VH_attention_linear_output_loss: 1.8675 - val_VL_attention_linear_output_acc: 0.4650 - val_VH_attention_linear_output_acc: 0.4459\n",
      "Epoch 1649/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6109 - VL_attention_linear_output_loss: 1.7655 - VH_attention_linear_output_loss: 1.8454 - VL_attention_linear_output_acc: 0.4805 - VH_attention_linear_output_acc: 0.4472 - val_loss: 3.6757 - val_VL_attention_linear_output_loss: 1.8097 - val_VH_attention_linear_output_loss: 1.8661 - val_VL_attention_linear_output_acc: 0.4771 - val_VH_attention_linear_output_acc: 0.4474\n",
      "Epoch 1650/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6189 - VL_attention_linear_output_loss: 1.7700 - VH_attention_linear_output_loss: 1.8489 - VL_attention_linear_output_acc: 0.4786 - VH_attention_linear_output_acc: 0.4451 - val_loss: 3.6456 - val_VL_attention_linear_output_loss: 1.7904 - val_VH_attention_linear_output_loss: 1.8552 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4488\n",
      "Epoch 1651/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6010 - VL_attention_linear_output_loss: 1.7608 - VH_attention_linear_output_loss: 1.8403 - VL_attention_linear_output_acc: 0.4829 - VH_attention_linear_output_acc: 0.4498 - val_loss: 3.6785 - val_VL_attention_linear_output_loss: 1.7960 - val_VH_attention_linear_output_loss: 1.8824 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4336\n",
      "Epoch 1652/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6062 - VL_attention_linear_output_loss: 1.7623 - VH_attention_linear_output_loss: 1.8439 - VL_attention_linear_output_acc: 0.4829 - VH_attention_linear_output_acc: 0.4479 - val_loss: 3.6564 - val_VL_attention_linear_output_loss: 1.7944 - val_VH_attention_linear_output_loss: 1.8620 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4474\n",
      "Epoch 1653/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6026 - VL_attention_linear_output_loss: 1.7556 - VH_attention_linear_output_loss: 1.8470 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4465 - val_loss: 3.7055 - val_VL_attention_linear_output_loss: 1.8248 - val_VH_attention_linear_output_loss: 1.8807 - val_VL_attention_linear_output_acc: 0.4637 - val_VH_attention_linear_output_acc: 0.4362\n",
      "Epoch 1654/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6059 - VL_attention_linear_output_loss: 1.7629 - VH_attention_linear_output_loss: 1.8430 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4483 - val_loss: 3.6612 - val_VL_attention_linear_output_loss: 1.7948 - val_VH_attention_linear_output_loss: 1.8664 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4445\n",
      "Epoch 1655/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6214 - VL_attention_linear_output_loss: 1.7638 - VH_attention_linear_output_loss: 1.8577 - VL_attention_linear_output_acc: 0.4824 - VH_attention_linear_output_acc: 0.4430 - val_loss: 3.6574 - val_VL_attention_linear_output_loss: 1.7897 - val_VH_attention_linear_output_loss: 1.8678 - val_VL_attention_linear_output_acc: 0.4854 - val_VH_attention_linear_output_acc: 0.4432\n",
      "Epoch 1656/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6064 - VL_attention_linear_output_loss: 1.7629 - VH_attention_linear_output_loss: 1.8436 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4478 - val_loss: 3.6611 - val_VL_attention_linear_output_loss: 1.7981 - val_VH_attention_linear_output_loss: 1.8630 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.4434\n",
      "Epoch 1657/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6029 - VL_attention_linear_output_loss: 1.7598 - VH_attention_linear_output_loss: 1.8430 - VL_attention_linear_output_acc: 0.4835 - VH_attention_linear_output_acc: 0.4482 - val_loss: 3.6776 - val_VL_attention_linear_output_loss: 1.8093 - val_VH_attention_linear_output_loss: 1.8683 - val_VL_attention_linear_output_acc: 0.4705 - val_VH_attention_linear_output_acc: 0.4454\n",
      "Epoch 1658/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6002 - VL_attention_linear_output_loss: 1.7555 - VH_attention_linear_output_loss: 1.8447 - VL_attention_linear_output_acc: 0.4851 - VH_attention_linear_output_acc: 0.4478 - val_loss: 3.6608 - val_VL_attention_linear_output_loss: 1.7915 - val_VH_attention_linear_output_loss: 1.8692 - val_VL_attention_linear_output_acc: 0.4720 - val_VH_attention_linear_output_acc: 0.4381\n",
      "Epoch 1659/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6013 - VL_attention_linear_output_loss: 1.7601 - VH_attention_linear_output_loss: 1.8412 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4490 - val_loss: 3.6748 - val_VL_attention_linear_output_loss: 1.8075 - val_VH_attention_linear_output_loss: 1.8673 - val_VL_attention_linear_output_acc: 0.4701 - val_VH_attention_linear_output_acc: 0.4437\n",
      "Epoch 1660/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6082 - VL_attention_linear_output_loss: 1.7561 - VH_attention_linear_output_loss: 1.8521 - VL_attention_linear_output_acc: 0.4858 - VH_attention_linear_output_acc: 0.4438 - val_loss: 3.6787 - val_VL_attention_linear_output_loss: 1.8067 - val_VH_attention_linear_output_loss: 1.8721 - val_VL_attention_linear_output_acc: 0.4740 - val_VH_attention_linear_output_acc: 0.4431\n",
      "Epoch 1661/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6108 - VL_attention_linear_output_loss: 1.7683 - VH_attention_linear_output_loss: 1.8426 - VL_attention_linear_output_acc: 0.4805 - VH_attention_linear_output_acc: 0.4498 - val_loss: 3.6702 - val_VL_attention_linear_output_loss: 1.7913 - val_VH_attention_linear_output_loss: 1.8789 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4374\n",
      "Epoch 1662/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6050 - VL_attention_linear_output_loss: 1.7638 - VH_attention_linear_output_loss: 1.8412 - VL_attention_linear_output_acc: 0.4815 - VH_attention_linear_output_acc: 0.4491 - val_loss: 3.6617 - val_VL_attention_linear_output_loss: 1.8028 - val_VH_attention_linear_output_loss: 1.8589 - val_VL_attention_linear_output_acc: 0.4729 - val_VH_attention_linear_output_acc: 0.4457\n",
      "Epoch 1663/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6108 - VL_attention_linear_output_loss: 1.7697 - VH_attention_linear_output_loss: 1.8410 - VL_attention_linear_output_acc: 0.4783 - VH_attention_linear_output_acc: 0.4491 - val_loss: 3.6567 - val_VL_attention_linear_output_loss: 1.7965 - val_VH_attention_linear_output_loss: 1.8602 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4470\n",
      "Epoch 1664/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6064 - VL_attention_linear_output_loss: 1.7543 - VH_attention_linear_output_loss: 1.8520 - VL_attention_linear_output_acc: 0.4869 - VH_attention_linear_output_acc: 0.4437 - val_loss: 3.6610 - val_VL_attention_linear_output_loss: 1.7881 - val_VH_attention_linear_output_loss: 1.8729 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4397\n",
      "Epoch 1665/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6050 - VL_attention_linear_output_loss: 1.7659 - VH_attention_linear_output_loss: 1.8392 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.4502 - val_loss: 3.6771 - val_VL_attention_linear_output_loss: 1.8101 - val_VH_attention_linear_output_loss: 1.8670 - val_VL_attention_linear_output_acc: 0.4711 - val_VH_attention_linear_output_acc: 0.4424\n",
      "Epoch 1666/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5958 - VL_attention_linear_output_loss: 1.7574 - VH_attention_linear_output_loss: 1.8383 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4512 - val_loss: 3.6994 - val_VL_attention_linear_output_loss: 1.8287 - val_VH_attention_linear_output_loss: 1.8707 - val_VL_attention_linear_output_acc: 0.4594 - val_VH_attention_linear_output_acc: 0.4394\n",
      "Epoch 1667/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6193 - VL_attention_linear_output_loss: 1.7779 - VH_attention_linear_output_loss: 1.8414 - VL_attention_linear_output_acc: 0.4746 - VH_attention_linear_output_acc: 0.4486 - val_loss: 3.6479 - val_VL_attention_linear_output_loss: 1.7891 - val_VH_attention_linear_output_loss: 1.8588 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4486\n",
      "Epoch 1668/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5903 - VL_attention_linear_output_loss: 1.7538 - VH_attention_linear_output_loss: 1.8365 - VL_attention_linear_output_acc: 0.4860 - VH_attention_linear_output_acc: 0.4512 - val_loss: 3.7288 - val_VL_attention_linear_output_loss: 1.7933 - val_VH_attention_linear_output_loss: 1.9355 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4130\n",
      "Epoch 1669/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5947 - VL_attention_linear_output_loss: 1.7499 - VH_attention_linear_output_loss: 1.8448 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4475 - val_loss: 3.6640 - val_VL_attention_linear_output_loss: 1.7984 - val_VH_attention_linear_output_loss: 1.8657 - val_VL_attention_linear_output_acc: 0.4650 - val_VH_attention_linear_output_acc: 0.4469\n",
      "Epoch 1670/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6009 - VL_attention_linear_output_loss: 1.7603 - VH_attention_linear_output_loss: 1.8406 - VL_attention_linear_output_acc: 0.4824 - VH_attention_linear_output_acc: 0.4496 - val_loss: 3.7062 - val_VL_attention_linear_output_loss: 1.8541 - val_VH_attention_linear_output_loss: 1.8521 - val_VL_attention_linear_output_acc: 0.4497 - val_VH_attention_linear_output_acc: 0.4503\n",
      "Epoch 1671/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6122 - VL_attention_linear_output_loss: 1.7779 - VH_attention_linear_output_loss: 1.8344 - VL_attention_linear_output_acc: 0.4757 - VH_attention_linear_output_acc: 0.4525 - val_loss: 3.6971 - val_VL_attention_linear_output_loss: 1.8301 - val_VH_attention_linear_output_loss: 1.8670 - val_VL_attention_linear_output_acc: 0.4571 - val_VH_attention_linear_output_acc: 0.4379\n",
      "Epoch 1672/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5983 - VL_attention_linear_output_loss: 1.7581 - VH_attention_linear_output_loss: 1.8402 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4494 - val_loss: 3.6994 - val_VL_attention_linear_output_loss: 1.8040 - val_VH_attention_linear_output_loss: 1.8954 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4264\n",
      "Epoch 1673/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5973 - VL_attention_linear_output_loss: 1.7584 - VH_attention_linear_output_loss: 1.8389 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4492 - val_loss: 3.6662 - val_VL_attention_linear_output_loss: 1.8087 - val_VH_attention_linear_output_loss: 1.8576 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.4499\n",
      "Epoch 1674/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6139 - VL_attention_linear_output_loss: 1.7642 - VH_attention_linear_output_loss: 1.8497 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4456 - val_loss: 3.6686 - val_VL_attention_linear_output_loss: 1.8029 - val_VH_attention_linear_output_loss: 1.8657 - val_VL_attention_linear_output_acc: 0.4766 - val_VH_attention_linear_output_acc: 0.4447\n",
      "Epoch 1675/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6059 - VL_attention_linear_output_loss: 1.7657 - VH_attention_linear_output_loss: 1.8401 - VL_attention_linear_output_acc: 0.4802 - VH_attention_linear_output_acc: 0.4494 - val_loss: 3.6670 - val_VL_attention_linear_output_loss: 1.8002 - val_VH_attention_linear_output_loss: 1.8668 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4462\n",
      "Epoch 1676/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6073 - VL_attention_linear_output_loss: 1.7614 - VH_attention_linear_output_loss: 1.8460 - VL_attention_linear_output_acc: 0.4835 - VH_attention_linear_output_acc: 0.4475 - val_loss: 3.6714 - val_VL_attention_linear_output_loss: 1.8075 - val_VH_attention_linear_output_loss: 1.8639 - val_VL_attention_linear_output_acc: 0.4647 - val_VH_attention_linear_output_acc: 0.4444\n",
      "Epoch 1677/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6059 - VL_attention_linear_output_loss: 1.7660 - VH_attention_linear_output_loss: 1.8399 - VL_attention_linear_output_acc: 0.4794 - VH_attention_linear_output_acc: 0.4500 - val_loss: 3.6588 - val_VL_attention_linear_output_loss: 1.7859 - val_VH_attention_linear_output_loss: 1.8730 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.4444\n",
      "Epoch 1678/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5888 - VL_attention_linear_output_loss: 1.7547 - VH_attention_linear_output_loss: 1.8341 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4520 - val_loss: 3.6495 - val_VL_attention_linear_output_loss: 1.7930 - val_VH_attention_linear_output_loss: 1.8565 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.4456\n",
      "Epoch 1679/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5952 - VL_attention_linear_output_loss: 1.7544 - VH_attention_linear_output_loss: 1.8408 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4491 - val_loss: 3.6811 - val_VL_attention_linear_output_loss: 1.7898 - val_VH_attention_linear_output_loss: 1.8913 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4364\n",
      "Epoch 1680/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5934 - VL_attention_linear_output_loss: 1.7526 - VH_attention_linear_output_loss: 1.8408 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4490 - val_loss: 3.6725 - val_VL_attention_linear_output_loss: 1.8173 - val_VH_attention_linear_output_loss: 1.8552 - val_VL_attention_linear_output_acc: 0.4686 - val_VH_attention_linear_output_acc: 0.4523\n",
      "Epoch 1681/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6093 - VL_attention_linear_output_loss: 1.7598 - VH_attention_linear_output_loss: 1.8494 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4459 - val_loss: 3.7293 - val_VL_attention_linear_output_loss: 1.8643 - val_VH_attention_linear_output_loss: 1.8650 - val_VL_attention_linear_output_acc: 0.4450 - val_VH_attention_linear_output_acc: 0.4428\n",
      "Epoch 1682/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6059 - VL_attention_linear_output_loss: 1.7684 - VH_attention_linear_output_loss: 1.8376 - VL_attention_linear_output_acc: 0.4790 - VH_attention_linear_output_acc: 0.4510 - val_loss: 3.6400 - val_VL_attention_linear_output_loss: 1.7862 - val_VH_attention_linear_output_loss: 1.8538 - val_VL_attention_linear_output_acc: 0.4793 - val_VH_attention_linear_output_acc: 0.4505\n",
      "Epoch 1683/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6024 - VL_attention_linear_output_loss: 1.7613 - VH_attention_linear_output_loss: 1.8412 - VL_attention_linear_output_acc: 0.4820 - VH_attention_linear_output_acc: 0.4488 - val_loss: 3.7375 - val_VL_attention_linear_output_loss: 1.8853 - val_VH_attention_linear_output_loss: 1.8522 - val_VL_attention_linear_output_acc: 0.4319 - val_VH_attention_linear_output_acc: 0.4524\n",
      "Epoch 1684/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6019 - VL_attention_linear_output_loss: 1.7625 - VH_attention_linear_output_loss: 1.8394 - VL_attention_linear_output_acc: 0.4823 - VH_attention_linear_output_acc: 0.4491 - val_loss: 3.7338 - val_VL_attention_linear_output_loss: 1.8641 - val_VH_attention_linear_output_loss: 1.8697 - val_VL_attention_linear_output_acc: 0.4435 - val_VH_attention_linear_output_acc: 0.4459\n",
      "Epoch 1685/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6083 - VL_attention_linear_output_loss: 1.7609 - VH_attention_linear_output_loss: 1.8474 - VL_attention_linear_output_acc: 0.4812 - VH_attention_linear_output_acc: 0.4477 - val_loss: 3.7046 - val_VL_attention_linear_output_loss: 1.8053 - val_VH_attention_linear_output_loss: 1.8993 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.4308\n",
      "Epoch 1686/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5908 - VL_attention_linear_output_loss: 1.7553 - VH_attention_linear_output_loss: 1.8354 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4517 - val_loss: 3.6971 - val_VL_attention_linear_output_loss: 1.8293 - val_VH_attention_linear_output_loss: 1.8678 - val_VL_attention_linear_output_acc: 0.4595 - val_VH_attention_linear_output_acc: 0.4376\n",
      "Epoch 1687/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6038 - VL_attention_linear_output_loss: 1.7662 - VH_attention_linear_output_loss: 1.8375 - VL_attention_linear_output_acc: 0.4807 - VH_attention_linear_output_acc: 0.4501 - val_loss: 3.6473 - val_VL_attention_linear_output_loss: 1.7905 - val_VH_attention_linear_output_loss: 1.8567 - val_VL_attention_linear_output_acc: 0.4816 - val_VH_attention_linear_output_acc: 0.4493\n",
      "Epoch 1688/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5940 - VL_attention_linear_output_loss: 1.7601 - VH_attention_linear_output_loss: 1.8339 - VL_attention_linear_output_acc: 0.4812 - VH_attention_linear_output_acc: 0.4521 - val_loss: 3.6660 - val_VL_attention_linear_output_loss: 1.7961 - val_VH_attention_linear_output_loss: 1.8699 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4466\n",
      "Epoch 1689/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5885 - VL_attention_linear_output_loss: 1.7510 - VH_attention_linear_output_loss: 1.8374 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4501 - val_loss: 3.6553 - val_VL_attention_linear_output_loss: 1.7862 - val_VH_attention_linear_output_loss: 1.8691 - val_VL_attention_linear_output_acc: 0.4869 - val_VH_attention_linear_output_acc: 0.4467\n",
      "Epoch 1690/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6039 - VL_attention_linear_output_loss: 1.7692 - VH_attention_linear_output_loss: 1.8347 - VL_attention_linear_output_acc: 0.4781 - VH_attention_linear_output_acc: 0.4516 - val_loss: 3.6418 - val_VL_attention_linear_output_loss: 1.7842 - val_VH_attention_linear_output_loss: 1.8576 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4496\n",
      "Epoch 1691/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5855 - VL_attention_linear_output_loss: 1.7488 - VH_attention_linear_output_loss: 1.8367 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4506 - val_loss: 3.6520 - val_VL_attention_linear_output_loss: 1.7865 - val_VH_attention_linear_output_loss: 1.8656 - val_VL_attention_linear_output_acc: 0.4860 - val_VH_attention_linear_output_acc: 0.4465\n",
      "Epoch 1692/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5926 - VL_attention_linear_output_loss: 1.7560 - VH_attention_linear_output_loss: 1.8366 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4515 - val_loss: 3.6578 - val_VL_attention_linear_output_loss: 1.7943 - val_VH_attention_linear_output_loss: 1.8635 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4412\n",
      "Epoch 1693/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5939 - VL_attention_linear_output_loss: 1.7566 - VH_attention_linear_output_loss: 1.8373 - VL_attention_linear_output_acc: 0.4851 - VH_attention_linear_output_acc: 0.4511 - val_loss: 3.6624 - val_VL_attention_linear_output_loss: 1.7912 - val_VH_attention_linear_output_loss: 1.8711 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4432\n",
      "Epoch 1694/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5970 - VL_attention_linear_output_loss: 1.7547 - VH_attention_linear_output_loss: 1.8424 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4483 - val_loss: 3.6624 - val_VL_attention_linear_output_loss: 1.8022 - val_VH_attention_linear_output_loss: 1.8602 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.4489\n",
      "Epoch 1695/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5974 - VL_attention_linear_output_loss: 1.7589 - VH_attention_linear_output_loss: 1.8385 - VL_attention_linear_output_acc: 0.4837 - VH_attention_linear_output_acc: 0.4498 - val_loss: 3.6475 - val_VL_attention_linear_output_loss: 1.7886 - val_VH_attention_linear_output_loss: 1.8590 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4489\n",
      "Epoch 1696/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6060 - VL_attention_linear_output_loss: 1.7615 - VH_attention_linear_output_loss: 1.8445 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4486 - val_loss: 3.6724 - val_VL_attention_linear_output_loss: 1.8114 - val_VH_attention_linear_output_loss: 1.8610 - val_VL_attention_linear_output_acc: 0.4725 - val_VH_attention_linear_output_acc: 0.4433\n",
      "Epoch 1697/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6127 - VL_attention_linear_output_loss: 1.7674 - VH_attention_linear_output_loss: 1.8453 - VL_attention_linear_output_acc: 0.4784 - VH_attention_linear_output_acc: 0.4475 - val_loss: 3.6683 - val_VL_attention_linear_output_loss: 1.8080 - val_VH_attention_linear_output_loss: 1.8602 - val_VL_attention_linear_output_acc: 0.4748 - val_VH_attention_linear_output_acc: 0.4461\n",
      "Epoch 1698/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6237 - VL_attention_linear_output_loss: 1.7769 - VH_attention_linear_output_loss: 1.8468 - VL_attention_linear_output_acc: 0.4752 - VH_attention_linear_output_acc: 0.4478 - val_loss: 3.6619 - val_VL_attention_linear_output_loss: 1.7955 - val_VH_attention_linear_output_loss: 1.8663 - val_VL_attention_linear_output_acc: 0.4778 - val_VH_attention_linear_output_acc: 0.4452\n",
      "Epoch 1699/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5989 - VL_attention_linear_output_loss: 1.7530 - VH_attention_linear_output_loss: 1.8459 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4494 - val_loss: 3.6778 - val_VL_attention_linear_output_loss: 1.7919 - val_VH_attention_linear_output_loss: 1.8859 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4356\n",
      "Epoch 1700/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6069 - VL_attention_linear_output_loss: 1.7523 - VH_attention_linear_output_loss: 1.8546 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4453 - val_loss: 3.6599 - val_VL_attention_linear_output_loss: 1.7895 - val_VH_attention_linear_output_loss: 1.8703 - val_VL_attention_linear_output_acc: 0.4769 - val_VH_attention_linear_output_acc: 0.4422\n",
      "Epoch 1701/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6041 - VL_attention_linear_output_loss: 1.7597 - VH_attention_linear_output_loss: 1.8444 - VL_attention_linear_output_acc: 0.4832 - VH_attention_linear_output_acc: 0.4485 - val_loss: 3.6629 - val_VL_attention_linear_output_loss: 1.8067 - val_VH_attention_linear_output_loss: 1.8562 - val_VL_attention_linear_output_acc: 0.4734 - val_VH_attention_linear_output_acc: 0.4463\n",
      "Epoch 1702/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6091 - VL_attention_linear_output_loss: 1.7667 - VH_attention_linear_output_loss: 1.8423 - VL_attention_linear_output_acc: 0.4798 - VH_attention_linear_output_acc: 0.4493 - val_loss: 3.6540 - val_VL_attention_linear_output_loss: 1.7859 - val_VH_attention_linear_output_loss: 1.8681 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4444\n",
      "Epoch 1703/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5930 - VL_attention_linear_output_loss: 1.7575 - VH_attention_linear_output_loss: 1.8356 - VL_attention_linear_output_acc: 0.4822 - VH_attention_linear_output_acc: 0.4525 - val_loss: 3.6518 - val_VL_attention_linear_output_loss: 1.7989 - val_VH_attention_linear_output_loss: 1.8528 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4486\n",
      "Epoch 1704/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6055 - VL_attention_linear_output_loss: 1.7625 - VH_attention_linear_output_loss: 1.8430 - VL_attention_linear_output_acc: 0.4827 - VH_attention_linear_output_acc: 0.4493 - val_loss: 3.6523 - val_VL_attention_linear_output_loss: 1.7900 - val_VH_attention_linear_output_loss: 1.8623 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4438\n",
      "Epoch 1705/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5891 - VL_attention_linear_output_loss: 1.7516 - VH_attention_linear_output_loss: 1.8375 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4516 - val_loss: 3.6470 - val_VL_attention_linear_output_loss: 1.7919 - val_VH_attention_linear_output_loss: 1.8551 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4511\n",
      "Epoch 1706/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5998 - VL_attention_linear_output_loss: 1.7649 - VH_attention_linear_output_loss: 1.8349 - VL_attention_linear_output_acc: 0.4791 - VH_attention_linear_output_acc: 0.4525 - val_loss: 3.6898 - val_VL_attention_linear_output_loss: 1.8212 - val_VH_attention_linear_output_loss: 1.8686 - val_VL_attention_linear_output_acc: 0.4489 - val_VH_attention_linear_output_acc: 0.4393\n",
      "Epoch 1707/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6058 - VL_attention_linear_output_loss: 1.7666 - VH_attention_linear_output_loss: 1.8392 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.4501 - val_loss: 3.6659 - val_VL_attention_linear_output_loss: 1.8020 - val_VH_attention_linear_output_loss: 1.8639 - val_VL_attention_linear_output_acc: 0.4777 - val_VH_attention_linear_output_acc: 0.4464\n",
      "Epoch 1708/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5831 - VL_attention_linear_output_loss: 1.7507 - VH_attention_linear_output_loss: 1.8324 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4535 - val_loss: 3.6406 - val_VL_attention_linear_output_loss: 1.7876 - val_VH_attention_linear_output_loss: 1.8530 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4508\n",
      "Epoch 1709/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5891 - VL_attention_linear_output_loss: 1.7600 - VH_attention_linear_output_loss: 1.8291 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4548 - val_loss: 3.6517 - val_VL_attention_linear_output_loss: 1.7919 - val_VH_attention_linear_output_loss: 1.8598 - val_VL_attention_linear_output_acc: 0.4814 - val_VH_attention_linear_output_acc: 0.4499\n",
      "Epoch 1710/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6002 - VL_attention_linear_output_loss: 1.7639 - VH_attention_linear_output_loss: 1.8364 - VL_attention_linear_output_acc: 0.4807 - VH_attention_linear_output_acc: 0.4513 - val_loss: 3.6625 - val_VL_attention_linear_output_loss: 1.8009 - val_VH_attention_linear_output_loss: 1.8615 - val_VL_attention_linear_output_acc: 0.4715 - val_VH_attention_linear_output_acc: 0.4486\n",
      "Epoch 1711/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6004 - VL_attention_linear_output_loss: 1.7669 - VH_attention_linear_output_loss: 1.8335 - VL_attention_linear_output_acc: 0.4799 - VH_attention_linear_output_acc: 0.4522 - val_loss: 3.6670 - val_VL_attention_linear_output_loss: 1.8003 - val_VH_attention_linear_output_loss: 1.8667 - val_VL_attention_linear_output_acc: 0.4787 - val_VH_attention_linear_output_acc: 0.4432\n",
      "Epoch 1712/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5869 - VL_attention_linear_output_loss: 1.7567 - VH_attention_linear_output_loss: 1.8302 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4537 - val_loss: 3.6617 - val_VL_attention_linear_output_loss: 1.7871 - val_VH_attention_linear_output_loss: 1.8745 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4347\n",
      "Epoch 1713/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5936 - VL_attention_linear_output_loss: 1.7496 - VH_attention_linear_output_loss: 1.8441 - VL_attention_linear_output_acc: 0.4881 - VH_attention_linear_output_acc: 0.4482 - val_loss: 3.6529 - val_VL_attention_linear_output_loss: 1.7948 - val_VH_attention_linear_output_loss: 1.8581 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4500\n",
      "Epoch 1714/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6082 - VL_attention_linear_output_loss: 1.7698 - VH_attention_linear_output_loss: 1.8384 - VL_attention_linear_output_acc: 0.4794 - VH_attention_linear_output_acc: 0.4497 - val_loss: 3.6771 - val_VL_attention_linear_output_loss: 1.7961 - val_VH_attention_linear_output_loss: 1.8810 - val_VL_attention_linear_output_acc: 0.4764 - val_VH_attention_linear_output_acc: 0.4316\n",
      "Epoch 1715/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5876 - VL_attention_linear_output_loss: 1.7576 - VH_attention_linear_output_loss: 1.8300 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4538 - val_loss: 3.7005 - val_VL_attention_linear_output_loss: 1.8472 - val_VH_attention_linear_output_loss: 1.8534 - val_VL_attention_linear_output_acc: 0.4500 - val_VH_attention_linear_output_acc: 0.4527\n",
      "Epoch 1716/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5982 - VL_attention_linear_output_loss: 1.7644 - VH_attention_linear_output_loss: 1.8338 - VL_attention_linear_output_acc: 0.4813 - VH_attention_linear_output_acc: 0.4514 - val_loss: 3.7740 - val_VL_attention_linear_output_loss: 1.8841 - val_VH_attention_linear_output_loss: 1.8899 - val_VL_attention_linear_output_acc: 0.4382 - val_VH_attention_linear_output_acc: 0.4344\n",
      "Epoch 1717/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5918 - VL_attention_linear_output_loss: 1.7635 - VH_attention_linear_output_loss: 1.8284 - VL_attention_linear_output_acc: 0.4810 - VH_attention_linear_output_acc: 0.4547 - val_loss: 3.6665 - val_VL_attention_linear_output_loss: 1.8125 - val_VH_attention_linear_output_loss: 1.8540 - val_VL_attention_linear_output_acc: 0.4667 - val_VH_attention_linear_output_acc: 0.4490\n",
      "Epoch 1718/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5970 - VL_attention_linear_output_loss: 1.7580 - VH_attention_linear_output_loss: 1.8390 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4501 - val_loss: 3.6419 - val_VL_attention_linear_output_loss: 1.7924 - val_VH_attention_linear_output_loss: 1.8495 - val_VL_attention_linear_output_acc: 0.4793 - val_VH_attention_linear_output_acc: 0.4510\n",
      "Epoch 1719/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5726 - VL_attention_linear_output_loss: 1.7484 - VH_attention_linear_output_loss: 1.8242 - VL_attention_linear_output_acc: 0.4877 - VH_attention_linear_output_acc: 0.4564 - val_loss: 3.6615 - val_VL_attention_linear_output_loss: 1.7908 - val_VH_attention_linear_output_loss: 1.8707 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4435\n",
      "Epoch 1720/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6035 - VL_attention_linear_output_loss: 1.7664 - VH_attention_linear_output_loss: 1.8371 - VL_attention_linear_output_acc: 0.4795 - VH_attention_linear_output_acc: 0.4506 - val_loss: 3.7044 - val_VL_attention_linear_output_loss: 1.8531 - val_VH_attention_linear_output_loss: 1.8513 - val_VL_attention_linear_output_acc: 0.4489 - val_VH_attention_linear_output_acc: 0.4512\n",
      "Epoch 1721/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5900 - VL_attention_linear_output_loss: 1.7509 - VH_attention_linear_output_loss: 1.8392 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4500 - val_loss: 3.6501 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.8629 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4473\n",
      "Epoch 1722/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5940 - VL_attention_linear_output_loss: 1.7586 - VH_attention_linear_output_loss: 1.8354 - VL_attention_linear_output_acc: 0.4835 - VH_attention_linear_output_acc: 0.4515 - val_loss: 3.6596 - val_VL_attention_linear_output_loss: 1.8001 - val_VH_attention_linear_output_loss: 1.8595 - val_VL_attention_linear_output_acc: 0.4795 - val_VH_attention_linear_output_acc: 0.4500\n",
      "Epoch 1723/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5945 - VL_attention_linear_output_loss: 1.7574 - VH_attention_linear_output_loss: 1.8371 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4497 - val_loss: 3.6972 - val_VL_attention_linear_output_loss: 1.7917 - val_VH_attention_linear_output_loss: 1.9055 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4310\n",
      "Epoch 1724/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6089 - VL_attention_linear_output_loss: 1.7710 - VH_attention_linear_output_loss: 1.8379 - VL_attention_linear_output_acc: 0.4775 - VH_attention_linear_output_acc: 0.4515 - val_loss: 3.6583 - val_VL_attention_linear_output_loss: 1.7997 - val_VH_attention_linear_output_loss: 1.8586 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4442\n",
      "Epoch 1725/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6005 - VL_attention_linear_output_loss: 1.7563 - VH_attention_linear_output_loss: 1.8442 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4509 - val_loss: 3.6646 - val_VL_attention_linear_output_loss: 1.7986 - val_VH_attention_linear_output_loss: 1.8660 - val_VL_attention_linear_output_acc: 0.4700 - val_VH_attention_linear_output_acc: 0.4467\n",
      "Epoch 1726/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6068 - VL_attention_linear_output_loss: 1.7652 - VH_attention_linear_output_loss: 1.8417 - VL_attention_linear_output_acc: 0.4800 - VH_attention_linear_output_acc: 0.4505 - val_loss: 3.6779 - val_VL_attention_linear_output_loss: 1.7943 - val_VH_attention_linear_output_loss: 1.8836 - val_VL_attention_linear_output_acc: 0.4769 - val_VH_attention_linear_output_acc: 0.4414\n",
      "Epoch 1727/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5848 - VL_attention_linear_output_loss: 1.7511 - VH_attention_linear_output_loss: 1.8338 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4532 - val_loss: 3.6436 - val_VL_attention_linear_output_loss: 1.7911 - val_VH_attention_linear_output_loss: 1.8525 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4487\n",
      "Epoch 1728/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5778 - VL_attention_linear_output_loss: 1.7535 - VH_attention_linear_output_loss: 1.8243 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4571 - val_loss: 3.6888 - val_VL_attention_linear_output_loss: 1.8369 - val_VH_attention_linear_output_loss: 1.8520 - val_VL_attention_linear_output_acc: 0.4521 - val_VH_attention_linear_output_acc: 0.4505\n",
      "Epoch 1729/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5921 - VL_attention_linear_output_loss: 1.7580 - VH_attention_linear_output_loss: 1.8341 - VL_attention_linear_output_acc: 0.4838 - VH_attention_linear_output_acc: 0.4525 - val_loss: 3.6729 - val_VL_attention_linear_output_loss: 1.8240 - val_VH_attention_linear_output_loss: 1.8489 - val_VL_attention_linear_output_acc: 0.4640 - val_VH_attention_linear_output_acc: 0.4520\n",
      "Epoch 1730/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5911 - VL_attention_linear_output_loss: 1.7624 - VH_attention_linear_output_loss: 1.8287 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4550 - val_loss: 3.6434 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.8562 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4503\n",
      "Epoch 1731/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5849 - VL_attention_linear_output_loss: 1.7528 - VH_attention_linear_output_loss: 1.8321 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4538 - val_loss: 3.6390 - val_VL_attention_linear_output_loss: 1.7922 - val_VH_attention_linear_output_loss: 1.8468 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4527\n",
      "Epoch 1732/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5878 - VL_attention_linear_output_loss: 1.7571 - VH_attention_linear_output_loss: 1.8308 - VL_attention_linear_output_acc: 0.4848 - VH_attention_linear_output_acc: 0.4539 - val_loss: 3.6609 - val_VL_attention_linear_output_loss: 1.8001 - val_VH_attention_linear_output_loss: 1.8608 - val_VL_attention_linear_output_acc: 0.4754 - val_VH_attention_linear_output_acc: 0.4437\n",
      "Epoch 1733/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5881 - VL_attention_linear_output_loss: 1.7551 - VH_attention_linear_output_loss: 1.8330 - VL_attention_linear_output_acc: 0.4848 - VH_attention_linear_output_acc: 0.4542 - val_loss: 3.6562 - val_VL_attention_linear_output_loss: 1.8019 - val_VH_attention_linear_output_loss: 1.8543 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4494\n",
      "Epoch 1734/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5869 - VL_attention_linear_output_loss: 1.7592 - VH_attention_linear_output_loss: 1.8277 - VL_attention_linear_output_acc: 0.4814 - VH_attention_linear_output_acc: 0.4555 - val_loss: 3.6393 - val_VL_attention_linear_output_loss: 1.7870 - val_VH_attention_linear_output_loss: 1.8523 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4510\n",
      "Epoch 1735/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5814 - VL_attention_linear_output_loss: 1.7485 - VH_attention_linear_output_loss: 1.8329 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4534 - val_loss: 3.6456 - val_VL_attention_linear_output_loss: 1.7847 - val_VH_attention_linear_output_loss: 1.8609 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4489\n",
      "Epoch 1736/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5727 - VL_attention_linear_output_loss: 1.7470 - VH_attention_linear_output_loss: 1.8257 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4564 - val_loss: 3.6806 - val_VL_attention_linear_output_loss: 1.7984 - val_VH_attention_linear_output_loss: 1.8822 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4410\n",
      "Epoch 1737/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5777 - VL_attention_linear_output_loss: 1.7525 - VH_attention_linear_output_loss: 1.8252 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4568 - val_loss: 3.6755 - val_VL_attention_linear_output_loss: 1.8197 - val_VH_attention_linear_output_loss: 1.8558 - val_VL_attention_linear_output_acc: 0.4668 - val_VH_attention_linear_output_acc: 0.4477\n",
      "Epoch 1738/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5707 - VL_attention_linear_output_loss: 1.7499 - VH_attention_linear_output_loss: 1.8208 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4584 - val_loss: 3.6423 - val_VL_attention_linear_output_loss: 1.7874 - val_VH_attention_linear_output_loss: 1.8549 - val_VL_attention_linear_output_acc: 0.4880 - val_VH_attention_linear_output_acc: 0.4494\n",
      "Epoch 1739/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5894 - VL_attention_linear_output_loss: 1.7618 - VH_attention_linear_output_loss: 1.8276 - VL_attention_linear_output_acc: 0.4804 - VH_attention_linear_output_acc: 0.4553 - val_loss: 3.6625 - val_VL_attention_linear_output_loss: 1.8123 - val_VH_attention_linear_output_loss: 1.8502 - val_VL_attention_linear_output_acc: 0.4699 - val_VH_attention_linear_output_acc: 0.4519\n",
      "Epoch 1740/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5762 - VL_attention_linear_output_loss: 1.7514 - VH_attention_linear_output_loss: 1.8248 - VL_attention_linear_output_acc: 0.4863 - VH_attention_linear_output_acc: 0.4563 - val_loss: 3.6461 - val_VL_attention_linear_output_loss: 1.7877 - val_VH_attention_linear_output_loss: 1.8584 - val_VL_attention_linear_output_acc: 0.4782 - val_VH_attention_linear_output_acc: 0.4454\n",
      "Epoch 1741/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5838 - VL_attention_linear_output_loss: 1.7592 - VH_attention_linear_output_loss: 1.8246 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4564 - val_loss: 3.6566 - val_VL_attention_linear_output_loss: 1.7917 - val_VH_attention_linear_output_loss: 1.8649 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4418\n",
      "Epoch 1742/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5842 - VL_attention_linear_output_loss: 1.7568 - VH_attention_linear_output_loss: 1.8273 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4553 - val_loss: 3.6490 - val_VL_attention_linear_output_loss: 1.7882 - val_VH_attention_linear_output_loss: 1.8609 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4460\n",
      "Epoch 1743/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5768 - VL_attention_linear_output_loss: 1.7474 - VH_attention_linear_output_loss: 1.8295 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4540 - val_loss: 3.6537 - val_VL_attention_linear_output_loss: 1.8008 - val_VH_attention_linear_output_loss: 1.8529 - val_VL_attention_linear_output_acc: 0.4746 - val_VH_attention_linear_output_acc: 0.4539\n",
      "Epoch 1744/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5797 - VL_attention_linear_output_loss: 1.7520 - VH_attention_linear_output_loss: 1.8278 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4556 - val_loss: 3.6733 - val_VL_attention_linear_output_loss: 1.8206 - val_VH_attention_linear_output_loss: 1.8527 - val_VL_attention_linear_output_acc: 0.4668 - val_VH_attention_linear_output_acc: 0.4468\n",
      "Epoch 1745/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5891 - VL_attention_linear_output_loss: 1.7595 - VH_attention_linear_output_loss: 1.8297 - VL_attention_linear_output_acc: 0.4817 - VH_attention_linear_output_acc: 0.4546 - val_loss: 3.6895 - val_VL_attention_linear_output_loss: 1.7913 - val_VH_attention_linear_output_loss: 1.8982 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4233\n",
      "Epoch 1746/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5736 - VL_attention_linear_output_loss: 1.7467 - VH_attention_linear_output_loss: 1.8269 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4552 - val_loss: 3.6513 - val_VL_attention_linear_output_loss: 1.8014 - val_VH_attention_linear_output_loss: 1.8498 - val_VL_attention_linear_output_acc: 0.4726 - val_VH_attention_linear_output_acc: 0.4542\n",
      "Epoch 1747/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5729 - VL_attention_linear_output_loss: 1.7546 - VH_attention_linear_output_loss: 1.8183 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4597 - val_loss: 3.6449 - val_VL_attention_linear_output_loss: 1.8004 - val_VH_attention_linear_output_loss: 1.8445 - val_VL_attention_linear_output_acc: 0.4740 - val_VH_attention_linear_output_acc: 0.4520\n",
      "Epoch 1748/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5915 - VL_attention_linear_output_loss: 1.7589 - VH_attention_linear_output_loss: 1.8326 - VL_attention_linear_output_acc: 0.4829 - VH_attention_linear_output_acc: 0.4531 - val_loss: 3.6372 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.8499 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4521\n",
      "Epoch 1749/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5781 - VL_attention_linear_output_loss: 1.7516 - VH_attention_linear_output_loss: 1.8264 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4554 - val_loss: 3.6512 - val_VL_attention_linear_output_loss: 1.7862 - val_VH_attention_linear_output_loss: 1.8650 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4452\n",
      "Epoch 1750/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5798 - VL_attention_linear_output_loss: 1.7531 - VH_attention_linear_output_loss: 1.8267 - VL_attention_linear_output_acc: 0.4851 - VH_attention_linear_output_acc: 0.4558 - val_loss: 3.6446 - val_VL_attention_linear_output_loss: 1.7933 - val_VH_attention_linear_output_loss: 1.8512 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.4493\n",
      "Epoch 1751/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5861 - VL_attention_linear_output_loss: 1.7550 - VH_attention_linear_output_loss: 1.8310 - VL_attention_linear_output_acc: 0.4833 - VH_attention_linear_output_acc: 0.4533 - val_loss: 3.6538 - val_VL_attention_linear_output_loss: 1.8011 - val_VH_attention_linear_output_loss: 1.8527 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.4483\n",
      "Epoch 1752/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5947 - VL_attention_linear_output_loss: 1.7669 - VH_attention_linear_output_loss: 1.8278 - VL_attention_linear_output_acc: 0.4790 - VH_attention_linear_output_acc: 0.4546 - val_loss: 3.6917 - val_VL_attention_linear_output_loss: 1.8039 - val_VH_attention_linear_output_loss: 1.8879 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.4367\n",
      "Epoch 1753/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6060 - VL_attention_linear_output_loss: 1.7673 - VH_attention_linear_output_loss: 1.8387 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4507 - val_loss: 3.6503 - val_VL_attention_linear_output_loss: 1.7892 - val_VH_attention_linear_output_loss: 1.8611 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4505\n",
      "Epoch 1754/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5726 - VL_attention_linear_output_loss: 1.7462 - VH_attention_linear_output_loss: 1.8264 - VL_attention_linear_output_acc: 0.4893 - VH_attention_linear_output_acc: 0.4559 - val_loss: 3.6435 - val_VL_attention_linear_output_loss: 1.7898 - val_VH_attention_linear_output_loss: 1.8537 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4466\n",
      "Epoch 1755/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5726 - VL_attention_linear_output_loss: 1.7478 - VH_attention_linear_output_loss: 1.8248 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4559 - val_loss: 3.6368 - val_VL_attention_linear_output_loss: 1.7883 - val_VH_attention_linear_output_loss: 1.8485 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4513\n",
      "Epoch 1756/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5734 - VL_attention_linear_output_loss: 1.7519 - VH_attention_linear_output_loss: 1.8215 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4571 - val_loss: 3.6530 - val_VL_attention_linear_output_loss: 1.8068 - val_VH_attention_linear_output_loss: 1.8462 - val_VL_attention_linear_output_acc: 0.4758 - val_VH_attention_linear_output_acc: 0.4532\n",
      "Epoch 1757/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5872 - VL_attention_linear_output_loss: 1.7660 - VH_attention_linear_output_loss: 1.8211 - VL_attention_linear_output_acc: 0.4800 - VH_attention_linear_output_acc: 0.4578 - val_loss: 3.6622 - val_VL_attention_linear_output_loss: 1.8044 - val_VH_attention_linear_output_loss: 1.8578 - val_VL_attention_linear_output_acc: 0.4757 - val_VH_attention_linear_output_acc: 0.4456\n",
      "Epoch 1758/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5954 - VL_attention_linear_output_loss: 1.7653 - VH_attention_linear_output_loss: 1.8300 - VL_attention_linear_output_acc: 0.4782 - VH_attention_linear_output_acc: 0.4529 - val_loss: 3.6603 - val_VL_attention_linear_output_loss: 1.8083 - val_VH_attention_linear_output_loss: 1.8520 - val_VL_attention_linear_output_acc: 0.4693 - val_VH_attention_linear_output_acc: 0.4499\n",
      "Epoch 1759/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5772 - VL_attention_linear_output_loss: 1.7564 - VH_attention_linear_output_loss: 1.8207 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4570 - val_loss: 3.7620 - val_VL_attention_linear_output_loss: 1.7891 - val_VH_attention_linear_output_loss: 1.9729 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.3907\n",
      "Epoch 1760/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5872 - VL_attention_linear_output_loss: 1.7547 - VH_attention_linear_output_loss: 1.8325 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4528 - val_loss: 3.6796 - val_VL_attention_linear_output_loss: 1.7866 - val_VH_attention_linear_output_loss: 1.8930 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4354\n",
      "Epoch 1761/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5817 - VL_attention_linear_output_loss: 1.7500 - VH_attention_linear_output_loss: 1.8318 - VL_attention_linear_output_acc: 0.4869 - VH_attention_linear_output_acc: 0.4521 - val_loss: 3.6376 - val_VL_attention_linear_output_loss: 1.7894 - val_VH_attention_linear_output_loss: 1.8482 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4476\n",
      "Epoch 1762/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5858 - VL_attention_linear_output_loss: 1.7610 - VH_attention_linear_output_loss: 1.8248 - VL_attention_linear_output_acc: 0.4815 - VH_attention_linear_output_acc: 0.4556 - val_loss: 3.6409 - val_VL_attention_linear_output_loss: 1.7894 - val_VH_attention_linear_output_loss: 1.8514 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4523\n",
      "Epoch 1763/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5919 - VL_attention_linear_output_loss: 1.7603 - VH_attention_linear_output_loss: 1.8316 - VL_attention_linear_output_acc: 0.4835 - VH_attention_linear_output_acc: 0.4531 - val_loss: 3.6433 - val_VL_attention_linear_output_loss: 1.7985 - val_VH_attention_linear_output_loss: 1.8448 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4525\n",
      "Epoch 1764/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5704 - VL_attention_linear_output_loss: 1.7550 - VH_attention_linear_output_loss: 1.8154 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4598 - val_loss: 3.6336 - val_VL_attention_linear_output_loss: 1.7900 - val_VH_attention_linear_output_loss: 1.8436 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4534\n",
      "Epoch 1765/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5705 - VL_attention_linear_output_loss: 1.7489 - VH_attention_linear_output_loss: 1.8216 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4571 - val_loss: 3.6425 - val_VL_attention_linear_output_loss: 1.7901 - val_VH_attention_linear_output_loss: 1.8524 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4506\n",
      "Epoch 1766/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5912 - VL_attention_linear_output_loss: 1.7625 - VH_attention_linear_output_loss: 1.8287 - VL_attention_linear_output_acc: 0.4806 - VH_attention_linear_output_acc: 0.4538 - val_loss: 3.6871 - val_VL_attention_linear_output_loss: 1.8124 - val_VH_attention_linear_output_loss: 1.8747 - val_VL_attention_linear_output_acc: 0.4711 - val_VH_attention_linear_output_acc: 0.4380\n",
      "Epoch 1767/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5769 - VL_attention_linear_output_loss: 1.7501 - VH_attention_linear_output_loss: 1.8268 - VL_attention_linear_output_acc: 0.4858 - VH_attention_linear_output_acc: 0.4547 - val_loss: 3.6321 - val_VL_attention_linear_output_loss: 1.7859 - val_VH_attention_linear_output_loss: 1.8462 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4539\n",
      "Epoch 1768/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5766 - VL_attention_linear_output_loss: 1.7527 - VH_attention_linear_output_loss: 1.8239 - VL_attention_linear_output_acc: 0.4861 - VH_attention_linear_output_acc: 0.4563 - val_loss: 3.6345 - val_VL_attention_linear_output_loss: 1.7877 - val_VH_attention_linear_output_loss: 1.8469 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4513\n",
      "Epoch 1769/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5749 - VL_attention_linear_output_loss: 1.7516 - VH_attention_linear_output_loss: 1.8233 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4563 - val_loss: 3.6576 - val_VL_attention_linear_output_loss: 1.8043 - val_VH_attention_linear_output_loss: 1.8533 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.4473\n",
      "Epoch 1770/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5801 - VL_attention_linear_output_loss: 1.7515 - VH_attention_linear_output_loss: 1.8286 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4542 - val_loss: 3.6535 - val_VL_attention_linear_output_loss: 1.7947 - val_VH_attention_linear_output_loss: 1.8589 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.4458\n",
      "Epoch 1771/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5879 - VL_attention_linear_output_loss: 1.7636 - VH_attention_linear_output_loss: 1.8244 - VL_attention_linear_output_acc: 0.4795 - VH_attention_linear_output_acc: 0.4554 - val_loss: 3.6361 - val_VL_attention_linear_output_loss: 1.7863 - val_VH_attention_linear_output_loss: 1.8498 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4526\n",
      "Epoch 1772/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5787 - VL_attention_linear_output_loss: 1.7532 - VH_attention_linear_output_loss: 1.8254 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4556 - val_loss: 3.6534 - val_VL_attention_linear_output_loss: 1.7944 - val_VH_attention_linear_output_loss: 1.8590 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4479\n",
      "Epoch 1773/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5813 - VL_attention_linear_output_loss: 1.7514 - VH_attention_linear_output_loss: 1.8298 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4532 - val_loss: 3.6918 - val_VL_attention_linear_output_loss: 1.8096 - val_VH_attention_linear_output_loss: 1.8821 - val_VL_attention_linear_output_acc: 0.4714 - val_VH_attention_linear_output_acc: 0.4402\n",
      "Epoch 1774/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5886 - VL_attention_linear_output_loss: 1.7523 - VH_attention_linear_output_loss: 1.8364 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4509 - val_loss: 3.6480 - val_VL_attention_linear_output_loss: 1.7928 - val_VH_attention_linear_output_loss: 1.8552 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4519\n",
      "Epoch 1775/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5939 - VL_attention_linear_output_loss: 1.7571 - VH_attention_linear_output_loss: 1.8367 - VL_attention_linear_output_acc: 0.4837 - VH_attention_linear_output_acc: 0.4504 - val_loss: 3.6462 - val_VL_attention_linear_output_loss: 1.7941 - val_VH_attention_linear_output_loss: 1.8521 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4491\n",
      "Epoch 1776/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5695 - VL_attention_linear_output_loss: 1.7527 - VH_attention_linear_output_loss: 1.8168 - VL_attention_linear_output_acc: 0.4844 - VH_attention_linear_output_acc: 0.4592 - val_loss: 3.6694 - val_VL_attention_linear_output_loss: 1.7991 - val_VH_attention_linear_output_loss: 1.8703 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4410\n",
      "Epoch 1777/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6151 - VL_attention_linear_output_loss: 1.7731 - VH_attention_linear_output_loss: 1.8420 - VL_attention_linear_output_acc: 0.4751 - VH_attention_linear_output_acc: 0.4488 - val_loss: 3.6293 - val_VL_attention_linear_output_loss: 1.7875 - val_VH_attention_linear_output_loss: 1.8418 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4556\n",
      "Epoch 1778/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5660 - VL_attention_linear_output_loss: 1.7483 - VH_attention_linear_output_loss: 1.8177 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4589 - val_loss: 3.6400 - val_VL_attention_linear_output_loss: 1.7894 - val_VH_attention_linear_output_loss: 1.8505 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4505\n",
      "Epoch 1779/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5752 - VL_attention_linear_output_loss: 1.7515 - VH_attention_linear_output_loss: 1.8237 - VL_attention_linear_output_acc: 0.4860 - VH_attention_linear_output_acc: 0.4560 - val_loss: 3.6561 - val_VL_attention_linear_output_loss: 1.7954 - val_VH_attention_linear_output_loss: 1.8607 - val_VL_attention_linear_output_acc: 0.4595 - val_VH_attention_linear_output_acc: 0.4429\n",
      "Epoch 1780/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5826 - VL_attention_linear_output_loss: 1.7594 - VH_attention_linear_output_loss: 1.8232 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4555 - val_loss: 3.6399 - val_VL_attention_linear_output_loss: 1.7941 - val_VH_attention_linear_output_loss: 1.8458 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4504\n",
      "Epoch 1781/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5870 - VL_attention_linear_output_loss: 1.7524 - VH_attention_linear_output_loss: 1.8346 - VL_attention_linear_output_acc: 0.4864 - VH_attention_linear_output_acc: 0.4512 - val_loss: 3.6412 - val_VL_attention_linear_output_loss: 1.7868 - val_VH_attention_linear_output_loss: 1.8544 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4475\n",
      "Epoch 1782/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5920 - VL_attention_linear_output_loss: 1.7627 - VH_attention_linear_output_loss: 1.8293 - VL_attention_linear_output_acc: 0.4807 - VH_attention_linear_output_acc: 0.4535 - val_loss: 3.6549 - val_VL_attention_linear_output_loss: 1.7869 - val_VH_attention_linear_output_loss: 1.8680 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4426\n",
      "Epoch 1783/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5779 - VL_attention_linear_output_loss: 1.7513 - VH_attention_linear_output_loss: 1.8266 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4551 - val_loss: 3.6321 - val_VL_attention_linear_output_loss: 1.7904 - val_VH_attention_linear_output_loss: 1.8417 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4521\n",
      "Epoch 1784/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5783 - VL_attention_linear_output_loss: 1.7506 - VH_attention_linear_output_loss: 1.8277 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4542 - val_loss: 3.6334 - val_VL_attention_linear_output_loss: 1.7826 - val_VH_attention_linear_output_loss: 1.8507 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.4498\n",
      "Epoch 1785/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5929 - VL_attention_linear_output_loss: 1.7638 - VH_attention_linear_output_loss: 1.8291 - VL_attention_linear_output_acc: 0.4813 - VH_attention_linear_output_acc: 0.4535 - val_loss: 3.6441 - val_VL_attention_linear_output_loss: 1.7971 - val_VH_attention_linear_output_loss: 1.8470 - val_VL_attention_linear_output_acc: 0.4795 - val_VH_attention_linear_output_acc: 0.4500\n",
      "Epoch 1786/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5860 - VL_attention_linear_output_loss: 1.7592 - VH_attention_linear_output_loss: 1.8269 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4544 - val_loss: 3.6618 - val_VL_attention_linear_output_loss: 1.8072 - val_VH_attention_linear_output_loss: 1.8546 - val_VL_attention_linear_output_acc: 0.4757 - val_VH_attention_linear_output_acc: 0.4473\n",
      "Epoch 1787/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5795 - VL_attention_linear_output_loss: 1.7567 - VH_attention_linear_output_loss: 1.8228 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4560 - val_loss: 3.6392 - val_VL_attention_linear_output_loss: 1.7972 - val_VH_attention_linear_output_loss: 1.8420 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4527\n",
      "Epoch 1788/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5796 - VL_attention_linear_output_loss: 1.7584 - VH_attention_linear_output_loss: 1.8212 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4573 - val_loss: 3.6452 - val_VL_attention_linear_output_loss: 1.7899 - val_VH_attention_linear_output_loss: 1.8554 - val_VL_attention_linear_output_acc: 0.4775 - val_VH_attention_linear_output_acc: 0.4474\n",
      "Epoch 1789/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5879 - VL_attention_linear_output_loss: 1.7624 - VH_attention_linear_output_loss: 1.8255 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4553 - val_loss: 3.7218 - val_VL_attention_linear_output_loss: 1.7977 - val_VH_attention_linear_output_loss: 1.9241 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.4070\n",
      "Epoch 1790/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5965 - VL_attention_linear_output_loss: 1.7696 - VH_attention_linear_output_loss: 1.8269 - VL_attention_linear_output_acc: 0.4770 - VH_attention_linear_output_acc: 0.4547 - val_loss: 3.6469 - val_VL_attention_linear_output_loss: 1.7955 - val_VH_attention_linear_output_loss: 1.8514 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4488\n",
      "Epoch 1791/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5778 - VL_attention_linear_output_loss: 1.7529 - VH_attention_linear_output_loss: 1.8249 - VL_attention_linear_output_acc: 0.4852 - VH_attention_linear_output_acc: 0.4556 - val_loss: 3.6736 - val_VL_attention_linear_output_loss: 1.8094 - val_VH_attention_linear_output_loss: 1.8641 - val_VL_attention_linear_output_acc: 0.4728 - val_VH_attention_linear_output_acc: 0.4433\n",
      "Epoch 1792/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5831 - VL_attention_linear_output_loss: 1.7545 - VH_attention_linear_output_loss: 1.8286 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4539 - val_loss: 3.6388 - val_VL_attention_linear_output_loss: 1.7946 - val_VH_attention_linear_output_loss: 1.8442 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.4520\n",
      "Epoch 1793/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5779 - VL_attention_linear_output_loss: 1.7608 - VH_attention_linear_output_loss: 1.8171 - VL_attention_linear_output_acc: 0.4800 - VH_attention_linear_output_acc: 0.4584 - val_loss: 3.6357 - val_VL_attention_linear_output_loss: 1.7879 - val_VH_attention_linear_output_loss: 1.8478 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4519\n",
      "Epoch 1794/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5608 - VL_attention_linear_output_loss: 1.7454 - VH_attention_linear_output_loss: 1.8154 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4591 - val_loss: 3.6493 - val_VL_attention_linear_output_loss: 1.8032 - val_VH_attention_linear_output_loss: 1.8461 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.4528\n",
      "Epoch 1795/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5901 - VL_attention_linear_output_loss: 1.7564 - VH_attention_linear_output_loss: 1.8337 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4510 - val_loss: 3.6331 - val_VL_attention_linear_output_loss: 1.7874 - val_VH_attention_linear_output_loss: 1.8456 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4534\n",
      "Epoch 1796/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5933 - VL_attention_linear_output_loss: 1.7698 - VH_attention_linear_output_loss: 1.8235 - VL_attention_linear_output_acc: 0.4771 - VH_attention_linear_output_acc: 0.4564 - val_loss: 3.6459 - val_VL_attention_linear_output_loss: 1.7971 - val_VH_attention_linear_output_loss: 1.8489 - val_VL_attention_linear_output_acc: 0.4778 - val_VH_attention_linear_output_acc: 0.4483\n",
      "Epoch 1797/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5754 - VL_attention_linear_output_loss: 1.7537 - VH_attention_linear_output_loss: 1.8217 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4562 - val_loss: 3.6290 - val_VL_attention_linear_output_loss: 1.7883 - val_VH_attention_linear_output_loss: 1.8407 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4556\n",
      "Epoch 1798/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5693 - VL_attention_linear_output_loss: 1.7471 - VH_attention_linear_output_loss: 1.8221 - VL_attention_linear_output_acc: 0.4878 - VH_attention_linear_output_acc: 0.4564 - val_loss: 3.6603 - val_VL_attention_linear_output_loss: 1.8033 - val_VH_attention_linear_output_loss: 1.8570 - val_VL_attention_linear_output_acc: 0.4787 - val_VH_attention_linear_output_acc: 0.4477\n",
      "Epoch 1799/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5927 - VL_attention_linear_output_loss: 1.7671 - VH_attention_linear_output_loss: 1.8256 - VL_attention_linear_output_acc: 0.4782 - VH_attention_linear_output_acc: 0.4547 - val_loss: 3.6300 - val_VL_attention_linear_output_loss: 1.7901 - val_VH_attention_linear_output_loss: 1.8399 - val_VL_attention_linear_output_acc: 0.4744 - val_VH_attention_linear_output_acc: 0.4544\n",
      "Epoch 1800/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5723 - VL_attention_linear_output_loss: 1.7508 - VH_attention_linear_output_loss: 1.8214 - VL_attention_linear_output_acc: 0.4860 - VH_attention_linear_output_acc: 0.4564 - val_loss: 3.6626 - val_VL_attention_linear_output_loss: 1.8114 - val_VH_attention_linear_output_loss: 1.8512 - val_VL_attention_linear_output_acc: 0.4669 - val_VH_attention_linear_output_acc: 0.4512\n",
      "Epoch 1801/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5751 - VL_attention_linear_output_loss: 1.7547 - VH_attention_linear_output_loss: 1.8204 - VL_attention_linear_output_acc: 0.4829 - VH_attention_linear_output_acc: 0.4568 - val_loss: 3.6715 - val_VL_attention_linear_output_loss: 1.7927 - val_VH_attention_linear_output_loss: 1.8788 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4400\n",
      "Epoch 1802/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5691 - VL_attention_linear_output_loss: 1.7511 - VH_attention_linear_output_loss: 1.8181 - VL_attention_linear_output_acc: 0.4863 - VH_attention_linear_output_acc: 0.4579 - val_loss: 3.6972 - val_VL_attention_linear_output_loss: 1.7991 - val_VH_attention_linear_output_loss: 1.8981 - val_VL_attention_linear_output_acc: 0.4754 - val_VH_attention_linear_output_acc: 0.4345\n",
      "Epoch 1803/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5853 - VL_attention_linear_output_loss: 1.7556 - VH_attention_linear_output_loss: 1.8297 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4529 - val_loss: 3.6299 - val_VL_attention_linear_output_loss: 1.7898 - val_VH_attention_linear_output_loss: 1.8401 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4539\n",
      "Epoch 1804/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5779 - VL_attention_linear_output_loss: 1.7512 - VH_attention_linear_output_loss: 1.8268 - VL_attention_linear_output_acc: 0.4861 - VH_attention_linear_output_acc: 0.4542 - val_loss: 3.6586 - val_VL_attention_linear_output_loss: 1.8039 - val_VH_attention_linear_output_loss: 1.8547 - val_VL_attention_linear_output_acc: 0.4771 - val_VH_attention_linear_output_acc: 0.4487\n",
      "Epoch 1805/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5977 - VL_attention_linear_output_loss: 1.7660 - VH_attention_linear_output_loss: 1.8317 - VL_attention_linear_output_acc: 0.4791 - VH_attention_linear_output_acc: 0.4520 - val_loss: 3.6594 - val_VL_attention_linear_output_loss: 1.8088 - val_VH_attention_linear_output_loss: 1.8506 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.4519\n",
      "Epoch 1806/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5770 - VL_attention_linear_output_loss: 1.7537 - VH_attention_linear_output_loss: 1.8233 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4561 - val_loss: 3.6324 - val_VL_attention_linear_output_loss: 1.7815 - val_VH_attention_linear_output_loss: 1.8509 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4496\n",
      "Epoch 1807/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5698 - VL_attention_linear_output_loss: 1.7503 - VH_attention_linear_output_loss: 1.8194 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4577 - val_loss: 3.6332 - val_VL_attention_linear_output_loss: 1.7870 - val_VH_attention_linear_output_loss: 1.8462 - val_VL_attention_linear_output_acc: 0.4766 - val_VH_attention_linear_output_acc: 0.4530\n",
      "Epoch 1808/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5749 - VL_attention_linear_output_loss: 1.7520 - VH_attention_linear_output_loss: 1.8229 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4559 - val_loss: 3.6457 - val_VL_attention_linear_output_loss: 1.7909 - val_VH_attention_linear_output_loss: 1.8548 - val_VL_attention_linear_output_acc: 0.4810 - val_VH_attention_linear_output_acc: 0.4466\n",
      "Epoch 1809/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5970 - VL_attention_linear_output_loss: 1.7586 - VH_attention_linear_output_loss: 1.8384 - VL_attention_linear_output_acc: 0.4810 - VH_attention_linear_output_acc: 0.4509 - val_loss: 3.6381 - val_VL_attention_linear_output_loss: 1.7866 - val_VH_attention_linear_output_loss: 1.8515 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4538\n",
      "Epoch 1810/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5829 - VL_attention_linear_output_loss: 1.7531 - VH_attention_linear_output_loss: 1.8298 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4531 - val_loss: 3.6404 - val_VL_attention_linear_output_loss: 1.7887 - val_VH_attention_linear_output_loss: 1.8517 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4541\n",
      "Epoch 1811/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5895 - VL_attention_linear_output_loss: 1.7706 - VH_attention_linear_output_loss: 1.8189 - VL_attention_linear_output_acc: 0.4764 - VH_attention_linear_output_acc: 0.4580 - val_loss: 3.7083 - val_VL_attention_linear_output_loss: 1.8617 - val_VH_attention_linear_output_loss: 1.8466 - val_VL_attention_linear_output_acc: 0.4331 - val_VH_attention_linear_output_acc: 0.4512\n",
      "Epoch 1812/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5775 - VL_attention_linear_output_loss: 1.7559 - VH_attention_linear_output_loss: 1.8216 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4564 - val_loss: 3.6352 - val_VL_attention_linear_output_loss: 1.7878 - val_VH_attention_linear_output_loss: 1.8474 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4514\n",
      "Epoch 1813/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5838 - VL_attention_linear_output_loss: 1.7555 - VH_attention_linear_output_loss: 1.8283 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4535 - val_loss: 3.6508 - val_VL_attention_linear_output_loss: 1.7999 - val_VH_attention_linear_output_loss: 1.8509 - val_VL_attention_linear_output_acc: 0.4734 - val_VH_attention_linear_output_acc: 0.4465\n",
      "Epoch 1814/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.6014 - VL_attention_linear_output_loss: 1.7675 - VH_attention_linear_output_loss: 1.8339 - VL_attention_linear_output_acc: 0.4772 - VH_attention_linear_output_acc: 0.4507 - val_loss: 3.6529 - val_VL_attention_linear_output_loss: 1.7968 - val_VH_attention_linear_output_loss: 1.8561 - val_VL_attention_linear_output_acc: 0.4761 - val_VH_attention_linear_output_acc: 0.4469\n",
      "Epoch 1815/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5687 - VL_attention_linear_output_loss: 1.7514 - VH_attention_linear_output_loss: 1.8174 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4578 - val_loss: 3.6417 - val_VL_attention_linear_output_loss: 1.7909 - val_VH_attention_linear_output_loss: 1.8508 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4500\n",
      "Epoch 1816/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5753 - VL_attention_linear_output_loss: 1.7556 - VH_attention_linear_output_loss: 1.8196 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4572 - val_loss: 3.6392 - val_VL_attention_linear_output_loss: 1.7816 - val_VH_attention_linear_output_loss: 1.8576 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4447\n",
      "Epoch 1817/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5763 - VL_attention_linear_output_loss: 1.7571 - VH_attention_linear_output_loss: 1.8192 - VL_attention_linear_output_acc: 0.4817 - VH_attention_linear_output_acc: 0.4583 - val_loss: 3.6420 - val_VL_attention_linear_output_loss: 1.7825 - val_VH_attention_linear_output_loss: 1.8595 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4531\n",
      "Epoch 1818/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5877 - VL_attention_linear_output_loss: 1.7613 - VH_attention_linear_output_loss: 1.8264 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4551 - val_loss: 3.6418 - val_VL_attention_linear_output_loss: 1.7943 - val_VH_attention_linear_output_loss: 1.8475 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.4524\n",
      "Epoch 1819/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5680 - VL_attention_linear_output_loss: 1.7521 - VH_attention_linear_output_loss: 1.8159 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4588 - val_loss: 3.6580 - val_VL_attention_linear_output_loss: 1.8116 - val_VH_attention_linear_output_loss: 1.8464 - val_VL_attention_linear_output_acc: 0.4641 - val_VH_attention_linear_output_acc: 0.4525\n",
      "Epoch 1820/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5678 - VL_attention_linear_output_loss: 1.7538 - VH_attention_linear_output_loss: 1.8140 - VL_attention_linear_output_acc: 0.4844 - VH_attention_linear_output_acc: 0.4592 - val_loss: 3.6558 - val_VL_attention_linear_output_loss: 1.8155 - val_VH_attention_linear_output_loss: 1.8403 - val_VL_attention_linear_output_acc: 0.4702 - val_VH_attention_linear_output_acc: 0.4546\n",
      "Epoch 1821/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5843 - VL_attention_linear_output_loss: 1.7637 - VH_attention_linear_output_loss: 1.8206 - VL_attention_linear_output_acc: 0.4796 - VH_attention_linear_output_acc: 0.4574 - val_loss: 3.6301 - val_VL_attention_linear_output_loss: 1.7877 - val_VH_attention_linear_output_loss: 1.8424 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4511\n",
      "Epoch 1822/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5680 - VL_attention_linear_output_loss: 1.7499 - VH_attention_linear_output_loss: 1.8181 - VL_attention_linear_output_acc: 0.4860 - VH_attention_linear_output_acc: 0.4568 - val_loss: 3.7156 - val_VL_attention_linear_output_loss: 1.8639 - val_VH_attention_linear_output_loss: 1.8517 - val_VL_attention_linear_output_acc: 0.4424 - val_VH_attention_linear_output_acc: 0.4511\n",
      "Epoch 1823/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5715 - VL_attention_linear_output_loss: 1.7561 - VH_attention_linear_output_loss: 1.8154 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4592 - val_loss: 3.6499 - val_VL_attention_linear_output_loss: 1.7988 - val_VH_attention_linear_output_loss: 1.8511 - val_VL_attention_linear_output_acc: 0.4769 - val_VH_attention_linear_output_acc: 0.4519\n",
      "Epoch 1824/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5762 - VL_attention_linear_output_loss: 1.7557 - VH_attention_linear_output_loss: 1.8206 - VL_attention_linear_output_acc: 0.4840 - VH_attention_linear_output_acc: 0.4563 - val_loss: 3.6493 - val_VL_attention_linear_output_loss: 1.7907 - val_VH_attention_linear_output_loss: 1.8586 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4421\n",
      "Epoch 1825/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5846 - VL_attention_linear_output_loss: 1.7594 - VH_attention_linear_output_loss: 1.8253 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4540 - val_loss: 3.6330 - val_VL_attention_linear_output_loss: 1.7918 - val_VH_attention_linear_output_loss: 1.8412 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4540\n",
      "Epoch 1826/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5661 - VL_attention_linear_output_loss: 1.7474 - VH_attention_linear_output_loss: 1.8187 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4578 - val_loss: 3.6210 - val_VL_attention_linear_output_loss: 1.7850 - val_VH_attention_linear_output_loss: 1.8360 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4554\n",
      "Epoch 1827/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5712 - VL_attention_linear_output_loss: 1.7488 - VH_attention_linear_output_loss: 1.8224 - VL_attention_linear_output_acc: 0.4869 - VH_attention_linear_output_acc: 0.4555 - val_loss: 3.6323 - val_VL_attention_linear_output_loss: 1.7911 - val_VH_attention_linear_output_loss: 1.8412 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4548\n",
      "Epoch 1828/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5770 - VL_attention_linear_output_loss: 1.7577 - VH_attention_linear_output_loss: 1.8193 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4574 - val_loss: 3.6394 - val_VL_attention_linear_output_loss: 1.7972 - val_VH_attention_linear_output_loss: 1.8422 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.4547\n",
      "Epoch 1829/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5713 - VL_attention_linear_output_loss: 1.7588 - VH_attention_linear_output_loss: 1.8125 - VL_attention_linear_output_acc: 0.4806 - VH_attention_linear_output_acc: 0.4603 - val_loss: 3.6620 - val_VL_attention_linear_output_loss: 1.8162 - val_VH_attention_linear_output_loss: 1.8459 - val_VL_attention_linear_output_acc: 0.4680 - val_VH_attention_linear_output_acc: 0.4511\n",
      "Epoch 1830/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5711 - VL_attention_linear_output_loss: 1.7528 - VH_attention_linear_output_loss: 1.8183 - VL_attention_linear_output_acc: 0.4840 - VH_attention_linear_output_acc: 0.4582 - val_loss: 3.6387 - val_VL_attention_linear_output_loss: 1.7894 - val_VH_attention_linear_output_loss: 1.8493 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4494\n",
      "Epoch 1831/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5590 - VL_attention_linear_output_loss: 1.7464 - VH_attention_linear_output_loss: 1.8126 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4600 - val_loss: 3.6420 - val_VL_attention_linear_output_loss: 1.7875 - val_VH_attention_linear_output_loss: 1.8545 - val_VL_attention_linear_output_acc: 0.4858 - val_VH_attention_linear_output_acc: 0.4503\n",
      "Epoch 1832/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5812 - VL_attention_linear_output_loss: 1.7544 - VH_attention_linear_output_loss: 1.8268 - VL_attention_linear_output_acc: 0.4837 - VH_attention_linear_output_acc: 0.4540 - val_loss: 3.6413 - val_VL_attention_linear_output_loss: 1.8037 - val_VH_attention_linear_output_loss: 1.8376 - val_VL_attention_linear_output_acc: 0.4744 - val_VH_attention_linear_output_acc: 0.4577\n",
      "Epoch 1833/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5778 - VL_attention_linear_output_loss: 1.7649 - VH_attention_linear_output_loss: 1.8129 - VL_attention_linear_output_acc: 0.4777 - VH_attention_linear_output_acc: 0.4592 - val_loss: 3.6682 - val_VL_attention_linear_output_loss: 1.8263 - val_VH_attention_linear_output_loss: 1.8419 - val_VL_attention_linear_output_acc: 0.4581 - val_VH_attention_linear_output_acc: 0.4524\n",
      "Epoch 1834/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5678 - VL_attention_linear_output_loss: 1.7499 - VH_attention_linear_output_loss: 1.8179 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4577 - val_loss: 3.6345 - val_VL_attention_linear_output_loss: 1.7865 - val_VH_attention_linear_output_loss: 1.8480 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4523\n",
      "Epoch 1835/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5618 - VL_attention_linear_output_loss: 1.7446 - VH_attention_linear_output_loss: 1.8172 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4584 - val_loss: 3.6507 - val_VL_attention_linear_output_loss: 1.7917 - val_VH_attention_linear_output_loss: 1.8590 - val_VL_attention_linear_output_acc: 0.4744 - val_VH_attention_linear_output_acc: 0.4459\n",
      "Epoch 1836/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5734 - VL_attention_linear_output_loss: 1.7546 - VH_attention_linear_output_loss: 1.8189 - VL_attention_linear_output_acc: 0.4840 - VH_attention_linear_output_acc: 0.4572 - val_loss: 3.6506 - val_VL_attention_linear_output_loss: 1.7870 - val_VH_attention_linear_output_loss: 1.8636 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4410\n",
      "Epoch 1837/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5678 - VL_attention_linear_output_loss: 1.7540 - VH_attention_linear_output_loss: 1.8138 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4597 - val_loss: 3.6577 - val_VL_attention_linear_output_loss: 1.7905 - val_VH_attention_linear_output_loss: 1.8672 - val_VL_attention_linear_output_acc: 0.4751 - val_VH_attention_linear_output_acc: 0.4432\n",
      "Epoch 1838/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5764 - VL_attention_linear_output_loss: 1.7560 - VH_attention_linear_output_loss: 1.8205 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4569 - val_loss: 3.6503 - val_VL_attention_linear_output_loss: 1.7874 - val_VH_attention_linear_output_loss: 1.8629 - val_VL_attention_linear_output_acc: 0.4816 - val_VH_attention_linear_output_acc: 0.4408\n",
      "Epoch 1839/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5566 - VL_attention_linear_output_loss: 1.7465 - VH_attention_linear_output_loss: 1.8101 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4611 - val_loss: 3.6189 - val_VL_attention_linear_output_loss: 1.7818 - val_VH_attention_linear_output_loss: 1.8370 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4553\n",
      "Epoch 1840/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5667 - VL_attention_linear_output_loss: 1.7471 - VH_attention_linear_output_loss: 1.8195 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4577 - val_loss: 3.6547 - val_VL_attention_linear_output_loss: 1.7942 - val_VH_attention_linear_output_loss: 1.8605 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4454\n",
      "Epoch 1841/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5761 - VL_attention_linear_output_loss: 1.7499 - VH_attention_linear_output_loss: 1.8262 - VL_attention_linear_output_acc: 0.4860 - VH_attention_linear_output_acc: 0.4530 - val_loss: 3.6986 - val_VL_attention_linear_output_loss: 1.8180 - val_VH_attention_linear_output_loss: 1.8806 - val_VL_attention_linear_output_acc: 0.4653 - val_VH_attention_linear_output_acc: 0.4417\n",
      "Epoch 1842/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5714 - VL_attention_linear_output_loss: 1.7516 - VH_attention_linear_output_loss: 1.8198 - VL_attention_linear_output_acc: 0.4851 - VH_attention_linear_output_acc: 0.4566 - val_loss: 3.6995 - val_VL_attention_linear_output_loss: 1.8467 - val_VH_attention_linear_output_loss: 1.8528 - val_VL_attention_linear_output_acc: 0.4526 - val_VH_attention_linear_output_acc: 0.4510\n",
      "Epoch 1843/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5707 - VL_attention_linear_output_loss: 1.7612 - VH_attention_linear_output_loss: 1.8095 - VL_attention_linear_output_acc: 0.4820 - VH_attention_linear_output_acc: 0.4610 - val_loss: 3.6334 - val_VL_attention_linear_output_loss: 1.7941 - val_VH_attention_linear_output_loss: 1.8394 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4568\n",
      "Epoch 1844/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5759 - VL_attention_linear_output_loss: 1.7590 - VH_attention_linear_output_loss: 1.8169 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4575 - val_loss: 3.6608 - val_VL_attention_linear_output_loss: 1.7863 - val_VH_attention_linear_output_loss: 1.8745 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4379\n",
      "Epoch 1845/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5783 - VL_attention_linear_output_loss: 1.7584 - VH_attention_linear_output_loss: 1.8200 - VL_attention_linear_output_acc: 0.4811 - VH_attention_linear_output_acc: 0.4566 - val_loss: 3.6430 - val_VL_attention_linear_output_loss: 1.7951 - val_VH_attention_linear_output_loss: 1.8479 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.4525\n",
      "Epoch 1846/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5687 - VL_attention_linear_output_loss: 1.7506 - VH_attention_linear_output_loss: 1.8181 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4587 - val_loss: 3.6347 - val_VL_attention_linear_output_loss: 1.7860 - val_VH_attention_linear_output_loss: 1.8487 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4530\n",
      "Epoch 1847/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5468 - VL_attention_linear_output_loss: 1.7418 - VH_attention_linear_output_loss: 1.8050 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.4629 - val_loss: 3.6355 - val_VL_attention_linear_output_loss: 1.7901 - val_VH_attention_linear_output_loss: 1.8455 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4515\n",
      "Epoch 1848/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5604 - VL_attention_linear_output_loss: 1.7479 - VH_attention_linear_output_loss: 1.8125 - VL_attention_linear_output_acc: 0.4869 - VH_attention_linear_output_acc: 0.4593 - val_loss: 3.6511 - val_VL_attention_linear_output_loss: 1.7876 - val_VH_attention_linear_output_loss: 1.8636 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4418\n",
      "Epoch 1849/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5690 - VL_attention_linear_output_loss: 1.7467 - VH_attention_linear_output_loss: 1.8223 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4563 - val_loss: 3.6277 - val_VL_attention_linear_output_loss: 1.7848 - val_VH_attention_linear_output_loss: 1.8429 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4534\n",
      "Epoch 1850/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5671 - VL_attention_linear_output_loss: 1.7505 - VH_attention_linear_output_loss: 1.8166 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4581 - val_loss: 3.6540 - val_VL_attention_linear_output_loss: 1.7976 - val_VH_attention_linear_output_loss: 1.8564 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4463\n",
      "Epoch 1851/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5767 - VL_attention_linear_output_loss: 1.7555 - VH_attention_linear_output_loss: 1.8213 - VL_attention_linear_output_acc: 0.4822 - VH_attention_linear_output_acc: 0.4562 - val_loss: 3.6432 - val_VL_attention_linear_output_loss: 1.7890 - val_VH_attention_linear_output_loss: 1.8542 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4483\n",
      "Epoch 1852/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5753 - VL_attention_linear_output_loss: 1.7552 - VH_attention_linear_output_loss: 1.8201 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.4570 - val_loss: 3.6324 - val_VL_attention_linear_output_loss: 1.7930 - val_VH_attention_linear_output_loss: 1.8394 - val_VL_attention_linear_output_acc: 0.4712 - val_VH_attention_linear_output_acc: 0.4552\n",
      "Epoch 1853/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5696 - VL_attention_linear_output_loss: 1.7508 - VH_attention_linear_output_loss: 1.8188 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4565 - val_loss: 3.6796 - val_VL_attention_linear_output_loss: 1.7966 - val_VH_attention_linear_output_loss: 1.8830 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4373\n",
      "Epoch 1854/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5772 - VL_attention_linear_output_loss: 1.7580 - VH_attention_linear_output_loss: 1.8192 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4569 - val_loss: 3.6333 - val_VL_attention_linear_output_loss: 1.7878 - val_VH_attention_linear_output_loss: 1.8454 - val_VL_attention_linear_output_acc: 0.4828 - val_VH_attention_linear_output_acc: 0.4505\n",
      "Epoch 1855/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5603 - VL_attention_linear_output_loss: 1.7461 - VH_attention_linear_output_loss: 1.8142 - VL_attention_linear_output_acc: 0.4873 - VH_attention_linear_output_acc: 0.4590 - val_loss: 3.6260 - val_VL_attention_linear_output_loss: 1.7834 - val_VH_attention_linear_output_loss: 1.8426 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4534\n",
      "Epoch 1856/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5692 - VL_attention_linear_output_loss: 1.7550 - VH_attention_linear_output_loss: 1.8142 - VL_attention_linear_output_acc: 0.4831 - VH_attention_linear_output_acc: 0.4589 - val_loss: 3.6237 - val_VL_attention_linear_output_loss: 1.7820 - val_VH_attention_linear_output_loss: 1.8417 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4532\n",
      "Epoch 1857/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5669 - VL_attention_linear_output_loss: 1.7480 - VH_attention_linear_output_loss: 1.8189 - VL_attention_linear_output_acc: 0.4864 - VH_attention_linear_output_acc: 0.4571 - val_loss: 3.6378 - val_VL_attention_linear_output_loss: 1.7929 - val_VH_attention_linear_output_loss: 1.8449 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4496\n",
      "Epoch 1858/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5794 - VL_attention_linear_output_loss: 1.7589 - VH_attention_linear_output_loss: 1.8204 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.4554 - val_loss: 3.6390 - val_VL_attention_linear_output_loss: 1.7966 - val_VH_attention_linear_output_loss: 1.8424 - val_VL_attention_linear_output_acc: 0.4773 - val_VH_attention_linear_output_acc: 0.4533\n",
      "Epoch 1859/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5708 - VL_attention_linear_output_loss: 1.7554 - VH_attention_linear_output_loss: 1.8154 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4585 - val_loss: 3.6374 - val_VL_attention_linear_output_loss: 1.7957 - val_VH_attention_linear_output_loss: 1.8418 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.4535\n",
      "Epoch 1860/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5668 - VL_attention_linear_output_loss: 1.7492 - VH_attention_linear_output_loss: 1.8176 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4580 - val_loss: 3.6840 - val_VL_attention_linear_output_loss: 1.8243 - val_VH_attention_linear_output_loss: 1.8597 - val_VL_attention_linear_output_acc: 0.4657 - val_VH_attention_linear_output_acc: 0.4496\n",
      "Epoch 1861/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5751 - VL_attention_linear_output_loss: 1.7568 - VH_attention_linear_output_loss: 1.8183 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4577 - val_loss: 3.6897 - val_VL_attention_linear_output_loss: 1.7881 - val_VH_attention_linear_output_loss: 1.9015 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4191\n",
      "Epoch 1862/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5698 - VL_attention_linear_output_loss: 1.7611 - VH_attention_linear_output_loss: 1.8087 - VL_attention_linear_output_acc: 0.4799 - VH_attention_linear_output_acc: 0.4617 - val_loss: 3.6453 - val_VL_attention_linear_output_loss: 1.7915 - val_VH_attention_linear_output_loss: 1.8538 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4485\n",
      "Epoch 1863/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5634 - VL_attention_linear_output_loss: 1.7518 - VH_attention_linear_output_loss: 1.8116 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4602 - val_loss: 3.6278 - val_VL_attention_linear_output_loss: 1.7912 - val_VH_attention_linear_output_loss: 1.8366 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4558\n",
      "Epoch 1864/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5666 - VL_attention_linear_output_loss: 1.7510 - VH_attention_linear_output_loss: 1.8156 - VL_attention_linear_output_acc: 0.4844 - VH_attention_linear_output_acc: 0.4582 - val_loss: 3.6749 - val_VL_attention_linear_output_loss: 1.8384 - val_VH_attention_linear_output_loss: 1.8365 - val_VL_attention_linear_output_acc: 0.4574 - val_VH_attention_linear_output_acc: 0.4571\n",
      "Epoch 1865/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5772 - VL_attention_linear_output_loss: 1.7585 - VH_attention_linear_output_loss: 1.8188 - VL_attention_linear_output_acc: 0.4814 - VH_attention_linear_output_acc: 0.4565 - val_loss: 3.6530 - val_VL_attention_linear_output_loss: 1.8032 - val_VH_attention_linear_output_loss: 1.8498 - val_VL_attention_linear_output_acc: 0.4729 - val_VH_attention_linear_output_acc: 0.4525\n",
      "Epoch 1866/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5624 - VL_attention_linear_output_loss: 1.7472 - VH_attention_linear_output_loss: 1.8152 - VL_attention_linear_output_acc: 0.4878 - VH_attention_linear_output_acc: 0.4588 - val_loss: 3.6271 - val_VL_attention_linear_output_loss: 1.7875 - val_VH_attention_linear_output_loss: 1.8396 - val_VL_attention_linear_output_acc: 0.4828 - val_VH_attention_linear_output_acc: 0.4520\n",
      "Epoch 1867/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5525 - VL_attention_linear_output_loss: 1.7436 - VH_attention_linear_output_loss: 1.8090 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4610 - val_loss: 3.6436 - val_VL_attention_linear_output_loss: 1.7899 - val_VH_attention_linear_output_loss: 1.8537 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4503\n",
      "Epoch 1868/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5564 - VL_attention_linear_output_loss: 1.7453 - VH_attention_linear_output_loss: 1.8112 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4602 - val_loss: 3.6413 - val_VL_attention_linear_output_loss: 1.7886 - val_VH_attention_linear_output_loss: 1.8527 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4493\n",
      "Epoch 1869/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5601 - VL_attention_linear_output_loss: 1.7491 - VH_attention_linear_output_loss: 1.8110 - VL_attention_linear_output_acc: 0.4851 - VH_attention_linear_output_acc: 0.4598 - val_loss: 3.7282 - val_VL_attention_linear_output_loss: 1.8612 - val_VH_attention_linear_output_loss: 1.8670 - val_VL_attention_linear_output_acc: 0.4441 - val_VH_attention_linear_output_acc: 0.4393\n",
      "Epoch 1870/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5715 - VL_attention_linear_output_loss: 1.7554 - VH_attention_linear_output_loss: 1.8161 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4582 - val_loss: 3.6356 - val_VL_attention_linear_output_loss: 1.7882 - val_VH_attention_linear_output_loss: 1.8474 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4523\n",
      "Epoch 1871/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5889 - VL_attention_linear_output_loss: 1.7559 - VH_attention_linear_output_loss: 1.8330 - VL_attention_linear_output_acc: 0.4833 - VH_attention_linear_output_acc: 0.4514 - val_loss: 3.6430 - val_VL_attention_linear_output_loss: 1.8109 - val_VH_attention_linear_output_loss: 1.8321 - val_VL_attention_linear_output_acc: 0.4674 - val_VH_attention_linear_output_acc: 0.4575\n",
      "Epoch 1872/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5683 - VL_attention_linear_output_loss: 1.7526 - VH_attention_linear_output_loss: 1.8157 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4591 - val_loss: 3.6337 - val_VL_attention_linear_output_loss: 1.7993 - val_VH_attention_linear_output_loss: 1.8344 - val_VL_attention_linear_output_acc: 0.4766 - val_VH_attention_linear_output_acc: 0.4551\n",
      "Epoch 1873/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5733 - VL_attention_linear_output_loss: 1.7580 - VH_attention_linear_output_loss: 1.8154 - VL_attention_linear_output_acc: 0.4813 - VH_attention_linear_output_acc: 0.4584 - val_loss: 3.7022 - val_VL_attention_linear_output_loss: 1.8687 - val_VH_attention_linear_output_loss: 1.8334 - val_VL_attention_linear_output_acc: 0.4378 - val_VH_attention_linear_output_acc: 0.4574\n",
      "Epoch 1874/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5706 - VL_attention_linear_output_loss: 1.7607 - VH_attention_linear_output_loss: 1.8099 - VL_attention_linear_output_acc: 0.4801 - VH_attention_linear_output_acc: 0.4610 - val_loss: 3.6509 - val_VL_attention_linear_output_loss: 1.7853 - val_VH_attention_linear_output_loss: 1.8656 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4414\n",
      "Epoch 1875/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5777 - VL_attention_linear_output_loss: 1.7545 - VH_attention_linear_output_loss: 1.8232 - VL_attention_linear_output_acc: 0.4831 - VH_attention_linear_output_acc: 0.4554 - val_loss: 3.6509 - val_VL_attention_linear_output_loss: 1.8004 - val_VH_attention_linear_output_loss: 1.8505 - val_VL_attention_linear_output_acc: 0.4725 - val_VH_attention_linear_output_acc: 0.4494\n",
      "Epoch 1876/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5683 - VL_attention_linear_output_loss: 1.7541 - VH_attention_linear_output_loss: 1.8142 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4594 - val_loss: 3.6303 - val_VL_attention_linear_output_loss: 1.7919 - val_VH_attention_linear_output_loss: 1.8383 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4550\n",
      "Epoch 1877/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5640 - VL_attention_linear_output_loss: 1.7562 - VH_attention_linear_output_loss: 1.8078 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4612 - val_loss: 3.6725 - val_VL_attention_linear_output_loss: 1.7928 - val_VH_attention_linear_output_loss: 1.8797 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4329\n",
      "Epoch 1878/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5683 - VL_attention_linear_output_loss: 1.7529 - VH_attention_linear_output_loss: 1.8154 - VL_attention_linear_output_acc: 0.4840 - VH_attention_linear_output_acc: 0.4587 - val_loss: 3.6262 - val_VL_attention_linear_output_loss: 1.7878 - val_VH_attention_linear_output_loss: 1.8384 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.4550\n",
      "Epoch 1879/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5488 - VL_attention_linear_output_loss: 1.7442 - VH_attention_linear_output_loss: 1.8046 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4631 - val_loss: 3.6285 - val_VL_attention_linear_output_loss: 1.7915 - val_VH_attention_linear_output_loss: 1.8370 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4559\n",
      "Epoch 1880/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5595 - VL_attention_linear_output_loss: 1.7508 - VH_attention_linear_output_loss: 1.8087 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4611 - val_loss: 3.6305 - val_VL_attention_linear_output_loss: 1.7925 - val_VH_attention_linear_output_loss: 1.8380 - val_VL_attention_linear_output_acc: 0.4774 - val_VH_attention_linear_output_acc: 0.4566\n",
      "Epoch 1881/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5796 - VL_attention_linear_output_loss: 1.7594 - VH_attention_linear_output_loss: 1.8202 - VL_attention_linear_output_acc: 0.4810 - VH_attention_linear_output_acc: 0.4557 - val_loss: 3.6582 - val_VL_attention_linear_output_loss: 1.8047 - val_VH_attention_linear_output_loss: 1.8535 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.4461\n",
      "Epoch 1882/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5579 - VL_attention_linear_output_loss: 1.7488 - VH_attention_linear_output_loss: 1.8091 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4609 - val_loss: 3.6374 - val_VL_attention_linear_output_loss: 1.7994 - val_VH_attention_linear_output_loss: 1.8379 - val_VL_attention_linear_output_acc: 0.4795 - val_VH_attention_linear_output_acc: 0.4555\n",
      "Epoch 1883/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5659 - VL_attention_linear_output_loss: 1.7513 - VH_attention_linear_output_loss: 1.8146 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4578 - val_loss: 3.6452 - val_VL_attention_linear_output_loss: 1.7999 - val_VH_attention_linear_output_loss: 1.8453 - val_VL_attention_linear_output_acc: 0.4739 - val_VH_attention_linear_output_acc: 0.4544\n",
      "Epoch 1884/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5694 - VL_attention_linear_output_loss: 1.7585 - VH_attention_linear_output_loss: 1.8109 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4594 - val_loss: 3.6599 - val_VL_attention_linear_output_loss: 1.8234 - val_VH_attention_linear_output_loss: 1.8365 - val_VL_attention_linear_output_acc: 0.4628 - val_VH_attention_linear_output_acc: 0.4569\n",
      "Epoch 1885/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5599 - VL_attention_linear_output_loss: 1.7458 - VH_attention_linear_output_loss: 1.8140 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4587 - val_loss: 3.6259 - val_VL_attention_linear_output_loss: 1.7854 - val_VH_attention_linear_output_loss: 1.8405 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4538\n",
      "Epoch 1886/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5580 - VL_attention_linear_output_loss: 1.7458 - VH_attention_linear_output_loss: 1.8122 - VL_attention_linear_output_acc: 0.4860 - VH_attention_linear_output_acc: 0.4590 - val_loss: 3.6963 - val_VL_attention_linear_output_loss: 1.8182 - val_VH_attention_linear_output_loss: 1.8782 - val_VL_attention_linear_output_acc: 0.4713 - val_VH_attention_linear_output_acc: 0.4417\n",
      "Epoch 1887/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5652 - VL_attention_linear_output_loss: 1.7500 - VH_attention_linear_output_loss: 1.8152 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4581 - val_loss: 3.6229 - val_VL_attention_linear_output_loss: 1.7894 - val_VH_attention_linear_output_loss: 1.8335 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.4562\n",
      "Epoch 1888/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5673 - VL_attention_linear_output_loss: 1.7518 - VH_attention_linear_output_loss: 1.8155 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4586 - val_loss: 3.6673 - val_VL_attention_linear_output_loss: 1.8036 - val_VH_attention_linear_output_loss: 1.8637 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4429\n",
      "Epoch 1889/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5775 - VL_attention_linear_output_loss: 1.7591 - VH_attention_linear_output_loss: 1.8184 - VL_attention_linear_output_acc: 0.4812 - VH_attention_linear_output_acc: 0.4570 - val_loss: 3.6283 - val_VL_attention_linear_output_loss: 1.7915 - val_VH_attention_linear_output_loss: 1.8368 - val_VL_attention_linear_output_acc: 0.4810 - val_VH_attention_linear_output_acc: 0.4555\n",
      "Epoch 1890/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5649 - VL_attention_linear_output_loss: 1.7541 - VH_attention_linear_output_loss: 1.8109 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4592 - val_loss: 3.6179 - val_VL_attention_linear_output_loss: 1.7799 - val_VH_attention_linear_output_loss: 1.8380 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4552\n",
      "Epoch 1891/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5581 - VL_attention_linear_output_loss: 1.7501 - VH_attention_linear_output_loss: 1.8080 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4609 - val_loss: 3.7066 - val_VL_attention_linear_output_loss: 1.8435 - val_VH_attention_linear_output_loss: 1.8632 - val_VL_attention_linear_output_acc: 0.4493 - val_VH_attention_linear_output_acc: 0.4424\n",
      "Epoch 1892/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5631 - VL_attention_linear_output_loss: 1.7499 - VH_attention_linear_output_loss: 1.8132 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4587 - val_loss: 3.6185 - val_VL_attention_linear_output_loss: 1.7900 - val_VH_attention_linear_output_loss: 1.8285 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.4600\n",
      "Epoch 1893/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5648 - VL_attention_linear_output_loss: 1.7501 - VH_attention_linear_output_loss: 1.8147 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4585 - val_loss: 3.6219 - val_VL_attention_linear_output_loss: 1.7912 - val_VH_attention_linear_output_loss: 1.8307 - val_VL_attention_linear_output_acc: 0.4699 - val_VH_attention_linear_output_acc: 0.4583\n",
      "Epoch 1894/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5772 - VL_attention_linear_output_loss: 1.7574 - VH_attention_linear_output_loss: 1.8198 - VL_attention_linear_output_acc: 0.4808 - VH_attention_linear_output_acc: 0.4559 - val_loss: 3.6560 - val_VL_attention_linear_output_loss: 1.8225 - val_VH_attention_linear_output_loss: 1.8335 - val_VL_attention_linear_output_acc: 0.4621 - val_VH_attention_linear_output_acc: 0.4553\n",
      "Epoch 1895/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5658 - VL_attention_linear_output_loss: 1.7586 - VH_attention_linear_output_loss: 1.8072 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4608 - val_loss: 3.6431 - val_VL_attention_linear_output_loss: 1.7934 - val_VH_attention_linear_output_loss: 1.8497 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4512\n",
      "Epoch 1896/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5634 - VL_attention_linear_output_loss: 1.7460 - VH_attention_linear_output_loss: 1.8174 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4571 - val_loss: 3.6665 - val_VL_attention_linear_output_loss: 1.8208 - val_VH_attention_linear_output_loss: 1.8457 - val_VL_attention_linear_output_acc: 0.4647 - val_VH_attention_linear_output_acc: 0.4490\n",
      "Epoch 1897/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5741 - VL_attention_linear_output_loss: 1.7507 - VH_attention_linear_output_loss: 1.8234 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4540 - val_loss: 3.6455 - val_VL_attention_linear_output_loss: 1.7912 - val_VH_attention_linear_output_loss: 1.8543 - val_VL_attention_linear_output_acc: 0.4788 - val_VH_attention_linear_output_acc: 0.4470\n",
      "Epoch 1898/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5599 - VL_attention_linear_output_loss: 1.7522 - VH_attention_linear_output_loss: 1.8077 - VL_attention_linear_output_acc: 0.4852 - VH_attention_linear_output_acc: 0.4609 - val_loss: 3.6449 - val_VL_attention_linear_output_loss: 1.7873 - val_VH_attention_linear_output_loss: 1.8575 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4467\n",
      "Epoch 1899/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5619 - VL_attention_linear_output_loss: 1.7508 - VH_attention_linear_output_loss: 1.8111 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4604 - val_loss: 3.6445 - val_VL_attention_linear_output_loss: 1.7988 - val_VH_attention_linear_output_loss: 1.8457 - val_VL_attention_linear_output_acc: 0.4780 - val_VH_attention_linear_output_acc: 0.4526\n",
      "Epoch 1900/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5604 - VL_attention_linear_output_loss: 1.7509 - VH_attention_linear_output_loss: 1.8095 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4609 - val_loss: 3.6244 - val_VL_attention_linear_output_loss: 1.7894 - val_VH_attention_linear_output_loss: 1.8350 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4568\n",
      "Epoch 1901/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5732 - VL_attention_linear_output_loss: 1.7546 - VH_attention_linear_output_loss: 1.8186 - VL_attention_linear_output_acc: 0.4835 - VH_attention_linear_output_acc: 0.4571 - val_loss: 3.6374 - val_VL_attention_linear_output_loss: 1.7849 - val_VH_attention_linear_output_loss: 1.8526 - val_VL_attention_linear_output_acc: 0.4738 - val_VH_attention_linear_output_acc: 0.4508\n",
      "Epoch 1902/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5677 - VL_attention_linear_output_loss: 1.7528 - VH_attention_linear_output_loss: 1.8150 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4584 - val_loss: 3.6337 - val_VL_attention_linear_output_loss: 1.7979 - val_VH_attention_linear_output_loss: 1.8358 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4551\n",
      "Epoch 1903/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5699 - VL_attention_linear_output_loss: 1.7577 - VH_attention_linear_output_loss: 1.8121 - VL_attention_linear_output_acc: 0.4817 - VH_attention_linear_output_acc: 0.4596 - val_loss: 3.6182 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.8310 - val_VL_attention_linear_output_acc: 0.4794 - val_VH_attention_linear_output_acc: 0.4566\n",
      "Epoch 1904/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5562 - VL_attention_linear_output_loss: 1.7426 - VH_attention_linear_output_loss: 1.8137 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4595 - val_loss: 3.6194 - val_VL_attention_linear_output_loss: 1.7879 - val_VH_attention_linear_output_loss: 1.8316 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4549\n",
      "Epoch 1905/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5720 - VL_attention_linear_output_loss: 1.7471 - VH_attention_linear_output_loss: 1.8249 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4541 - val_loss: 3.6293 - val_VL_attention_linear_output_loss: 1.7836 - val_VH_attention_linear_output_loss: 1.8457 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4522\n",
      "Epoch 1906/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5693 - VL_attention_linear_output_loss: 1.7482 - VH_attention_linear_output_loss: 1.8211 - VL_attention_linear_output_acc: 0.4849 - VH_attention_linear_output_acc: 0.4562 - val_loss: 3.6316 - val_VL_attention_linear_output_loss: 1.7949 - val_VH_attention_linear_output_loss: 1.8368 - val_VL_attention_linear_output_acc: 0.4684 - val_VH_attention_linear_output_acc: 0.4530\n",
      "Epoch 1907/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5673 - VL_attention_linear_output_loss: 1.7538 - VH_attention_linear_output_loss: 1.8136 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4588 - val_loss: 3.6346 - val_VL_attention_linear_output_loss: 1.8000 - val_VH_attention_linear_output_loss: 1.8346 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4532\n",
      "Epoch 1908/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5635 - VL_attention_linear_output_loss: 1.7550 - VH_attention_linear_output_loss: 1.8085 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4608 - val_loss: 3.6470 - val_VL_attention_linear_output_loss: 1.7835 - val_VH_attention_linear_output_loss: 1.8635 - val_VL_attention_linear_output_acc: 0.4858 - val_VH_attention_linear_output_acc: 0.4408\n",
      "Epoch 1909/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5539 - VL_attention_linear_output_loss: 1.7436 - VH_attention_linear_output_loss: 1.8103 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4599 - val_loss: 3.6302 - val_VL_attention_linear_output_loss: 1.7915 - val_VH_attention_linear_output_loss: 1.8388 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.4534\n",
      "Epoch 1910/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5529 - VL_attention_linear_output_loss: 1.7521 - VH_attention_linear_output_loss: 1.8007 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4635 - val_loss: 3.6768 - val_VL_attention_linear_output_loss: 1.8146 - val_VH_attention_linear_output_loss: 1.8622 - val_VL_attention_linear_output_acc: 0.4675 - val_VH_attention_linear_output_acc: 0.4469\n",
      "Epoch 1911/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5596 - VL_attention_linear_output_loss: 1.7522 - VH_attention_linear_output_loss: 1.8074 - VL_attention_linear_output_acc: 0.4848 - VH_attention_linear_output_acc: 0.4613 - val_loss: 3.6250 - val_VL_attention_linear_output_loss: 1.7878 - val_VH_attention_linear_output_loss: 1.8372 - val_VL_attention_linear_output_acc: 0.4805 - val_VH_attention_linear_output_acc: 0.4553\n",
      "Epoch 1912/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5709 - VL_attention_linear_output_loss: 1.7573 - VH_attention_linear_output_loss: 1.8136 - VL_attention_linear_output_acc: 0.4799 - VH_attention_linear_output_acc: 0.4587 - val_loss: 3.6307 - val_VL_attention_linear_output_loss: 1.7819 - val_VH_attention_linear_output_loss: 1.8488 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4463\n",
      "Epoch 1913/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5512 - VL_attention_linear_output_loss: 1.7427 - VH_attention_linear_output_loss: 1.8084 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4608 - val_loss: 3.6580 - val_VL_attention_linear_output_loss: 1.7917 - val_VH_attention_linear_output_loss: 1.8663 - val_VL_attention_linear_output_acc: 0.4788 - val_VH_attention_linear_output_acc: 0.4465\n",
      "Epoch 1914/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5703 - VL_attention_linear_output_loss: 1.7564 - VH_attention_linear_output_loss: 1.8140 - VL_attention_linear_output_acc: 0.4815 - VH_attention_linear_output_acc: 0.4580 - val_loss: 3.6457 - val_VL_attention_linear_output_loss: 1.8102 - val_VH_attention_linear_output_loss: 1.8355 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.4554\n",
      "Epoch 1915/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5551 - VL_attention_linear_output_loss: 1.7519 - VH_attention_linear_output_loss: 1.8032 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4626 - val_loss: 3.6529 - val_VL_attention_linear_output_loss: 1.8226 - val_VH_attention_linear_output_loss: 1.8303 - val_VL_attention_linear_output_acc: 0.4562 - val_VH_attention_linear_output_acc: 0.4566\n",
      "Epoch 1916/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5467 - VL_attention_linear_output_loss: 1.7465 - VH_attention_linear_output_loss: 1.8002 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4645 - val_loss: 3.6389 - val_VL_attention_linear_output_loss: 1.8023 - val_VH_attention_linear_output_loss: 1.8366 - val_VL_attention_linear_output_acc: 0.4715 - val_VH_attention_linear_output_acc: 0.4560\n",
      "Epoch 1917/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5734 - VL_attention_linear_output_loss: 1.7540 - VH_attention_linear_output_loss: 1.8194 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4563 - val_loss: 3.6200 - val_VL_attention_linear_output_loss: 1.7863 - val_VH_attention_linear_output_loss: 1.8337 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4566\n",
      "Epoch 1918/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5587 - VL_attention_linear_output_loss: 1.7575 - VH_attention_linear_output_loss: 1.8012 - VL_attention_linear_output_acc: 0.4810 - VH_attention_linear_output_acc: 0.4633 - val_loss: 3.6545 - val_VL_attention_linear_output_loss: 1.7903 - val_VH_attention_linear_output_loss: 1.8642 - val_VL_attention_linear_output_acc: 0.4795 - val_VH_attention_linear_output_acc: 0.4430\n",
      "Epoch 1919/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5578 - VL_attention_linear_output_loss: 1.7499 - VH_attention_linear_output_loss: 1.8079 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4604 - val_loss: 3.6174 - val_VL_attention_linear_output_loss: 1.7834 - val_VH_attention_linear_output_loss: 1.8339 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4574\n",
      "Epoch 1920/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5589 - VL_attention_linear_output_loss: 1.7502 - VH_attention_linear_output_loss: 1.8087 - VL_attention_linear_output_acc: 0.4844 - VH_attention_linear_output_acc: 0.4602 - val_loss: 3.6336 - val_VL_attention_linear_output_loss: 1.8033 - val_VH_attention_linear_output_loss: 1.8303 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.4567\n",
      "Epoch 1921/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5552 - VL_attention_linear_output_loss: 1.7481 - VH_attention_linear_output_loss: 1.8071 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4607 - val_loss: 3.6241 - val_VL_attention_linear_output_loss: 1.7822 - val_VH_attention_linear_output_loss: 1.8419 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4554\n",
      "Epoch 1922/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5669 - VL_attention_linear_output_loss: 1.7578 - VH_attention_linear_output_loss: 1.8090 - VL_attention_linear_output_acc: 0.4814 - VH_attention_linear_output_acc: 0.4598 - val_loss: 3.6133 - val_VL_attention_linear_output_loss: 1.7839 - val_VH_attention_linear_output_loss: 1.8294 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4560\n",
      "Epoch 1923/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5496 - VL_attention_linear_output_loss: 1.7417 - VH_attention_linear_output_loss: 1.8079 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4598 - val_loss: 3.6307 - val_VL_attention_linear_output_loss: 1.7856 - val_VH_attention_linear_output_loss: 1.8451 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4524\n",
      "Epoch 1924/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5673 - VL_attention_linear_output_loss: 1.7454 - VH_attention_linear_output_loss: 1.8219 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4541 - val_loss: 3.6185 - val_VL_attention_linear_output_loss: 1.7855 - val_VH_attention_linear_output_loss: 1.8330 - val_VL_attention_linear_output_acc: 0.4788 - val_VH_attention_linear_output_acc: 0.4552\n",
      "Epoch 1925/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5488 - VL_attention_linear_output_loss: 1.7431 - VH_attention_linear_output_loss: 1.8056 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4618 - val_loss: 3.6663 - val_VL_attention_linear_output_loss: 1.7982 - val_VH_attention_linear_output_loss: 1.8680 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.4458\n",
      "Epoch 1926/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5624 - VL_attention_linear_output_loss: 1.7558 - VH_attention_linear_output_loss: 1.8066 - VL_attention_linear_output_acc: 0.4824 - VH_attention_linear_output_acc: 0.4604 - val_loss: 3.6433 - val_VL_attention_linear_output_loss: 1.7994 - val_VH_attention_linear_output_loss: 1.8439 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4505\n",
      "Epoch 1927/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5523 - VL_attention_linear_output_loss: 1.7462 - VH_attention_linear_output_loss: 1.8060 - VL_attention_linear_output_acc: 0.4864 - VH_attention_linear_output_acc: 0.4614 - val_loss: 3.6273 - val_VL_attention_linear_output_loss: 1.7841 - val_VH_attention_linear_output_loss: 1.8432 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4519\n",
      "Epoch 1928/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5660 - VL_attention_linear_output_loss: 1.7515 - VH_attention_linear_output_loss: 1.8146 - VL_attention_linear_output_acc: 0.4844 - VH_attention_linear_output_acc: 0.4574 - val_loss: 3.6657 - val_VL_attention_linear_output_loss: 1.8006 - val_VH_attention_linear_output_loss: 1.8651 - val_VL_attention_linear_output_acc: 0.4769 - val_VH_attention_linear_output_acc: 0.4483\n",
      "Epoch 1929/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5649 - VL_attention_linear_output_loss: 1.7524 - VH_attention_linear_output_loss: 1.8125 - VL_attention_linear_output_acc: 0.4838 - VH_attention_linear_output_acc: 0.4588 - val_loss: 3.6890 - val_VL_attention_linear_output_loss: 1.8124 - val_VH_attention_linear_output_loss: 1.8767 - val_VL_attention_linear_output_acc: 0.4723 - val_VH_attention_linear_output_acc: 0.4427\n",
      "Epoch 1930/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5726 - VL_attention_linear_output_loss: 1.7624 - VH_attention_linear_output_loss: 1.8102 - VL_attention_linear_output_acc: 0.4795 - VH_attention_linear_output_acc: 0.4595 - val_loss: 3.6550 - val_VL_attention_linear_output_loss: 1.7982 - val_VH_attention_linear_output_loss: 1.8568 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4465\n",
      "Epoch 1931/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5605 - VL_attention_linear_output_loss: 1.7438 - VH_attention_linear_output_loss: 1.8168 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4570 - val_loss: 3.6304 - val_VL_attention_linear_output_loss: 1.7945 - val_VH_attention_linear_output_loss: 1.8359 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4555\n",
      "Epoch 1932/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5458 - VL_attention_linear_output_loss: 1.7466 - VH_attention_linear_output_loss: 1.7992 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4645 - val_loss: 3.6043 - val_VL_attention_linear_output_loss: 1.7815 - val_VH_attention_linear_output_loss: 1.8228 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4599\n",
      "Epoch 1933/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5485 - VL_attention_linear_output_loss: 1.7430 - VH_attention_linear_output_loss: 1.8054 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4612 - val_loss: 3.6166 - val_VL_attention_linear_output_loss: 1.7908 - val_VH_attention_linear_output_loss: 1.8258 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4587\n",
      "Epoch 1934/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5580 - VL_attention_linear_output_loss: 1.7577 - VH_attention_linear_output_loss: 1.8003 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4637 - val_loss: 3.6581 - val_VL_attention_linear_output_loss: 1.8264 - val_VH_attention_linear_output_loss: 1.8318 - val_VL_attention_linear_output_acc: 0.4630 - val_VH_attention_linear_output_acc: 0.4577\n",
      "Epoch 1935/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5667 - VL_attention_linear_output_loss: 1.7604 - VH_attention_linear_output_loss: 1.8063 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4604 - val_loss: 3.6420 - val_VL_attention_linear_output_loss: 1.8080 - val_VH_attention_linear_output_loss: 1.8340 - val_VL_attention_linear_output_acc: 0.4714 - val_VH_attention_linear_output_acc: 0.4555\n",
      "Epoch 1936/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5541 - VL_attention_linear_output_loss: 1.7480 - VH_attention_linear_output_loss: 1.8061 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4608 - val_loss: 3.6166 - val_VL_attention_linear_output_loss: 1.7910 - val_VH_attention_linear_output_loss: 1.8256 - val_VL_attention_linear_output_acc: 0.4784 - val_VH_attention_linear_output_acc: 0.4600\n",
      "Epoch 1937/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5509 - VL_attention_linear_output_loss: 1.7453 - VH_attention_linear_output_loss: 1.8055 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4621 - val_loss: 3.6144 - val_VL_attention_linear_output_loss: 1.7851 - val_VH_attention_linear_output_loss: 1.8293 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4582\n",
      "Epoch 1938/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5492 - VL_attention_linear_output_loss: 1.7453 - VH_attention_linear_output_loss: 1.8039 - VL_attention_linear_output_acc: 0.4869 - VH_attention_linear_output_acc: 0.4624 - val_loss: 3.6201 - val_VL_attention_linear_output_loss: 1.7890 - val_VH_attention_linear_output_loss: 1.8311 - val_VL_attention_linear_output_acc: 0.4705 - val_VH_attention_linear_output_acc: 0.4576\n",
      "Epoch 1939/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5691 - VL_attention_linear_output_loss: 1.7604 - VH_attention_linear_output_loss: 1.8087 - VL_attention_linear_output_acc: 0.4800 - VH_attention_linear_output_acc: 0.4604 - val_loss: 3.6249 - val_VL_attention_linear_output_loss: 1.7858 - val_VH_attention_linear_output_loss: 1.8391 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4521\n",
      "Epoch 1940/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5510 - VL_attention_linear_output_loss: 1.7469 - VH_attention_linear_output_loss: 1.8041 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4615 - val_loss: 3.6199 - val_VL_attention_linear_output_loss: 1.7870 - val_VH_attention_linear_output_loss: 1.8329 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4558\n",
      "Epoch 1941/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5662 - VL_attention_linear_output_loss: 1.7514 - VH_attention_linear_output_loss: 1.8148 - VL_attention_linear_output_acc: 0.4835 - VH_attention_linear_output_acc: 0.4578 - val_loss: 3.6489 - val_VL_attention_linear_output_loss: 1.8022 - val_VH_attention_linear_output_loss: 1.8468 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.4514\n",
      "Epoch 1942/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5607 - VL_attention_linear_output_loss: 1.7536 - VH_attention_linear_output_loss: 1.8072 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4611 - val_loss: 3.6584 - val_VL_attention_linear_output_loss: 1.8163 - val_VH_attention_linear_output_loss: 1.8421 - val_VL_attention_linear_output_acc: 0.4644 - val_VH_attention_linear_output_acc: 0.4481\n",
      "Epoch 1943/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5605 - VL_attention_linear_output_loss: 1.7511 - VH_attention_linear_output_loss: 1.8094 - VL_attention_linear_output_acc: 0.4822 - VH_attention_linear_output_acc: 0.4605 - val_loss: 3.6852 - val_VL_attention_linear_output_loss: 1.7884 - val_VH_attention_linear_output_loss: 1.8968 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4214\n",
      "Epoch 1944/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5557 - VL_attention_linear_output_loss: 1.7479 - VH_attention_linear_output_loss: 1.8078 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4600 - val_loss: 3.6128 - val_VL_attention_linear_output_loss: 1.7820 - val_VH_attention_linear_output_loss: 1.8308 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4575\n",
      "Epoch 1945/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5425 - VL_attention_linear_output_loss: 1.7439 - VH_attention_linear_output_loss: 1.7986 - VL_attention_linear_output_acc: 0.4873 - VH_attention_linear_output_acc: 0.4647 - val_loss: 3.6354 - val_VL_attention_linear_output_loss: 1.8035 - val_VH_attention_linear_output_loss: 1.8319 - val_VL_attention_linear_output_acc: 0.4746 - val_VH_attention_linear_output_acc: 0.4536\n",
      "Epoch 1946/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5672 - VL_attention_linear_output_loss: 1.7516 - VH_attention_linear_output_loss: 1.8156 - VL_attention_linear_output_acc: 0.4852 - VH_attention_linear_output_acc: 0.4578 - val_loss: 3.6378 - val_VL_attention_linear_output_loss: 1.7895 - val_VH_attention_linear_output_loss: 1.8482 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4524\n",
      "Epoch 1947/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5502 - VL_attention_linear_output_loss: 1.7447 - VH_attention_linear_output_loss: 1.8054 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4631 - val_loss: 3.6189 - val_VL_attention_linear_output_loss: 1.7951 - val_VH_attention_linear_output_loss: 1.8238 - val_VL_attention_linear_output_acc: 0.4714 - val_VH_attention_linear_output_acc: 0.4589\n",
      "Epoch 1948/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5351 - VL_attention_linear_output_loss: 1.7429 - VH_attention_linear_output_loss: 1.7922 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4671 - val_loss: 3.6102 - val_VL_attention_linear_output_loss: 1.7860 - val_VH_attention_linear_output_loss: 1.8242 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4590\n",
      "Epoch 1949/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5417 - VL_attention_linear_output_loss: 1.7447 - VH_attention_linear_output_loss: 1.7970 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4649 - val_loss: 3.6078 - val_VL_attention_linear_output_loss: 1.7813 - val_VH_attention_linear_output_loss: 1.8266 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4582\n",
      "Epoch 1950/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5361 - VL_attention_linear_output_loss: 1.7376 - VH_attention_linear_output_loss: 1.7985 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4644 - val_loss: 3.6095 - val_VL_attention_linear_output_loss: 1.7864 - val_VH_attention_linear_output_loss: 1.8231 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4578\n",
      "Epoch 1951/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5512 - VL_attention_linear_output_loss: 1.7474 - VH_attention_linear_output_loss: 1.8038 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4624 - val_loss: 3.6179 - val_VL_attention_linear_output_loss: 1.7854 - val_VH_attention_linear_output_loss: 1.8325 - val_VL_attention_linear_output_acc: 0.4778 - val_VH_attention_linear_output_acc: 0.4558\n",
      "Epoch 1952/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5403 - VL_attention_linear_output_loss: 1.7412 - VH_attention_linear_output_loss: 1.7991 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4640 - val_loss: 3.6483 - val_VL_attention_linear_output_loss: 1.7936 - val_VH_attention_linear_output_loss: 1.8547 - val_VL_attention_linear_output_acc: 0.4804 - val_VH_attention_linear_output_acc: 0.4465\n",
      "Epoch 1953/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5426 - VL_attention_linear_output_loss: 1.7473 - VH_attention_linear_output_loss: 1.7953 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4651 - val_loss: 3.6484 - val_VL_attention_linear_output_loss: 1.8189 - val_VH_attention_linear_output_loss: 1.8296 - val_VL_attention_linear_output_acc: 0.4629 - val_VH_attention_linear_output_acc: 0.4558\n",
      "Epoch 1954/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5537 - VL_attention_linear_output_loss: 1.7546 - VH_attention_linear_output_loss: 1.7991 - VL_attention_linear_output_acc: 0.4823 - VH_attention_linear_output_acc: 0.4642 - val_loss: 3.6237 - val_VL_attention_linear_output_loss: 1.7952 - val_VH_attention_linear_output_loss: 1.8284 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.4570\n",
      "Epoch 1955/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5568 - VL_attention_linear_output_loss: 1.7531 - VH_attention_linear_output_loss: 1.8038 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4621 - val_loss: 3.6583 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.8711 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4363\n",
      "Epoch 1956/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5402 - VL_attention_linear_output_loss: 1.7388 - VH_attention_linear_output_loss: 1.8013 - VL_attention_linear_output_acc: 0.4893 - VH_attention_linear_output_acc: 0.4627 - val_loss: 3.6216 - val_VL_attention_linear_output_loss: 1.7973 - val_VH_attention_linear_output_loss: 1.8242 - val_VL_attention_linear_output_acc: 0.4716 - val_VH_attention_linear_output_acc: 0.4591\n",
      "Epoch 1957/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5439 - VL_attention_linear_output_loss: 1.7429 - VH_attention_linear_output_loss: 1.8011 - VL_attention_linear_output_acc: 0.4863 - VH_attention_linear_output_acc: 0.4627 - val_loss: 3.6668 - val_VL_attention_linear_output_loss: 1.7771 - val_VH_attention_linear_output_loss: 1.8897 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4308\n",
      "Epoch 1958/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5368 - VL_attention_linear_output_loss: 1.7376 - VH_attention_linear_output_loss: 1.7992 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4631 - val_loss: 3.6084 - val_VL_attention_linear_output_loss: 1.7801 - val_VH_attention_linear_output_loss: 1.8283 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4582\n",
      "Epoch 1959/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5499 - VL_attention_linear_output_loss: 1.7470 - VH_attention_linear_output_loss: 1.8029 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4617 - val_loss: 3.6223 - val_VL_attention_linear_output_loss: 1.7890 - val_VH_attention_linear_output_loss: 1.8333 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4550\n",
      "Epoch 1960/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5536 - VL_attention_linear_output_loss: 1.7466 - VH_attention_linear_output_loss: 1.8070 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4606 - val_loss: 3.6276 - val_VL_attention_linear_output_loss: 1.7900 - val_VH_attention_linear_output_loss: 1.8377 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4542\n",
      "Epoch 1961/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5448 - VL_attention_linear_output_loss: 1.7474 - VH_attention_linear_output_loss: 1.7974 - VL_attention_linear_output_acc: 0.4852 - VH_attention_linear_output_acc: 0.4641 - val_loss: 3.6322 - val_VL_attention_linear_output_loss: 1.7991 - val_VH_attention_linear_output_loss: 1.8331 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.4558\n",
      "Epoch 1962/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5595 - VL_attention_linear_output_loss: 1.7511 - VH_attention_linear_output_loss: 1.8084 - VL_attention_linear_output_acc: 0.4837 - VH_attention_linear_output_acc: 0.4599 - val_loss: 3.6555 - val_VL_attention_linear_output_loss: 1.8237 - val_VH_attention_linear_output_loss: 1.8318 - val_VL_attention_linear_output_acc: 0.4599 - val_VH_attention_linear_output_acc: 0.4600\n",
      "Epoch 1963/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5459 - VL_attention_linear_output_loss: 1.7479 - VH_attention_linear_output_loss: 1.7980 - VL_attention_linear_output_acc: 0.4861 - VH_attention_linear_output_acc: 0.4638 - val_loss: 3.6192 - val_VL_attention_linear_output_loss: 1.7910 - val_VH_attention_linear_output_loss: 1.8282 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4578\n",
      "Epoch 1964/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5511 - VL_attention_linear_output_loss: 1.7478 - VH_attention_linear_output_loss: 1.8033 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4623 - val_loss: 3.6259 - val_VL_attention_linear_output_loss: 1.7909 - val_VH_attention_linear_output_loss: 1.8350 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4570\n",
      "Epoch 1965/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5404 - VL_attention_linear_output_loss: 1.7456 - VH_attention_linear_output_loss: 1.7948 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4656 - val_loss: 3.6084 - val_VL_attention_linear_output_loss: 1.7848 - val_VH_attention_linear_output_loss: 1.8237 - val_VL_attention_linear_output_acc: 0.4781 - val_VH_attention_linear_output_acc: 0.4604\n",
      "Epoch 1966/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5783 - VL_attention_linear_output_loss: 1.7619 - VH_attention_linear_output_loss: 1.8164 - VL_attention_linear_output_acc: 0.4773 - VH_attention_linear_output_acc: 0.4577 - val_loss: 3.6409 - val_VL_attention_linear_output_loss: 1.7967 - val_VH_attention_linear_output_loss: 1.8442 - val_VL_attention_linear_output_acc: 0.4739 - val_VH_attention_linear_output_acc: 0.4539\n",
      "Epoch 1967/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5546 - VL_attention_linear_output_loss: 1.7578 - VH_attention_linear_output_loss: 1.7968 - VL_attention_linear_output_acc: 0.4800 - VH_attention_linear_output_acc: 0.4650 - val_loss: 3.6093 - val_VL_attention_linear_output_loss: 1.7881 - val_VH_attention_linear_output_loss: 1.8212 - val_VL_attention_linear_output_acc: 0.4812 - val_VH_attention_linear_output_acc: 0.4580\n",
      "Epoch 1968/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5448 - VL_attention_linear_output_loss: 1.7518 - VH_attention_linear_output_loss: 1.7930 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4660 - val_loss: 3.6142 - val_VL_attention_linear_output_loss: 1.7888 - val_VH_attention_linear_output_loss: 1.8254 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4612\n",
      "Epoch 1969/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5416 - VL_attention_linear_output_loss: 1.7436 - VH_attention_linear_output_loss: 1.7980 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4645 - val_loss: 3.6076 - val_VL_attention_linear_output_loss: 1.7847 - val_VH_attention_linear_output_loss: 1.8230 - val_VL_attention_linear_output_acc: 0.4784 - val_VH_attention_linear_output_acc: 0.4618\n",
      "Epoch 1970/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5579 - VL_attention_linear_output_loss: 1.7524 - VH_attention_linear_output_loss: 1.8055 - VL_attention_linear_output_acc: 0.4827 - VH_attention_linear_output_acc: 0.4617 - val_loss: 3.6076 - val_VL_attention_linear_output_loss: 1.7828 - val_VH_attention_linear_output_loss: 1.8248 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4611\n",
      "Epoch 1971/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5376 - VL_attention_linear_output_loss: 1.7434 - VH_attention_linear_output_loss: 1.7942 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4659 - val_loss: 3.6148 - val_VL_attention_linear_output_loss: 1.7813 - val_VH_attention_linear_output_loss: 1.8335 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4571\n",
      "Epoch 1972/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5643 - VL_attention_linear_output_loss: 1.7542 - VH_attention_linear_output_loss: 1.8101 - VL_attention_linear_output_acc: 0.4824 - VH_attention_linear_output_acc: 0.4590 - val_loss: 3.6064 - val_VL_attention_linear_output_loss: 1.7802 - val_VH_attention_linear_output_loss: 1.8262 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4571\n",
      "Epoch 1973/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5444 - VL_attention_linear_output_loss: 1.7392 - VH_attention_linear_output_loss: 1.8051 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4615 - val_loss: 3.6275 - val_VL_attention_linear_output_loss: 1.7952 - val_VH_attention_linear_output_loss: 1.8324 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4542\n",
      "Epoch 1974/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5543 - VL_attention_linear_output_loss: 1.7530 - VH_attention_linear_output_loss: 1.8013 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4629 - val_loss: 3.6518 - val_VL_attention_linear_output_loss: 1.8038 - val_VH_attention_linear_output_loss: 1.8480 - val_VL_attention_linear_output_acc: 0.4709 - val_VH_attention_linear_output_acc: 0.4504\n",
      "Epoch 1975/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5516 - VL_attention_linear_output_loss: 1.7524 - VH_attention_linear_output_loss: 1.7993 - VL_attention_linear_output_acc: 0.4827 - VH_attention_linear_output_acc: 0.4635 - val_loss: 3.6299 - val_VL_attention_linear_output_loss: 1.7870 - val_VH_attention_linear_output_loss: 1.8430 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4498\n",
      "Epoch 1976/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5501 - VL_attention_linear_output_loss: 1.7414 - VH_attention_linear_output_loss: 1.8087 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4598 - val_loss: 3.6105 - val_VL_attention_linear_output_loss: 1.7823 - val_VH_attention_linear_output_loss: 1.8282 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4599\n",
      "Epoch 1977/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5504 - VL_attention_linear_output_loss: 1.7552 - VH_attention_linear_output_loss: 1.7952 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4655 - val_loss: 3.6203 - val_VL_attention_linear_output_loss: 1.7884 - val_VH_attention_linear_output_loss: 1.8320 - val_VL_attention_linear_output_acc: 0.4805 - val_VH_attention_linear_output_acc: 0.4557\n",
      "Epoch 1978/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5616 - VL_attention_linear_output_loss: 1.7533 - VH_attention_linear_output_loss: 1.8083 - VL_attention_linear_output_acc: 0.4820 - VH_attention_linear_output_acc: 0.4595 - val_loss: 3.6322 - val_VL_attention_linear_output_loss: 1.7972 - val_VH_attention_linear_output_loss: 1.8350 - val_VL_attention_linear_output_acc: 0.4780 - val_VH_attention_linear_output_acc: 0.4586\n",
      "Epoch 1979/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5620 - VL_attention_linear_output_loss: 1.7541 - VH_attention_linear_output_loss: 1.8080 - VL_attention_linear_output_acc: 0.4823 - VH_attention_linear_output_acc: 0.4601 - val_loss: 3.6412 - val_VL_attention_linear_output_loss: 1.7906 - val_VH_attention_linear_output_loss: 1.8506 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4478\n",
      "Epoch 1980/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5502 - VL_attention_linear_output_loss: 1.7403 - VH_attention_linear_output_loss: 1.8099 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4602 - val_loss: 3.6442 - val_VL_attention_linear_output_loss: 1.7941 - val_VH_attention_linear_output_loss: 1.8501 - val_VL_attention_linear_output_acc: 0.4744 - val_VH_attention_linear_output_acc: 0.4517\n",
      "Epoch 1981/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5688 - VL_attention_linear_output_loss: 1.7575 - VH_attention_linear_output_loss: 1.8113 - VL_attention_linear_output_acc: 0.4806 - VH_attention_linear_output_acc: 0.4598 - val_loss: 3.6452 - val_VL_attention_linear_output_loss: 1.7944 - val_VH_attention_linear_output_loss: 1.8508 - val_VL_attention_linear_output_acc: 0.4766 - val_VH_attention_linear_output_acc: 0.4465\n",
      "Epoch 1982/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5489 - VL_attention_linear_output_loss: 1.7466 - VH_attention_linear_output_loss: 1.8022 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4627 - val_loss: 3.6336 - val_VL_attention_linear_output_loss: 1.7881 - val_VH_attention_linear_output_loss: 1.8455 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4528\n",
      "Epoch 1983/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5537 - VL_attention_linear_output_loss: 1.7507 - VH_attention_linear_output_loss: 1.8030 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4628 - val_loss: 3.6163 - val_VL_attention_linear_output_loss: 1.7877 - val_VH_attention_linear_output_loss: 1.8286 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.4588\n",
      "Epoch 1984/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5507 - VL_attention_linear_output_loss: 1.7434 - VH_attention_linear_output_loss: 1.8073 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4611 - val_loss: 3.6121 - val_VL_attention_linear_output_loss: 1.7842 - val_VH_attention_linear_output_loss: 1.8279 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4569\n",
      "Epoch 1985/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5590 - VL_attention_linear_output_loss: 1.7490 - VH_attention_linear_output_loss: 1.8100 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4601 - val_loss: 3.6241 - val_VL_attention_linear_output_loss: 1.7940 - val_VH_attention_linear_output_loss: 1.8301 - val_VL_attention_linear_output_acc: 0.4764 - val_VH_attention_linear_output_acc: 0.4573\n",
      "Epoch 1986/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5564 - VL_attention_linear_output_loss: 1.7535 - VH_attention_linear_output_loss: 1.8029 - VL_attention_linear_output_acc: 0.4827 - VH_attention_linear_output_acc: 0.4627 - val_loss: 3.6447 - val_VL_attention_linear_output_loss: 1.7820 - val_VH_attention_linear_output_loss: 1.8627 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4422\n",
      "Epoch 1987/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5558 - VL_attention_linear_output_loss: 1.7392 - VH_attention_linear_output_loss: 1.8166 - VL_attention_linear_output_acc: 0.4894 - VH_attention_linear_output_acc: 0.4583 - val_loss: 3.6323 - val_VL_attention_linear_output_loss: 1.7888 - val_VH_attention_linear_output_loss: 1.8436 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4537\n",
      "Epoch 1988/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5639 - VL_attention_linear_output_loss: 1.7486 - VH_attention_linear_output_loss: 1.8154 - VL_attention_linear_output_acc: 0.4828 - VH_attention_linear_output_acc: 0.4577 - val_loss: 3.6359 - val_VL_attention_linear_output_loss: 1.8057 - val_VH_attention_linear_output_loss: 1.8302 - val_VL_attention_linear_output_acc: 0.4716 - val_VH_attention_linear_output_acc: 0.4590\n",
      "Epoch 1989/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5384 - VL_attention_linear_output_loss: 1.7448 - VH_attention_linear_output_loss: 1.7936 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4659 - val_loss: 3.6926 - val_VL_attention_linear_output_loss: 1.8264 - val_VH_attention_linear_output_loss: 1.8662 - val_VL_attention_linear_output_acc: 0.4570 - val_VH_attention_linear_output_acc: 0.4377\n",
      "Epoch 1990/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5699 - VL_attention_linear_output_loss: 1.7606 - VH_attention_linear_output_loss: 1.8094 - VL_attention_linear_output_acc: 0.4781 - VH_attention_linear_output_acc: 0.4597 - val_loss: 3.6202 - val_VL_attention_linear_output_loss: 1.7958 - val_VH_attention_linear_output_loss: 1.8244 - val_VL_attention_linear_output_acc: 0.4773 - val_VH_attention_linear_output_acc: 0.4601\n",
      "Epoch 1991/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5353 - VL_attention_linear_output_loss: 1.7411 - VH_attention_linear_output_loss: 1.7942 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4656 - val_loss: 3.6092 - val_VL_attention_linear_output_loss: 1.7854 - val_VH_attention_linear_output_loss: 1.8237 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4596\n",
      "Epoch 1992/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5370 - VL_attention_linear_output_loss: 1.7405 - VH_attention_linear_output_loss: 1.7965 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4650 - val_loss: 3.6099 - val_VL_attention_linear_output_loss: 1.7891 - val_VH_attention_linear_output_loss: 1.8208 - val_VL_attention_linear_output_acc: 0.4812 - val_VH_attention_linear_output_acc: 0.4616\n",
      "Epoch 1993/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5322 - VL_attention_linear_output_loss: 1.7387 - VH_attention_linear_output_loss: 1.7935 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4663 - val_loss: 3.6268 - val_VL_attention_linear_output_loss: 1.7873 - val_VH_attention_linear_output_loss: 1.8395 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4551\n",
      "Epoch 1994/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5542 - VL_attention_linear_output_loss: 1.7482 - VH_attention_linear_output_loss: 1.8061 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4611 - val_loss: 3.6329 - val_VL_attention_linear_output_loss: 1.8045 - val_VH_attention_linear_output_loss: 1.8284 - val_VL_attention_linear_output_acc: 0.4707 - val_VH_attention_linear_output_acc: 0.4562\n",
      "Epoch 1995/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5441 - VL_attention_linear_output_loss: 1.7462 - VH_attention_linear_output_loss: 1.7979 - VL_attention_linear_output_acc: 0.4869 - VH_attention_linear_output_acc: 0.4648 - val_loss: 3.6429 - val_VL_attention_linear_output_loss: 1.8150 - val_VH_attention_linear_output_loss: 1.8279 - val_VL_attention_linear_output_acc: 0.4653 - val_VH_attention_linear_output_acc: 0.4556\n",
      "Epoch 1996/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5612 - VL_attention_linear_output_loss: 1.7640 - VH_attention_linear_output_loss: 1.7972 - VL_attention_linear_output_acc: 0.4770 - VH_attention_linear_output_acc: 0.4645 - val_loss: 3.6115 - val_VL_attention_linear_output_loss: 1.7869 - val_VH_attention_linear_output_loss: 1.8247 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4603\n",
      "Epoch 1997/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5358 - VL_attention_linear_output_loss: 1.7383 - VH_attention_linear_output_loss: 1.7975 - VL_attention_linear_output_acc: 0.4894 - VH_attention_linear_output_acc: 0.4648 - val_loss: 3.6255 - val_VL_attention_linear_output_loss: 1.7799 - val_VH_attention_linear_output_loss: 1.8455 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4527\n",
      "Epoch 1998/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5507 - VL_attention_linear_output_loss: 1.7450 - VH_attention_linear_output_loss: 1.8057 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4606 - val_loss: 3.6252 - val_VL_attention_linear_output_loss: 1.7817 - val_VH_attention_linear_output_loss: 1.8435 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4546\n",
      "Epoch 1999/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5388 - VL_attention_linear_output_loss: 1.7419 - VH_attention_linear_output_loss: 1.7969 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4643 - val_loss: 3.6255 - val_VL_attention_linear_output_loss: 1.7835 - val_VH_attention_linear_output_loss: 1.8421 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4514\n",
      "Epoch 2000/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5457 - VL_attention_linear_output_loss: 1.7491 - VH_attention_linear_output_loss: 1.7966 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4643 - val_loss: 3.6264 - val_VL_attention_linear_output_loss: 1.7968 - val_VH_attention_linear_output_loss: 1.8296 - val_VL_attention_linear_output_acc: 0.4758 - val_VH_attention_linear_output_acc: 0.4581\n",
      "Epoch 2001/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5525 - VL_attention_linear_output_loss: 1.7560 - VH_attention_linear_output_loss: 1.7966 - VL_attention_linear_output_acc: 0.4815 - VH_attention_linear_output_acc: 0.4645 - val_loss: 3.6074 - val_VL_attention_linear_output_loss: 1.7806 - val_VH_attention_linear_output_loss: 1.8268 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4576\n",
      "Epoch 2002/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5609 - VL_attention_linear_output_loss: 1.7559 - VH_attention_linear_output_loss: 1.8050 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4614 - val_loss: 3.6378 - val_VL_attention_linear_output_loss: 1.7820 - val_VH_attention_linear_output_loss: 1.8558 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4432\n",
      "Epoch 2003/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5394 - VL_attention_linear_output_loss: 1.7379 - VH_attention_linear_output_loss: 1.8016 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4629 - val_loss: 3.6349 - val_VL_attention_linear_output_loss: 1.7914 - val_VH_attention_linear_output_loss: 1.8436 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4498\n",
      "Epoch 2004/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5632 - VL_attention_linear_output_loss: 1.7507 - VH_attention_linear_output_loss: 1.8125 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4603 - val_loss: 3.6192 - val_VL_attention_linear_output_loss: 1.7903 - val_VH_attention_linear_output_loss: 1.8289 - val_VL_attention_linear_output_acc: 0.4748 - val_VH_attention_linear_output_acc: 0.4598\n",
      "Epoch 2005/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5392 - VL_attention_linear_output_loss: 1.7393 - VH_attention_linear_output_loss: 1.7999 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4628 - val_loss: 3.6212 - val_VL_attention_linear_output_loss: 1.7840 - val_VH_attention_linear_output_loss: 1.8372 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4571\n",
      "Epoch 2006/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5490 - VL_attention_linear_output_loss: 1.7417 - VH_attention_linear_output_loss: 1.8073 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4599 - val_loss: 3.6131 - val_VL_attention_linear_output_loss: 1.7890 - val_VH_attention_linear_output_loss: 1.8240 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4621\n",
      "Epoch 2007/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5418 - VL_attention_linear_output_loss: 1.7455 - VH_attention_linear_output_loss: 1.7963 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4642 - val_loss: 3.6399 - val_VL_attention_linear_output_loss: 1.8068 - val_VH_attention_linear_output_loss: 1.8332 - val_VL_attention_linear_output_acc: 0.4620 - val_VH_attention_linear_output_acc: 0.4554\n",
      "Epoch 2008/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5500 - VL_attention_linear_output_loss: 1.7496 - VH_attention_linear_output_loss: 1.8003 - VL_attention_linear_output_acc: 0.4838 - VH_attention_linear_output_acc: 0.4632 - val_loss: 3.6152 - val_VL_attention_linear_output_loss: 1.7820 - val_VH_attention_linear_output_loss: 1.8332 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4584\n",
      "Epoch 2009/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5326 - VL_attention_linear_output_loss: 1.7374 - VH_attention_linear_output_loss: 1.7952 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4655 - val_loss: 3.6194 - val_VL_attention_linear_output_loss: 1.7889 - val_VH_attention_linear_output_loss: 1.8304 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4570\n",
      "Epoch 2010/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5421 - VL_attention_linear_output_loss: 1.7446 - VH_attention_linear_output_loss: 1.7976 - VL_attention_linear_output_acc: 0.4860 - VH_attention_linear_output_acc: 0.4638 - val_loss: 3.6083 - val_VL_attention_linear_output_loss: 1.7857 - val_VH_attention_linear_output_loss: 1.8226 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4600\n",
      "Epoch 2011/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5372 - VL_attention_linear_output_loss: 1.7471 - VH_attention_linear_output_loss: 1.7901 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4672 - val_loss: 3.6302 - val_VL_attention_linear_output_loss: 1.7958 - val_VH_attention_linear_output_loss: 1.8344 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.4532\n",
      "Epoch 2012/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5562 - VL_attention_linear_output_loss: 1.7509 - VH_attention_linear_output_loss: 1.8053 - VL_attention_linear_output_acc: 0.4826 - VH_attention_linear_output_acc: 0.4607 - val_loss: 3.6222 - val_VL_attention_linear_output_loss: 1.7899 - val_VH_attention_linear_output_loss: 1.8323 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.4555\n",
      "Epoch 2013/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5417 - VL_attention_linear_output_loss: 1.7455 - VH_attention_linear_output_loss: 1.7962 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4648 - val_loss: 3.6483 - val_VL_attention_linear_output_loss: 1.8134 - val_VH_attention_linear_output_loss: 1.8349 - val_VL_attention_linear_output_acc: 0.4672 - val_VH_attention_linear_output_acc: 0.4516\n",
      "Epoch 2014/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5517 - VL_attention_linear_output_loss: 1.7449 - VH_attention_linear_output_loss: 1.8067 - VL_attention_linear_output_acc: 0.4852 - VH_attention_linear_output_acc: 0.4595 - val_loss: 3.6177 - val_VL_attention_linear_output_loss: 1.7927 - val_VH_attention_linear_output_loss: 1.8250 - val_VL_attention_linear_output_acc: 0.4778 - val_VH_attention_linear_output_acc: 0.4594\n",
      "Epoch 2015/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5399 - VL_attention_linear_output_loss: 1.7407 - VH_attention_linear_output_loss: 1.7992 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4647 - val_loss: 3.6470 - val_VL_attention_linear_output_loss: 1.7866 - val_VH_attention_linear_output_loss: 1.8604 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4407\n",
      "Epoch 2016/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5505 - VL_attention_linear_output_loss: 1.7479 - VH_attention_linear_output_loss: 1.8026 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4625 - val_loss: 3.6336 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.8465 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4506\n",
      "Epoch 2017/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5569 - VL_attention_linear_output_loss: 1.7544 - VH_attention_linear_output_loss: 1.8025 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4624 - val_loss: 3.6137 - val_VL_attention_linear_output_loss: 1.7871 - val_VH_attention_linear_output_loss: 1.8267 - val_VL_attention_linear_output_acc: 0.4750 - val_VH_attention_linear_output_acc: 0.4578\n",
      "Epoch 2018/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5440 - VL_attention_linear_output_loss: 1.7441 - VH_attention_linear_output_loss: 1.7999 - VL_attention_linear_output_acc: 0.4864 - VH_attention_linear_output_acc: 0.4638 - val_loss: 3.6186 - val_VL_attention_linear_output_loss: 1.7821 - val_VH_attention_linear_output_loss: 1.8365 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4564\n",
      "Epoch 2019/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5483 - VL_attention_linear_output_loss: 1.7472 - VH_attention_linear_output_loss: 1.8011 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4648 - val_loss: 3.6247 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.8375 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4553\n",
      "Epoch 2020/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5484 - VL_attention_linear_output_loss: 1.7552 - VH_attention_linear_output_loss: 1.7931 - VL_attention_linear_output_acc: 0.4823 - VH_attention_linear_output_acc: 0.4663 - val_loss: 3.6591 - val_VL_attention_linear_output_loss: 1.8263 - val_VH_attention_linear_output_loss: 1.8328 - val_VL_attention_linear_output_acc: 0.4581 - val_VH_attention_linear_output_acc: 0.4555\n",
      "Epoch 2021/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5419 - VL_attention_linear_output_loss: 1.7454 - VH_attention_linear_output_loss: 1.7964 - VL_attention_linear_output_acc: 0.4864 - VH_attention_linear_output_acc: 0.4654 - val_loss: 3.6166 - val_VL_attention_linear_output_loss: 1.7902 - val_VH_attention_linear_output_loss: 1.8264 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4605\n",
      "Epoch 2022/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5384 - VL_attention_linear_output_loss: 1.7439 - VH_attention_linear_output_loss: 1.7944 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4650 - val_loss: 3.6385 - val_VL_attention_linear_output_loss: 1.8056 - val_VH_attention_linear_output_loss: 1.8329 - val_VL_attention_linear_output_acc: 0.4628 - val_VH_attention_linear_output_acc: 0.4574\n",
      "Epoch 2023/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5496 - VL_attention_linear_output_loss: 1.7498 - VH_attention_linear_output_loss: 1.7998 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4631 - val_loss: 3.6332 - val_VL_attention_linear_output_loss: 1.8086 - val_VH_attention_linear_output_loss: 1.8246 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.4595\n",
      "Epoch 2024/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5254 - VL_attention_linear_output_loss: 1.7381 - VH_attention_linear_output_loss: 1.7873 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4685 - val_loss: 3.6161 - val_VL_attention_linear_output_loss: 1.7915 - val_VH_attention_linear_output_loss: 1.8247 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4598\n",
      "Epoch 2025/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5403 - VL_attention_linear_output_loss: 1.7448 - VH_attention_linear_output_loss: 1.7954 - VL_attention_linear_output_acc: 0.4861 - VH_attention_linear_output_acc: 0.4647 - val_loss: 3.6226 - val_VL_attention_linear_output_loss: 1.7920 - val_VH_attention_linear_output_loss: 1.8306 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4603\n",
      "Epoch 2026/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5401 - VL_attention_linear_output_loss: 1.7461 - VH_attention_linear_output_loss: 1.7940 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4657 - val_loss: 3.6069 - val_VL_attention_linear_output_loss: 1.7800 - val_VH_attention_linear_output_loss: 1.8270 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4579\n",
      "Epoch 2027/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5399 - VL_attention_linear_output_loss: 1.7497 - VH_attention_linear_output_loss: 1.7902 - VL_attention_linear_output_acc: 0.4837 - VH_attention_linear_output_acc: 0.4673 - val_loss: 3.6522 - val_VL_attention_linear_output_loss: 1.7825 - val_VH_attention_linear_output_loss: 1.8697 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4456\n",
      "Epoch 2028/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5565 - VL_attention_linear_output_loss: 1.7483 - VH_attention_linear_output_loss: 1.8082 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4611 - val_loss: 3.6507 - val_VL_attention_linear_output_loss: 1.7867 - val_VH_attention_linear_output_loss: 1.8640 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4406\n",
      "Epoch 2029/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5342 - VL_attention_linear_output_loss: 1.7412 - VH_attention_linear_output_loss: 1.7930 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4661 - val_loss: 3.6114 - val_VL_attention_linear_output_loss: 1.7775 - val_VH_attention_linear_output_loss: 1.8338 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4550\n",
      "Epoch 2030/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5403 - VL_attention_linear_output_loss: 1.7378 - VH_attention_linear_output_loss: 1.8024 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4618 - val_loss: 3.6070 - val_VL_attention_linear_output_loss: 1.7812 - val_VH_attention_linear_output_loss: 1.8259 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4566\n",
      "Epoch 2031/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5318 - VL_attention_linear_output_loss: 1.7418 - VH_attention_linear_output_loss: 1.7900 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4669 - val_loss: 3.6314 - val_VL_attention_linear_output_loss: 1.7862 - val_VH_attention_linear_output_loss: 1.8453 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4542\n",
      "Epoch 2032/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5486 - VL_attention_linear_output_loss: 1.7548 - VH_attention_linear_output_loss: 1.7937 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4651 - val_loss: 3.6055 - val_VL_attention_linear_output_loss: 1.7848 - val_VH_attention_linear_output_loss: 1.8207 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4589\n",
      "Epoch 2033/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5341 - VL_attention_linear_output_loss: 1.7444 - VH_attention_linear_output_loss: 1.7896 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4671 - val_loss: 3.6506 - val_VL_attention_linear_output_loss: 1.7916 - val_VH_attention_linear_output_loss: 1.8590 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4443\n",
      "Epoch 2034/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5386 - VL_attention_linear_output_loss: 1.7418 - VH_attention_linear_output_loss: 1.7968 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4640 - val_loss: 3.6248 - val_VL_attention_linear_output_loss: 1.8032 - val_VH_attention_linear_output_loss: 1.8216 - val_VL_attention_linear_output_acc: 0.4707 - val_VH_attention_linear_output_acc: 0.4624\n",
      "Epoch 2035/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5439 - VL_attention_linear_output_loss: 1.7475 - VH_attention_linear_output_loss: 1.7964 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4650 - val_loss: 3.6326 - val_VL_attention_linear_output_loss: 1.8005 - val_VH_attention_linear_output_loss: 1.8322 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.4560\n",
      "Epoch 2036/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5473 - VL_attention_linear_output_loss: 1.7474 - VH_attention_linear_output_loss: 1.7999 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4634 - val_loss: 3.6126 - val_VL_attention_linear_output_loss: 1.7850 - val_VH_attention_linear_output_loss: 1.8276 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4571\n",
      "Epoch 2037/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5429 - VL_attention_linear_output_loss: 1.7530 - VH_attention_linear_output_loss: 1.7899 - VL_attention_linear_output_acc: 0.4812 - VH_attention_linear_output_acc: 0.4674 - val_loss: 3.6037 - val_VL_attention_linear_output_loss: 1.7812 - val_VH_attention_linear_output_loss: 1.8225 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4595\n",
      "Epoch 2038/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5418 - VL_attention_linear_output_loss: 1.7565 - VH_attention_linear_output_loss: 1.7853 - VL_attention_linear_output_acc: 0.4796 - VH_attention_linear_output_acc: 0.4689 - val_loss: 3.6680 - val_VL_attention_linear_output_loss: 1.8495 - val_VH_attention_linear_output_loss: 1.8184 - val_VL_attention_linear_output_acc: 0.4503 - val_VH_attention_linear_output_acc: 0.4623\n",
      "Epoch 2039/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5325 - VL_attention_linear_output_loss: 1.7394 - VH_attention_linear_output_loss: 1.7931 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4652 - val_loss: 3.6752 - val_VL_attention_linear_output_loss: 1.8371 - val_VH_attention_linear_output_loss: 1.8380 - val_VL_attention_linear_output_acc: 0.4553 - val_VH_attention_linear_output_acc: 0.4541\n",
      "Epoch 2040/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5590 - VL_attention_linear_output_loss: 1.7595 - VH_attention_linear_output_loss: 1.7995 - VL_attention_linear_output_acc: 0.4791 - VH_attention_linear_output_acc: 0.4632 - val_loss: 3.6717 - val_VL_attention_linear_output_loss: 1.7902 - val_VH_attention_linear_output_loss: 1.8815 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4350\n",
      "Epoch 2041/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5358 - VL_attention_linear_output_loss: 1.7432 - VH_attention_linear_output_loss: 1.7926 - VL_attention_linear_output_acc: 0.4880 - VH_attention_linear_output_acc: 0.4664 - val_loss: 3.6003 - val_VL_attention_linear_output_loss: 1.7809 - val_VH_attention_linear_output_loss: 1.8193 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4616\n",
      "Epoch 2042/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5387 - VL_attention_linear_output_loss: 1.7441 - VH_attention_linear_output_loss: 1.7946 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4653 - val_loss: 3.6107 - val_VL_attention_linear_output_loss: 1.7934 - val_VH_attention_linear_output_loss: 1.8173 - val_VL_attention_linear_output_acc: 0.4736 - val_VH_attention_linear_output_acc: 0.4623\n",
      "Epoch 2043/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5359 - VL_attention_linear_output_loss: 1.7487 - VH_attention_linear_output_loss: 1.7872 - VL_attention_linear_output_acc: 0.4851 - VH_attention_linear_output_acc: 0.4679 - val_loss: 3.6109 - val_VL_attention_linear_output_loss: 1.7897 - val_VH_attention_linear_output_loss: 1.8213 - val_VL_attention_linear_output_acc: 0.4780 - val_VH_attention_linear_output_acc: 0.4610\n",
      "Epoch 2044/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5516 - VL_attention_linear_output_loss: 1.7429 - VH_attention_linear_output_loss: 1.8088 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4594 - val_loss: 3.6173 - val_VL_attention_linear_output_loss: 1.7867 - val_VH_attention_linear_output_loss: 1.8306 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4578\n",
      "Epoch 2045/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5574 - VL_attention_linear_output_loss: 1.7471 - VH_attention_linear_output_loss: 1.8102 - VL_attention_linear_output_acc: 0.4858 - VH_attention_linear_output_acc: 0.4597 - val_loss: 3.6338 - val_VL_attention_linear_output_loss: 1.8053 - val_VH_attention_linear_output_loss: 1.8284 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4562\n",
      "Epoch 2046/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5359 - VL_attention_linear_output_loss: 1.7493 - VH_attention_linear_output_loss: 1.7866 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4689 - val_loss: 3.6081 - val_VL_attention_linear_output_loss: 1.7812 - val_VH_attention_linear_output_loss: 1.8269 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4585\n",
      "Epoch 2047/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5469 - VL_attention_linear_output_loss: 1.7471 - VH_attention_linear_output_loss: 1.7998 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4629 - val_loss: 3.6170 - val_VL_attention_linear_output_loss: 1.7804 - val_VH_attention_linear_output_loss: 1.8366 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4556\n",
      "Epoch 2048/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5468 - VL_attention_linear_output_loss: 1.7462 - VH_attention_linear_output_loss: 1.8006 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4630 - val_loss: 3.6104 - val_VL_attention_linear_output_loss: 1.7928 - val_VH_attention_linear_output_loss: 1.8176 - val_VL_attention_linear_output_acc: 0.4795 - val_VH_attention_linear_output_acc: 0.4609\n",
      "Epoch 2049/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5423 - VL_attention_linear_output_loss: 1.7528 - VH_attention_linear_output_loss: 1.7894 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4679 - val_loss: 3.6064 - val_VL_attention_linear_output_loss: 1.7825 - val_VH_attention_linear_output_loss: 1.8239 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4617\n",
      "Epoch 2050/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5381 - VL_attention_linear_output_loss: 1.7410 - VH_attention_linear_output_loss: 1.7971 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4645 - val_loss: 3.6043 - val_VL_attention_linear_output_loss: 1.7813 - val_VH_attention_linear_output_loss: 1.8229 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.4580\n",
      "Epoch 2051/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5400 - VL_attention_linear_output_loss: 1.7453 - VH_attention_linear_output_loss: 1.7947 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4654 - val_loss: 3.6292 - val_VL_attention_linear_output_loss: 1.8016 - val_VH_attention_linear_output_loss: 1.8275 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.4577\n",
      "Epoch 2052/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5427 - VL_attention_linear_output_loss: 1.7480 - VH_attention_linear_output_loss: 1.7947 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4658 - val_loss: 3.6036 - val_VL_attention_linear_output_loss: 1.7820 - val_VH_attention_linear_output_loss: 1.8216 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4596\n",
      "Epoch 2053/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5250 - VL_attention_linear_output_loss: 1.7345 - VH_attention_linear_output_loss: 1.7905 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4668 - val_loss: 3.6612 - val_VL_attention_linear_output_loss: 1.7819 - val_VH_attention_linear_output_loss: 1.8793 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4283\n",
      "Epoch 2054/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5345 - VL_attention_linear_output_loss: 1.7372 - VH_attention_linear_output_loss: 1.7974 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4643 - val_loss: 3.5950 - val_VL_attention_linear_output_loss: 1.7805 - val_VH_attention_linear_output_loss: 1.8145 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4632\n",
      "Epoch 2055/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5384 - VL_attention_linear_output_loss: 1.7418 - VH_attention_linear_output_loss: 1.7967 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4650 - val_loss: 3.6412 - val_VL_attention_linear_output_loss: 1.8129 - val_VH_attention_linear_output_loss: 1.8283 - val_VL_attention_linear_output_acc: 0.4682 - val_VH_attention_linear_output_acc: 0.4569\n",
      "Epoch 2056/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5341 - VL_attention_linear_output_loss: 1.7462 - VH_attention_linear_output_loss: 1.7879 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4682 - val_loss: 3.6792 - val_VL_attention_linear_output_loss: 1.8473 - val_VH_attention_linear_output_loss: 1.8319 - val_VL_attention_linear_output_acc: 0.4497 - val_VH_attention_linear_output_acc: 0.4533\n",
      "Epoch 2057/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5417 - VL_attention_linear_output_loss: 1.7483 - VH_attention_linear_output_loss: 1.7934 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4656 - val_loss: 3.6023 - val_VL_attention_linear_output_loss: 1.7812 - val_VH_attention_linear_output_loss: 1.8211 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4582\n",
      "Epoch 2058/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5384 - VL_attention_linear_output_loss: 1.7415 - VH_attention_linear_output_loss: 1.7969 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4640 - val_loss: 3.6160 - val_VL_attention_linear_output_loss: 1.7861 - val_VH_attention_linear_output_loss: 1.8299 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4551\n",
      "Epoch 2059/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5397 - VL_attention_linear_output_loss: 1.7501 - VH_attention_linear_output_loss: 1.7896 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4673 - val_loss: 3.6276 - val_VL_attention_linear_output_loss: 1.7955 - val_VH_attention_linear_output_loss: 1.8321 - val_VL_attention_linear_output_acc: 0.4649 - val_VH_attention_linear_output_acc: 0.4562\n",
      "Epoch 2060/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5402 - VL_attention_linear_output_loss: 1.7454 - VH_attention_linear_output_loss: 1.7947 - VL_attention_linear_output_acc: 0.4861 - VH_attention_linear_output_acc: 0.4649 - val_loss: 3.6191 - val_VL_attention_linear_output_loss: 1.7825 - val_VH_attention_linear_output_loss: 1.8366 - val_VL_attention_linear_output_acc: 0.4867 - val_VH_attention_linear_output_acc: 0.4550\n",
      "Epoch 2061/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5284 - VL_attention_linear_output_loss: 1.7376 - VH_attention_linear_output_loss: 1.7909 - VL_attention_linear_output_acc: 0.4893 - VH_attention_linear_output_acc: 0.4660 - val_loss: 3.6849 - val_VL_attention_linear_output_loss: 1.7844 - val_VH_attention_linear_output_loss: 1.9005 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4290\n",
      "Epoch 2062/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5422 - VL_attention_linear_output_loss: 1.7412 - VH_attention_linear_output_loss: 1.8009 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4630 - val_loss: 3.6261 - val_VL_attention_linear_output_loss: 1.7871 - val_VH_attention_linear_output_loss: 1.8390 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4508\n",
      "Epoch 2063/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5346 - VL_attention_linear_output_loss: 1.7393 - VH_attention_linear_output_loss: 1.7953 - VL_attention_linear_output_acc: 0.4881 - VH_attention_linear_output_acc: 0.4651 - val_loss: 3.6541 - val_VL_attention_linear_output_loss: 1.7811 - val_VH_attention_linear_output_loss: 1.8730 - val_VL_attention_linear_output_acc: 0.4748 - val_VH_attention_linear_output_acc: 0.4389\n",
      "Epoch 2064/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5370 - VL_attention_linear_output_loss: 1.7450 - VH_attention_linear_output_loss: 1.7920 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4659 - val_loss: 3.5971 - val_VL_attention_linear_output_loss: 1.7850 - val_VH_attention_linear_output_loss: 1.8121 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4630\n",
      "Epoch 2065/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5444 - VL_attention_linear_output_loss: 1.7498 - VH_attention_linear_output_loss: 1.7946 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4648 - val_loss: 3.6487 - val_VL_attention_linear_output_loss: 1.8044 - val_VH_attention_linear_output_loss: 1.8444 - val_VL_attention_linear_output_acc: 0.4705 - val_VH_attention_linear_output_acc: 0.4508\n",
      "Epoch 2066/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5499 - VL_attention_linear_output_loss: 1.7550 - VH_attention_linear_output_loss: 1.7949 - VL_attention_linear_output_acc: 0.4797 - VH_attention_linear_output_acc: 0.4654 - val_loss: 3.6679 - val_VL_attention_linear_output_loss: 1.8424 - val_VH_attention_linear_output_loss: 1.8255 - val_VL_attention_linear_output_acc: 0.4513 - val_VH_attention_linear_output_acc: 0.4562\n",
      "Epoch 2067/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5377 - VL_attention_linear_output_loss: 1.7433 - VH_attention_linear_output_loss: 1.7944 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4655 - val_loss: 3.6254 - val_VL_attention_linear_output_loss: 1.7804 - val_VH_attention_linear_output_loss: 1.8449 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4479\n",
      "Epoch 2068/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5425 - VL_attention_linear_output_loss: 1.7481 - VH_attention_linear_output_loss: 1.7944 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4647 - val_loss: 3.6396 - val_VL_attention_linear_output_loss: 1.7931 - val_VH_attention_linear_output_loss: 1.8465 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4510\n",
      "Epoch 2069/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5337 - VL_attention_linear_output_loss: 1.7409 - VH_attention_linear_output_loss: 1.7927 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4654 - val_loss: 3.6147 - val_VL_attention_linear_output_loss: 1.7988 - val_VH_attention_linear_output_loss: 1.8159 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4626\n",
      "Epoch 2070/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5372 - VL_attention_linear_output_loss: 1.7437 - VH_attention_linear_output_loss: 1.7935 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4658 - val_loss: 3.6118 - val_VL_attention_linear_output_loss: 1.7880 - val_VH_attention_linear_output_loss: 1.8237 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4609\n",
      "Epoch 2071/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5382 - VL_attention_linear_output_loss: 1.7422 - VH_attention_linear_output_loss: 1.7960 - VL_attention_linear_output_acc: 0.4879 - VH_attention_linear_output_acc: 0.4641 - val_loss: 3.6307 - val_VL_attention_linear_output_loss: 1.7982 - val_VH_attention_linear_output_loss: 1.8325 - val_VL_attention_linear_output_acc: 0.4703 - val_VH_attention_linear_output_acc: 0.4589\n",
      "Epoch 2072/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5374 - VL_attention_linear_output_loss: 1.7433 - VH_attention_linear_output_loss: 1.7941 - VL_attention_linear_output_acc: 0.4858 - VH_attention_linear_output_acc: 0.4657 - val_loss: 3.6052 - val_VL_attention_linear_output_loss: 1.7873 - val_VH_attention_linear_output_loss: 1.8179 - val_VL_attention_linear_output_acc: 0.4816 - val_VH_attention_linear_output_acc: 0.4619\n",
      "Epoch 2073/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5432 - VL_attention_linear_output_loss: 1.7502 - VH_attention_linear_output_loss: 1.7930 - VL_attention_linear_output_acc: 0.4823 - VH_attention_linear_output_acc: 0.4657 - val_loss: 3.6020 - val_VL_attention_linear_output_loss: 1.7883 - val_VH_attention_linear_output_loss: 1.8138 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4618\n",
      "Epoch 2074/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5306 - VL_attention_linear_output_loss: 1.7438 - VH_attention_linear_output_loss: 1.7868 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4679 - val_loss: 3.6692 - val_VL_attention_linear_output_loss: 1.8463 - val_VH_attention_linear_output_loss: 1.8229 - val_VL_attention_linear_output_acc: 0.4483 - val_VH_attention_linear_output_acc: 0.4624\n",
      "Epoch 2075/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5390 - VL_attention_linear_output_loss: 1.7416 - VH_attention_linear_output_loss: 1.7974 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4633 - val_loss: 3.6078 - val_VL_attention_linear_output_loss: 1.7821 - val_VH_attention_linear_output_loss: 1.8257 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4568\n",
      "Epoch 2076/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5371 - VL_attention_linear_output_loss: 1.7481 - VH_attention_linear_output_loss: 1.7890 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4672 - val_loss: 3.5993 - val_VL_attention_linear_output_loss: 1.7822 - val_VH_attention_linear_output_loss: 1.8170 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4615\n",
      "Epoch 2077/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5214 - VL_attention_linear_output_loss: 1.7357 - VH_attention_linear_output_loss: 1.7857 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4683 - val_loss: 3.6460 - val_VL_attention_linear_output_loss: 1.7854 - val_VH_attention_linear_output_loss: 1.8607 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4382\n",
      "Epoch 2078/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5324 - VL_attention_linear_output_loss: 1.7361 - VH_attention_linear_output_loss: 1.7963 - VL_attention_linear_output_acc: 0.4893 - VH_attention_linear_output_acc: 0.4644 - val_loss: 3.6040 - val_VL_attention_linear_output_loss: 1.7855 - val_VH_attention_linear_output_loss: 1.8185 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4609\n",
      "Epoch 2079/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5285 - VL_attention_linear_output_loss: 1.7367 - VH_attention_linear_output_loss: 1.7918 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4662 - val_loss: 3.6022 - val_VL_attention_linear_output_loss: 1.7817 - val_VH_attention_linear_output_loss: 1.8206 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4602\n",
      "Epoch 2080/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5365 - VL_attention_linear_output_loss: 1.7455 - VH_attention_linear_output_loss: 1.7910 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4670 - val_loss: 3.6004 - val_VL_attention_linear_output_loss: 1.7821 - val_VH_attention_linear_output_loss: 1.8182 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4618\n",
      "Epoch 2081/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5298 - VL_attention_linear_output_loss: 1.7360 - VH_attention_linear_output_loss: 1.7938 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4654 - val_loss: 3.6159 - val_VL_attention_linear_output_loss: 1.7964 - val_VH_attention_linear_output_loss: 1.8194 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4605\n",
      "Epoch 2082/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5361 - VL_attention_linear_output_loss: 1.7454 - VH_attention_linear_output_loss: 1.7907 - VL_attention_linear_output_acc: 0.4848 - VH_attention_linear_output_acc: 0.4664 - val_loss: 3.6164 - val_VL_attention_linear_output_loss: 1.7853 - val_VH_attention_linear_output_loss: 1.8311 - val_VL_attention_linear_output_acc: 0.4828 - val_VH_attention_linear_output_acc: 0.4537\n",
      "Epoch 2083/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5324 - VL_attention_linear_output_loss: 1.7445 - VH_attention_linear_output_loss: 1.7879 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4681 - val_loss: 3.6143 - val_VL_attention_linear_output_loss: 1.7869 - val_VH_attention_linear_output_loss: 1.8275 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4588\n",
      "Epoch 2084/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5258 - VL_attention_linear_output_loss: 1.7387 - VH_attention_linear_output_loss: 1.7871 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4674 - val_loss: 3.5976 - val_VL_attention_linear_output_loss: 1.7808 - val_VH_attention_linear_output_loss: 1.8168 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4616\n",
      "Epoch 2085/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5202 - VL_attention_linear_output_loss: 1.7360 - VH_attention_linear_output_loss: 1.7842 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4691 - val_loss: 3.6135 - val_VL_attention_linear_output_loss: 1.7992 - val_VH_attention_linear_output_loss: 1.8142 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4639\n",
      "Epoch 2086/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5242 - VL_attention_linear_output_loss: 1.7395 - VH_attention_linear_output_loss: 1.7847 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4689 - val_loss: 3.6097 - val_VL_attention_linear_output_loss: 1.7923 - val_VH_attention_linear_output_loss: 1.8174 - val_VL_attention_linear_output_acc: 0.4769 - val_VH_attention_linear_output_acc: 0.4615\n",
      "Epoch 2087/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5388 - VL_attention_linear_output_loss: 1.7493 - VH_attention_linear_output_loss: 1.7894 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4671 - val_loss: 3.6196 - val_VL_attention_linear_output_loss: 1.7937 - val_VH_attention_linear_output_loss: 1.8259 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4574\n",
      "Epoch 2088/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5418 - VL_attention_linear_output_loss: 1.7457 - VH_attention_linear_output_loss: 1.7961 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4640 - val_loss: 3.6027 - val_VL_attention_linear_output_loss: 1.7842 - val_VH_attention_linear_output_loss: 1.8185 - val_VL_attention_linear_output_acc: 0.4718 - val_VH_attention_linear_output_acc: 0.4621\n",
      "Epoch 2089/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5336 - VL_attention_linear_output_loss: 1.7390 - VH_attention_linear_output_loss: 1.7946 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4646 - val_loss: 3.6117 - val_VL_attention_linear_output_loss: 1.7882 - val_VH_attention_linear_output_loss: 1.8235 - val_VL_attention_linear_output_acc: 0.4758 - val_VH_attention_linear_output_acc: 0.4585\n",
      "Epoch 2090/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5490 - VL_attention_linear_output_loss: 1.7558 - VH_attention_linear_output_loss: 1.7932 - VL_attention_linear_output_acc: 0.4797 - VH_attention_linear_output_acc: 0.4655 - val_loss: 3.6306 - val_VL_attention_linear_output_loss: 1.8079 - val_VH_attention_linear_output_loss: 1.8227 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.4632\n",
      "Epoch 2091/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5206 - VL_attention_linear_output_loss: 1.7376 - VH_attention_linear_output_loss: 1.7830 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4695 - val_loss: 3.6298 - val_VL_attention_linear_output_loss: 1.7967 - val_VH_attention_linear_output_loss: 1.8331 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4605\n",
      "Epoch 2092/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5255 - VL_attention_linear_output_loss: 1.7395 - VH_attention_linear_output_loss: 1.7860 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4685 - val_loss: 3.6463 - val_VL_attention_linear_output_loss: 1.7888 - val_VH_attention_linear_output_loss: 1.8575 - val_VL_attention_linear_output_acc: 0.4787 - val_VH_attention_linear_output_acc: 0.4490\n",
      "Epoch 2093/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5473 - VL_attention_linear_output_loss: 1.7463 - VH_attention_linear_output_loss: 1.8011 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4625 - val_loss: 3.6444 - val_VL_attention_linear_output_loss: 1.7957 - val_VH_attention_linear_output_loss: 1.8487 - val_VL_attention_linear_output_acc: 0.4658 - val_VH_attention_linear_output_acc: 0.4494\n",
      "Epoch 2094/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5262 - VL_attention_linear_output_loss: 1.7428 - VH_attention_linear_output_loss: 1.7834 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4696 - val_loss: 3.6093 - val_VL_attention_linear_output_loss: 1.7904 - val_VH_attention_linear_output_loss: 1.8189 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4625\n",
      "Epoch 2095/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5415 - VL_attention_linear_output_loss: 1.7443 - VH_attention_linear_output_loss: 1.7973 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4651 - val_loss: 3.6487 - val_VL_attention_linear_output_loss: 1.8137 - val_VH_attention_linear_output_loss: 1.8350 - val_VL_attention_linear_output_acc: 0.4485 - val_VH_attention_linear_output_acc: 0.4548\n",
      "Epoch 2096/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5213 - VL_attention_linear_output_loss: 1.7362 - VH_attention_linear_output_loss: 1.7852 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4697 - val_loss: 3.5958 - val_VL_attention_linear_output_loss: 1.7808 - val_VH_attention_linear_output_loss: 1.8149 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4619\n",
      "Epoch 2097/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5118 - VL_attention_linear_output_loss: 1.7337 - VH_attention_linear_output_loss: 1.7780 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4719 - val_loss: 3.6106 - val_VL_attention_linear_output_loss: 1.7832 - val_VH_attention_linear_output_loss: 1.8274 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4611\n",
      "Epoch 2098/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5259 - VL_attention_linear_output_loss: 1.7429 - VH_attention_linear_output_loss: 1.7831 - VL_attention_linear_output_acc: 0.4851 - VH_attention_linear_output_acc: 0.4699 - val_loss: 3.5937 - val_VL_attention_linear_output_loss: 1.7788 - val_VH_attention_linear_output_loss: 1.8149 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4633\n",
      "Epoch 2099/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5086 - VL_attention_linear_output_loss: 1.7304 - VH_attention_linear_output_loss: 1.7782 - VL_attention_linear_output_acc: 0.4932 - VH_attention_linear_output_acc: 0.4718 - val_loss: 3.6006 - val_VL_attention_linear_output_loss: 1.7803 - val_VH_attention_linear_output_loss: 1.8202 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4620\n",
      "Epoch 2100/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5202 - VL_attention_linear_output_loss: 1.7338 - VH_attention_linear_output_loss: 1.7864 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4681 - val_loss: 3.6090 - val_VL_attention_linear_output_loss: 1.7968 - val_VH_attention_linear_output_loss: 1.8122 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4639\n",
      "Epoch 2101/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5202 - VL_attention_linear_output_loss: 1.7402 - VH_attention_linear_output_loss: 1.7800 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4711 - val_loss: 3.6098 - val_VL_attention_linear_output_loss: 1.7988 - val_VH_attention_linear_output_loss: 1.8110 - val_VL_attention_linear_output_acc: 0.4740 - val_VH_attention_linear_output_acc: 0.4625\n",
      "Epoch 2102/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5217 - VL_attention_linear_output_loss: 1.7409 - VH_attention_linear_output_loss: 1.7808 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4698 - val_loss: 3.5953 - val_VL_attention_linear_output_loss: 1.7837 - val_VH_attention_linear_output_loss: 1.8116 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4623\n",
      "Epoch 2103/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5236 - VL_attention_linear_output_loss: 1.7398 - VH_attention_linear_output_loss: 1.7838 - VL_attention_linear_output_acc: 0.4863 - VH_attention_linear_output_acc: 0.4692 - val_loss: 3.6083 - val_VL_attention_linear_output_loss: 1.7863 - val_VH_attention_linear_output_loss: 1.8221 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4563\n",
      "Epoch 2104/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5194 - VL_attention_linear_output_loss: 1.7375 - VH_attention_linear_output_loss: 1.7819 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4697 - val_loss: 3.6011 - val_VL_attention_linear_output_loss: 1.7839 - val_VH_attention_linear_output_loss: 1.8172 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4628\n",
      "Epoch 2105/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5194 - VL_attention_linear_output_loss: 1.7363 - VH_attention_linear_output_loss: 1.7831 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4685 - val_loss: 3.6057 - val_VL_attention_linear_output_loss: 1.7930 - val_VH_attention_linear_output_loss: 1.8127 - val_VL_attention_linear_output_acc: 0.4787 - val_VH_attention_linear_output_acc: 0.4645\n",
      "Epoch 2106/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5173 - VL_attention_linear_output_loss: 1.7375 - VH_attention_linear_output_loss: 1.7798 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4703 - val_loss: 3.6535 - val_VL_attention_linear_output_loss: 1.7889 - val_VH_attention_linear_output_loss: 1.8646 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4441\n",
      "Epoch 2107/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5322 - VL_attention_linear_output_loss: 1.7413 - VH_attention_linear_output_loss: 1.7909 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4665 - val_loss: 3.6328 - val_VL_attention_linear_output_loss: 1.8018 - val_VH_attention_linear_output_loss: 1.8310 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.4583\n",
      "Epoch 2108/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5269 - VL_attention_linear_output_loss: 1.7459 - VH_attention_linear_output_loss: 1.7810 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4699 - val_loss: 3.6047 - val_VL_attention_linear_output_loss: 1.7931 - val_VH_attention_linear_output_loss: 1.8116 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4642\n",
      "Epoch 2109/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5227 - VL_attention_linear_output_loss: 1.7393 - VH_attention_linear_output_loss: 1.7835 - VL_attention_linear_output_acc: 0.4881 - VH_attention_linear_output_acc: 0.4688 - val_loss: 3.6214 - val_VL_attention_linear_output_loss: 1.7923 - val_VH_attention_linear_output_loss: 1.8291 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4575\n",
      "Epoch 2110/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5285 - VL_attention_linear_output_loss: 1.7408 - VH_attention_linear_output_loss: 1.7877 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4677 - val_loss: 3.6182 - val_VL_attention_linear_output_loss: 1.7948 - val_VH_attention_linear_output_loss: 1.8234 - val_VL_attention_linear_output_acc: 0.4766 - val_VH_attention_linear_output_acc: 0.4583\n",
      "Epoch 2111/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5359 - VL_attention_linear_output_loss: 1.7443 - VH_attention_linear_output_loss: 1.7916 - VL_attention_linear_output_acc: 0.4860 - VH_attention_linear_output_acc: 0.4656 - val_loss: 3.6019 - val_VL_attention_linear_output_loss: 1.7865 - val_VH_attention_linear_output_loss: 1.8154 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4637\n",
      "Epoch 2112/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5261 - VL_attention_linear_output_loss: 1.7364 - VH_attention_linear_output_loss: 1.7897 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4666 - val_loss: 3.6079 - val_VL_attention_linear_output_loss: 1.7908 - val_VH_attention_linear_output_loss: 1.8171 - val_VL_attention_linear_output_acc: 0.4804 - val_VH_attention_linear_output_acc: 0.4641\n",
      "Epoch 2113/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5192 - VL_attention_linear_output_loss: 1.7381 - VH_attention_linear_output_loss: 1.7811 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4706 - val_loss: 3.6064 - val_VL_attention_linear_output_loss: 1.7882 - val_VH_attention_linear_output_loss: 1.8183 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4612\n",
      "Epoch 2114/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5265 - VL_attention_linear_output_loss: 1.7426 - VH_attention_linear_output_loss: 1.7839 - VL_attention_linear_output_acc: 0.4858 - VH_attention_linear_output_acc: 0.4686 - val_loss: 3.6736 - val_VL_attention_linear_output_loss: 1.7853 - val_VH_attention_linear_output_loss: 1.8882 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4294\n",
      "Epoch 2115/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5310 - VL_attention_linear_output_loss: 1.7410 - VH_attention_linear_output_loss: 1.7900 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4658 - val_loss: 3.6714 - val_VL_attention_linear_output_loss: 1.8215 - val_VH_attention_linear_output_loss: 1.8499 - val_VL_attention_linear_output_acc: 0.4546 - val_VH_attention_linear_output_acc: 0.4519\n",
      "Epoch 2116/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5407 - VL_attention_linear_output_loss: 1.7422 - VH_attention_linear_output_loss: 1.7984 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4627 - val_loss: 3.6215 - val_VL_attention_linear_output_loss: 1.7961 - val_VH_attention_linear_output_loss: 1.8254 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4606\n",
      "Epoch 2117/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5357 - VL_attention_linear_output_loss: 1.7523 - VH_attention_linear_output_loss: 1.7834 - VL_attention_linear_output_acc: 0.4829 - VH_attention_linear_output_acc: 0.4686 - val_loss: 3.6300 - val_VL_attention_linear_output_loss: 1.8189 - val_VH_attention_linear_output_loss: 1.8112 - val_VL_attention_linear_output_acc: 0.4641 - val_VH_attention_linear_output_acc: 0.4646\n",
      "Epoch 2118/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5298 - VL_attention_linear_output_loss: 1.7395 - VH_attention_linear_output_loss: 1.7904 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4668 - val_loss: 3.6073 - val_VL_attention_linear_output_loss: 1.7896 - val_VH_attention_linear_output_loss: 1.8176 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4639\n",
      "Epoch 2119/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5282 - VL_attention_linear_output_loss: 1.7416 - VH_attention_linear_output_loss: 1.7866 - VL_attention_linear_output_acc: 0.4849 - VH_attention_linear_output_acc: 0.4682 - val_loss: 3.6286 - val_VL_attention_linear_output_loss: 1.7975 - val_VH_attention_linear_output_loss: 1.8312 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4562\n",
      "Epoch 2120/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5221 - VL_attention_linear_output_loss: 1.7372 - VH_attention_linear_output_loss: 1.7849 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4688 - val_loss: 3.6038 - val_VL_attention_linear_output_loss: 1.7804 - val_VH_attention_linear_output_loss: 1.8234 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4625\n",
      "Epoch 2121/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5269 - VL_attention_linear_output_loss: 1.7389 - VH_attention_linear_output_loss: 1.7880 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4673 - val_loss: 3.5996 - val_VL_attention_linear_output_loss: 1.7860 - val_VH_attention_linear_output_loss: 1.8137 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4620\n",
      "Epoch 2122/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5209 - VL_attention_linear_output_loss: 1.7396 - VH_attention_linear_output_loss: 1.7813 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4701 - val_loss: 3.6300 - val_VL_attention_linear_output_loss: 1.7852 - val_VH_attention_linear_output_loss: 1.8448 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4543\n",
      "Epoch 2123/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5206 - VL_attention_linear_output_loss: 1.7361 - VH_attention_linear_output_loss: 1.7845 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4686 - val_loss: 3.6452 - val_VL_attention_linear_output_loss: 1.8191 - val_VH_attention_linear_output_loss: 1.8261 - val_VL_attention_linear_output_acc: 0.4633 - val_VH_attention_linear_output_acc: 0.4561\n",
      "Epoch 2124/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5361 - VL_attention_linear_output_loss: 1.7465 - VH_attention_linear_output_loss: 1.7896 - VL_attention_linear_output_acc: 0.4837 - VH_attention_linear_output_acc: 0.4671 - val_loss: 3.5997 - val_VL_attention_linear_output_loss: 1.7868 - val_VH_attention_linear_output_loss: 1.8129 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4645\n",
      "Epoch 2125/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5198 - VL_attention_linear_output_loss: 1.7392 - VH_attention_linear_output_loss: 1.7806 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4706 - val_loss: 3.6282 - val_VL_attention_linear_output_loss: 1.7862 - val_VH_attention_linear_output_loss: 1.8421 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4454\n",
      "Epoch 2126/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5312 - VL_attention_linear_output_loss: 1.7405 - VH_attention_linear_output_loss: 1.7908 - VL_attention_linear_output_acc: 0.4880 - VH_attention_linear_output_acc: 0.4664 - val_loss: 3.6074 - val_VL_attention_linear_output_loss: 1.7910 - val_VH_attention_linear_output_loss: 1.8164 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4628\n",
      "Epoch 2127/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5377 - VL_attention_linear_output_loss: 1.7446 - VH_attention_linear_output_loss: 1.7932 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4657 - val_loss: 3.6016 - val_VL_attention_linear_output_loss: 1.7935 - val_VH_attention_linear_output_loss: 1.8081 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4670\n",
      "Epoch 2128/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5357 - VL_attention_linear_output_loss: 1.7425 - VH_attention_linear_output_loss: 1.7933 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4653 - val_loss: 3.6402 - val_VL_attention_linear_output_loss: 1.8254 - val_VH_attention_linear_output_loss: 1.8148 - val_VL_attention_linear_output_acc: 0.4688 - val_VH_attention_linear_output_acc: 0.4645\n",
      "Epoch 2129/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5183 - VL_attention_linear_output_loss: 1.7373 - VH_attention_linear_output_loss: 1.7810 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4702 - val_loss: 3.5964 - val_VL_attention_linear_output_loss: 1.7864 - val_VH_attention_linear_output_loss: 1.8100 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4662\n",
      "Epoch 2130/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5321 - VL_attention_linear_output_loss: 1.7459 - VH_attention_linear_output_loss: 1.7862 - VL_attention_linear_output_acc: 0.4848 - VH_attention_linear_output_acc: 0.4685 - val_loss: 3.6302 - val_VL_attention_linear_output_loss: 1.8100 - val_VH_attention_linear_output_loss: 1.8202 - val_VL_attention_linear_output_acc: 0.4628 - val_VH_attention_linear_output_acc: 0.4622\n",
      "Epoch 2131/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5295 - VL_attention_linear_output_loss: 1.7395 - VH_attention_linear_output_loss: 1.7900 - VL_attention_linear_output_acc: 0.4869 - VH_attention_linear_output_acc: 0.4670 - val_loss: 3.6241 - val_VL_attention_linear_output_loss: 1.8059 - val_VH_attention_linear_output_loss: 1.8182 - val_VL_attention_linear_output_acc: 0.4747 - val_VH_attention_linear_output_acc: 0.4617\n",
      "Epoch 2132/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5232 - VL_attention_linear_output_loss: 1.7434 - VH_attention_linear_output_loss: 1.7798 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4707 - val_loss: 3.6120 - val_VL_attention_linear_output_loss: 1.7933 - val_VH_attention_linear_output_loss: 1.8187 - val_VL_attention_linear_output_acc: 0.4758 - val_VH_attention_linear_output_acc: 0.4621\n",
      "Epoch 2133/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5264 - VL_attention_linear_output_loss: 1.7384 - VH_attention_linear_output_loss: 1.7880 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4670 - val_loss: 3.6136 - val_VL_attention_linear_output_loss: 1.7936 - val_VH_attention_linear_output_loss: 1.8200 - val_VL_attention_linear_output_acc: 0.4804 - val_VH_attention_linear_output_acc: 0.4616\n",
      "Epoch 2134/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5222 - VL_attention_linear_output_loss: 1.7374 - VH_attention_linear_output_loss: 1.7848 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4693 - val_loss: 3.6175 - val_VL_attention_linear_output_loss: 1.7967 - val_VH_attention_linear_output_loss: 1.8207 - val_VL_attention_linear_output_acc: 0.4757 - val_VH_attention_linear_output_acc: 0.4623\n",
      "Epoch 2135/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5261 - VL_attention_linear_output_loss: 1.7459 - VH_attention_linear_output_loss: 1.7802 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4707 - val_loss: 3.6648 - val_VL_attention_linear_output_loss: 1.8395 - val_VH_attention_linear_output_loss: 1.8253 - val_VL_attention_linear_output_acc: 0.4528 - val_VH_attention_linear_output_acc: 0.4569\n",
      "Epoch 2136/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5276 - VL_attention_linear_output_loss: 1.7437 - VH_attention_linear_output_loss: 1.7838 - VL_attention_linear_output_acc: 0.4840 - VH_attention_linear_output_acc: 0.4691 - val_loss: 3.6152 - val_VL_attention_linear_output_loss: 1.7822 - val_VH_attention_linear_output_loss: 1.8331 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4568\n",
      "Epoch 2137/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5307 - VL_attention_linear_output_loss: 1.7462 - VH_attention_linear_output_loss: 1.7846 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4695 - val_loss: 3.6193 - val_VL_attention_linear_output_loss: 1.7882 - val_VH_attention_linear_output_loss: 1.8310 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4559\n",
      "Epoch 2138/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5346 - VL_attention_linear_output_loss: 1.7377 - VH_attention_linear_output_loss: 1.7969 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4645 - val_loss: 3.6400 - val_VL_attention_linear_output_loss: 1.7976 - val_VH_attention_linear_output_loss: 1.8425 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.4487\n",
      "Epoch 2139/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5286 - VL_attention_linear_output_loss: 1.7402 - VH_attention_linear_output_loss: 1.7884 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4678 - val_loss: 3.6092 - val_VL_attention_linear_output_loss: 1.7859 - val_VH_attention_linear_output_loss: 1.8234 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4586\n",
      "Epoch 2140/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5364 - VL_attention_linear_output_loss: 1.7481 - VH_attention_linear_output_loss: 1.7884 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4670 - val_loss: 3.6493 - val_VL_attention_linear_output_loss: 1.8213 - val_VH_attention_linear_output_loss: 1.8279 - val_VL_attention_linear_output_acc: 0.4645 - val_VH_attention_linear_output_acc: 0.4583\n",
      "Epoch 2141/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5440 - VL_attention_linear_output_loss: 1.7610 - VH_attention_linear_output_loss: 1.7830 - VL_attention_linear_output_acc: 0.4778 - VH_attention_linear_output_acc: 0.4696 - val_loss: 3.6482 - val_VL_attention_linear_output_loss: 1.8105 - val_VH_attention_linear_output_loss: 1.8377 - val_VL_attention_linear_output_acc: 0.4639 - val_VH_attention_linear_output_acc: 0.4536\n",
      "Epoch 2142/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5184 - VL_attention_linear_output_loss: 1.7335 - VH_attention_linear_output_loss: 1.7849 - VL_attention_linear_output_acc: 0.4910 - VH_attention_linear_output_acc: 0.4694 - val_loss: 3.5991 - val_VL_attention_linear_output_loss: 1.7840 - val_VH_attention_linear_output_loss: 1.8151 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4616\n",
      "Epoch 2143/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5122 - VL_attention_linear_output_loss: 1.7295 - VH_attention_linear_output_loss: 1.7827 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4691 - val_loss: 3.6105 - val_VL_attention_linear_output_loss: 1.7859 - val_VH_attention_linear_output_loss: 1.8246 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4631\n",
      "Epoch 2144/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5194 - VL_attention_linear_output_loss: 1.7353 - VH_attention_linear_output_loss: 1.7841 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4690 - val_loss: 3.6262 - val_VL_attention_linear_output_loss: 1.7938 - val_VH_attention_linear_output_loss: 1.8324 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4574\n",
      "Epoch 2145/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5289 - VL_attention_linear_output_loss: 1.7394 - VH_attention_linear_output_loss: 1.7894 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4671 - val_loss: 3.6358 - val_VL_attention_linear_output_loss: 1.8112 - val_VH_attention_linear_output_loss: 1.8247 - val_VL_attention_linear_output_acc: 0.4690 - val_VH_attention_linear_output_acc: 0.4609\n",
      "Epoch 2146/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5334 - VL_attention_linear_output_loss: 1.7414 - VH_attention_linear_output_loss: 1.7920 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4665 - val_loss: 3.6062 - val_VL_attention_linear_output_loss: 1.7960 - val_VH_attention_linear_output_loss: 1.8102 - val_VL_attention_linear_output_acc: 0.4771 - val_VH_attention_linear_output_acc: 0.4645\n",
      "Epoch 2147/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5216 - VL_attention_linear_output_loss: 1.7386 - VH_attention_linear_output_loss: 1.7830 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4695 - val_loss: 3.6064 - val_VL_attention_linear_output_loss: 1.7988 - val_VH_attention_linear_output_loss: 1.8076 - val_VL_attention_linear_output_acc: 0.4738 - val_VH_attention_linear_output_acc: 0.4641\n",
      "Epoch 2148/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5373 - VL_attention_linear_output_loss: 1.7507 - VH_attention_linear_output_loss: 1.7866 - VL_attention_linear_output_acc: 0.4822 - VH_attention_linear_output_acc: 0.4681 - val_loss: 3.6397 - val_VL_attention_linear_output_loss: 1.8065 - val_VH_attention_linear_output_loss: 1.8333 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4510\n",
      "Epoch 2149/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5362 - VL_attention_linear_output_loss: 1.7474 - VH_attention_linear_output_loss: 1.7887 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4681 - val_loss: 3.6249 - val_VL_attention_linear_output_loss: 1.7988 - val_VH_attention_linear_output_loss: 1.8261 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4581\n",
      "Epoch 2150/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5354 - VL_attention_linear_output_loss: 1.7558 - VH_attention_linear_output_loss: 1.7796 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.4707 - val_loss: 3.6367 - val_VL_attention_linear_output_loss: 1.7939 - val_VH_attention_linear_output_loss: 1.8428 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4511\n",
      "Epoch 2151/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5152 - VL_attention_linear_output_loss: 1.7385 - VH_attention_linear_output_loss: 1.7767 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4721 - val_loss: 3.6074 - val_VL_attention_linear_output_loss: 1.7845 - val_VH_attention_linear_output_loss: 1.8229 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4607\n",
      "Epoch 2152/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5298 - VL_attention_linear_output_loss: 1.7395 - VH_attention_linear_output_loss: 1.7903 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4668 - val_loss: 3.6242 - val_VL_attention_linear_output_loss: 1.8100 - val_VH_attention_linear_output_loss: 1.8142 - val_VL_attention_linear_output_acc: 0.4671 - val_VH_attention_linear_output_acc: 0.4640\n",
      "Epoch 2153/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5190 - VL_attention_linear_output_loss: 1.7398 - VH_attention_linear_output_loss: 1.7791 - VL_attention_linear_output_acc: 0.4879 - VH_attention_linear_output_acc: 0.4710 - val_loss: 3.5961 - val_VL_attention_linear_output_loss: 1.7846 - val_VH_attention_linear_output_loss: 1.8115 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4641\n",
      "Epoch 2154/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5307 - VL_attention_linear_output_loss: 1.7394 - VH_attention_linear_output_loss: 1.7913 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4661 - val_loss: 3.5980 - val_VL_attention_linear_output_loss: 1.7805 - val_VH_attention_linear_output_loss: 1.8175 - val_VL_attention_linear_output_acc: 0.4893 - val_VH_attention_linear_output_acc: 0.4636\n",
      "Epoch 2155/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5394 - VL_attention_linear_output_loss: 1.7405 - VH_attention_linear_output_loss: 1.7989 - VL_attention_linear_output_acc: 0.4879 - VH_attention_linear_output_acc: 0.4647 - val_loss: 3.6195 - val_VL_attention_linear_output_loss: 1.7914 - val_VH_attention_linear_output_loss: 1.8281 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4615\n",
      "Epoch 2156/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5364 - VL_attention_linear_output_loss: 1.7438 - VH_attention_linear_output_loss: 1.7926 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4661 - val_loss: 3.6573 - val_VL_attention_linear_output_loss: 1.8333 - val_VH_attention_linear_output_loss: 1.8240 - val_VL_attention_linear_output_acc: 0.4540 - val_VH_attention_linear_output_acc: 0.4633\n",
      "Epoch 2157/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5406 - VL_attention_linear_output_loss: 1.7495 - VH_attention_linear_output_loss: 1.7910 - VL_attention_linear_output_acc: 0.4825 - VH_attention_linear_output_acc: 0.4680 - val_loss: 3.5990 - val_VL_attention_linear_output_loss: 1.7830 - val_VH_attention_linear_output_loss: 1.8161 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4627\n",
      "Epoch 2158/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5297 - VL_attention_linear_output_loss: 1.7430 - VH_attention_linear_output_loss: 1.7867 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4697 - val_loss: 3.6070 - val_VL_attention_linear_output_loss: 1.7858 - val_VH_attention_linear_output_loss: 1.8211 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4591\n",
      "Epoch 2159/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5279 - VL_attention_linear_output_loss: 1.7368 - VH_attention_linear_output_loss: 1.7912 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4669 - val_loss: 3.6074 - val_VL_attention_linear_output_loss: 1.7909 - val_VH_attention_linear_output_loss: 1.8165 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4629\n",
      "Epoch 2160/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5346 - VL_attention_linear_output_loss: 1.7503 - VH_attention_linear_output_loss: 1.7843 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4697 - val_loss: 3.5959 - val_VL_attention_linear_output_loss: 1.7847 - val_VH_attention_linear_output_loss: 1.8113 - val_VL_attention_linear_output_acc: 0.4812 - val_VH_attention_linear_output_acc: 0.4645\n",
      "Epoch 2161/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5212 - VL_attention_linear_output_loss: 1.7336 - VH_attention_linear_output_loss: 1.7877 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4685 - val_loss: 3.6012 - val_VL_attention_linear_output_loss: 1.7899 - val_VH_attention_linear_output_loss: 1.8113 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4647\n",
      "Epoch 2162/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5225 - VL_attention_linear_output_loss: 1.7396 - VH_attention_linear_output_loss: 1.7829 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4701 - val_loss: 3.6143 - val_VL_attention_linear_output_loss: 1.7916 - val_VH_attention_linear_output_loss: 1.8227 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4595\n",
      "Epoch 2163/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5294 - VL_attention_linear_output_loss: 1.7406 - VH_attention_linear_output_loss: 1.7888 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4677 - val_loss: 3.5934 - val_VL_attention_linear_output_loss: 1.7783 - val_VH_attention_linear_output_loss: 1.8152 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4643\n",
      "Epoch 2164/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5269 - VL_attention_linear_output_loss: 1.7355 - VH_attention_linear_output_loss: 1.7914 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4674 - val_loss: 3.6745 - val_VL_attention_linear_output_loss: 1.7844 - val_VH_attention_linear_output_loss: 1.8902 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4325\n",
      "Epoch 2165/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5302 - VL_attention_linear_output_loss: 1.7424 - VH_attention_linear_output_loss: 1.7878 - VL_attention_linear_output_acc: 0.4858 - VH_attention_linear_output_acc: 0.4683 - val_loss: 3.5925 - val_VL_attention_linear_output_loss: 1.7866 - val_VH_attention_linear_output_loss: 1.8059 - val_VL_attention_linear_output_acc: 0.4810 - val_VH_attention_linear_output_acc: 0.4685\n",
      "Epoch 2166/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5360 - VL_attention_linear_output_loss: 1.7504 - VH_attention_linear_output_loss: 1.7856 - VL_attention_linear_output_acc: 0.4822 - VH_attention_linear_output_acc: 0.4697 - val_loss: 3.6008 - val_VL_attention_linear_output_loss: 1.7812 - val_VH_attention_linear_output_loss: 1.8196 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4586\n",
      "Epoch 2167/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5315 - VL_attention_linear_output_loss: 1.7337 - VH_attention_linear_output_loss: 1.7979 - VL_attention_linear_output_acc: 0.4895 - VH_attention_linear_output_acc: 0.4645 - val_loss: 3.6078 - val_VL_attention_linear_output_loss: 1.7970 - val_VH_attention_linear_output_loss: 1.8108 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4614\n",
      "Epoch 2168/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5287 - VL_attention_linear_output_loss: 1.7460 - VH_attention_linear_output_loss: 1.7828 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4705 - val_loss: 3.5994 - val_VL_attention_linear_output_loss: 1.7842 - val_VH_attention_linear_output_loss: 1.8151 - val_VL_attention_linear_output_acc: 0.4858 - val_VH_attention_linear_output_acc: 0.4619\n",
      "Epoch 2169/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5354 - VL_attention_linear_output_loss: 1.7454 - VH_attention_linear_output_loss: 1.7900 - VL_attention_linear_output_acc: 0.4851 - VH_attention_linear_output_acc: 0.4670 - val_loss: 3.6110 - val_VL_attention_linear_output_loss: 1.7795 - val_VH_attention_linear_output_loss: 1.8316 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4549\n",
      "Epoch 2170/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5159 - VL_attention_linear_output_loss: 1.7361 - VH_attention_linear_output_loss: 1.7798 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4708 - val_loss: 3.6384 - val_VL_attention_linear_output_loss: 1.7998 - val_VH_attention_linear_output_loss: 1.8387 - val_VL_attention_linear_output_acc: 0.4740 - val_VH_attention_linear_output_acc: 0.4548\n",
      "Epoch 2171/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5278 - VL_attention_linear_output_loss: 1.7414 - VH_attention_linear_output_loss: 1.7864 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4688 - val_loss: 3.6020 - val_VL_attention_linear_output_loss: 1.7786 - val_VH_attention_linear_output_loss: 1.8234 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4596\n",
      "Epoch 2172/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5171 - VL_attention_linear_output_loss: 1.7304 - VH_attention_linear_output_loss: 1.7867 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4683 - val_loss: 3.6100 - val_VL_attention_linear_output_loss: 1.7960 - val_VH_attention_linear_output_loss: 1.8140 - val_VL_attention_linear_output_acc: 0.4747 - val_VH_attention_linear_output_acc: 0.4631\n",
      "Epoch 2173/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5062 - VL_attention_linear_output_loss: 1.7340 - VH_attention_linear_output_loss: 1.7722 - VL_attention_linear_output_acc: 0.4896 - VH_attention_linear_output_acc: 0.4735 - val_loss: 3.6147 - val_VL_attention_linear_output_loss: 1.8000 - val_VH_attention_linear_output_loss: 1.8147 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4643\n",
      "Epoch 2174/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5239 - VL_attention_linear_output_loss: 1.7382 - VH_attention_linear_output_loss: 1.7857 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4688 - val_loss: 3.6158 - val_VL_attention_linear_output_loss: 1.7884 - val_VH_attention_linear_output_loss: 1.8274 - val_VL_attention_linear_output_acc: 0.4805 - val_VH_attention_linear_output_acc: 0.4567\n",
      "Epoch 2175/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5216 - VL_attention_linear_output_loss: 1.7354 - VH_attention_linear_output_loss: 1.7862 - VL_attention_linear_output_acc: 0.4896 - VH_attention_linear_output_acc: 0.4684 - val_loss: 3.6336 - val_VL_attention_linear_output_loss: 1.8203 - val_VH_attention_linear_output_loss: 1.8133 - val_VL_attention_linear_output_acc: 0.4602 - val_VH_attention_linear_output_acc: 0.4651\n",
      "Epoch 2176/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5344 - VL_attention_linear_output_loss: 1.7504 - VH_attention_linear_output_loss: 1.7841 - VL_attention_linear_output_acc: 0.4818 - VH_attention_linear_output_acc: 0.4696 - val_loss: 3.6083 - val_VL_attention_linear_output_loss: 1.7837 - val_VH_attention_linear_output_loss: 1.8247 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4602\n",
      "Epoch 2177/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5305 - VL_attention_linear_output_loss: 1.7407 - VH_attention_linear_output_loss: 1.7898 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4666 - val_loss: 3.6059 - val_VL_attention_linear_output_loss: 1.7946 - val_VH_attention_linear_output_loss: 1.8113 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.4633\n",
      "Epoch 2178/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5171 - VL_attention_linear_output_loss: 1.7362 - VH_attention_linear_output_loss: 1.7809 - VL_attention_linear_output_acc: 0.4877 - VH_attention_linear_output_acc: 0.4700 - val_loss: 3.5996 - val_VL_attention_linear_output_loss: 1.7827 - val_VH_attention_linear_output_loss: 1.8169 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4613\n",
      "Epoch 2179/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5251 - VL_attention_linear_output_loss: 1.7395 - VH_attention_linear_output_loss: 1.7855 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4677 - val_loss: 3.5910 - val_VL_attention_linear_output_loss: 1.7834 - val_VH_attention_linear_output_loss: 1.8076 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4657\n",
      "Epoch 2180/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5188 - VL_attention_linear_output_loss: 1.7379 - VH_attention_linear_output_loss: 1.7809 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4708 - val_loss: 3.5979 - val_VL_attention_linear_output_loss: 1.7828 - val_VH_attention_linear_output_loss: 1.8150 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4629\n",
      "Epoch 2181/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5136 - VL_attention_linear_output_loss: 1.7367 - VH_attention_linear_output_loss: 1.7769 - VL_attention_linear_output_acc: 0.4881 - VH_attention_linear_output_acc: 0.4720 - val_loss: 3.5905 - val_VL_attention_linear_output_loss: 1.7845 - val_VH_attention_linear_output_loss: 1.8059 - val_VL_attention_linear_output_acc: 0.4794 - val_VH_attention_linear_output_acc: 0.4674\n",
      "Epoch 2182/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5345 - VL_attention_linear_output_loss: 1.7513 - VH_attention_linear_output_loss: 1.7832 - VL_attention_linear_output_acc: 0.4813 - VH_attention_linear_output_acc: 0.4690 - val_loss: 3.6305 - val_VL_attention_linear_output_loss: 1.8187 - val_VH_attention_linear_output_loss: 1.8118 - val_VL_attention_linear_output_acc: 0.4671 - val_VH_attention_linear_output_acc: 0.4642\n",
      "Epoch 2183/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5179 - VL_attention_linear_output_loss: 1.7400 - VH_attention_linear_output_loss: 1.7779 - VL_attention_linear_output_acc: 0.4880 - VH_attention_linear_output_acc: 0.4716 - val_loss: 3.6034 - val_VL_attention_linear_output_loss: 1.7877 - val_VH_attention_linear_output_loss: 1.8157 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4635\n",
      "Epoch 2184/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5176 - VL_attention_linear_output_loss: 1.7362 - VH_attention_linear_output_loss: 1.7815 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4703 - val_loss: 3.6360 - val_VL_attention_linear_output_loss: 1.8055 - val_VH_attention_linear_output_loss: 1.8304 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.4575\n",
      "Epoch 2185/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5291 - VL_attention_linear_output_loss: 1.7449 - VH_attention_linear_output_loss: 1.7843 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4695 - val_loss: 3.5893 - val_VL_attention_linear_output_loss: 1.7832 - val_VH_attention_linear_output_loss: 1.8061 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4656\n",
      "Epoch 2186/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5280 - VL_attention_linear_output_loss: 1.7444 - VH_attention_linear_output_loss: 1.7835 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4694 - val_loss: 3.6123 - val_VL_attention_linear_output_loss: 1.7960 - val_VH_attention_linear_output_loss: 1.8163 - val_VL_attention_linear_output_acc: 0.4794 - val_VH_attention_linear_output_acc: 0.4612\n",
      "Epoch 2187/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5097 - VL_attention_linear_output_loss: 1.7382 - VH_attention_linear_output_loss: 1.7716 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4739 - val_loss: 3.6151 - val_VL_attention_linear_output_loss: 1.7855 - val_VH_attention_linear_output_loss: 1.8295 - val_VL_attention_linear_output_acc: 0.4860 - val_VH_attention_linear_output_acc: 0.4595\n",
      "Epoch 2188/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5277 - VL_attention_linear_output_loss: 1.7373 - VH_attention_linear_output_loss: 1.7904 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4667 - val_loss: 3.6303 - val_VL_attention_linear_output_loss: 1.7878 - val_VH_attention_linear_output_loss: 1.8425 - val_VL_attention_linear_output_acc: 0.4812 - val_VH_attention_linear_output_acc: 0.4585\n",
      "Epoch 2189/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5094 - VL_attention_linear_output_loss: 1.7333 - VH_attention_linear_output_loss: 1.7760 - VL_attention_linear_output_acc: 0.4895 - VH_attention_linear_output_acc: 0.4726 - val_loss: 3.5890 - val_VL_attention_linear_output_loss: 1.7838 - val_VH_attention_linear_output_loss: 1.8052 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4661\n",
      "Epoch 2190/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5252 - VL_attention_linear_output_loss: 1.7451 - VH_attention_linear_output_loss: 1.7800 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4701 - val_loss: 3.6581 - val_VL_attention_linear_output_loss: 1.8307 - val_VH_attention_linear_output_loss: 1.8273 - val_VL_attention_linear_output_acc: 0.4603 - val_VH_attention_linear_output_acc: 0.4585\n",
      "Epoch 2191/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5254 - VL_attention_linear_output_loss: 1.7442 - VH_attention_linear_output_loss: 1.7812 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4697 - val_loss: 3.5975 - val_VL_attention_linear_output_loss: 1.7800 - val_VH_attention_linear_output_loss: 1.8175 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4627\n",
      "Epoch 2192/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5125 - VL_attention_linear_output_loss: 1.7323 - VH_attention_linear_output_loss: 1.7802 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4707 - val_loss: 3.6309 - val_VL_attention_linear_output_loss: 1.8048 - val_VH_attention_linear_output_loss: 1.8261 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4587\n",
      "Epoch 2193/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5274 - VL_attention_linear_output_loss: 1.7471 - VH_attention_linear_output_loss: 1.7803 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4706 - val_loss: 3.6127 - val_VL_attention_linear_output_loss: 1.7894 - val_VH_attention_linear_output_loss: 1.8233 - val_VL_attention_linear_output_acc: 0.4764 - val_VH_attention_linear_output_acc: 0.4621\n",
      "Epoch 2194/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5099 - VL_attention_linear_output_loss: 1.7315 - VH_attention_linear_output_loss: 1.7783 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4714 - val_loss: 3.5909 - val_VL_attention_linear_output_loss: 1.7802 - val_VH_attention_linear_output_loss: 1.8107 - val_VL_attention_linear_output_acc: 0.4870 - val_VH_attention_linear_output_acc: 0.4647\n",
      "Epoch 2195/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5309 - VL_attention_linear_output_loss: 1.7393 - VH_attention_linear_output_loss: 1.7916 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4655 - val_loss: 3.6128 - val_VL_attention_linear_output_loss: 1.7883 - val_VH_attention_linear_output_loss: 1.8245 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4612\n",
      "Epoch 2196/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5049 - VL_attention_linear_output_loss: 1.7320 - VH_attention_linear_output_loss: 1.7729 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4736 - val_loss: 3.5933 - val_VL_attention_linear_output_loss: 1.7852 - val_VH_attention_linear_output_loss: 1.8081 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4660\n",
      "Epoch 2197/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5078 - VL_attention_linear_output_loss: 1.7367 - VH_attention_linear_output_loss: 1.7711 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4735 - val_loss: 3.6243 - val_VL_attention_linear_output_loss: 1.7931 - val_VH_attention_linear_output_loss: 1.8312 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4590\n",
      "Epoch 2198/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5207 - VL_attention_linear_output_loss: 1.7460 - VH_attention_linear_output_loss: 1.7748 - VL_attention_linear_output_acc: 0.4844 - VH_attention_linear_output_acc: 0.4721 - val_loss: 3.6003 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.8131 - val_VL_attention_linear_output_acc: 0.4794 - val_VH_attention_linear_output_acc: 0.4632\n",
      "Epoch 2199/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5373 - VL_attention_linear_output_loss: 1.7496 - VH_attention_linear_output_loss: 1.7877 - VL_attention_linear_output_acc: 0.4821 - VH_attention_linear_output_acc: 0.4673 - val_loss: 3.6311 - val_VL_attention_linear_output_loss: 1.8015 - val_VH_attention_linear_output_loss: 1.8296 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4589\n",
      "Epoch 2200/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5049 - VL_attention_linear_output_loss: 1.7327 - VH_attention_linear_output_loss: 1.7722 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4731 - val_loss: 3.6110 - val_VL_attention_linear_output_loss: 1.8108 - val_VH_attention_linear_output_loss: 1.8003 - val_VL_attention_linear_output_acc: 0.4667 - val_VH_attention_linear_output_acc: 0.4668\n",
      "Epoch 2201/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5126 - VL_attention_linear_output_loss: 1.7339 - VH_attention_linear_output_loss: 1.7787 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4714 - val_loss: 3.6369 - val_VL_attention_linear_output_loss: 1.7877 - val_VH_attention_linear_output_loss: 1.8493 - val_VL_attention_linear_output_acc: 0.4784 - val_VH_attention_linear_output_acc: 0.4464\n",
      "Epoch 2202/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5287 - VL_attention_linear_output_loss: 1.7400 - VH_attention_linear_output_loss: 1.7888 - VL_attention_linear_output_acc: 0.4873 - VH_attention_linear_output_acc: 0.4673 - val_loss: 3.6064 - val_VL_attention_linear_output_loss: 1.7850 - val_VH_attention_linear_output_loss: 1.8215 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4606\n",
      "Epoch 2203/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5252 - VL_attention_linear_output_loss: 1.7370 - VH_attention_linear_output_loss: 1.7882 - VL_attention_linear_output_acc: 0.4895 - VH_attention_linear_output_acc: 0.4665 - val_loss: 3.6134 - val_VL_attention_linear_output_loss: 1.7866 - val_VH_attention_linear_output_loss: 1.8269 - val_VL_attention_linear_output_acc: 0.4805 - val_VH_attention_linear_output_acc: 0.4559\n",
      "Epoch 2204/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5136 - VL_attention_linear_output_loss: 1.7365 - VH_attention_linear_output_loss: 1.7772 - VL_attention_linear_output_acc: 0.4894 - VH_attention_linear_output_acc: 0.4725 - val_loss: 3.6172 - val_VL_attention_linear_output_loss: 1.8004 - val_VH_attention_linear_output_loss: 1.8168 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.4619\n",
      "Epoch 2205/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5261 - VL_attention_linear_output_loss: 1.7440 - VH_attention_linear_output_loss: 1.7821 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4698 - val_loss: 3.6131 - val_VL_attention_linear_output_loss: 1.7848 - val_VH_attention_linear_output_loss: 1.8283 - val_VL_attention_linear_output_acc: 0.4812 - val_VH_attention_linear_output_acc: 0.4600\n",
      "Epoch 2206/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5218 - VL_attention_linear_output_loss: 1.7416 - VH_attention_linear_output_loss: 1.7801 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4703 - val_loss: 3.6060 - val_VL_attention_linear_output_loss: 1.7987 - val_VH_attention_linear_output_loss: 1.8074 - val_VL_attention_linear_output_acc: 0.4713 - val_VH_attention_linear_output_acc: 0.4650\n",
      "Epoch 2207/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5235 - VL_attention_linear_output_loss: 1.7446 - VH_attention_linear_output_loss: 1.7790 - VL_attention_linear_output_acc: 0.4849 - VH_attention_linear_output_acc: 0.4709 - val_loss: 3.6097 - val_VL_attention_linear_output_loss: 1.7921 - val_VH_attention_linear_output_loss: 1.8176 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4618\n",
      "Epoch 2208/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5072 - VL_attention_linear_output_loss: 1.7309 - VH_attention_linear_output_loss: 1.7763 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4715 - val_loss: 3.6082 - val_VL_attention_linear_output_loss: 1.8039 - val_VH_attention_linear_output_loss: 1.8043 - val_VL_attention_linear_output_acc: 0.4725 - val_VH_attention_linear_output_acc: 0.4697\n",
      "Epoch 2209/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5218 - VL_attention_linear_output_loss: 1.7403 - VH_attention_linear_output_loss: 1.7816 - VL_attention_linear_output_acc: 0.4869 - VH_attention_linear_output_acc: 0.4700 - val_loss: 3.6269 - val_VL_attention_linear_output_loss: 1.7844 - val_VH_attention_linear_output_loss: 1.8425 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4515\n",
      "Epoch 2210/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5174 - VL_attention_linear_output_loss: 1.7408 - VH_attention_linear_output_loss: 1.7766 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4715 - val_loss: 3.6161 - val_VL_attention_linear_output_loss: 1.8123 - val_VH_attention_linear_output_loss: 1.8038 - val_VL_attention_linear_output_acc: 0.4682 - val_VH_attention_linear_output_acc: 0.4681\n",
      "Epoch 2211/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5133 - VL_attention_linear_output_loss: 1.7386 - VH_attention_linear_output_loss: 1.7747 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4726 - val_loss: 3.5996 - val_VL_attention_linear_output_loss: 1.7985 - val_VH_attention_linear_output_loss: 1.8011 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4689\n",
      "Epoch 2212/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5278 - VL_attention_linear_output_loss: 1.7411 - VH_attention_linear_output_loss: 1.7867 - VL_attention_linear_output_acc: 0.4860 - VH_attention_linear_output_acc: 0.4682 - val_loss: 3.5986 - val_VL_attention_linear_output_loss: 1.7922 - val_VH_attention_linear_output_loss: 1.8063 - val_VL_attention_linear_output_acc: 0.4742 - val_VH_attention_linear_output_acc: 0.4671\n",
      "Epoch 2213/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5223 - VL_attention_linear_output_loss: 1.7406 - VH_attention_linear_output_loss: 1.7817 - VL_attention_linear_output_acc: 0.4849 - VH_attention_linear_output_acc: 0.4701 - val_loss: 3.6405 - val_VL_attention_linear_output_loss: 1.8260 - val_VH_attention_linear_output_loss: 1.8145 - val_VL_attention_linear_output_acc: 0.4625 - val_VH_attention_linear_output_acc: 0.4647\n",
      "Epoch 2214/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5228 - VL_attention_linear_output_loss: 1.7435 - VH_attention_linear_output_loss: 1.7794 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4712 - val_loss: 3.6113 - val_VL_attention_linear_output_loss: 1.7972 - val_VH_attention_linear_output_loss: 1.8141 - val_VL_attention_linear_output_acc: 0.4805 - val_VH_attention_linear_output_acc: 0.4631\n",
      "Epoch 2215/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5207 - VL_attention_linear_output_loss: 1.7421 - VH_attention_linear_output_loss: 1.7786 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4710 - val_loss: 3.6296 - val_VL_attention_linear_output_loss: 1.8142 - val_VH_attention_linear_output_loss: 1.8154 - val_VL_attention_linear_output_acc: 0.4710 - val_VH_attention_linear_output_acc: 0.4630\n",
      "Epoch 2216/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5183 - VL_attention_linear_output_loss: 1.7393 - VH_attention_linear_output_loss: 1.7790 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4711 - val_loss: 3.6048 - val_VL_attention_linear_output_loss: 1.7934 - val_VH_attention_linear_output_loss: 1.8115 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.4656\n",
      "Epoch 2217/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5233 - VL_attention_linear_output_loss: 1.7438 - VH_attention_linear_output_loss: 1.7795 - VL_attention_linear_output_acc: 0.4838 - VH_attention_linear_output_acc: 0.4707 - val_loss: 3.5931 - val_VL_attention_linear_output_loss: 1.7829 - val_VH_attention_linear_output_loss: 1.8101 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4648\n",
      "Epoch 2218/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5153 - VL_attention_linear_output_loss: 1.7365 - VH_attention_linear_output_loss: 1.7788 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4708 - val_loss: 3.5945 - val_VL_attention_linear_output_loss: 1.7807 - val_VH_attention_linear_output_loss: 1.8138 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4633\n",
      "Epoch 2219/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5071 - VL_attention_linear_output_loss: 1.7384 - VH_attention_linear_output_loss: 1.7686 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4746 - val_loss: 3.5995 - val_VL_attention_linear_output_loss: 1.7787 - val_VH_attention_linear_output_loss: 1.8208 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4609\n",
      "Epoch 2220/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5157 - VL_attention_linear_output_loss: 1.7338 - VH_attention_linear_output_loss: 1.7819 - VL_attention_linear_output_acc: 0.4896 - VH_attention_linear_output_acc: 0.4703 - val_loss: 3.6084 - val_VL_attention_linear_output_loss: 1.8053 - val_VH_attention_linear_output_loss: 1.8030 - val_VL_attention_linear_output_acc: 0.4725 - val_VH_attention_linear_output_acc: 0.4666\n",
      "Epoch 2221/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5062 - VL_attention_linear_output_loss: 1.7326 - VH_attention_linear_output_loss: 1.7736 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4726 - val_loss: 3.6082 - val_VL_attention_linear_output_loss: 1.7838 - val_VH_attention_linear_output_loss: 1.8243 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4574\n",
      "Epoch 2222/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5144 - VL_attention_linear_output_loss: 1.7358 - VH_attention_linear_output_loss: 1.7786 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4704 - val_loss: 3.5977 - val_VL_attention_linear_output_loss: 1.7889 - val_VH_attention_linear_output_loss: 1.8088 - val_VL_attention_linear_output_acc: 0.4778 - val_VH_attention_linear_output_acc: 0.4667\n",
      "Epoch 2223/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5278 - VL_attention_linear_output_loss: 1.7480 - VH_attention_linear_output_loss: 1.7799 - VL_attention_linear_output_acc: 0.4829 - VH_attention_linear_output_acc: 0.4708 - val_loss: 3.5924 - val_VL_attention_linear_output_loss: 1.7846 - val_VH_attention_linear_output_loss: 1.8079 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4685\n",
      "Epoch 2224/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5038 - VL_attention_linear_output_loss: 1.7332 - VH_attention_linear_output_loss: 1.7706 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4741 - val_loss: 3.5795 - val_VL_attention_linear_output_loss: 1.7787 - val_VH_attention_linear_output_loss: 1.8007 - val_VL_attention_linear_output_acc: 0.4885 - val_VH_attention_linear_output_acc: 0.4710\n",
      "Epoch 2225/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5099 - VL_attention_linear_output_loss: 1.7364 - VH_attention_linear_output_loss: 1.7735 - VL_attention_linear_output_acc: 0.4877 - VH_attention_linear_output_acc: 0.4730 - val_loss: 3.5945 - val_VL_attention_linear_output_loss: 1.7862 - val_VH_attention_linear_output_loss: 1.8083 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4645\n",
      "Epoch 2226/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5170 - VL_attention_linear_output_loss: 1.7402 - VH_attention_linear_output_loss: 1.7768 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4715 - val_loss: 3.6116 - val_VL_attention_linear_output_loss: 1.8007 - val_VH_attention_linear_output_loss: 1.8109 - val_VL_attention_linear_output_acc: 0.4713 - val_VH_attention_linear_output_acc: 0.4656\n",
      "Epoch 2227/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5201 - VL_attention_linear_output_loss: 1.7370 - VH_attention_linear_output_loss: 1.7831 - VL_attention_linear_output_acc: 0.4880 - VH_attention_linear_output_acc: 0.4694 - val_loss: 3.5909 - val_VL_attention_linear_output_loss: 1.7848 - val_VH_attention_linear_output_loss: 1.8062 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4665\n",
      "Epoch 2228/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5127 - VL_attention_linear_output_loss: 1.7328 - VH_attention_linear_output_loss: 1.7798 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.4699 - val_loss: 3.5931 - val_VL_attention_linear_output_loss: 1.7898 - val_VH_attention_linear_output_loss: 1.8033 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4681\n",
      "Epoch 2229/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5150 - VL_attention_linear_output_loss: 1.7454 - VH_attention_linear_output_loss: 1.7696 - VL_attention_linear_output_acc: 0.4832 - VH_attention_linear_output_acc: 0.4745 - val_loss: 3.6119 - val_VL_attention_linear_output_loss: 1.7946 - val_VH_attention_linear_output_loss: 1.8173 - val_VL_attention_linear_output_acc: 0.4730 - val_VH_attention_linear_output_acc: 0.4602\n",
      "Epoch 2230/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5128 - VL_attention_linear_output_loss: 1.7360 - VH_attention_linear_output_loss: 1.7768 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4714 - val_loss: 3.6976 - val_VL_attention_linear_output_loss: 1.8916 - val_VH_attention_linear_output_loss: 1.8060 - val_VL_attention_linear_output_acc: 0.4243 - val_VH_attention_linear_output_acc: 0.4659\n",
      "Epoch 2231/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5244 - VL_attention_linear_output_loss: 1.7435 - VH_attention_linear_output_loss: 1.7809 - VL_attention_linear_output_acc: 0.4832 - VH_attention_linear_output_acc: 0.4706 - val_loss: 3.6083 - val_VL_attention_linear_output_loss: 1.7990 - val_VH_attention_linear_output_loss: 1.8092 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4630\n",
      "Epoch 2232/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5027 - VL_attention_linear_output_loss: 1.7349 - VH_attention_linear_output_loss: 1.7678 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4745 - val_loss: 3.6049 - val_VL_attention_linear_output_loss: 1.8016 - val_VH_attention_linear_output_loss: 1.8033 - val_VL_attention_linear_output_acc: 0.4754 - val_VH_attention_linear_output_acc: 0.4669\n",
      "Epoch 2233/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5200 - VL_attention_linear_output_loss: 1.7374 - VH_attention_linear_output_loss: 1.7826 - VL_attention_linear_output_acc: 0.4880 - VH_attention_linear_output_acc: 0.4695 - val_loss: 3.6178 - val_VL_attention_linear_output_loss: 1.7874 - val_VH_attention_linear_output_loss: 1.8304 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4582\n",
      "Epoch 2234/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5057 - VL_attention_linear_output_loss: 1.7292 - VH_attention_linear_output_loss: 1.7766 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4716 - val_loss: 3.5871 - val_VL_attention_linear_output_loss: 1.7874 - val_VH_attention_linear_output_loss: 1.7997 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4674\n",
      "Epoch 2235/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5188 - VL_attention_linear_output_loss: 1.7395 - VH_attention_linear_output_loss: 1.7793 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4706 - val_loss: 3.6271 - val_VL_attention_linear_output_loss: 1.8007 - val_VH_attention_linear_output_loss: 1.8264 - val_VL_attention_linear_output_acc: 0.4752 - val_VH_attention_linear_output_acc: 0.4581\n",
      "Epoch 2236/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5149 - VL_attention_linear_output_loss: 1.7407 - VH_attention_linear_output_loss: 1.7741 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4729 - val_loss: 3.6086 - val_VL_attention_linear_output_loss: 1.8069 - val_VH_attention_linear_output_loss: 1.8018 - val_VL_attention_linear_output_acc: 0.4653 - val_VH_attention_linear_output_acc: 0.4673\n",
      "Epoch 2237/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5175 - VL_attention_linear_output_loss: 1.7394 - VH_attention_linear_output_loss: 1.7781 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4705 - val_loss: 3.6018 - val_VL_attention_linear_output_loss: 1.7926 - val_VH_attention_linear_output_loss: 1.8093 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4669\n",
      "Epoch 2238/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5120 - VL_attention_linear_output_loss: 1.7412 - VH_attention_linear_output_loss: 1.7708 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4742 - val_loss: 3.5913 - val_VL_attention_linear_output_loss: 1.7895 - val_VH_attention_linear_output_loss: 1.8018 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4685\n",
      "Epoch 2239/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5130 - VL_attention_linear_output_loss: 1.7327 - VH_attention_linear_output_loss: 1.7803 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4697 - val_loss: 3.5979 - val_VL_attention_linear_output_loss: 1.7893 - val_VH_attention_linear_output_loss: 1.8086 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4687\n",
      "Epoch 2240/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5129 - VL_attention_linear_output_loss: 1.7418 - VH_attention_linear_output_loss: 1.7711 - VL_attention_linear_output_acc: 0.4851 - VH_attention_linear_output_acc: 0.4738 - val_loss: 3.5990 - val_VL_attention_linear_output_loss: 1.7827 - val_VH_attention_linear_output_loss: 1.8163 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4640\n",
      "Epoch 2241/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5197 - VL_attention_linear_output_loss: 1.7473 - VH_attention_linear_output_loss: 1.7724 - VL_attention_linear_output_acc: 0.4824 - VH_attention_linear_output_acc: 0.4736 - val_loss: 3.5941 - val_VL_attention_linear_output_loss: 1.7922 - val_VH_attention_linear_output_loss: 1.8019 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4670\n",
      "Epoch 2242/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5341 - VL_attention_linear_output_loss: 1.7532 - VH_attention_linear_output_loss: 1.7809 - VL_attention_linear_output_acc: 0.4803 - VH_attention_linear_output_acc: 0.4703 - val_loss: 3.6257 - val_VL_attention_linear_output_loss: 1.7935 - val_VH_attention_linear_output_loss: 1.8321 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4547\n",
      "Epoch 2243/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5118 - VL_attention_linear_output_loss: 1.7390 - VH_attention_linear_output_loss: 1.7729 - VL_attention_linear_output_acc: 0.4881 - VH_attention_linear_output_acc: 0.4726 - val_loss: 3.5918 - val_VL_attention_linear_output_loss: 1.7804 - val_VH_attention_linear_output_loss: 1.8114 - val_VL_attention_linear_output_acc: 0.4767 - val_VH_attention_linear_output_acc: 0.4648\n",
      "Epoch 2244/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5254 - VL_attention_linear_output_loss: 1.7448 - VH_attention_linear_output_loss: 1.7806 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4713 - val_loss: 3.6194 - val_VL_attention_linear_output_loss: 1.8088 - val_VH_attention_linear_output_loss: 1.8106 - val_VL_attention_linear_output_acc: 0.4729 - val_VH_attention_linear_output_acc: 0.4664\n",
      "Epoch 2245/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5103 - VL_attention_linear_output_loss: 1.7340 - VH_attention_linear_output_loss: 1.7763 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4724 - val_loss: 3.6043 - val_VL_attention_linear_output_loss: 1.7856 - val_VH_attention_linear_output_loss: 1.8187 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4622\n",
      "Epoch 2246/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5220 - VL_attention_linear_output_loss: 1.7417 - VH_attention_linear_output_loss: 1.7803 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4708 - val_loss: 3.6135 - val_VL_attention_linear_output_loss: 1.8026 - val_VH_attention_linear_output_loss: 1.8109 - val_VL_attention_linear_output_acc: 0.4757 - val_VH_attention_linear_output_acc: 0.4657\n",
      "Epoch 2247/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5137 - VL_attention_linear_output_loss: 1.7463 - VH_attention_linear_output_loss: 1.7674 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4755 - val_loss: 3.5898 - val_VL_attention_linear_output_loss: 1.7811 - val_VH_attention_linear_output_loss: 1.8087 - val_VL_attention_linear_output_acc: 0.4814 - val_VH_attention_linear_output_acc: 0.4645\n",
      "Epoch 2248/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5162 - VL_attention_linear_output_loss: 1.7437 - VH_attention_linear_output_loss: 1.7725 - VL_attention_linear_output_acc: 0.4838 - VH_attention_linear_output_acc: 0.4736 - val_loss: 3.6012 - val_VL_attention_linear_output_loss: 1.7857 - val_VH_attention_linear_output_loss: 1.8155 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4605\n",
      "Epoch 2249/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5196 - VL_attention_linear_output_loss: 1.7406 - VH_attention_linear_output_loss: 1.7790 - VL_attention_linear_output_acc: 0.4848 - VH_attention_linear_output_acc: 0.4706 - val_loss: 3.5970 - val_VL_attention_linear_output_loss: 1.7923 - val_VH_attention_linear_output_loss: 1.8047 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4669\n",
      "Epoch 2250/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5148 - VL_attention_linear_output_loss: 1.7389 - VH_attention_linear_output_loss: 1.7760 - VL_attention_linear_output_acc: 0.4873 - VH_attention_linear_output_acc: 0.4725 - val_loss: 3.6066 - val_VL_attention_linear_output_loss: 1.7878 - val_VH_attention_linear_output_loss: 1.8188 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4639\n",
      "Epoch 2251/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5177 - VL_attention_linear_output_loss: 1.7440 - VH_attention_linear_output_loss: 1.7737 - VL_attention_linear_output_acc: 0.4831 - VH_attention_linear_output_acc: 0.4727 - val_loss: 3.6301 - val_VL_attention_linear_output_loss: 1.7949 - val_VH_attention_linear_output_loss: 1.8353 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4556\n",
      "Epoch 2252/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5140 - VL_attention_linear_output_loss: 1.7394 - VH_attention_linear_output_loss: 1.7746 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4727 - val_loss: 3.7314 - val_VL_attention_linear_output_loss: 1.7976 - val_VH_attention_linear_output_loss: 1.9338 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4113\n",
      "Epoch 2253/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5226 - VL_attention_linear_output_loss: 1.7420 - VH_attention_linear_output_loss: 1.7806 - VL_attention_linear_output_acc: 0.4847 - VH_attention_linear_output_acc: 0.4697 - val_loss: 3.6029 - val_VL_attention_linear_output_loss: 1.7958 - val_VH_attention_linear_output_loss: 1.8070 - val_VL_attention_linear_output_acc: 0.4761 - val_VH_attention_linear_output_acc: 0.4664\n",
      "Epoch 2254/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5092 - VL_attention_linear_output_loss: 1.7317 - VH_attention_linear_output_loss: 1.7774 - VL_attention_linear_output_acc: 0.4894 - VH_attention_linear_output_acc: 0.4719 - val_loss: 3.6006 - val_VL_attention_linear_output_loss: 1.7917 - val_VH_attention_linear_output_loss: 1.8090 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4652\n",
      "Epoch 2255/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5229 - VL_attention_linear_output_loss: 1.7458 - VH_attention_linear_output_loss: 1.7770 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4720 - val_loss: 3.6602 - val_VL_attention_linear_output_loss: 1.7925 - val_VH_attention_linear_output_loss: 1.8678 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.4410\n",
      "Epoch 2256/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5256 - VL_attention_linear_output_loss: 1.7313 - VH_attention_linear_output_loss: 1.7943 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4655 - val_loss: 3.6503 - val_VL_attention_linear_output_loss: 1.7961 - val_VH_attention_linear_output_loss: 1.8542 - val_VL_attention_linear_output_acc: 0.4782 - val_VH_attention_linear_output_acc: 0.4473\n",
      "Epoch 2257/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5205 - VL_attention_linear_output_loss: 1.7411 - VH_attention_linear_output_loss: 1.7794 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4709 - val_loss: 3.6885 - val_VL_attention_linear_output_loss: 1.8593 - val_VH_attention_linear_output_loss: 1.8292 - val_VL_attention_linear_output_acc: 0.4432 - val_VH_attention_linear_output_acc: 0.4590\n",
      "Epoch 2258/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5045 - VL_attention_linear_output_loss: 1.7318 - VH_attention_linear_output_loss: 1.7727 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4735 - val_loss: 3.5945 - val_VL_attention_linear_output_loss: 1.7851 - val_VH_attention_linear_output_loss: 1.8094 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4668\n",
      "Epoch 2259/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5040 - VL_attention_linear_output_loss: 1.7356 - VH_attention_linear_output_loss: 1.7684 - VL_attention_linear_output_acc: 0.4894 - VH_attention_linear_output_acc: 0.4758 - val_loss: 3.5940 - val_VL_attention_linear_output_loss: 1.7903 - val_VH_attention_linear_output_loss: 1.8037 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4677\n",
      "Epoch 2260/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4953 - VL_attention_linear_output_loss: 1.7295 - VH_attention_linear_output_loss: 1.7658 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4762 - val_loss: 3.5932 - val_VL_attention_linear_output_loss: 1.7904 - val_VH_attention_linear_output_loss: 1.8028 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.4682\n",
      "Epoch 2261/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5147 - VL_attention_linear_output_loss: 1.7438 - VH_attention_linear_output_loss: 1.7709 - VL_attention_linear_output_acc: 0.4821 - VH_attention_linear_output_acc: 0.4738 - val_loss: 3.6013 - val_VL_attention_linear_output_loss: 1.7881 - val_VH_attention_linear_output_loss: 1.8132 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4630\n",
      "Epoch 2262/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5004 - VL_attention_linear_output_loss: 1.7306 - VH_attention_linear_output_loss: 1.7698 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4742 - val_loss: 3.6026 - val_VL_attention_linear_output_loss: 1.7890 - val_VH_attention_linear_output_loss: 1.8135 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4656\n",
      "Epoch 2263/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5013 - VL_attention_linear_output_loss: 1.7341 - VH_attention_linear_output_loss: 1.7672 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4752 - val_loss: 3.6249 - val_VL_attention_linear_output_loss: 1.7995 - val_VH_attention_linear_output_loss: 1.8254 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4584\n",
      "Epoch 2264/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5021 - VL_attention_linear_output_loss: 1.7365 - VH_attention_linear_output_loss: 1.7656 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4763 - val_loss: 3.6198 - val_VL_attention_linear_output_loss: 1.8131 - val_VH_attention_linear_output_loss: 1.8067 - val_VL_attention_linear_output_acc: 0.4676 - val_VH_attention_linear_output_acc: 0.4687\n",
      "Epoch 2265/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4997 - VL_attention_linear_output_loss: 1.7364 - VH_attention_linear_output_loss: 1.7633 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4773 - val_loss: 3.6125 - val_VL_attention_linear_output_loss: 1.8020 - val_VH_attention_linear_output_loss: 1.8105 - val_VL_attention_linear_output_acc: 0.4724 - val_VH_attention_linear_output_acc: 0.4641\n",
      "Epoch 2266/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5094 - VL_attention_linear_output_loss: 1.7404 - VH_attention_linear_output_loss: 1.7690 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4742 - val_loss: 3.6716 - val_VL_attention_linear_output_loss: 1.8658 - val_VH_attention_linear_output_loss: 1.8058 - val_VL_attention_linear_output_acc: 0.4370 - val_VH_attention_linear_output_acc: 0.4686\n",
      "Epoch 2267/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5108 - VL_attention_linear_output_loss: 1.7395 - VH_attention_linear_output_loss: 1.7714 - VL_attention_linear_output_acc: 0.4858 - VH_attention_linear_output_acc: 0.4734 - val_loss: 3.5870 - val_VL_attention_linear_output_loss: 1.7824 - val_VH_attention_linear_output_loss: 1.8046 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4679\n",
      "Epoch 2268/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4960 - VL_attention_linear_output_loss: 1.7308 - VH_attention_linear_output_loss: 1.7652 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4761 - val_loss: 3.5883 - val_VL_attention_linear_output_loss: 1.7862 - val_VH_attention_linear_output_loss: 1.8021 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4666\n",
      "Epoch 2269/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5005 - VL_attention_linear_output_loss: 1.7303 - VH_attention_linear_output_loss: 1.7702 - VL_attention_linear_output_acc: 0.4910 - VH_attention_linear_output_acc: 0.4751 - val_loss: 3.6002 - val_VL_attention_linear_output_loss: 1.7969 - val_VH_attention_linear_output_loss: 1.8033 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.4679\n",
      "Epoch 2270/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5137 - VL_attention_linear_output_loss: 1.7395 - VH_attention_linear_output_loss: 1.7742 - VL_attention_linear_output_acc: 0.4852 - VH_attention_linear_output_acc: 0.4723 - val_loss: 3.6181 - val_VL_attention_linear_output_loss: 1.7985 - val_VH_attention_linear_output_loss: 1.8196 - val_VL_attention_linear_output_acc: 0.4684 - val_VH_attention_linear_output_acc: 0.4616\n",
      "Epoch 2271/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5051 - VL_attention_linear_output_loss: 1.7361 - VH_attention_linear_output_loss: 1.7690 - VL_attention_linear_output_acc: 0.4879 - VH_attention_linear_output_acc: 0.4746 - val_loss: 3.5821 - val_VL_attention_linear_output_loss: 1.7789 - val_VH_attention_linear_output_loss: 1.8033 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4692\n",
      "Epoch 2272/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5086 - VL_attention_linear_output_loss: 1.7324 - VH_attention_linear_output_loss: 1.7762 - VL_attention_linear_output_acc: 0.4894 - VH_attention_linear_output_acc: 0.4721 - val_loss: 3.5924 - val_VL_attention_linear_output_loss: 1.7838 - val_VH_attention_linear_output_loss: 1.8087 - val_VL_attention_linear_output_acc: 0.4814 - val_VH_attention_linear_output_acc: 0.4643\n",
      "Epoch 2273/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4984 - VL_attention_linear_output_loss: 1.7308 - VH_attention_linear_output_loss: 1.7676 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4750 - val_loss: 3.6337 - val_VL_attention_linear_output_loss: 1.8177 - val_VH_attention_linear_output_loss: 1.8160 - val_VL_attention_linear_output_acc: 0.4609 - val_VH_attention_linear_output_acc: 0.4634\n",
      "Epoch 2274/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5124 - VL_attention_linear_output_loss: 1.7386 - VH_attention_linear_output_loss: 1.7738 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4731 - val_loss: 3.6919 - val_VL_attention_linear_output_loss: 1.8432 - val_VH_attention_linear_output_loss: 1.8487 - val_VL_attention_linear_output_acc: 0.4507 - val_VH_attention_linear_output_acc: 0.4446\n",
      "Epoch 2275/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5217 - VL_attention_linear_output_loss: 1.7481 - VH_attention_linear_output_loss: 1.7735 - VL_attention_linear_output_acc: 0.4836 - VH_attention_linear_output_acc: 0.4732 - val_loss: 3.6024 - val_VL_attention_linear_output_loss: 1.8013 - val_VH_attention_linear_output_loss: 1.8011 - val_VL_attention_linear_output_acc: 0.4729 - val_VH_attention_linear_output_acc: 0.4680\n",
      "Epoch 2276/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5057 - VL_attention_linear_output_loss: 1.7347 - VH_attention_linear_output_loss: 1.7711 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4735 - val_loss: 3.6180 - val_VL_attention_linear_output_loss: 1.7979 - val_VH_attention_linear_output_loss: 1.8202 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.4564\n",
      "Epoch 2277/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4961 - VL_attention_linear_output_loss: 1.7263 - VH_attention_linear_output_loss: 1.7697 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4740 - val_loss: 3.6135 - val_VL_attention_linear_output_loss: 1.7873 - val_VH_attention_linear_output_loss: 1.8263 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4583\n",
      "Epoch 2278/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5060 - VL_attention_linear_output_loss: 1.7339 - VH_attention_linear_output_loss: 1.7721 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4741 - val_loss: 3.5965 - val_VL_attention_linear_output_loss: 1.7905 - val_VH_attention_linear_output_loss: 1.8060 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4672\n",
      "Epoch 2279/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5065 - VL_attention_linear_output_loss: 1.7320 - VH_attention_linear_output_loss: 1.7745 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4733 - val_loss: 3.5916 - val_VL_attention_linear_output_loss: 1.7882 - val_VH_attention_linear_output_loss: 1.8034 - val_VL_attention_linear_output_acc: 0.4810 - val_VH_attention_linear_output_acc: 0.4676\n",
      "Epoch 2280/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5143 - VL_attention_linear_output_loss: 1.7457 - VH_attention_linear_output_loss: 1.7685 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4752 - val_loss: 3.5894 - val_VL_attention_linear_output_loss: 1.7826 - val_VH_attention_linear_output_loss: 1.8068 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4663\n",
      "Epoch 2281/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5021 - VL_attention_linear_output_loss: 1.7334 - VH_attention_linear_output_loss: 1.7687 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4750 - val_loss: 3.5937 - val_VL_attention_linear_output_loss: 1.7802 - val_VH_attention_linear_output_loss: 1.8135 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4657\n",
      "Epoch 2282/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5157 - VL_attention_linear_output_loss: 1.7329 - VH_attention_linear_output_loss: 1.7829 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4697 - val_loss: 3.6173 - val_VL_attention_linear_output_loss: 1.7924 - val_VH_attention_linear_output_loss: 1.8249 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4607\n",
      "Epoch 2283/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5207 - VL_attention_linear_output_loss: 1.7386 - VH_attention_linear_output_loss: 1.7821 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4694 - val_loss: 3.6257 - val_VL_attention_linear_output_loss: 1.8169 - val_VH_attention_linear_output_loss: 1.8088 - val_VL_attention_linear_output_acc: 0.4661 - val_VH_attention_linear_output_acc: 0.4692\n",
      "Epoch 2284/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5038 - VL_attention_linear_output_loss: 1.7393 - VH_attention_linear_output_loss: 1.7644 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4773 - val_loss: 3.5834 - val_VL_attention_linear_output_loss: 1.7897 - val_VH_attention_linear_output_loss: 1.7937 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4720\n",
      "Epoch 2285/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5223 - VL_attention_linear_output_loss: 1.7470 - VH_attention_linear_output_loss: 1.7753 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4725 - val_loss: 3.6274 - val_VL_attention_linear_output_loss: 1.8051 - val_VH_attention_linear_output_loss: 1.8224 - val_VL_attention_linear_output_acc: 0.4671 - val_VH_attention_linear_output_acc: 0.4593\n",
      "Epoch 2286/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5159 - VL_attention_linear_output_loss: 1.7392 - VH_attention_linear_output_loss: 1.7767 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4721 - val_loss: 3.6129 - val_VL_attention_linear_output_loss: 1.7966 - val_VH_attention_linear_output_loss: 1.8163 - val_VL_attention_linear_output_acc: 0.4794 - val_VH_attention_linear_output_acc: 0.4671\n",
      "Epoch 2287/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5127 - VL_attention_linear_output_loss: 1.7343 - VH_attention_linear_output_loss: 1.7784 - VL_attention_linear_output_acc: 0.4893 - VH_attention_linear_output_acc: 0.4716 - val_loss: 3.7387 - val_VL_attention_linear_output_loss: 1.8528 - val_VH_attention_linear_output_loss: 1.8859 - val_VL_attention_linear_output_acc: 0.4406 - val_VH_attention_linear_output_acc: 0.4383\n",
      "Epoch 2288/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5152 - VL_attention_linear_output_loss: 1.7422 - VH_attention_linear_output_loss: 1.7730 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4740 - val_loss: 3.5945 - val_VL_attention_linear_output_loss: 1.7860 - val_VH_attention_linear_output_loss: 1.8085 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4669\n",
      "Epoch 2289/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5043 - VL_attention_linear_output_loss: 1.7399 - VH_attention_linear_output_loss: 1.7644 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4766 - val_loss: 3.5932 - val_VL_attention_linear_output_loss: 1.7929 - val_VH_attention_linear_output_loss: 1.8003 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.4702\n",
      "Epoch 2290/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5067 - VL_attention_linear_output_loss: 1.7401 - VH_attention_linear_output_loss: 1.7666 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4759 - val_loss: 3.6267 - val_VL_attention_linear_output_loss: 1.7844 - val_VH_attention_linear_output_loss: 1.8422 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4535\n",
      "Epoch 2291/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5172 - VL_attention_linear_output_loss: 1.7450 - VH_attention_linear_output_loss: 1.7722 - VL_attention_linear_output_acc: 0.4840 - VH_attention_linear_output_acc: 0.4735 - val_loss: 3.6015 - val_VL_attention_linear_output_loss: 1.7879 - val_VH_attention_linear_output_loss: 1.8137 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4632\n",
      "Epoch 2292/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5064 - VL_attention_linear_output_loss: 1.7315 - VH_attention_linear_output_loss: 1.7748 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4721 - val_loss: 3.5870 - val_VL_attention_linear_output_loss: 1.7836 - val_VH_attention_linear_output_loss: 1.8034 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.4685\n",
      "Epoch 2293/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4960 - VL_attention_linear_output_loss: 1.7288 - VH_attention_linear_output_loss: 1.7671 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4752 - val_loss: 3.5776 - val_VL_attention_linear_output_loss: 1.7789 - val_VH_attention_linear_output_loss: 1.7986 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4710\n",
      "Epoch 2294/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4903 - VL_attention_linear_output_loss: 1.7286 - VH_attention_linear_output_loss: 1.7617 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4777 - val_loss: 3.5959 - val_VL_attention_linear_output_loss: 1.7863 - val_VH_attention_linear_output_loss: 1.8097 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4643\n",
      "Epoch 2295/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4938 - VL_attention_linear_output_loss: 1.7285 - VH_attention_linear_output_loss: 1.7653 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4764 - val_loss: 3.5791 - val_VL_attention_linear_output_loss: 1.7779 - val_VH_attention_linear_output_loss: 1.8011 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4687\n",
      "Epoch 2296/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5093 - VL_attention_linear_output_loss: 1.7356 - VH_attention_linear_output_loss: 1.7737 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4729 - val_loss: 3.6246 - val_VL_attention_linear_output_loss: 1.7962 - val_VH_attention_linear_output_loss: 1.8284 - val_VL_attention_linear_output_acc: 0.4738 - val_VH_attention_linear_output_acc: 0.4604\n",
      "Epoch 2297/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5128 - VL_attention_linear_output_loss: 1.7401 - VH_attention_linear_output_loss: 1.7727 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4730 - val_loss: 3.6459 - val_VL_attention_linear_output_loss: 1.7964 - val_VH_attention_linear_output_loss: 1.8494 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4490\n",
      "Epoch 2298/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5166 - VL_attention_linear_output_loss: 1.7383 - VH_attention_linear_output_loss: 1.7783 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4709 - val_loss: 3.6353 - val_VL_attention_linear_output_loss: 1.7992 - val_VH_attention_linear_output_loss: 1.8361 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4518\n",
      "Epoch 2299/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4982 - VL_attention_linear_output_loss: 1.7261 - VH_attention_linear_output_loss: 1.7720 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4737 - val_loss: 3.6056 - val_VL_attention_linear_output_loss: 1.8086 - val_VH_attention_linear_output_loss: 1.7970 - val_VL_attention_linear_output_acc: 0.4682 - val_VH_attention_linear_output_acc: 0.4726\n",
      "Epoch 2300/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4980 - VL_attention_linear_output_loss: 1.7318 - VH_attention_linear_output_loss: 1.7662 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.4762 - val_loss: 3.6044 - val_VL_attention_linear_output_loss: 1.7867 - val_VH_attention_linear_output_loss: 1.8177 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4594\n",
      "Epoch 2301/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5161 - VL_attention_linear_output_loss: 1.7395 - VH_attention_linear_output_loss: 1.7766 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4716 - val_loss: 3.6191 - val_VL_attention_linear_output_loss: 1.7900 - val_VH_attention_linear_output_loss: 1.8292 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4609\n",
      "Epoch 2302/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5084 - VL_attention_linear_output_loss: 1.7430 - VH_attention_linear_output_loss: 1.7654 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4768 - val_loss: 3.5907 - val_VL_attention_linear_output_loss: 1.7836 - val_VH_attention_linear_output_loss: 1.8071 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4686\n",
      "Epoch 2303/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5054 - VL_attention_linear_output_loss: 1.7367 - VH_attention_linear_output_loss: 1.7687 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4751 - val_loss: 3.5828 - val_VL_attention_linear_output_loss: 1.7768 - val_VH_attention_linear_output_loss: 1.8059 - val_VL_attention_linear_output_acc: 0.4812 - val_VH_attention_linear_output_acc: 0.4684\n",
      "Epoch 2304/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5112 - VL_attention_linear_output_loss: 1.7346 - VH_attention_linear_output_loss: 1.7766 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4723 - val_loss: 3.5967 - val_VL_attention_linear_output_loss: 1.7962 - val_VH_attention_linear_output_loss: 1.8005 - val_VL_attention_linear_output_acc: 0.4738 - val_VH_attention_linear_output_acc: 0.4710\n",
      "Epoch 2305/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5024 - VL_attention_linear_output_loss: 1.7414 - VH_attention_linear_output_loss: 1.7610 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4775 - val_loss: 3.5975 - val_VL_attention_linear_output_loss: 1.7784 - val_VH_attention_linear_output_loss: 1.8191 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4648\n",
      "Epoch 2306/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5024 - VL_attention_linear_output_loss: 1.7347 - VH_attention_linear_output_loss: 1.7677 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4751 - val_loss: 3.5898 - val_VL_attention_linear_output_loss: 1.7929 - val_VH_attention_linear_output_loss: 1.7969 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.4703\n",
      "Epoch 2307/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5186 - VL_attention_linear_output_loss: 1.7440 - VH_attention_linear_output_loss: 1.7745 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4736 - val_loss: 3.6160 - val_VL_attention_linear_output_loss: 1.7859 - val_VH_attention_linear_output_loss: 1.8301 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4567\n",
      "Epoch 2308/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5128 - VL_attention_linear_output_loss: 1.7332 - VH_attention_linear_output_loss: 1.7796 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4705 - val_loss: 3.5782 - val_VL_attention_linear_output_loss: 1.7790 - val_VH_attention_linear_output_loss: 1.7993 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4708\n",
      "Epoch 2309/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5145 - VL_attention_linear_output_loss: 1.7343 - VH_attention_linear_output_loss: 1.7802 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4711 - val_loss: 3.6477 - val_VL_attention_linear_output_loss: 1.7903 - val_VH_attention_linear_output_loss: 1.8574 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4440\n",
      "Epoch 2310/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5093 - VL_attention_linear_output_loss: 1.7319 - VH_attention_linear_output_loss: 1.7774 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4723 - val_loss: 3.6209 - val_VL_attention_linear_output_loss: 1.7965 - val_VH_attention_linear_output_loss: 1.8244 - val_VL_attention_linear_output_acc: 0.4779 - val_VH_attention_linear_output_acc: 0.4635\n",
      "Epoch 2311/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5070 - VL_attention_linear_output_loss: 1.7397 - VH_attention_linear_output_loss: 1.7673 - VL_attention_linear_output_acc: 0.4864 - VH_attention_linear_output_acc: 0.4760 - val_loss: 3.6229 - val_VL_attention_linear_output_loss: 1.7927 - val_VH_attention_linear_output_loss: 1.8302 - val_VL_attention_linear_output_acc: 0.4784 - val_VH_attention_linear_output_acc: 0.4558\n",
      "Epoch 2312/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5204 - VL_attention_linear_output_loss: 1.7421 - VH_attention_linear_output_loss: 1.7783 - VL_attention_linear_output_acc: 0.4854 - VH_attention_linear_output_acc: 0.4713 - val_loss: 3.5923 - val_VL_attention_linear_output_loss: 1.7826 - val_VH_attention_linear_output_loss: 1.8097 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4676\n",
      "Epoch 2313/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5208 - VL_attention_linear_output_loss: 1.7395 - VH_attention_linear_output_loss: 1.7813 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4707 - val_loss: 3.5953 - val_VL_attention_linear_output_loss: 1.7827 - val_VH_attention_linear_output_loss: 1.8126 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4652\n",
      "Epoch 2314/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5096 - VL_attention_linear_output_loss: 1.7360 - VH_attention_linear_output_loss: 1.7736 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4734 - val_loss: 3.5805 - val_VL_attention_linear_output_loss: 1.7800 - val_VH_attention_linear_output_loss: 1.8005 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4692\n",
      "Epoch 2315/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5124 - VL_attention_linear_output_loss: 1.7451 - VH_attention_linear_output_loss: 1.7673 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4752 - val_loss: 3.6093 - val_VL_attention_linear_output_loss: 1.7968 - val_VH_attention_linear_output_loss: 1.8126 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4658\n",
      "Epoch 2316/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5021 - VL_attention_linear_output_loss: 1.7329 - VH_attention_linear_output_loss: 1.7692 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.4752 - val_loss: 3.5867 - val_VL_attention_linear_output_loss: 1.7761 - val_VH_attention_linear_output_loss: 1.8107 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4667\n",
      "Epoch 2317/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4950 - VL_attention_linear_output_loss: 1.7295 - VH_attention_linear_output_loss: 1.7655 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4768 - val_loss: 3.5867 - val_VL_attention_linear_output_loss: 1.7852 - val_VH_attention_linear_output_loss: 1.8015 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4705\n",
      "Epoch 2318/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5141 - VL_attention_linear_output_loss: 1.7373 - VH_attention_linear_output_loss: 1.7768 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4721 - val_loss: 3.5771 - val_VL_attention_linear_output_loss: 1.7791 - val_VH_attention_linear_output_loss: 1.7980 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 2319/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4956 - VL_attention_linear_output_loss: 1.7311 - VH_attention_linear_output_loss: 1.7645 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4770 - val_loss: 3.6131 - val_VL_attention_linear_output_loss: 1.8028 - val_VH_attention_linear_output_loss: 1.8102 - val_VL_attention_linear_output_acc: 0.4721 - val_VH_attention_linear_output_acc: 0.4672\n",
      "Epoch 2320/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5035 - VL_attention_linear_output_loss: 1.7386 - VH_attention_linear_output_loss: 1.7649 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4763 - val_loss: 3.5903 - val_VL_attention_linear_output_loss: 1.7835 - val_VH_attention_linear_output_loss: 1.8068 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4664\n",
      "Epoch 2321/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5071 - VL_attention_linear_output_loss: 1.7391 - VH_attention_linear_output_loss: 1.7680 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4753 - val_loss: 3.5988 - val_VL_attention_linear_output_loss: 1.7806 - val_VH_attention_linear_output_loss: 1.8182 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4597\n",
      "Epoch 2322/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5031 - VL_attention_linear_output_loss: 1.7285 - VH_attention_linear_output_loss: 1.7746 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4725 - val_loss: 3.6117 - val_VL_attention_linear_output_loss: 1.7983 - val_VH_attention_linear_output_loss: 1.8134 - val_VL_attention_linear_output_acc: 0.4700 - val_VH_attention_linear_output_acc: 0.4597\n",
      "Epoch 2323/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5026 - VL_attention_linear_output_loss: 1.7302 - VH_attention_linear_output_loss: 1.7724 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4733 - val_loss: 3.6366 - val_VL_attention_linear_output_loss: 1.7925 - val_VH_attention_linear_output_loss: 1.8441 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.4513\n",
      "Epoch 2324/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5021 - VL_attention_linear_output_loss: 1.7346 - VH_attention_linear_output_loss: 1.7674 - VL_attention_linear_output_acc: 0.4880 - VH_attention_linear_output_acc: 0.4758 - val_loss: 3.5971 - val_VL_attention_linear_output_loss: 1.7822 - val_VH_attention_linear_output_loss: 1.8149 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4652\n",
      "Epoch 2325/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5031 - VL_attention_linear_output_loss: 1.7347 - VH_attention_linear_output_loss: 1.7684 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4748 - val_loss: 3.5960 - val_VL_attention_linear_output_loss: 1.7796 - val_VH_attention_linear_output_loss: 1.8163 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4649\n",
      "Epoch 2326/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5156 - VL_attention_linear_output_loss: 1.7422 - VH_attention_linear_output_loss: 1.7734 - VL_attention_linear_output_acc: 0.4869 - VH_attention_linear_output_acc: 0.4733 - val_loss: 3.6787 - val_VL_attention_linear_output_loss: 1.8754 - val_VH_attention_linear_output_loss: 1.8033 - val_VL_attention_linear_output_acc: 0.4337 - val_VH_attention_linear_output_acc: 0.4667\n",
      "Epoch 2327/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5217 - VL_attention_linear_output_loss: 1.7477 - VH_attention_linear_output_loss: 1.7740 - VL_attention_linear_output_acc: 0.4822 - VH_attention_linear_output_acc: 0.4729 - val_loss: 3.6214 - val_VL_attention_linear_output_loss: 1.8019 - val_VH_attention_linear_output_loss: 1.8195 - val_VL_attention_linear_output_acc: 0.4725 - val_VH_attention_linear_output_acc: 0.4657\n",
      "Epoch 2328/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4916 - VL_attention_linear_output_loss: 1.7276 - VH_attention_linear_output_loss: 1.7640 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4766 - val_loss: 3.6293 - val_VL_attention_linear_output_loss: 1.8147 - val_VH_attention_linear_output_loss: 1.8146 - val_VL_attention_linear_output_acc: 0.4665 - val_VH_attention_linear_output_acc: 0.4667\n",
      "Epoch 2329/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4971 - VL_attention_linear_output_loss: 1.7320 - VH_attention_linear_output_loss: 1.7651 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4770 - val_loss: 3.5814 - val_VL_attention_linear_output_loss: 1.7818 - val_VH_attention_linear_output_loss: 1.7996 - val_VL_attention_linear_output_acc: 0.4854 - val_VH_attention_linear_output_acc: 0.4705\n",
      "Epoch 2330/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5074 - VL_attention_linear_output_loss: 1.7339 - VH_attention_linear_output_loss: 1.7735 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4729 - val_loss: 3.5963 - val_VL_attention_linear_output_loss: 1.7935 - val_VH_attention_linear_output_loss: 1.8028 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.4738\n",
      "Epoch 2331/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4966 - VL_attention_linear_output_loss: 1.7265 - VH_attention_linear_output_loss: 1.7701 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4756 - val_loss: 3.5913 - val_VL_attention_linear_output_loss: 1.7833 - val_VH_attention_linear_output_loss: 1.8080 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4649\n",
      "Epoch 2332/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5087 - VL_attention_linear_output_loss: 1.7369 - VH_attention_linear_output_loss: 1.7717 - VL_attention_linear_output_acc: 0.4852 - VH_attention_linear_output_acc: 0.4742 - val_loss: 3.5795 - val_VL_attention_linear_output_loss: 1.7802 - val_VH_attention_linear_output_loss: 1.7994 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.4728\n",
      "Epoch 2333/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5059 - VL_attention_linear_output_loss: 1.7356 - VH_attention_linear_output_loss: 1.7703 - VL_attention_linear_output_acc: 0.4863 - VH_attention_linear_output_acc: 0.4746 - val_loss: 3.6052 - val_VL_attention_linear_output_loss: 1.7848 - val_VH_attention_linear_output_loss: 1.8203 - val_VL_attention_linear_output_acc: 0.4685 - val_VH_attention_linear_output_acc: 0.4647\n",
      "Epoch 2334/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5043 - VL_attention_linear_output_loss: 1.7354 - VH_attention_linear_output_loss: 1.7689 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4751 - val_loss: 3.5818 - val_VL_attention_linear_output_loss: 1.7833 - val_VH_attention_linear_output_loss: 1.7985 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4719\n",
      "Epoch 2335/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5018 - VL_attention_linear_output_loss: 1.7358 - VH_attention_linear_output_loss: 1.7660 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4758 - val_loss: 3.5953 - val_VL_attention_linear_output_loss: 1.7912 - val_VH_attention_linear_output_loss: 1.8041 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4690\n",
      "Epoch 2336/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5067 - VL_attention_linear_output_loss: 1.7375 - VH_attention_linear_output_loss: 1.7692 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4746 - val_loss: 3.6317 - val_VL_attention_linear_output_loss: 1.8358 - val_VH_attention_linear_output_loss: 1.7959 - val_VL_attention_linear_output_acc: 0.4552 - val_VH_attention_linear_output_acc: 0.4704\n",
      "Epoch 2337/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5370 - VL_attention_linear_output_loss: 1.7535 - VH_attention_linear_output_loss: 1.7834 - VL_attention_linear_output_acc: 0.4787 - VH_attention_linear_output_acc: 0.4699 - val_loss: 3.5934 - val_VL_attention_linear_output_loss: 1.7813 - val_VH_attention_linear_output_loss: 1.8120 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4666\n",
      "Epoch 2338/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4937 - VL_attention_linear_output_loss: 1.7266 - VH_attention_linear_output_loss: 1.7671 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4759 - val_loss: 3.5712 - val_VL_attention_linear_output_loss: 1.7749 - val_VH_attention_linear_output_loss: 1.7963 - val_VL_attention_linear_output_acc: 0.4867 - val_VH_attention_linear_output_acc: 0.4724\n",
      "Epoch 2339/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4889 - VL_attention_linear_output_loss: 1.7258 - VH_attention_linear_output_loss: 1.7631 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4772 - val_loss: 3.5837 - val_VL_attention_linear_output_loss: 1.7780 - val_VH_attention_linear_output_loss: 1.8057 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4642\n",
      "Epoch 2340/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5073 - VL_attention_linear_output_loss: 1.7409 - VH_attention_linear_output_loss: 1.7664 - VL_attention_linear_output_acc: 0.4851 - VH_attention_linear_output_acc: 0.4761 - val_loss: 3.5885 - val_VL_attention_linear_output_loss: 1.7835 - val_VH_attention_linear_output_loss: 1.8050 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4717\n",
      "Epoch 2341/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5086 - VL_attention_linear_output_loss: 1.7317 - VH_attention_linear_output_loss: 1.7769 - VL_attention_linear_output_acc: 0.4894 - VH_attention_linear_output_acc: 0.4724 - val_loss: 3.5918 - val_VL_attention_linear_output_loss: 1.7886 - val_VH_attention_linear_output_loss: 1.8032 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4685\n",
      "Epoch 2342/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5072 - VL_attention_linear_output_loss: 1.7442 - VH_attention_linear_output_loss: 1.7630 - VL_attention_linear_output_acc: 0.4819 - VH_attention_linear_output_acc: 0.4767 - val_loss: 3.6040 - val_VL_attention_linear_output_loss: 1.7831 - val_VH_attention_linear_output_loss: 1.8209 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4666\n",
      "Epoch 2343/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5038 - VL_attention_linear_output_loss: 1.7316 - VH_attention_linear_output_loss: 1.7721 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4738 - val_loss: 3.7181 - val_VL_attention_linear_output_loss: 1.8426 - val_VH_attention_linear_output_loss: 1.8754 - val_VL_attention_linear_output_acc: 0.4523 - val_VH_attention_linear_output_acc: 0.4326\n",
      "Epoch 2344/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5198 - VL_attention_linear_output_loss: 1.7425 - VH_attention_linear_output_loss: 1.7773 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4711 - val_loss: 3.5785 - val_VL_attention_linear_output_loss: 1.7771 - val_VH_attention_linear_output_loss: 1.8014 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4698\n",
      "Epoch 2345/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5079 - VL_attention_linear_output_loss: 1.7434 - VH_attention_linear_output_loss: 1.7645 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4767 - val_loss: 3.6226 - val_VL_attention_linear_output_loss: 1.7874 - val_VH_attention_linear_output_loss: 1.8352 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4527\n",
      "Epoch 2346/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5098 - VL_attention_linear_output_loss: 1.7418 - VH_attention_linear_output_loss: 1.7680 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4758 - val_loss: 3.5739 - val_VL_attention_linear_output_loss: 1.7735 - val_VH_attention_linear_output_loss: 1.8004 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4705ntion_linear_output_loss: 1.7416 - VH_attention_linear_output_loss: 1.7581 - VL_attention_linear_output_ac\n",
      "Epoch 2347/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5040 - VL_attention_linear_output_loss: 1.7409 - VH_attention_linear_output_loss: 1.7631 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4772 - val_loss: 3.5852 - val_VL_attention_linear_output_loss: 1.7799 - val_VH_attention_linear_output_loss: 1.8052 - val_VL_attention_linear_output_acc: 0.4814 - val_VH_attention_linear_output_acc: 0.4704\n",
      "Epoch 2348/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4978 - VL_attention_linear_output_loss: 1.7327 - VH_attention_linear_output_loss: 1.7651 - VL_attention_linear_output_acc: 0.4895 - VH_attention_linear_output_acc: 0.4766 - val_loss: 3.5850 - val_VL_attention_linear_output_loss: 1.7899 - val_VH_attention_linear_output_loss: 1.7950 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4746\n",
      "Epoch 2349/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5021 - VL_attention_linear_output_loss: 1.7321 - VH_attention_linear_output_loss: 1.7700 - VL_attention_linear_output_acc: 0.4895 - VH_attention_linear_output_acc: 0.4745 - val_loss: 3.5994 - val_VL_attention_linear_output_loss: 1.7903 - val_VH_attention_linear_output_loss: 1.8091 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4674\n",
      "Epoch 2350/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5050 - VL_attention_linear_output_loss: 1.7368 - VH_attention_linear_output_loss: 1.7682 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4752 - val_loss: 3.5990 - val_VL_attention_linear_output_loss: 1.7875 - val_VH_attention_linear_output_loss: 1.8115 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4666\n",
      "Epoch 2351/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5137 - VL_attention_linear_output_loss: 1.7449 - VH_attention_linear_output_loss: 1.7688 - VL_attention_linear_output_acc: 0.4838 - VH_attention_linear_output_acc: 0.4750 - val_loss: 3.6168 - val_VL_attention_linear_output_loss: 1.7827 - val_VH_attention_linear_output_loss: 1.8341 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4592\n",
      "Epoch 2352/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5202 - VL_attention_linear_output_loss: 1.7372 - VH_attention_linear_output_loss: 1.7830 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4689 - val_loss: 3.5916 - val_VL_attention_linear_output_loss: 1.7891 - val_VH_attention_linear_output_loss: 1.8025 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4686\n",
      "Epoch 2353/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5173 - VL_attention_linear_output_loss: 1.7415 - VH_attention_linear_output_loss: 1.7758 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4725 - val_loss: 3.6027 - val_VL_attention_linear_output_loss: 1.7874 - val_VH_attention_linear_output_loss: 1.8152 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4655\n",
      "Epoch 2354/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5060 - VL_attention_linear_output_loss: 1.7320 - VH_attention_linear_output_loss: 1.7740 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4734 - val_loss: 3.5826 - val_VL_attention_linear_output_loss: 1.7767 - val_VH_attention_linear_output_loss: 1.8060 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4706\n",
      "Epoch 2355/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4924 - VL_attention_linear_output_loss: 1.7298 - VH_attention_linear_output_loss: 1.7627 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4775 - val_loss: 3.5870 - val_VL_attention_linear_output_loss: 1.7788 - val_VH_attention_linear_output_loss: 1.8082 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4648\n",
      "Epoch 2356/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5090 - VL_attention_linear_output_loss: 1.7279 - VH_attention_linear_output_loss: 1.7810 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4713 - val_loss: 3.6137 - val_VL_attention_linear_output_loss: 1.7797 - val_VH_attention_linear_output_loss: 1.8341 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4599\n",
      "Epoch 2357/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4997 - VL_attention_linear_output_loss: 1.7371 - VH_attention_linear_output_loss: 1.7625 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4771 - val_loss: 3.5950 - val_VL_attention_linear_output_loss: 1.7938 - val_VH_attention_linear_output_loss: 1.8011 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4720\n",
      "Epoch 2358/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4972 - VL_attention_linear_output_loss: 1.7273 - VH_attention_linear_output_loss: 1.7699 - VL_attention_linear_output_acc: 0.4920 - VH_attention_linear_output_acc: 0.4741 - val_loss: 3.6011 - val_VL_attention_linear_output_loss: 1.7953 - val_VH_attention_linear_output_loss: 1.8058 - val_VL_attention_linear_output_acc: 0.4724 - val_VH_attention_linear_output_acc: 0.4707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2359/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4999 - VL_attention_linear_output_loss: 1.7305 - VH_attention_linear_output_loss: 1.7694 - VL_attention_linear_output_acc: 0.4896 - VH_attention_linear_output_acc: 0.4749 - val_loss: 3.5848 - val_VL_attention_linear_output_loss: 1.7844 - val_VH_attention_linear_output_loss: 1.8003 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4693\n",
      "Epoch 2360/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5020 - VL_attention_linear_output_loss: 1.7325 - VH_attention_linear_output_loss: 1.7695 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4759 - val_loss: 3.5871 - val_VL_attention_linear_output_loss: 1.7922 - val_VH_attention_linear_output_loss: 1.7948 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4728\n",
      "Epoch 2361/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5114 - VL_attention_linear_output_loss: 1.7421 - VH_attention_linear_output_loss: 1.7693 - VL_attention_linear_output_acc: 0.4831 - VH_attention_linear_output_acc: 0.4758 - val_loss: 3.6014 - val_VL_attention_linear_output_loss: 1.7758 - val_VH_attention_linear_output_loss: 1.8256 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4577\n",
      "Epoch 2362/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5020 - VL_attention_linear_output_loss: 1.7375 - VH_attention_linear_output_loss: 1.7645 - VL_attention_linear_output_acc: 0.4864 - VH_attention_linear_output_acc: 0.4772 - val_loss: 3.6232 - val_VL_attention_linear_output_loss: 1.8127 - val_VH_attention_linear_output_loss: 1.8105 - val_VL_attention_linear_output_acc: 0.4620 - val_VH_attention_linear_output_acc: 0.4639\n",
      "Epoch 2363/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5054 - VL_attention_linear_output_loss: 1.7353 - VH_attention_linear_output_loss: 1.7701 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4749 - val_loss: 3.5978 - val_VL_attention_linear_output_loss: 1.7969 - val_VH_attention_linear_output_loss: 1.8009 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.4694\n",
      "Epoch 2364/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5133 - VL_attention_linear_output_loss: 1.7346 - VH_attention_linear_output_loss: 1.7787 - VL_attention_linear_output_acc: 0.4878 - VH_attention_linear_output_acc: 0.4718 - val_loss: 3.6201 - val_VL_attention_linear_output_loss: 1.8112 - val_VH_attention_linear_output_loss: 1.8090 - val_VL_attention_linear_output_acc: 0.4607 - val_VH_attention_linear_output_acc: 0.4658\n",
      "Epoch 2365/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4928 - VL_attention_linear_output_loss: 1.7315 - VH_attention_linear_output_loss: 1.7613 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4776 - val_loss: 3.6218 - val_VL_attention_linear_output_loss: 1.8078 - val_VH_attention_linear_output_loss: 1.8140 - val_VL_attention_linear_output_acc: 0.4627 - val_VH_attention_linear_output_acc: 0.4689\n",
      "Epoch 2366/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4977 - VL_attention_linear_output_loss: 1.7321 - VH_attention_linear_output_loss: 1.7656 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4765 - val_loss: 3.6353 - val_VL_attention_linear_output_loss: 1.7936 - val_VH_attention_linear_output_loss: 1.8417 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4541\n",
      "Epoch 2367/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5126 - VL_attention_linear_output_loss: 1.7383 - VH_attention_linear_output_loss: 1.7743 - VL_attention_linear_output_acc: 0.4861 - VH_attention_linear_output_acc: 0.4731 - val_loss: 3.6060 - val_VL_attention_linear_output_loss: 1.7869 - val_VH_attention_linear_output_loss: 1.8190 - val_VL_attention_linear_output_acc: 0.4828 - val_VH_attention_linear_output_acc: 0.4602\n",
      "Epoch 2368/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4922 - VL_attention_linear_output_loss: 1.7255 - VH_attention_linear_output_loss: 1.7667 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4764 - val_loss: 3.6064 - val_VL_attention_linear_output_loss: 1.7827 - val_VH_attention_linear_output_loss: 1.8237 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4596\n",
      "Epoch 2369/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5100 - VL_attention_linear_output_loss: 1.7371 - VH_attention_linear_output_loss: 1.7729 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4739 - val_loss: 3.5823 - val_VL_attention_linear_output_loss: 1.7875 - val_VH_attention_linear_output_loss: 1.7948 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4724\n",
      "Epoch 2370/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4899 - VL_attention_linear_output_loss: 1.7314 - VH_attention_linear_output_loss: 1.7585 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4790 - val_loss: 3.5831 - val_VL_attention_linear_output_loss: 1.7854 - val_VH_attention_linear_output_loss: 1.7978 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4723\n",
      "Epoch 2371/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5136 - VL_attention_linear_output_loss: 1.7400 - VH_attention_linear_output_loss: 1.7736 - VL_attention_linear_output_acc: 0.4856 - VH_attention_linear_output_acc: 0.4731 - val_loss: 3.6091 - val_VL_attention_linear_output_loss: 1.7946 - val_VH_attention_linear_output_loss: 1.8145 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4661\n",
      "Epoch 2372/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5110 - VL_attention_linear_output_loss: 1.7381 - VH_attention_linear_output_loss: 1.7729 - VL_attention_linear_output_acc: 0.4845 - VH_attention_linear_output_acc: 0.4735 - val_loss: 3.5777 - val_VL_attention_linear_output_loss: 1.7778 - val_VH_attention_linear_output_loss: 1.7998 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4698\n",
      "Epoch 2373/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4971 - VL_attention_linear_output_loss: 1.7252 - VH_attention_linear_output_loss: 1.7719 - VL_attention_linear_output_acc: 0.4928 - VH_attention_linear_output_acc: 0.4740 - val_loss: 3.5779 - val_VL_attention_linear_output_loss: 1.7774 - val_VH_attention_linear_output_loss: 1.8005 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4724\n",
      "Epoch 2374/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4864 - VL_attention_linear_output_loss: 1.7268 - VH_attention_linear_output_loss: 1.7596 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4785 - val_loss: 3.5960 - val_VL_attention_linear_output_loss: 1.7901 - val_VH_attention_linear_output_loss: 1.8059 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4663\n",
      "Epoch 2375/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4913 - VL_attention_linear_output_loss: 1.7334 - VH_attention_linear_output_loss: 1.7578 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4796 - val_loss: 3.5891 - val_VL_attention_linear_output_loss: 1.7835 - val_VH_attention_linear_output_loss: 1.8056 - val_VL_attention_linear_output_acc: 0.4794 - val_VH_attention_linear_output_acc: 0.4700\n",
      "Epoch 2376/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5197 - VL_attention_linear_output_loss: 1.7373 - VH_attention_linear_output_loss: 1.7824 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4696 - val_loss: 3.6090 - val_VL_attention_linear_output_loss: 1.7857 - val_VH_attention_linear_output_loss: 1.8233 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4634\n",
      "Epoch 2377/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4993 - VL_attention_linear_output_loss: 1.7388 - VH_attention_linear_output_loss: 1.7604 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4784 - val_loss: 3.5925 - val_VL_attention_linear_output_loss: 1.7911 - val_VH_attention_linear_output_loss: 1.8014 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.4709\n",
      "Epoch 2378/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4927 - VL_attention_linear_output_loss: 1.7320 - VH_attention_linear_output_loss: 1.7608 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4782 - val_loss: 3.5693 - val_VL_attention_linear_output_loss: 1.7759 - val_VH_attention_linear_output_loss: 1.7934 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4730\n",
      "Epoch 2379/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4957 - VL_attention_linear_output_loss: 1.7313 - VH_attention_linear_output_loss: 1.7645 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4766 - val_loss: 3.5778 - val_VL_attention_linear_output_loss: 1.7806 - val_VH_attention_linear_output_loss: 1.7973 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4709\n",
      "Epoch 2380/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5099 - VL_attention_linear_output_loss: 1.7459 - VH_attention_linear_output_loss: 1.7640 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4777 - val_loss: 3.5784 - val_VL_attention_linear_output_loss: 1.7762 - val_VH_attention_linear_output_loss: 1.8023 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.4663\n",
      "Epoch 2381/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4887 - VL_attention_linear_output_loss: 1.7250 - VH_attention_linear_output_loss: 1.7637 - VL_attention_linear_output_acc: 0.4920 - VH_attention_linear_output_acc: 0.4771 - val_loss: 3.5819 - val_VL_attention_linear_output_loss: 1.7791 - val_VH_attention_linear_output_loss: 1.8028 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4686\n",
      "Epoch 2382/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5056 - VL_attention_linear_output_loss: 1.7262 - VH_attention_linear_output_loss: 1.7794 - VL_attention_linear_output_acc: 0.4928 - VH_attention_linear_output_acc: 0.4721 - val_loss: 3.5990 - val_VL_attention_linear_output_loss: 1.7933 - val_VH_attention_linear_output_loss: 1.8057 - val_VL_attention_linear_output_acc: 0.4676 - val_VH_attention_linear_output_acc: 0.4696\n",
      "Epoch 2383/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4927 - VL_attention_linear_output_loss: 1.7277 - VH_attention_linear_output_loss: 1.7650 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4773 - val_loss: 3.6000 - val_VL_attention_linear_output_loss: 1.7924 - val_VH_attention_linear_output_loss: 1.8077 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4649\n",
      "Epoch 2384/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4986 - VL_attention_linear_output_loss: 1.7314 - VH_attention_linear_output_loss: 1.7672 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4756 - val_loss: 3.5977 - val_VL_attention_linear_output_loss: 1.7789 - val_VH_attention_linear_output_loss: 1.8188 - val_VL_attention_linear_output_acc: 0.4720 - val_VH_attention_linear_output_acc: 0.4639\n",
      "Epoch 2385/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5055 - VL_attention_linear_output_loss: 1.7408 - VH_attention_linear_output_loss: 1.7647 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4767 - val_loss: 3.5825 - val_VL_attention_linear_output_loss: 1.7827 - val_VH_attention_linear_output_loss: 1.7998 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4702\n",
      "Epoch 2386/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4976 - VL_attention_linear_output_loss: 1.7334 - VH_attention_linear_output_loss: 1.7642 - VL_attention_linear_output_acc: 0.4881 - VH_attention_linear_output_acc: 0.4772 - val_loss: 3.5879 - val_VL_attention_linear_output_loss: 1.7790 - val_VH_attention_linear_output_loss: 1.8089 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4658\n",
      "Epoch 2387/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4914 - VL_attention_linear_output_loss: 1.7296 - VH_attention_linear_output_loss: 1.7617 - VL_attention_linear_output_acc: 0.4895 - VH_attention_linear_output_acc: 0.4784 - val_loss: 3.6138 - val_VL_attention_linear_output_loss: 1.7937 - val_VH_attention_linear_output_loss: 1.8201 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4640\n",
      "Epoch 2388/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5114 - VL_attention_linear_output_loss: 1.7478 - VH_attention_linear_output_loss: 1.7636 - VL_attention_linear_output_acc: 0.4801 - VH_attention_linear_output_acc: 0.4768 - val_loss: 3.5915 - val_VL_attention_linear_output_loss: 1.7871 - val_VH_attention_linear_output_loss: 1.8044 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4661\n",
      "Epoch 2389/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5007 - VL_attention_linear_output_loss: 1.7274 - VH_attention_linear_output_loss: 1.7733 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4738 - val_loss: 3.5927 - val_VL_attention_linear_output_loss: 1.7833 - val_VH_attention_linear_output_loss: 1.8093 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4658\n",
      "Epoch 2390/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4948 - VL_attention_linear_output_loss: 1.7287 - VH_attention_linear_output_loss: 1.7661 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4762 - val_loss: 3.5781 - val_VL_attention_linear_output_loss: 1.7765 - val_VH_attention_linear_output_loss: 1.8016 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4703\n",
      "Epoch 2391/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4797 - VL_attention_linear_output_loss: 1.7266 - VH_attention_linear_output_loss: 1.7531 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4812 - val_loss: 3.5736 - val_VL_attention_linear_output_loss: 1.7848 - val_VH_attention_linear_output_loss: 1.7887 - val_VL_attention_linear_output_acc: 0.4774 - val_VH_attention_linear_output_acc: 0.4749\n",
      "Epoch 2392/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5033 - VL_attention_linear_output_loss: 1.7397 - VH_attention_linear_output_loss: 1.7636 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4772 - val_loss: 3.5875 - val_VL_attention_linear_output_loss: 1.7793 - val_VH_attention_linear_output_loss: 1.8082 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4676\n",
      "Epoch 2393/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5060 - VL_attention_linear_output_loss: 1.7393 - VH_attention_linear_output_loss: 1.7666 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4761 - val_loss: 3.5829 - val_VL_attention_linear_output_loss: 1.7824 - val_VH_attention_linear_output_loss: 1.8005 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4711\n",
      "Epoch 2394/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4882 - VL_attention_linear_output_loss: 1.7315 - VH_attention_linear_output_loss: 1.7567 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4800 - val_loss: 3.5816 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.7944 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4737\n",
      "Epoch 2395/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4896 - VL_attention_linear_output_loss: 1.7231 - VH_attention_linear_output_loss: 1.7665 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4757 - val_loss: 3.5833 - val_VL_attention_linear_output_loss: 1.7856 - val_VH_attention_linear_output_loss: 1.7977 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4681\n",
      "Epoch 2396/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5028 - VL_attention_linear_output_loss: 1.7331 - VH_attention_linear_output_loss: 1.7696 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4751 - val_loss: 3.6141 - val_VL_attention_linear_output_loss: 1.8018 - val_VH_attention_linear_output_loss: 1.8122 - val_VL_attention_linear_output_acc: 0.4701 - val_VH_attention_linear_output_acc: 0.4680\n",
      "Epoch 2397/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4939 - VL_attention_linear_output_loss: 1.7315 - VH_attention_linear_output_loss: 1.7624 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4784 - val_loss: 3.5856 - val_VL_attention_linear_output_loss: 1.7941 - val_VH_attention_linear_output_loss: 1.7915 - val_VL_attention_linear_output_acc: 0.4714 - val_VH_attention_linear_output_acc: 0.4732\n",
      "Epoch 2398/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5087 - VL_attention_linear_output_loss: 1.7401 - VH_attention_linear_output_loss: 1.7686 - VL_attention_linear_output_acc: 0.4861 - VH_attention_linear_output_acc: 0.4748 - val_loss: 3.5852 - val_VL_attention_linear_output_loss: 1.7854 - val_VH_attention_linear_output_loss: 1.7998 - val_VL_attention_linear_output_acc: 0.4814 - val_VH_attention_linear_output_acc: 0.4698\n",
      "Epoch 2399/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4858 - VL_attention_linear_output_loss: 1.7279 - VH_attention_linear_output_loss: 1.7579 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4795 - val_loss: 3.5798 - val_VL_attention_linear_output_loss: 1.7859 - val_VH_attention_linear_output_loss: 1.7939 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4718\n",
      "Epoch 2400/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5025 - VL_attention_linear_output_loss: 1.7383 - VH_attention_linear_output_loss: 1.7642 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4773 - val_loss: 3.6012 - val_VL_attention_linear_output_loss: 1.7911 - val_VH_attention_linear_output_loss: 1.8100 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.4684\n",
      "Epoch 2401/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5115 - VL_attention_linear_output_loss: 1.7430 - VH_attention_linear_output_loss: 1.7686 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4757 - val_loss: 3.5654 - val_VL_attention_linear_output_loss: 1.7759 - val_VH_attention_linear_output_loss: 1.7895 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4730\n",
      "Epoch 2402/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4902 - VL_attention_linear_output_loss: 1.7363 - VH_attention_linear_output_loss: 1.7539 - VL_attention_linear_output_acc: 0.4861 - VH_attention_linear_output_acc: 0.4813 - val_loss: 3.6072 - val_VL_attention_linear_output_loss: 1.7953 - val_VH_attention_linear_output_loss: 1.8119 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4641\n",
      "Epoch 2403/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5079 - VL_attention_linear_output_loss: 1.7368 - VH_attention_linear_output_loss: 1.7711 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4745 - val_loss: 3.5923 - val_VL_attention_linear_output_loss: 1.7877 - val_VH_attention_linear_output_loss: 1.8046 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4645\n",
      "Epoch 2404/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4959 - VL_attention_linear_output_loss: 1.7338 - VH_attention_linear_output_loss: 1.7622 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4783 - val_loss: 3.6055 - val_VL_attention_linear_output_loss: 1.8100 - val_VH_attention_linear_output_loss: 1.7955 - val_VL_attention_linear_output_acc: 0.4682 - val_VH_attention_linear_output_acc: 0.4731\n",
      "Epoch 2405/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5038 - VL_attention_linear_output_loss: 1.7366 - VH_attention_linear_output_loss: 1.7673 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4760 - val_loss: 3.5802 - val_VL_attention_linear_output_loss: 1.7880 - val_VH_attention_linear_output_loss: 1.7922 - val_VL_attention_linear_output_acc: 0.4794 - val_VH_attention_linear_output_acc: 0.4736\n",
      "Epoch 2406/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5017 - VL_attention_linear_output_loss: 1.7401 - VH_attention_linear_output_loss: 1.7616 - VL_attention_linear_output_acc: 0.4840 - VH_attention_linear_output_acc: 0.4782 - val_loss: 3.5887 - val_VL_attention_linear_output_loss: 1.7812 - val_VH_attention_linear_output_loss: 1.8075 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4664\n",
      "Epoch 2407/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5108 - VL_attention_linear_output_loss: 1.7423 - VH_attention_linear_output_loss: 1.7685 - VL_attention_linear_output_acc: 0.4837 - VH_attention_linear_output_acc: 0.4755 - val_loss: 3.5828 - val_VL_attention_linear_output_loss: 1.7847 - val_VH_attention_linear_output_loss: 1.7981 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4705\n",
      "Epoch 2408/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4965 - VL_attention_linear_output_loss: 1.7269 - VH_attention_linear_output_loss: 1.7696 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4760 - val_loss: 3.6026 - val_VL_attention_linear_output_loss: 1.8067 - val_VH_attention_linear_output_loss: 1.7960 - val_VL_attention_linear_output_acc: 0.4666 - val_VH_attention_linear_output_acc: 0.4707\n",
      "Epoch 2409/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4820 - VL_attention_linear_output_loss: 1.7238 - VH_attention_linear_output_loss: 1.7582 - VL_attention_linear_output_acc: 0.4945 - VH_attention_linear_output_acc: 0.4792 - val_loss: 3.5788 - val_VL_attention_linear_output_loss: 1.7848 - val_VH_attention_linear_output_loss: 1.7940 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4716\n",
      "Epoch 2410/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4830 - VL_attention_linear_output_loss: 1.7274 - VH_attention_linear_output_loss: 1.7556 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4808 - val_loss: 3.6055 - val_VL_attention_linear_output_loss: 1.7991 - val_VH_attention_linear_output_loss: 1.8064 - val_VL_attention_linear_output_acc: 0.4685 - val_VH_attention_linear_output_acc: 0.4697\n",
      "Epoch 2411/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5030 - VL_attention_linear_output_loss: 1.7329 - VH_attention_linear_output_loss: 1.7702 - VL_attention_linear_output_acc: 0.4877 - VH_attention_linear_output_acc: 0.4751 - val_loss: 3.6020 - val_VL_attention_linear_output_loss: 1.8073 - val_VH_attention_linear_output_loss: 1.7947 - val_VL_attention_linear_output_acc: 0.4724 - val_VH_attention_linear_output_acc: 0.4742\n",
      "Epoch 2412/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5031 - VL_attention_linear_output_loss: 1.7381 - VH_attention_linear_output_loss: 1.7651 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4770 - val_loss: 3.6036 - val_VL_attention_linear_output_loss: 1.8054 - val_VH_attention_linear_output_loss: 1.7982 - val_VL_attention_linear_output_acc: 0.4720 - val_VH_attention_linear_output_acc: 0.4700\n",
      "Epoch 2413/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4900 - VL_attention_linear_output_loss: 1.7284 - VH_attention_linear_output_loss: 1.7615 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4784 - val_loss: 3.5652 - val_VL_attention_linear_output_loss: 1.7773 - val_VH_attention_linear_output_loss: 1.7880 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4758\n",
      "Epoch 2414/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4899 - VL_attention_linear_output_loss: 1.7275 - VH_attention_linear_output_loss: 1.7625 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4783 - val_loss: 3.5814 - val_VL_attention_linear_output_loss: 1.7804 - val_VH_attention_linear_output_loss: 1.8010 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4693\n",
      "Epoch 2415/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4956 - VL_attention_linear_output_loss: 1.7322 - VH_attention_linear_output_loss: 1.7634 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4774 - val_loss: 3.6016 - val_VL_attention_linear_output_loss: 1.7974 - val_VH_attention_linear_output_loss: 1.8042 - val_VL_attention_linear_output_acc: 0.4734 - val_VH_attention_linear_output_acc: 0.4681\n",
      "Epoch 2416/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4817 - VL_attention_linear_output_loss: 1.7283 - VH_attention_linear_output_loss: 1.7534 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4814 - val_loss: 3.5863 - val_VL_attention_linear_output_loss: 1.7870 - val_VH_attention_linear_output_loss: 1.7993 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4721\n",
      "Epoch 2417/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4999 - VL_attention_linear_output_loss: 1.7369 - VH_attention_linear_output_loss: 1.7631 - VL_attention_linear_output_acc: 0.4844 - VH_attention_linear_output_acc: 0.4775 - val_loss: 3.5925 - val_VL_attention_linear_output_loss: 1.7890 - val_VH_attention_linear_output_loss: 1.8035 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.4722\n",
      "Epoch 2418/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5181 - VL_attention_linear_output_loss: 1.7421 - VH_attention_linear_output_loss: 1.7760 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4723 - val_loss: 3.6739 - val_VL_attention_linear_output_loss: 1.8777 - val_VH_attention_linear_output_loss: 1.7962 - val_VL_attention_linear_output_acc: 0.4444 - val_VH_attention_linear_output_acc: 0.4688\n",
      "Epoch 2419/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4831 - VL_attention_linear_output_loss: 1.7292 - VH_attention_linear_output_loss: 1.7539 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4808 - val_loss: 3.5857 - val_VL_attention_linear_output_loss: 1.7939 - val_VH_attention_linear_output_loss: 1.7918 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4733\n",
      "Epoch 2420/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4855 - VL_attention_linear_output_loss: 1.7284 - VH_attention_linear_output_loss: 1.7571 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4802 - val_loss: 3.6277 - val_VL_attention_linear_output_loss: 1.8054 - val_VH_attention_linear_output_loss: 1.8223 - val_VL_attention_linear_output_acc: 0.4664 - val_VH_attention_linear_output_acc: 0.4642\n",
      "Epoch 2421/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4930 - VL_attention_linear_output_loss: 1.7325 - VH_attention_linear_output_loss: 1.7605 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4786 - val_loss: 3.6357 - val_VL_attention_linear_output_loss: 1.8431 - val_VH_attention_linear_output_loss: 1.7927 - val_VL_attention_linear_output_acc: 0.4504 - val_VH_attention_linear_output_acc: 0.4742\n",
      "Epoch 2422/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4784 - VL_attention_linear_output_loss: 1.7244 - VH_attention_linear_output_loss: 1.7540 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.4814 - val_loss: 3.5780 - val_VL_attention_linear_output_loss: 1.7800 - val_VH_attention_linear_output_loss: 1.7979 - val_VL_attention_linear_output_acc: 0.4812 - val_VH_attention_linear_output_acc: 0.4724\n",
      "Epoch 2423/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4931 - VL_attention_linear_output_loss: 1.7378 - VH_attention_linear_output_loss: 1.7553 - VL_attention_linear_output_acc: 0.4858 - VH_attention_linear_output_acc: 0.4811 - val_loss: 3.6166 - val_VL_attention_linear_output_loss: 1.7866 - val_VH_attention_linear_output_loss: 1.8299 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4580\n",
      "Epoch 2424/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5041 - VL_attention_linear_output_loss: 1.7314 - VH_attention_linear_output_loss: 1.7727 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4737 - val_loss: 3.5789 - val_VL_attention_linear_output_loss: 1.7806 - val_VH_attention_linear_output_loss: 1.7983 - val_VL_attention_linear_output_acc: 0.4875 - val_VH_attention_linear_output_acc: 0.4714\n",
      "Epoch 2425/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4902 - VL_attention_linear_output_loss: 1.7353 - VH_attention_linear_output_loss: 1.7549 - VL_attention_linear_output_acc: 0.4881 - VH_attention_linear_output_acc: 0.4803 - val_loss: 3.5837 - val_VL_attention_linear_output_loss: 1.7835 - val_VH_attention_linear_output_loss: 1.8002 - val_VL_attention_linear_output_acc: 0.4743 - val_VH_attention_linear_output_acc: 0.4715\n",
      "Epoch 2426/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4787 - VL_attention_linear_output_loss: 1.7225 - VH_attention_linear_output_loss: 1.7561 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4801 - val_loss: 3.6047 - val_VL_attention_linear_output_loss: 1.7832 - val_VH_attention_linear_output_loss: 1.8215 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4658\n",
      "Epoch 2427/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4783 - VL_attention_linear_output_loss: 1.7231 - VH_attention_linear_output_loss: 1.7552 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4809 - val_loss: 3.5765 - val_VL_attention_linear_output_loss: 1.7821 - val_VH_attention_linear_output_loss: 1.7944 - val_VL_attention_linear_output_acc: 0.4816 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 2428/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5072 - VL_attention_linear_output_loss: 1.7411 - VH_attention_linear_output_loss: 1.7661 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4763 - val_loss: 3.5864 - val_VL_attention_linear_output_loss: 1.7907 - val_VH_attention_linear_output_loss: 1.7957 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4733\n",
      "Epoch 2429/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4748 - VL_attention_linear_output_loss: 1.7224 - VH_attention_linear_output_loss: 1.7524 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4814 - val_loss: 3.5828 - val_VL_attention_linear_output_loss: 1.7801 - val_VH_attention_linear_output_loss: 1.8026 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.4688\n",
      "Epoch 2430/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4842 - VL_attention_linear_output_loss: 1.7245 - VH_attention_linear_output_loss: 1.7596 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4791 - val_loss: 3.5834 - val_VL_attention_linear_output_loss: 1.7895 - val_VH_attention_linear_output_loss: 1.7939 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4770\n",
      "Epoch 2431/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4984 - VL_attention_linear_output_loss: 1.7235 - VH_attention_linear_output_loss: 1.7749 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4732 - val_loss: 3.6052 - val_VL_attention_linear_output_loss: 1.8025 - val_VH_attention_linear_output_loss: 1.8027 - val_VL_attention_linear_output_acc: 0.4688 - val_VH_attention_linear_output_acc: 0.4729\n",
      "Epoch 2432/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4916 - VL_attention_linear_output_loss: 1.7349 - VH_attention_linear_output_loss: 1.7567 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4804 - val_loss: 3.6232 - val_VL_attention_linear_output_loss: 1.7882 - val_VH_attention_linear_output_loss: 1.8350 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4512\n",
      "Epoch 2433/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4912 - VL_attention_linear_output_loss: 1.7300 - VH_attention_linear_output_loss: 1.7612 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4779 - val_loss: 3.5835 - val_VL_attention_linear_output_loss: 1.7882 - val_VH_attention_linear_output_loss: 1.7953 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4723\n",
      "Epoch 2434/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4896 - VL_attention_linear_output_loss: 1.7298 - VH_attention_linear_output_loss: 1.7599 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4794 - val_loss: 3.5984 - val_VL_attention_linear_output_loss: 1.7851 - val_VH_attention_linear_output_loss: 1.8133 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4672\n",
      "Epoch 2435/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5051 - VL_attention_linear_output_loss: 1.7420 - VH_attention_linear_output_loss: 1.7631 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4776 - val_loss: 3.6716 - val_VL_attention_linear_output_loss: 1.8712 - val_VH_attention_linear_output_loss: 1.8005 - val_VL_attention_linear_output_acc: 0.4448 - val_VH_attention_linear_output_acc: 0.4706\n",
      "Epoch 2436/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4879 - VL_attention_linear_output_loss: 1.7276 - VH_attention_linear_output_loss: 1.7603 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4784 - val_loss: 3.5825 - val_VL_attention_linear_output_loss: 1.7866 - val_VH_attention_linear_output_loss: 1.7959 - val_VL_attention_linear_output_acc: 0.4816 - val_VH_attention_linear_output_acc: 0.4729\n",
      "Epoch 2437/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4923 - VL_attention_linear_output_loss: 1.7329 - VH_attention_linear_output_loss: 1.7593 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4789 - val_loss: 3.5696 - val_VL_attention_linear_output_loss: 1.7779 - val_VH_attention_linear_output_loss: 1.7916 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4753\n",
      "Epoch 2438/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5043 - VL_attention_linear_output_loss: 1.7410 - VH_attention_linear_output_loss: 1.7633 - VL_attention_linear_output_acc: 0.4832 - VH_attention_linear_output_acc: 0.4774 - val_loss: 3.5782 - val_VL_attention_linear_output_loss: 1.7840 - val_VH_attention_linear_output_loss: 1.7941 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4753\n",
      "Epoch 2439/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4762 - VL_attention_linear_output_loss: 1.7229 - VH_attention_linear_output_loss: 1.7533 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4818 - val_loss: 3.5717 - val_VL_attention_linear_output_loss: 1.7738 - val_VH_attention_linear_output_loss: 1.7979 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.4764\n",
      "Epoch 2440/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4991 - VL_attention_linear_output_loss: 1.7291 - VH_attention_linear_output_loss: 1.7699 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4747 - val_loss: 3.5996 - val_VL_attention_linear_output_loss: 1.7848 - val_VH_attention_linear_output_loss: 1.8147 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4632\n",
      "Epoch 2441/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4871 - VL_attention_linear_output_loss: 1.7296 - VH_attention_linear_output_loss: 1.7575 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4801 - val_loss: 3.5923 - val_VL_attention_linear_output_loss: 1.7952 - val_VH_attention_linear_output_loss: 1.7970 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.4722\n",
      "Epoch 2442/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4898 - VL_attention_linear_output_loss: 1.7311 - VH_attention_linear_output_loss: 1.7587 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4790 - val_loss: 3.6034 - val_VL_attention_linear_output_loss: 1.8036 - val_VH_attention_linear_output_loss: 1.7997 - val_VL_attention_linear_output_acc: 0.4775 - val_VH_attention_linear_output_acc: 0.4718\n",
      "Epoch 2443/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4920 - VL_attention_linear_output_loss: 1.7298 - VH_attention_linear_output_loss: 1.7622 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4781 - val_loss: 3.5884 - val_VL_attention_linear_output_loss: 1.7894 - val_VH_attention_linear_output_loss: 1.7990 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4708\n",
      "Epoch 2444/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4880 - VL_attention_linear_output_loss: 1.7274 - VH_attention_linear_output_loss: 1.7605 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4788 - val_loss: 3.6290 - val_VL_attention_linear_output_loss: 1.8080 - val_VH_attention_linear_output_loss: 1.8211 - val_VL_attention_linear_output_acc: 0.4672 - val_VH_attention_linear_output_acc: 0.4606\n",
      "Epoch 2445/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4898 - VL_attention_linear_output_loss: 1.7360 - VH_attention_linear_output_loss: 1.7538 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4808 - val_loss: 3.6034 - val_VL_attention_linear_output_loss: 1.8066 - val_VH_attention_linear_output_loss: 1.7967 - val_VL_attention_linear_output_acc: 0.4652 - val_VH_attention_linear_output_acc: 0.4719\n",
      "Epoch 2446/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4932 - VL_attention_linear_output_loss: 1.7325 - VH_attention_linear_output_loss: 1.7607 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4783 - val_loss: 3.5748 - val_VL_attention_linear_output_loss: 1.7811 - val_VH_attention_linear_output_loss: 1.7937 - val_VL_attention_linear_output_acc: 0.4875 - val_VH_attention_linear_output_acc: 0.4751\n",
      "Epoch 2447/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5003 - VL_attention_linear_output_loss: 1.7319 - VH_attention_linear_output_loss: 1.7684 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4756 - val_loss: 3.5845 - val_VL_attention_linear_output_loss: 1.7834 - val_VH_attention_linear_output_loss: 1.8011 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4763\n",
      "Epoch 2448/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4926 - VL_attention_linear_output_loss: 1.7293 - VH_attention_linear_output_loss: 1.7634 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4772 - val_loss: 3.5756 - val_VL_attention_linear_output_loss: 1.7808 - val_VH_attention_linear_output_loss: 1.7948 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4737\n",
      "Epoch 2449/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4887 - VL_attention_linear_output_loss: 1.7339 - VH_attention_linear_output_loss: 1.7548 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4808 - val_loss: 3.6108 - val_VL_attention_linear_output_loss: 1.8096 - val_VH_attention_linear_output_loss: 1.8012 - val_VL_attention_linear_output_acc: 0.4678 - val_VH_attention_linear_output_acc: 0.4712\n",
      "Epoch 2450/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4928 - VL_attention_linear_output_loss: 1.7357 - VH_attention_linear_output_loss: 1.7570 - VL_attention_linear_output_acc: 0.4858 - VH_attention_linear_output_acc: 0.4801 - val_loss: 3.6348 - val_VL_attention_linear_output_loss: 1.8240 - val_VH_attention_linear_output_loss: 1.8108 - val_VL_attention_linear_output_acc: 0.4565 - val_VH_attention_linear_output_acc: 0.4655\n",
      "Epoch 2451/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5059 - VL_attention_linear_output_loss: 1.7358 - VH_attention_linear_output_loss: 1.7701 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4748 - val_loss: 3.5770 - val_VL_attention_linear_output_loss: 1.7851 - val_VH_attention_linear_output_loss: 1.7919 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4745\n",
      "Epoch 2452/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4960 - VL_attention_linear_output_loss: 1.7262 - VH_attention_linear_output_loss: 1.7698 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4753 - val_loss: 3.5893 - val_VL_attention_linear_output_loss: 1.7875 - val_VH_attention_linear_output_loss: 1.8018 - val_VL_attention_linear_output_acc: 0.4805 - val_VH_attention_linear_output_acc: 0.4684\n",
      "Epoch 2453/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4893 - VL_attention_linear_output_loss: 1.7296 - VH_attention_linear_output_loss: 1.7597 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4786 - val_loss: 3.5843 - val_VL_attention_linear_output_loss: 1.7880 - val_VH_attention_linear_output_loss: 1.7963 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4733\n",
      "Epoch 2454/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4904 - VL_attention_linear_output_loss: 1.7338 - VH_attention_linear_output_loss: 1.7566 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4804 - val_loss: 3.6023 - val_VL_attention_linear_output_loss: 1.7962 - val_VH_attention_linear_output_loss: 1.8060 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4665\n",
      "Epoch 2455/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4983 - VL_attention_linear_output_loss: 1.7367 - VH_attention_linear_output_loss: 1.7617 - VL_attention_linear_output_acc: 0.4858 - VH_attention_linear_output_acc: 0.4782 - val_loss: 3.5884 - val_VL_attention_linear_output_loss: 1.7961 - val_VH_attention_linear_output_loss: 1.7923 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4722\n",
      "Epoch 2456/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4892 - VL_attention_linear_output_loss: 1.7282 - VH_attention_linear_output_loss: 1.7609 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4785 - val_loss: 3.5991 - val_VL_attention_linear_output_loss: 1.8069 - val_VH_attention_linear_output_loss: 1.7921 - val_VL_attention_linear_output_acc: 0.4663 - val_VH_attention_linear_output_acc: 0.4783\n",
      "Epoch 2457/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5025 - VL_attention_linear_output_loss: 1.7372 - VH_attention_linear_output_loss: 1.7653 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4771 - val_loss: 3.5786 - val_VL_attention_linear_output_loss: 1.7784 - val_VH_attention_linear_output_loss: 1.8002 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4697\n",
      "Epoch 2458/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4934 - VL_attention_linear_output_loss: 1.7288 - VH_attention_linear_output_loss: 1.7645 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4772 - val_loss: 3.5743 - val_VL_attention_linear_output_loss: 1.7811 - val_VH_attention_linear_output_loss: 1.7933 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4750\n",
      "Epoch 2459/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4977 - VL_attention_linear_output_loss: 1.7377 - VH_attention_linear_output_loss: 1.7600 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4785 - val_loss: 3.5763 - val_VL_attention_linear_output_loss: 1.7822 - val_VH_attention_linear_output_loss: 1.7941 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4738\n",
      "Epoch 2460/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4972 - VL_attention_linear_output_loss: 1.7305 - VH_attention_linear_output_loss: 1.7667 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4760 - val_loss: 3.6129 - val_VL_attention_linear_output_loss: 1.7927 - val_VH_attention_linear_output_loss: 1.8202 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4663\n",
      "Epoch 2461/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5115 - VL_attention_linear_output_loss: 1.7436 - VH_attention_linear_output_loss: 1.7679 - VL_attention_linear_output_acc: 0.4831 - VH_attention_linear_output_acc: 0.4757 - val_loss: 3.5836 - val_VL_attention_linear_output_loss: 1.7869 - val_VH_attention_linear_output_loss: 1.7967 - val_VL_attention_linear_output_acc: 0.4804 - val_VH_attention_linear_output_acc: 0.4705\n",
      "Epoch 2462/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4988 - VL_attention_linear_output_loss: 1.7400 - VH_attention_linear_output_loss: 1.7588 - VL_attention_linear_output_acc: 0.4846 - VH_attention_linear_output_acc: 0.4798 - val_loss: 3.5974 - val_VL_attention_linear_output_loss: 1.7808 - val_VH_attention_linear_output_loss: 1.8166 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4710\n",
      "Epoch 2463/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4839 - VL_attention_linear_output_loss: 1.7241 - VH_attention_linear_output_loss: 1.7598 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.4789 - val_loss: 3.6042 - val_VL_attention_linear_output_loss: 1.7762 - val_VH_attention_linear_output_loss: 1.8280 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4572\n",
      "Epoch 2464/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5073 - VL_attention_linear_output_loss: 1.7407 - VH_attention_linear_output_loss: 1.7666 - VL_attention_linear_output_acc: 0.4835 - VH_attention_linear_output_acc: 0.4765 - val_loss: 3.5931 - val_VL_attention_linear_output_loss: 1.8002 - val_VH_attention_linear_output_loss: 1.7930 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4736\n",
      "Epoch 2465/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4879 - VL_attention_linear_output_loss: 1.7300 - VH_attention_linear_output_loss: 1.7580 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4798 - val_loss: 3.6406 - val_VL_attention_linear_output_loss: 1.8098 - val_VH_attention_linear_output_loss: 1.8308 - val_VL_attention_linear_output_acc: 0.4654 - val_VH_attention_linear_output_acc: 0.4596\n",
      "Epoch 2466/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5026 - VL_attention_linear_output_loss: 1.7391 - VH_attention_linear_output_loss: 1.7635 - VL_attention_linear_output_acc: 0.4843 - VH_attention_linear_output_acc: 0.4776 - val_loss: 3.5830 - val_VL_attention_linear_output_loss: 1.7859 - val_VH_attention_linear_output_loss: 1.7971 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.4716\n",
      "Epoch 2467/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4911 - VL_attention_linear_output_loss: 1.7400 - VH_attention_linear_output_loss: 1.7511 - VL_attention_linear_output_acc: 0.4830 - VH_attention_linear_output_acc: 0.4822 - val_loss: 3.6209 - val_VL_attention_linear_output_loss: 1.8071 - val_VH_attention_linear_output_loss: 1.8138 - val_VL_attention_linear_output_acc: 0.4617 - val_VH_attention_linear_output_acc: 0.4662\n",
      "Epoch 2468/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4903 - VL_attention_linear_output_loss: 1.7337 - VH_attention_linear_output_loss: 1.7566 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4797 - val_loss: 3.5823 - val_VL_attention_linear_output_loss: 1.7765 - val_VH_attention_linear_output_loss: 1.8058 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4693\n",
      "Epoch 2469/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4878 - VL_attention_linear_output_loss: 1.7311 - VH_attention_linear_output_loss: 1.7567 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4798 - val_loss: 3.6257 - val_VL_attention_linear_output_loss: 1.7796 - val_VH_attention_linear_output_loss: 1.8462 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4543\n",
      "Epoch 2470/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4968 - VL_attention_linear_output_loss: 1.7308 - VH_attention_linear_output_loss: 1.7659 - VL_attention_linear_output_acc: 0.4896 - VH_attention_linear_output_acc: 0.4756 - val_loss: 3.5912 - val_VL_attention_linear_output_loss: 1.7866 - val_VH_attention_linear_output_loss: 1.8046 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4672\n",
      "Epoch 2471/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4743 - VL_attention_linear_output_loss: 1.7214 - VH_attention_linear_output_loss: 1.7530 - VL_attention_linear_output_acc: 0.4938 - VH_attention_linear_output_acc: 0.4817 - val_loss: 3.5840 - val_VL_attention_linear_output_loss: 1.7825 - val_VH_attention_linear_output_loss: 1.8014 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4688\n",
      "Epoch 2472/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4957 - VL_attention_linear_output_loss: 1.7271 - VH_attention_linear_output_loss: 1.7686 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4750 - val_loss: 3.5871 - val_VL_attention_linear_output_loss: 1.7933 - val_VH_attention_linear_output_loss: 1.7938 - val_VL_attention_linear_output_acc: 0.4758 - val_VH_attention_linear_output_acc: 0.4731\n",
      "Epoch 2473/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4831 - VL_attention_linear_output_loss: 1.7340 - VH_attention_linear_output_loss: 1.7490 - VL_attention_linear_output_acc: 0.4869 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5856 - val_VL_attention_linear_output_loss: 1.7958 - val_VH_attention_linear_output_loss: 1.7898 - val_VL_attention_linear_output_acc: 0.4684 - val_VH_attention_linear_output_acc: 0.4735\n",
      "Epoch 2474/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4857 - VL_attention_linear_output_loss: 1.7304 - VH_attention_linear_output_loss: 1.7553 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4801 - val_loss: 3.5688 - val_VL_attention_linear_output_loss: 1.7798 - val_VH_attention_linear_output_loss: 1.7889 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4747\n",
      "Epoch 2475/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4829 - VL_attention_linear_output_loss: 1.7320 - VH_attention_linear_output_loss: 1.7509 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4823 - val_loss: 3.5766 - val_VL_attention_linear_output_loss: 1.7817 - val_VH_attention_linear_output_loss: 1.7949 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4730\n",
      "Epoch 2476/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4906 - VL_attention_linear_output_loss: 1.7371 - VH_attention_linear_output_loss: 1.7535 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4811 - val_loss: 3.5716 - val_VL_attention_linear_output_loss: 1.7788 - val_VH_attention_linear_output_loss: 1.7928 - val_VL_attention_linear_output_acc: 0.4870 - val_VH_attention_linear_output_acc: 0.4765\n",
      "Epoch 2477/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5054 - VL_attention_linear_output_loss: 1.7451 - VH_attention_linear_output_loss: 1.7603 - VL_attention_linear_output_acc: 0.4813 - VH_attention_linear_output_acc: 0.4782 - val_loss: 3.5676 - val_VL_attention_linear_output_loss: 1.7743 - val_VH_attention_linear_output_loss: 1.7933 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4718\n",
      "Epoch 2478/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4761 - VL_attention_linear_output_loss: 1.7190 - VH_attention_linear_output_loss: 1.7571 - VL_attention_linear_output_acc: 0.4945 - VH_attention_linear_output_acc: 0.4792 - val_loss: 3.5843 - val_VL_attention_linear_output_loss: 1.7756 - val_VH_attention_linear_output_loss: 1.8087 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4659\n",
      "Epoch 2479/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4854 - VL_attention_linear_output_loss: 1.7263 - VH_attention_linear_output_loss: 1.7591 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4788 - val_loss: 3.5993 - val_VL_attention_linear_output_loss: 1.7856 - val_VH_attention_linear_output_loss: 1.8138 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4662\n",
      "Epoch 2480/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4774 - VL_attention_linear_output_loss: 1.7228 - VH_attention_linear_output_loss: 1.7545 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4811 - val_loss: 3.5906 - val_VL_attention_linear_output_loss: 1.8010 - val_VH_attention_linear_output_loss: 1.7896 - val_VL_attention_linear_output_acc: 0.4788 - val_VH_attention_linear_output_acc: 0.4719\n",
      "Epoch 2481/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4782 - VL_attention_linear_output_loss: 1.7221 - VH_attention_linear_output_loss: 1.7562 - VL_attention_linear_output_acc: 0.4923 - VH_attention_linear_output_acc: 0.4796 - val_loss: 3.5696 - val_VL_attention_linear_output_loss: 1.7767 - val_VH_attention_linear_output_loss: 1.7929 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4738\n",
      "Epoch 2482/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5056 - VL_attention_linear_output_loss: 1.7437 - VH_attention_linear_output_loss: 1.7619 - VL_attention_linear_output_acc: 0.4811 - VH_attention_linear_output_acc: 0.4780 - val_loss: 3.6420 - val_VL_attention_linear_output_loss: 1.7858 - val_VH_attention_linear_output_loss: 1.8562 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4383\n",
      "Epoch 2483/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4925 - VL_attention_linear_output_loss: 1.7221 - VH_attention_linear_output_loss: 1.7703 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4745 - val_loss: 3.6246 - val_VL_attention_linear_output_loss: 1.7923 - val_VH_attention_linear_output_loss: 1.8322 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.4551\n",
      "Epoch 2484/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4765 - VL_attention_linear_output_loss: 1.7233 - VH_attention_linear_output_loss: 1.7532 - VL_attention_linear_output_acc: 0.4923 - VH_attention_linear_output_acc: 0.4813 - val_loss: 3.5708 - val_VL_attention_linear_output_loss: 1.7742 - val_VH_attention_linear_output_loss: 1.7966 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4723\n",
      "Epoch 2485/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4958 - VL_attention_linear_output_loss: 1.7288 - VH_attention_linear_output_loss: 1.7671 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4756 - val_loss: 3.6464 - val_VL_attention_linear_output_loss: 1.7829 - val_VH_attention_linear_output_loss: 1.8635 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4409\n",
      "Epoch 2486/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4921 - VL_attention_linear_output_loss: 1.7320 - VH_attention_linear_output_loss: 1.7601 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4784 - val_loss: 3.6226 - val_VL_attention_linear_output_loss: 1.8173 - val_VH_attention_linear_output_loss: 1.8053 - val_VL_attention_linear_output_acc: 0.4686 - val_VH_attention_linear_output_acc: 0.4662\n",
      "Epoch 2487/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4843 - VL_attention_linear_output_loss: 1.7305 - VH_attention_linear_output_loss: 1.7538 - VL_attention_linear_output_acc: 0.4881 - VH_attention_linear_output_acc: 0.4806 - val_loss: 3.5844 - val_VL_attention_linear_output_loss: 1.7826 - val_VH_attention_linear_output_loss: 1.8018 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4669\n",
      "Epoch 2488/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4890 - VL_attention_linear_output_loss: 1.7283 - VH_attention_linear_output_loss: 1.7607 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4780 - val_loss: 3.5895 - val_VL_attention_linear_output_loss: 1.7875 - val_VH_attention_linear_output_loss: 1.8020 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4697\n",
      "Epoch 2489/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4916 - VL_attention_linear_output_loss: 1.7354 - VH_attention_linear_output_loss: 1.7562 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4802 - val_loss: 3.5842 - val_VL_attention_linear_output_loss: 1.7760 - val_VH_attention_linear_output_loss: 1.8082 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4680\n",
      "Epoch 2490/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4885 - VL_attention_linear_output_loss: 1.7236 - VH_attention_linear_output_loss: 1.7649 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4762 - val_loss: 3.5859 - val_VL_attention_linear_output_loss: 1.7903 - val_VH_attention_linear_output_loss: 1.7957 - val_VL_attention_linear_output_acc: 0.4649 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 2491/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4890 - VL_attention_linear_output_loss: 1.7293 - VH_attention_linear_output_loss: 1.7597 - VL_attention_linear_output_acc: 0.4880 - VH_attention_linear_output_acc: 0.4788 - val_loss: 3.5859 - val_VL_attention_linear_output_loss: 1.7953 - val_VH_attention_linear_output_loss: 1.7906 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4734\n",
      "Epoch 2492/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4794 - VL_attention_linear_output_loss: 1.7237 - VH_attention_linear_output_loss: 1.7557 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4805 - val_loss: 3.5707 - val_VL_attention_linear_output_loss: 1.7753 - val_VH_attention_linear_output_loss: 1.7954 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4737\n",
      "Epoch 2493/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4874 - VL_attention_linear_output_loss: 1.7365 - VH_attention_linear_output_loss: 1.7510 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4814 - val_loss: 3.6138 - val_VL_attention_linear_output_loss: 1.8143 - val_VH_attention_linear_output_loss: 1.7995 - val_VL_attention_linear_output_acc: 0.4639 - val_VH_attention_linear_output_acc: 0.4679\n",
      "Epoch 2494/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4831 - VL_attention_linear_output_loss: 1.7274 - VH_attention_linear_output_loss: 1.7557 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4798 - val_loss: 3.5854 - val_VL_attention_linear_output_loss: 1.7861 - val_VH_attention_linear_output_loss: 1.7993 - val_VL_attention_linear_output_acc: 0.4812 - val_VH_attention_linear_output_acc: 0.4717\n",
      "Epoch 2495/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4953 - VL_attention_linear_output_loss: 1.7295 - VH_attention_linear_output_loss: 1.7658 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4766 - val_loss: 3.5757 - val_VL_attention_linear_output_loss: 1.7802 - val_VH_attention_linear_output_loss: 1.7955 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4724\n",
      "Epoch 2496/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4918 - VL_attention_linear_output_loss: 1.7325 - VH_attention_linear_output_loss: 1.7593 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4789 - val_loss: 3.5810 - val_VL_attention_linear_output_loss: 1.7882 - val_VH_attention_linear_output_loss: 1.7929 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4744\n",
      "Epoch 2497/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4833 - VL_attention_linear_output_loss: 1.7284 - VH_attention_linear_output_loss: 1.7549 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4802 - val_loss: 3.5885 - val_VL_attention_linear_output_loss: 1.7780 - val_VH_attention_linear_output_loss: 1.8105 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4703\n",
      "Epoch 2498/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4900 - VL_attention_linear_output_loss: 1.7288 - VH_attention_linear_output_loss: 1.7612 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4777 - val_loss: 3.5837 - val_VL_attention_linear_output_loss: 1.7894 - val_VH_attention_linear_output_loss: 1.7943 - val_VL_attention_linear_output_acc: 0.4771 - val_VH_attention_linear_output_acc: 0.4747\n",
      "Epoch 2499/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4994 - VL_attention_linear_output_loss: 1.7347 - VH_attention_linear_output_loss: 1.7647 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4770 - val_loss: 3.5919 - val_VL_attention_linear_output_loss: 1.7965 - val_VH_attention_linear_output_loss: 1.7954 - val_VL_attention_linear_output_acc: 0.4681 - val_VH_attention_linear_output_acc: 0.4718\n",
      "Epoch 2500/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4894 - VL_attention_linear_output_loss: 1.7263 - VH_attention_linear_output_loss: 1.7632 - VL_attention_linear_output_acc: 0.4910 - VH_attention_linear_output_acc: 0.4766 - val_loss: 3.5700 - val_VL_attention_linear_output_loss: 1.7770 - val_VH_attention_linear_output_loss: 1.7930 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4726\n",
      "Epoch 2501/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4832 - VL_attention_linear_output_loss: 1.7285 - VH_attention_linear_output_loss: 1.7547 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.4804 - val_loss: 3.5687 - val_VL_attention_linear_output_loss: 1.7755 - val_VH_attention_linear_output_loss: 1.7933 - val_VL_attention_linear_output_acc: 0.4921 - val_VH_attention_linear_output_acc: 0.4721\n",
      "Epoch 2502/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4987 - VL_attention_linear_output_loss: 1.7324 - VH_attention_linear_output_loss: 1.7663 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4762 - val_loss: 3.5686 - val_VL_attention_linear_output_loss: 1.7754 - val_VH_attention_linear_output_loss: 1.7932 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4728\n",
      "Epoch 2503/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4748 - VL_attention_linear_output_loss: 1.7199 - VH_attention_linear_output_loss: 1.7549 - VL_attention_linear_output_acc: 0.4946 - VH_attention_linear_output_acc: 0.4808 - val_loss: 3.5767 - val_VL_attention_linear_output_loss: 1.7818 - val_VH_attention_linear_output_loss: 1.7949 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4699\n",
      "Epoch 2504/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4879 - VL_attention_linear_output_loss: 1.7298 - VH_attention_linear_output_loss: 1.7581 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4787 - val_loss: 3.6015 - val_VL_attention_linear_output_loss: 1.7976 - val_VH_attention_linear_output_loss: 1.8039 - val_VL_attention_linear_output_acc: 0.4740 - val_VH_attention_linear_output_acc: 0.4680\n",
      "Epoch 2505/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4851 - VL_attention_linear_output_loss: 1.7312 - VH_attention_linear_output_loss: 1.7539 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4809 - val_loss: 3.5855 - val_VL_attention_linear_output_loss: 1.7944 - val_VH_attention_linear_output_loss: 1.7911 - val_VL_attention_linear_output_acc: 0.4667 - val_VH_attention_linear_output_acc: 0.4725\n",
      "Epoch 2506/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5007 - VL_attention_linear_output_loss: 1.7419 - VH_attention_linear_output_loss: 1.7587 - VL_attention_linear_output_acc: 0.4835 - VH_attention_linear_output_acc: 0.4792 - val_loss: 3.5865 - val_VL_attention_linear_output_loss: 1.7927 - val_VH_attention_linear_output_loss: 1.7939 - val_VL_attention_linear_output_acc: 0.4768 - val_VH_attention_linear_output_acc: 0.4739\n",
      "Epoch 2507/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4805 - VL_attention_linear_output_loss: 1.7208 - VH_attention_linear_output_loss: 1.7596 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4780 - val_loss: 3.5741 - val_VL_attention_linear_output_loss: 1.7771 - val_VH_attention_linear_output_loss: 1.7971 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4742\n",
      "Epoch 2508/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4915 - VL_attention_linear_output_loss: 1.7244 - VH_attention_linear_output_loss: 1.7672 - VL_attention_linear_output_acc: 0.4910 - VH_attention_linear_output_acc: 0.4758 - val_loss: 3.5976 - val_VL_attention_linear_output_loss: 1.7882 - val_VH_attention_linear_output_loss: 1.8094 - val_VL_attention_linear_output_acc: 0.4769 - val_VH_attention_linear_output_acc: 0.4672\n",
      "Epoch 2509/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4935 - VL_attention_linear_output_loss: 1.7439 - VH_attention_linear_output_loss: 1.7496 - VL_attention_linear_output_acc: 0.4829 - VH_attention_linear_output_acc: 0.4830 - val_loss: 3.5731 - val_VL_attention_linear_output_loss: 1.7824 - val_VH_attention_linear_output_loss: 1.7907 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4747\n",
      "Epoch 2510/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4824 - VL_attention_linear_output_loss: 1.7247 - VH_attention_linear_output_loss: 1.7577 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.4798 - val_loss: 3.5791 - val_VL_attention_linear_output_loss: 1.7847 - val_VH_attention_linear_output_loss: 1.7945 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4720\n",
      "Epoch 2511/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4910 - VL_attention_linear_output_loss: 1.7333 - VH_attention_linear_output_loss: 1.7577 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4802 - val_loss: 3.5820 - val_VL_attention_linear_output_loss: 1.7853 - val_VH_attention_linear_output_loss: 1.7966 - val_VL_attention_linear_output_acc: 0.4767 - val_VH_attention_linear_output_acc: 0.4754\n",
      "Epoch 2512/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4718 - VL_attention_linear_output_loss: 1.7196 - VH_attention_linear_output_loss: 1.7522 - VL_attention_linear_output_acc: 0.4940 - VH_attention_linear_output_acc: 0.4815 - val_loss: 3.5621 - val_VL_attention_linear_output_loss: 1.7757 - val_VH_attention_linear_output_loss: 1.7864 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4765\n",
      "Epoch 2513/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4744 - VL_attention_linear_output_loss: 1.7234 - VH_attention_linear_output_loss: 1.7510 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4824 - val_loss: 3.5772 - val_VL_attention_linear_output_loss: 1.7812 - val_VH_attention_linear_output_loss: 1.7961 - val_VL_attention_linear_output_acc: 0.4812 - val_VH_attention_linear_output_acc: 0.4699\n",
      "Epoch 2514/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4798 - VL_attention_linear_output_loss: 1.7253 - VH_attention_linear_output_loss: 1.7545 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4803 - val_loss: 3.5744 - val_VL_attention_linear_output_loss: 1.7804 - val_VH_attention_linear_output_loss: 1.7940 - val_VL_attention_linear_output_acc: 0.4816 - val_VH_attention_linear_output_acc: 0.4749\n",
      "Epoch 2515/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4899 - VL_attention_linear_output_loss: 1.7371 - VH_attention_linear_output_loss: 1.7528 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4807 - val_loss: 3.5860 - val_VL_attention_linear_output_loss: 1.7896 - val_VH_attention_linear_output_loss: 1.7964 - val_VL_attention_linear_output_acc: 0.4795 - val_VH_attention_linear_output_acc: 0.4670\n",
      "Epoch 2516/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4861 - VL_attention_linear_output_loss: 1.7240 - VH_attention_linear_output_loss: 1.7621 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4770 - val_loss: 3.5711 - val_VL_attention_linear_output_loss: 1.7803 - val_VH_attention_linear_output_loss: 1.7908 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4777\n",
      "Epoch 2517/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4798 - VL_attention_linear_output_loss: 1.7273 - VH_attention_linear_output_loss: 1.7526 - VL_attention_linear_output_acc: 0.4893 - VH_attention_linear_output_acc: 0.4814 - val_loss: 3.5950 - val_VL_attention_linear_output_loss: 1.7706 - val_VH_attention_linear_output_loss: 1.8245 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4594\n",
      "Epoch 2518/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4759 - VL_attention_linear_output_loss: 1.7209 - VH_attention_linear_output_loss: 1.7550 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4804 - val_loss: 3.5580 - val_VL_attention_linear_output_loss: 1.7738 - val_VH_attention_linear_output_loss: 1.7842 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4757\n",
      "Epoch 2519/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4760 - VL_attention_linear_output_loss: 1.7287 - VH_attention_linear_output_loss: 1.7474 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4834 - val_loss: 3.5760 - val_VL_attention_linear_output_loss: 1.7758 - val_VH_attention_linear_output_loss: 1.8002 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 2520/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4870 - VL_attention_linear_output_loss: 1.7281 - VH_attention_linear_output_loss: 1.7590 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4790 - val_loss: 3.5690 - val_VL_attention_linear_output_loss: 1.7853 - val_VH_attention_linear_output_loss: 1.7837 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4796\n",
      "Epoch 2521/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4678 - VL_attention_linear_output_loss: 1.7213 - VH_attention_linear_output_loss: 1.7464 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4839 - val_loss: 3.5635 - val_VL_attention_linear_output_loss: 1.7762 - val_VH_attention_linear_output_loss: 1.7873 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4738\n",
      "Epoch 2522/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4905 - VL_attention_linear_output_loss: 1.7370 - VH_attention_linear_output_loss: 1.7535 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4806 - val_loss: 3.5837 - val_VL_attention_linear_output_loss: 1.7822 - val_VH_attention_linear_output_loss: 1.8016 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4708\n",
      "Epoch 2523/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4939 - VL_attention_linear_output_loss: 1.7337 - VH_attention_linear_output_loss: 1.7602 - VL_attention_linear_output_acc: 0.4879 - VH_attention_linear_output_acc: 0.4781 - val_loss: 3.6305 - val_VL_attention_linear_output_loss: 1.7787 - val_VH_attention_linear_output_loss: 1.8518 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4555\n",
      "Epoch 2524/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4820 - VL_attention_linear_output_loss: 1.7212 - VH_attention_linear_output_loss: 1.7609 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4776 - val_loss: 3.5800 - val_VL_attention_linear_output_loss: 1.7773 - val_VH_attention_linear_output_loss: 1.8027 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4689\n",
      "Epoch 2525/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4799 - VL_attention_linear_output_loss: 1.7261 - VH_attention_linear_output_loss: 1.7538 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4807 - val_loss: 3.5610 - val_VL_attention_linear_output_loss: 1.7753 - val_VH_attention_linear_output_loss: 1.7857 - val_VL_attention_linear_output_acc: 0.4870 - val_VH_attention_linear_output_acc: 0.4734\n",
      "Epoch 2526/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4853 - VL_attention_linear_output_loss: 1.7285 - VH_attention_linear_output_loss: 1.7568 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4791 - val_loss: 3.5690 - val_VL_attention_linear_output_loss: 1.7803 - val_VH_attention_linear_output_loss: 1.7887 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4747\n",
      "Epoch 2527/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4807 - VL_attention_linear_output_loss: 1.7249 - VH_attention_linear_output_loss: 1.7558 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4795 - val_loss: 3.5828 - val_VL_attention_linear_output_loss: 1.7816 - val_VH_attention_linear_output_loss: 1.8012 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4692\n",
      "Epoch 2528/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4816 - VL_attention_linear_output_loss: 1.7282 - VH_attention_linear_output_loss: 1.7534 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4808 - val_loss: 3.5637 - val_VL_attention_linear_output_loss: 1.7715 - val_VH_attention_linear_output_loss: 1.7922 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4724\n",
      "Epoch 2529/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4768 - VL_attention_linear_output_loss: 1.7236 - VH_attention_linear_output_loss: 1.7532 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4811 - val_loss: 3.5766 - val_VL_attention_linear_output_loss: 1.7903 - val_VH_attention_linear_output_loss: 1.7863 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4763\n",
      "Epoch 2530/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4874 - VL_attention_linear_output_loss: 1.7377 - VH_attention_linear_output_loss: 1.7497 - VL_attention_linear_output_acc: 0.4841 - VH_attention_linear_output_acc: 0.4821 - val_loss: 3.6063 - val_VL_attention_linear_output_loss: 1.8218 - val_VH_attention_linear_output_loss: 1.7845 - val_VL_attention_linear_output_acc: 0.4618 - val_VH_attention_linear_output_acc: 0.4766\n",
      "Epoch 2531/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4877 - VL_attention_linear_output_loss: 1.7365 - VH_attention_linear_output_loss: 1.7513 - VL_attention_linear_output_acc: 0.4850 - VH_attention_linear_output_acc: 0.4817 - val_loss: 3.6327 - val_VL_attention_linear_output_loss: 1.7747 - val_VH_attention_linear_output_loss: 1.8580 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4442\n",
      "Epoch 2532/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4891 - VL_attention_linear_output_loss: 1.7270 - VH_attention_linear_output_loss: 1.7621 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.4777 - val_loss: 3.5680 - val_VL_attention_linear_output_loss: 1.7745 - val_VH_attention_linear_output_loss: 1.7935 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4727\n",
      "Epoch 2533/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4813 - VL_attention_linear_output_loss: 1.7281 - VH_attention_linear_output_loss: 1.7532 - VL_attention_linear_output_acc: 0.4895 - VH_attention_linear_output_acc: 0.4810 - val_loss: 3.5720 - val_VL_attention_linear_output_loss: 1.7774 - val_VH_attention_linear_output_loss: 1.7946 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4738\n",
      "Epoch 2534/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4831 - VL_attention_linear_output_loss: 1.7318 - VH_attention_linear_output_loss: 1.7513 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4816 - val_loss: 3.5661 - val_VL_attention_linear_output_loss: 1.7767 - val_VH_attention_linear_output_loss: 1.7894 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4746\n",
      "Epoch 2535/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4890 - VL_attention_linear_output_loss: 1.7312 - VH_attention_linear_output_loss: 1.7579 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4797 - val_loss: 3.5814 - val_VL_attention_linear_output_loss: 1.7730 - val_VH_attention_linear_output_loss: 1.8085 - val_VL_attention_linear_output_acc: 0.4880 - val_VH_attention_linear_output_acc: 0.4712\n",
      "Epoch 2536/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4806 - VL_attention_linear_output_loss: 1.7220 - VH_attention_linear_output_loss: 1.7586 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4792 - val_loss: 3.5690 - val_VL_attention_linear_output_loss: 1.7758 - val_VH_attention_linear_output_loss: 1.7932 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4747\n",
      "Epoch 2537/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4851 - VL_attention_linear_output_loss: 1.7328 - VH_attention_linear_output_loss: 1.7522 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4808 - val_loss: 3.5650 - val_VL_attention_linear_output_loss: 1.7764 - val_VH_attention_linear_output_loss: 1.7886 - val_VL_attention_linear_output_acc: 0.4895 - val_VH_attention_linear_output_acc: 0.4746\n",
      "Epoch 2538/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4948 - VL_attention_linear_output_loss: 1.7293 - VH_attention_linear_output_loss: 1.7655 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4775 - val_loss: 3.5593 - val_VL_attention_linear_output_loss: 1.7769 - val_VH_attention_linear_output_loss: 1.7824 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4755\n",
      "Epoch 2539/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4875 - VL_attention_linear_output_loss: 1.7361 - VH_attention_linear_output_loss: 1.7514 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4818 - val_loss: 3.6068 - val_VL_attention_linear_output_loss: 1.7965 - val_VH_attention_linear_output_loss: 1.8103 - val_VL_attention_linear_output_acc: 0.4720 - val_VH_attention_linear_output_acc: 0.4648\n",
      "Epoch 2540/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.5056 - VL_attention_linear_output_loss: 1.7451 - VH_attention_linear_output_loss: 1.7605 - VL_attention_linear_output_acc: 0.4816 - VH_attention_linear_output_acc: 0.4777 - val_loss: 3.5944 - val_VL_attention_linear_output_loss: 1.7977 - val_VH_attention_linear_output_loss: 1.7967 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.4737\n",
      "Epoch 2541/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4716 - VL_attention_linear_output_loss: 1.7232 - VH_attention_linear_output_loss: 1.7483 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4827 - val_loss: 3.5578 - val_VL_attention_linear_output_loss: 1.7723 - val_VH_attention_linear_output_loss: 1.7855 - val_VL_attention_linear_output_acc: 0.4886 - val_VH_attention_linear_output_acc: 0.4800\n",
      "Epoch 2542/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4812 - VL_attention_linear_output_loss: 1.7258 - VH_attention_linear_output_loss: 1.7554 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4803 - val_loss: 3.5772 - val_VL_attention_linear_output_loss: 1.7833 - val_VH_attention_linear_output_loss: 1.7940 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4741\n",
      "Epoch 2543/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4895 - VL_attention_linear_output_loss: 1.7277 - VH_attention_linear_output_loss: 1.7618 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4776 - val_loss: 3.5864 - val_VL_attention_linear_output_loss: 1.7796 - val_VH_attention_linear_output_loss: 1.8068 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4722\n",
      "Epoch 2544/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4821 - VL_attention_linear_output_loss: 1.7235 - VH_attention_linear_output_loss: 1.7586 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4791 - val_loss: 3.5859 - val_VL_attention_linear_output_loss: 1.7745 - val_VH_attention_linear_output_loss: 1.8114 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.4672\n",
      "Epoch 2545/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4856 - VL_attention_linear_output_loss: 1.7385 - VH_attention_linear_output_loss: 1.7470 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4831 - val_loss: 3.5693 - val_VL_attention_linear_output_loss: 1.7797 - val_VH_attention_linear_output_loss: 1.7896 - val_VL_attention_linear_output_acc: 0.4767 - val_VH_attention_linear_output_acc: 0.4773\n",
      "Epoch 2546/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4694 - VL_attention_linear_output_loss: 1.7202 - VH_attention_linear_output_loss: 1.7492 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4830 - val_loss: 3.5659 - val_VL_attention_linear_output_loss: 1.7739 - val_VH_attention_linear_output_loss: 1.7920 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4721\n",
      "Epoch 2547/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4733 - VL_attention_linear_output_loss: 1.7211 - VH_attention_linear_output_loss: 1.7522 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.4810 - val_loss: 3.7067 - val_VL_attention_linear_output_loss: 1.7775 - val_VH_attention_linear_output_loss: 1.9292 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4097\n",
      "Epoch 2548/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4778 - VL_attention_linear_output_loss: 1.7261 - VH_attention_linear_output_loss: 1.7518 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4817 - val_loss: 3.5707 - val_VL_attention_linear_output_loss: 1.7787 - val_VH_attention_linear_output_loss: 1.7920 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4725\n",
      "Epoch 2549/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4869 - VL_attention_linear_output_loss: 1.7270 - VH_attention_linear_output_loss: 1.7599 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4784 - val_loss: 3.6139 - val_VL_attention_linear_output_loss: 1.8072 - val_VH_attention_linear_output_loss: 1.8067 - val_VL_attention_linear_output_acc: 0.4726 - val_VH_attention_linear_output_acc: 0.4688\n",
      "Epoch 2550/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4839 - VL_attention_linear_output_loss: 1.7311 - VH_attention_linear_output_loss: 1.7528 - VL_attention_linear_output_acc: 0.4878 - VH_attention_linear_output_acc: 0.4808 - val_loss: 3.6142 - val_VL_attention_linear_output_loss: 1.8249 - val_VH_attention_linear_output_loss: 1.7894 - val_VL_attention_linear_output_acc: 0.4611 - val_VH_attention_linear_output_acc: 0.4747\n",
      "Epoch 2551/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4957 - VL_attention_linear_output_loss: 1.7408 - VH_attention_linear_output_loss: 1.7549 - VL_attention_linear_output_acc: 0.4838 - VH_attention_linear_output_acc: 0.4799 - val_loss: 3.5870 - val_VL_attention_linear_output_loss: 1.7937 - val_VH_attention_linear_output_loss: 1.7933 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.4742\n",
      "Epoch 2552/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4811 - VL_attention_linear_output_loss: 1.7327 - VH_attention_linear_output_loss: 1.7484 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4823 - val_loss: 3.5937 - val_VL_attention_linear_output_loss: 1.7782 - val_VH_attention_linear_output_loss: 1.8155 - val_VL_attention_linear_output_acc: 0.4854 - val_VH_attention_linear_output_acc: 0.4615\n",
      "Epoch 2553/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4739 - VL_attention_linear_output_loss: 1.7212 - VH_attention_linear_output_loss: 1.7527 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4816 - val_loss: 3.5665 - val_VL_attention_linear_output_loss: 1.7751 - val_VH_attention_linear_output_loss: 1.7913 - val_VL_attention_linear_output_acc: 0.4896 - val_VH_attention_linear_output_acc: 0.4767\n",
      "Epoch 2554/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4830 - VL_attention_linear_output_loss: 1.7237 - VH_attention_linear_output_loss: 1.7593 - VL_attention_linear_output_acc: 0.4923 - VH_attention_linear_output_acc: 0.4791 - val_loss: 3.5780 - val_VL_attention_linear_output_loss: 1.7827 - val_VH_attention_linear_output_loss: 1.7953 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4702\n",
      "Epoch 2555/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4809 - VL_attention_linear_output_loss: 1.7313 - VH_attention_linear_output_loss: 1.7495 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4818 - val_loss: 3.5531 - val_VL_attention_linear_output_loss: 1.7710 - val_VH_attention_linear_output_loss: 1.7821 - val_VL_attention_linear_output_acc: 0.4872 - val_VH_attention_linear_output_acc: 0.4764\n",
      "Epoch 2556/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4660 - VL_attention_linear_output_loss: 1.7168 - VH_attention_linear_output_loss: 1.7492 - VL_attention_linear_output_acc: 0.4948 - VH_attention_linear_output_acc: 0.4823 - val_loss: 3.5638 - val_VL_attention_linear_output_loss: 1.7765 - val_VH_attention_linear_output_loss: 1.7873 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4773\n",
      "Epoch 2557/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4902 - VL_attention_linear_output_loss: 1.7287 - VH_attention_linear_output_loss: 1.7615 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4765 - val_loss: 3.5992 - val_VL_attention_linear_output_loss: 1.8138 - val_VH_attention_linear_output_loss: 1.7854 - val_VL_attention_linear_output_acc: 0.4609 - val_VH_attention_linear_output_acc: 0.4746\n",
      "Epoch 2558/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4820 - VL_attention_linear_output_loss: 1.7295 - VH_attention_linear_output_loss: 1.7525 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4813 - val_loss: 3.5852 - val_VL_attention_linear_output_loss: 1.7770 - val_VH_attention_linear_output_loss: 1.8082 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4683\n",
      "Epoch 2559/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4836 - VL_attention_linear_output_loss: 1.7324 - VH_attention_linear_output_loss: 1.7512 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4821 - val_loss: 3.5599 - val_VL_attention_linear_output_loss: 1.7771 - val_VH_attention_linear_output_loss: 1.7828 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4744\n",
      "Epoch 2560/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4760 - VL_attention_linear_output_loss: 1.7206 - VH_attention_linear_output_loss: 1.7554 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4796 - val_loss: 3.5993 - val_VL_attention_linear_output_loss: 1.7854 - val_VH_attention_linear_output_loss: 1.8138 - val_VL_attention_linear_output_acc: 0.4778 - val_VH_attention_linear_output_acc: 0.4642\n",
      "Epoch 2561/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4828 - VL_attention_linear_output_loss: 1.7203 - VH_attention_linear_output_loss: 1.7625 - VL_attention_linear_output_acc: 0.4932 - VH_attention_linear_output_acc: 0.4764 - val_loss: 3.5692 - val_VL_attention_linear_output_loss: 1.7772 - val_VH_attention_linear_output_loss: 1.7919 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4708\n",
      "Epoch 2562/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4714 - VL_attention_linear_output_loss: 1.7213 - VH_attention_linear_output_loss: 1.7501 - VL_attention_linear_output_acc: 0.4940 - VH_attention_linear_output_acc: 0.4818 - val_loss: 3.5601 - val_VL_attention_linear_output_loss: 1.7761 - val_VH_attention_linear_output_loss: 1.7841 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4767\n",
      "Epoch 2563/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4823 - VL_attention_linear_output_loss: 1.7296 - VH_attention_linear_output_loss: 1.7527 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4808 - val_loss: 3.5676 - val_VL_attention_linear_output_loss: 1.7867 - val_VH_attention_linear_output_loss: 1.7809 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4793\n",
      "Epoch 2564/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4733 - VL_attention_linear_output_loss: 1.7234 - VH_attention_linear_output_loss: 1.7500 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4821 - val_loss: 3.5891 - val_VL_attention_linear_output_loss: 1.7997 - val_VH_attention_linear_output_loss: 1.7894 - val_VL_attention_linear_output_acc: 0.4746 - val_VH_attention_linear_output_acc: 0.4778\n",
      "Epoch 2565/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4761 - VL_attention_linear_output_loss: 1.7266 - VH_attention_linear_output_loss: 1.7495 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5733 - val_VL_attention_linear_output_loss: 1.7884 - val_VH_attention_linear_output_loss: 1.7849 - val_VL_attention_linear_output_acc: 0.4794 - val_VH_attention_linear_output_acc: 0.4756\n",
      "Epoch 2566/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4801 - VL_attention_linear_output_loss: 1.7266 - VH_attention_linear_output_loss: 1.7535 - VL_attention_linear_output_acc: 0.4896 - VH_attention_linear_output_acc: 0.4812 - val_loss: 3.5749 - val_VL_attention_linear_output_loss: 1.7748 - val_VH_attention_linear_output_loss: 1.8001 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4718\n",
      "Epoch 2567/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4785 - VL_attention_linear_output_loss: 1.7185 - VH_attention_linear_output_loss: 1.7600 - VL_attention_linear_output_acc: 0.4944 - VH_attention_linear_output_acc: 0.4786 - val_loss: 3.5638 - val_VL_attention_linear_output_loss: 1.7808 - val_VH_attention_linear_output_loss: 1.7830 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4760\n",
      "Epoch 2568/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4796 - VL_attention_linear_output_loss: 1.7335 - VH_attention_linear_output_loss: 1.7461 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4836 - val_loss: 3.5814 - val_VL_attention_linear_output_loss: 1.7941 - val_VH_attention_linear_output_loss: 1.7873 - val_VL_attention_linear_output_acc: 0.4687 - val_VH_attention_linear_output_acc: 0.4793\n",
      "Epoch 2569/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4742 - VL_attention_linear_output_loss: 1.7220 - VH_attention_linear_output_loss: 1.7522 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4801 - val_loss: 3.5684 - val_VL_attention_linear_output_loss: 1.7781 - val_VH_attention_linear_output_loss: 1.7903 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4767\n",
      "Epoch 2570/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4723 - VL_attention_linear_output_loss: 1.7232 - VH_attention_linear_output_loss: 1.7491 - VL_attention_linear_output_acc: 0.4928 - VH_attention_linear_output_acc: 0.4820 - val_loss: 3.5844 - val_VL_attention_linear_output_loss: 1.7965 - val_VH_attention_linear_output_loss: 1.7879 - val_VL_attention_linear_output_acc: 0.4748 - val_VH_attention_linear_output_acc: 0.4762\n",
      "Epoch 2571/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4753 - VL_attention_linear_output_loss: 1.7253 - VH_attention_linear_output_loss: 1.7500 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4818 - val_loss: 3.5717 - val_VL_attention_linear_output_loss: 1.7811 - val_VH_attention_linear_output_loss: 1.7906 - val_VL_attention_linear_output_acc: 0.4750 - val_VH_attention_linear_output_acc: 0.4742\n",
      "Epoch 2572/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4880 - VL_attention_linear_output_loss: 1.7337 - VH_attention_linear_output_loss: 1.7543 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4801 - val_loss: 3.5726 - val_VL_attention_linear_output_loss: 1.7771 - val_VH_attention_linear_output_loss: 1.7954 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4753\n",
      "Epoch 2573/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4816 - VL_attention_linear_output_loss: 1.7302 - VH_attention_linear_output_loss: 1.7514 - VL_attention_linear_output_acc: 0.4860 - VH_attention_linear_output_acc: 0.4810 - val_loss: 3.5876 - val_VL_attention_linear_output_loss: 1.7837 - val_VH_attention_linear_output_loss: 1.8039 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4705\n",
      "Epoch 2574/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4851 - VL_attention_linear_output_loss: 1.7311 - VH_attention_linear_output_loss: 1.7540 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4809 - val_loss: 3.5932 - val_VL_attention_linear_output_loss: 1.8010 - val_VH_attention_linear_output_loss: 1.7922 - val_VL_attention_linear_output_acc: 0.4659 - val_VH_attention_linear_output_acc: 0.4729\n",
      "Epoch 2575/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4827 - VL_attention_linear_output_loss: 1.7322 - VH_attention_linear_output_loss: 1.7505 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4818 - val_loss: 3.5845 - val_VL_attention_linear_output_loss: 1.7916 - val_VH_attention_linear_output_loss: 1.7930 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4690\n",
      "Epoch 2576/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4805 - VL_attention_linear_output_loss: 1.7306 - VH_attention_linear_output_loss: 1.7499 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4817 - val_loss: 3.5650 - val_VL_attention_linear_output_loss: 1.7693 - val_VH_attention_linear_output_loss: 1.7957 - val_VL_attention_linear_output_acc: 0.4905 - val_VH_attention_linear_output_acc: 0.4719\n",
      "Epoch 2577/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4809 - VL_attention_linear_output_loss: 1.7252 - VH_attention_linear_output_loss: 1.7558 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4791 - val_loss: 3.5549 - val_VL_attention_linear_output_loss: 1.7718 - val_VH_attention_linear_output_loss: 1.7831 - val_VL_attention_linear_output_acc: 0.4880 - val_VH_attention_linear_output_acc: 0.4790\n",
      "Epoch 2578/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4852 - VL_attention_linear_output_loss: 1.7316 - VH_attention_linear_output_loss: 1.7536 - VL_attention_linear_output_acc: 0.4877 - VH_attention_linear_output_acc: 0.4802 - val_loss: 3.5816 - val_VL_attention_linear_output_loss: 1.7750 - val_VH_attention_linear_output_loss: 1.8066 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4682\n",
      "Epoch 2579/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4655 - VL_attention_linear_output_loss: 1.7168 - VH_attention_linear_output_loss: 1.7486 - VL_attention_linear_output_acc: 0.4957 - VH_attention_linear_output_acc: 0.4821 - val_loss: 3.5570 - val_VL_attention_linear_output_loss: 1.7770 - val_VH_attention_linear_output_loss: 1.7800 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4776\n",
      "Epoch 2580/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4914 - VL_attention_linear_output_loss: 1.7359 - VH_attention_linear_output_loss: 1.7556 - VL_attention_linear_output_acc: 0.4844 - VH_attention_linear_output_acc: 0.4803 - val_loss: 3.5764 - val_VL_attention_linear_output_loss: 1.7906 - val_VH_attention_linear_output_loss: 1.7858 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4739\n",
      "Epoch 2581/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4752 - VL_attention_linear_output_loss: 1.7248 - VH_attention_linear_output_loss: 1.7504 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4812 - val_loss: 3.5834 - val_VL_attention_linear_output_loss: 1.7788 - val_VH_attention_linear_output_loss: 1.8045 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4650\n",
      "Epoch 2582/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4788 - VL_attention_linear_output_loss: 1.7319 - VH_attention_linear_output_loss: 1.7469 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4832 - val_loss: 3.5686 - val_VL_attention_linear_output_loss: 1.7790 - val_VH_attention_linear_output_loss: 1.7896 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4774\n",
      "Epoch 2583/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4737 - VL_attention_linear_output_loss: 1.7228 - VH_attention_linear_output_loss: 1.7509 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4817 - val_loss: 3.5783 - val_VL_attention_linear_output_loss: 1.7796 - val_VH_attention_linear_output_loss: 1.7987 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4723\n",
      "Epoch 2584/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4853 - VL_attention_linear_output_loss: 1.7286 - VH_attention_linear_output_loss: 1.7568 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4785 - val_loss: 3.6322 - val_VL_attention_linear_output_loss: 1.7777 - val_VH_attention_linear_output_loss: 1.8545 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4437\n",
      "Epoch 2585/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4739 - VL_attention_linear_output_loss: 1.7209 - VH_attention_linear_output_loss: 1.7530 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4805 - val_loss: 3.5712 - val_VL_attention_linear_output_loss: 1.7769 - val_VH_attention_linear_output_loss: 1.7943 - val_VL_attention_linear_output_acc: 0.4773 - val_VH_attention_linear_output_acc: 0.4725\n",
      "Epoch 2586/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4682 - VL_attention_linear_output_loss: 1.7215 - VH_attention_linear_output_loss: 1.7467 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5718 - val_VL_attention_linear_output_loss: 1.7749 - val_VH_attention_linear_output_loss: 1.7969 - val_VL_attention_linear_output_acc: 0.4858 - val_VH_attention_linear_output_acc: 0.4714\n",
      "Epoch 2587/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4783 - VL_attention_linear_output_loss: 1.7199 - VH_attention_linear_output_loss: 1.7584 - VL_attention_linear_output_acc: 0.4929 - VH_attention_linear_output_acc: 0.4781 - val_loss: 3.5957 - val_VL_attention_linear_output_loss: 1.7823 - val_VH_attention_linear_output_loss: 1.8134 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4671\n",
      "Epoch 2588/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4772 - VL_attention_linear_output_loss: 1.7247 - VH_attention_linear_output_loss: 1.7525 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4805 - val_loss: 3.5805 - val_VL_attention_linear_output_loss: 1.7772 - val_VH_attention_linear_output_loss: 1.8032 - val_VL_attention_linear_output_acc: 0.4870 - val_VH_attention_linear_output_acc: 0.4691\n",
      "Epoch 2589/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4690 - VL_attention_linear_output_loss: 1.7188 - VH_attention_linear_output_loss: 1.7501 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4810 - val_loss: 3.5776 - val_VL_attention_linear_output_loss: 1.7892 - val_VH_attention_linear_output_loss: 1.7883 - val_VL_attention_linear_output_acc: 0.4793 - val_VH_attention_linear_output_acc: 0.4753\n",
      "Epoch 2590/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4836 - VL_attention_linear_output_loss: 1.7329 - VH_attention_linear_output_loss: 1.7507 - VL_attention_linear_output_acc: 0.4858 - VH_attention_linear_output_acc: 0.4822 - val_loss: 3.5832 - val_VL_attention_linear_output_loss: 1.7764 - val_VH_attention_linear_output_loss: 1.8067 - val_VL_attention_linear_output_acc: 0.4869 - val_VH_attention_linear_output_acc: 0.4674\n",
      "Epoch 2591/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4809 - VL_attention_linear_output_loss: 1.7316 - VH_attention_linear_output_loss: 1.7493 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4822 - val_loss: 3.5597 - val_VL_attention_linear_output_loss: 1.7756 - val_VH_attention_linear_output_loss: 1.7842 - val_VL_attention_linear_output_acc: 0.4860 - val_VH_attention_linear_output_acc: 0.4775\n",
      "Epoch 2592/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4663 - VL_attention_linear_output_loss: 1.7210 - VH_attention_linear_output_loss: 1.7453 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.4837 - val_loss: 3.6193 - val_VL_attention_linear_output_loss: 1.8202 - val_VH_attention_linear_output_loss: 1.7991 - val_VL_attention_linear_output_acc: 0.4688 - val_VH_attention_linear_output_acc: 0.4688\n",
      "Epoch 2593/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4711 - VL_attention_linear_output_loss: 1.7237 - VH_attention_linear_output_loss: 1.7474 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4827 - val_loss: 3.5593 - val_VL_attention_linear_output_loss: 1.7767 - val_VH_attention_linear_output_loss: 1.7827 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.4792\n",
      "Epoch 2594/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4668 - VL_attention_linear_output_loss: 1.7186 - VH_attention_linear_output_loss: 1.7482 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4829 - val_loss: 3.5827 - val_VL_attention_linear_output_loss: 1.7788 - val_VH_attention_linear_output_loss: 1.8039 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 2595/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4827 - VL_attention_linear_output_loss: 1.7272 - VH_attention_linear_output_loss: 1.7555 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4793 - val_loss: 3.6762 - val_VL_attention_linear_output_loss: 1.8872 - val_VH_attention_linear_output_loss: 1.7890 - val_VL_attention_linear_output_acc: 0.4327 - val_VH_attention_linear_output_acc: 0.4752\n",
      "Epoch 2596/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4885 - VL_attention_linear_output_loss: 1.7240 - VH_attention_linear_output_loss: 1.7645 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4759 - val_loss: 3.6047 - val_VL_attention_linear_output_loss: 1.8232 - val_VH_attention_linear_output_loss: 1.7816 - val_VL_attention_linear_output_acc: 0.4607 - val_VH_attention_linear_output_acc: 0.4753\n",
      "Epoch 2597/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4618 - VL_attention_linear_output_loss: 1.7235 - VH_attention_linear_output_loss: 1.7383 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4860 - val_loss: 3.5583 - val_VL_attention_linear_output_loss: 1.7729 - val_VH_attention_linear_output_loss: 1.7854 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4763\n",
      "Epoch 2598/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4842 - VL_attention_linear_output_loss: 1.7321 - VH_attention_linear_output_loss: 1.7521 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4807 - val_loss: 3.5716 - val_VL_attention_linear_output_loss: 1.7880 - val_VH_attention_linear_output_loss: 1.7836 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4749\n",
      "Epoch 2599/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4631 - VL_attention_linear_output_loss: 1.7193 - VH_attention_linear_output_loss: 1.7438 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4839 - val_loss: 3.5685 - val_VL_attention_linear_output_loss: 1.7835 - val_VH_attention_linear_output_loss: 1.7850 - val_VL_attention_linear_output_acc: 0.4784 - val_VH_attention_linear_output_acc: 0.4794\n",
      "Epoch 2600/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4847 - VL_attention_linear_output_loss: 1.7327 - VH_attention_linear_output_loss: 1.7519 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4813 - val_loss: 3.5676 - val_VL_attention_linear_output_loss: 1.7866 - val_VH_attention_linear_output_loss: 1.7809 - val_VL_attention_linear_output_acc: 0.4750 - val_VH_attention_linear_output_acc: 0.4781\n",
      "Epoch 2601/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4767 - VL_attention_linear_output_loss: 1.7269 - VH_attention_linear_output_loss: 1.7498 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4812 - val_loss: 3.5643 - val_VL_attention_linear_output_loss: 1.7794 - val_VH_attention_linear_output_loss: 1.7849 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4803\n",
      "Epoch 2602/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4856 - VL_attention_linear_output_loss: 1.7274 - VH_attention_linear_output_loss: 1.7582 - VL_attention_linear_output_acc: 0.4895 - VH_attention_linear_output_acc: 0.4777 - val_loss: 3.5646 - val_VL_attention_linear_output_loss: 1.7769 - val_VH_attention_linear_output_loss: 1.7877 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4727\n",
      "Epoch 2603/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4694 - VL_attention_linear_output_loss: 1.7181 - VH_attention_linear_output_loss: 1.7513 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.4809 - val_loss: 3.5869 - val_VL_attention_linear_output_loss: 1.7786 - val_VH_attention_linear_output_loss: 1.8083 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4658\n",
      "Epoch 2604/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4871 - VL_attention_linear_output_loss: 1.7311 - VH_attention_linear_output_loss: 1.7560 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4786 - val_loss: 3.5594 - val_VL_attention_linear_output_loss: 1.7709 - val_VH_attention_linear_output_loss: 1.7885 - val_VL_attention_linear_output_acc: 0.4867 - val_VH_attention_linear_output_acc: 0.4743\n",
      "Epoch 2605/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4710 - VL_attention_linear_output_loss: 1.7294 - VH_attention_linear_output_loss: 1.7416 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4855 - val_loss: 3.5673 - val_VL_attention_linear_output_loss: 1.7735 - val_VH_attention_linear_output_loss: 1.7938 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4690\n",
      "Epoch 2606/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4701 - VL_attention_linear_output_loss: 1.7276 - VH_attention_linear_output_loss: 1.7425 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4845 - val_loss: 3.5541 - val_VL_attention_linear_output_loss: 1.7701 - val_VH_attention_linear_output_loss: 1.7840 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4741\n",
      "Epoch 2607/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4662 - VL_attention_linear_output_loss: 1.7220 - VH_attention_linear_output_loss: 1.7442 - VL_attention_linear_output_acc: 0.4923 - VH_attention_linear_output_acc: 0.4833 - val_loss: 3.5629 - val_VL_attention_linear_output_loss: 1.7748 - val_VH_attention_linear_output_loss: 1.7881 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 2608/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4787 - VL_attention_linear_output_loss: 1.7250 - VH_attention_linear_output_loss: 1.7537 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4804 - val_loss: 3.5557 - val_VL_attention_linear_output_loss: 1.7705 - val_VH_attention_linear_output_loss: 1.7852 - val_VL_attention_linear_output_acc: 0.4894 - val_VH_attention_linear_output_acc: 0.4747\n",
      "Epoch 2609/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4651 - VL_attention_linear_output_loss: 1.7210 - VH_attention_linear_output_loss: 1.7441 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4836 - val_loss: 3.5646 - val_VL_attention_linear_output_loss: 1.7770 - val_VH_attention_linear_output_loss: 1.7876 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4752\n",
      "Epoch 2610/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4766 - VL_attention_linear_output_loss: 1.7294 - VH_attention_linear_output_loss: 1.7472 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4817 - val_loss: 3.5894 - val_VL_attention_linear_output_loss: 1.7949 - val_VH_attention_linear_output_loss: 1.7946 - val_VL_attention_linear_output_acc: 0.4721 - val_VH_attention_linear_output_acc: 0.4731\n",
      "Epoch 2611/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4729 - VL_attention_linear_output_loss: 1.7255 - VH_attention_linear_output_loss: 1.7475 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4822 - val_loss: 3.5645 - val_VL_attention_linear_output_loss: 1.7769 - val_VH_attention_linear_output_loss: 1.7876 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4755\n",
      "Epoch 2612/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4803 - VL_attention_linear_output_loss: 1.7302 - VH_attention_linear_output_loss: 1.7501 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4813 - val_loss: 3.5795 - val_VL_attention_linear_output_loss: 1.7886 - val_VH_attention_linear_output_loss: 1.7909 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4746\n",
      "Epoch 2613/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4806 - VL_attention_linear_output_loss: 1.7260 - VH_attention_linear_output_loss: 1.7546 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4795 - val_loss: 3.5749 - val_VL_attention_linear_output_loss: 1.7885 - val_VH_attention_linear_output_loss: 1.7864 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4773\n",
      "Epoch 2614/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4664 - VL_attention_linear_output_loss: 1.7200 - VH_attention_linear_output_loss: 1.7464 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4833 - val_loss: 3.5606 - val_VL_attention_linear_output_loss: 1.7761 - val_VH_attention_linear_output_loss: 1.7844 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4716\n",
      "Epoch 2615/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4675 - VL_attention_linear_output_loss: 1.7209 - VH_attention_linear_output_loss: 1.7466 - VL_attention_linear_output_acc: 0.4928 - VH_attention_linear_output_acc: 0.4823 - val_loss: 3.5651 - val_VL_attention_linear_output_loss: 1.7728 - val_VH_attention_linear_output_loss: 1.7922 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4726\n",
      "Epoch 2616/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4830 - VL_attention_linear_output_loss: 1.7274 - VH_attention_linear_output_loss: 1.7556 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4793 - val_loss: 3.6594 - val_VL_attention_linear_output_loss: 1.7727 - val_VH_attention_linear_output_loss: 1.8867 - val_VL_attention_linear_output_acc: 0.4858 - val_VH_attention_linear_output_acc: 0.4367\n",
      "Epoch 2617/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4895 - VL_attention_linear_output_loss: 1.7387 - VH_attention_linear_output_loss: 1.7508 - VL_attention_linear_output_acc: 0.4842 - VH_attention_linear_output_acc: 0.4816 - val_loss: 3.5571 - val_VL_attention_linear_output_loss: 1.7778 - val_VH_attention_linear_output_loss: 1.7793 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4773\n",
      "Epoch 2618/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4689 - VL_attention_linear_output_loss: 1.7218 - VH_attention_linear_output_loss: 1.7471 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4816 - val_loss: 3.5673 - val_VL_attention_linear_output_loss: 1.7875 - val_VH_attention_linear_output_loss: 1.7797 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4784\n",
      "Epoch 2619/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4660 - VL_attention_linear_output_loss: 1.7238 - VH_attention_linear_output_loss: 1.7421 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4842 - val_loss: 3.5702 - val_VL_attention_linear_output_loss: 1.7720 - val_VH_attention_linear_output_loss: 1.7982 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4662\n",
      "Epoch 2620/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4607 - VL_attention_linear_output_loss: 1.7184 - VH_attention_linear_output_loss: 1.7423 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4840 - val_loss: 3.5965 - val_VL_attention_linear_output_loss: 1.7983 - val_VH_attention_linear_output_loss: 1.7981 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.4696\n",
      "Epoch 2621/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4791 - VL_attention_linear_output_loss: 1.7304 - VH_attention_linear_output_loss: 1.7487 - VL_attention_linear_output_acc: 0.4873 - VH_attention_linear_output_acc: 0.4819 - val_loss: 3.5540 - val_VL_attention_linear_output_loss: 1.7728 - val_VH_attention_linear_output_loss: 1.7812 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4778\n",
      "Epoch 2622/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4642 - VL_attention_linear_output_loss: 1.7203 - VH_attention_linear_output_loss: 1.7439 - VL_attention_linear_output_acc: 0.4933 - VH_attention_linear_output_acc: 0.4839 - val_loss: 3.5515 - val_VL_attention_linear_output_loss: 1.7683 - val_VH_attention_linear_output_loss: 1.7832 - val_VL_attention_linear_output_acc: 0.4869 - val_VH_attention_linear_output_acc: 0.4757\n",
      "Epoch 2623/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4671 - VL_attention_linear_output_loss: 1.7202 - VH_attention_linear_output_loss: 1.7469 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5605 - val_VL_attention_linear_output_loss: 1.7765 - val_VH_attention_linear_output_loss: 1.7840 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4753\n",
      "Epoch 2624/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4645 - VL_attention_linear_output_loss: 1.7216 - VH_attention_linear_output_loss: 1.7430 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4842 - val_loss: 3.5580 - val_VL_attention_linear_output_loss: 1.7707 - val_VH_attention_linear_output_loss: 1.7872 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4749\n",
      "Epoch 2625/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4880 - VL_attention_linear_output_loss: 1.7326 - VH_attention_linear_output_loss: 1.7555 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4787 - val_loss: 3.6202 - val_VL_attention_linear_output_loss: 1.8028 - val_VH_attention_linear_output_loss: 1.8174 - val_VL_attention_linear_output_acc: 0.4714 - val_VH_attention_linear_output_acc: 0.4584\n",
      "Epoch 2626/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4767 - VL_attention_linear_output_loss: 1.7287 - VH_attention_linear_output_loss: 1.7481 - VL_attention_linear_output_acc: 0.4879 - VH_attention_linear_output_acc: 0.4822 - val_loss: 3.6952 - val_VL_attention_linear_output_loss: 1.8104 - val_VH_attention_linear_output_loss: 1.8849 - val_VL_attention_linear_output_acc: 0.4679 - val_VH_attention_linear_output_acc: 0.4314\n",
      "Epoch 2627/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4846 - VL_attention_linear_output_loss: 1.7303 - VH_attention_linear_output_loss: 1.7543 - VL_attention_linear_output_acc: 0.4879 - VH_attention_linear_output_acc: 0.4795 - val_loss: 3.5777 - val_VL_attention_linear_output_loss: 1.7920 - val_VH_attention_linear_output_loss: 1.7857 - val_VL_attention_linear_output_acc: 0.4654 - val_VH_attention_linear_output_acc: 0.4742\n",
      "Epoch 2628/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4648 - VL_attention_linear_output_loss: 1.7248 - VH_attention_linear_output_loss: 1.7400 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4847 - val_loss: 3.5557 - val_VL_attention_linear_output_loss: 1.7699 - val_VH_attention_linear_output_loss: 1.7858 - val_VL_attention_linear_output_acc: 0.4917 - val_VH_attention_linear_output_acc: 0.4762\n",
      "Epoch 2629/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4706 - VL_attention_linear_output_loss: 1.7300 - VH_attention_linear_output_loss: 1.7407 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4848 - val_loss: 3.5645 - val_VL_attention_linear_output_loss: 1.7695 - val_VH_attention_linear_output_loss: 1.7949 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.4748\n",
      "Epoch 2630/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4765 - VL_attention_linear_output_loss: 1.7230 - VH_attention_linear_output_loss: 1.7535 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4794 - val_loss: 3.5889 - val_VL_attention_linear_output_loss: 1.7848 - val_VH_attention_linear_output_loss: 1.8041 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4657\n",
      "Epoch 2631/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4708 - VL_attention_linear_output_loss: 1.7222 - VH_attention_linear_output_loss: 1.7487 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4814 - val_loss: 3.5784 - val_VL_attention_linear_output_loss: 1.7699 - val_VH_attention_linear_output_loss: 1.8085 - val_VL_attention_linear_output_acc: 0.4886 - val_VH_attention_linear_output_acc: 0.4660\n",
      "Epoch 2632/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4708 - VL_attention_linear_output_loss: 1.7228 - VH_attention_linear_output_loss: 1.7479 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4812 - val_loss: 3.5571 - val_VL_attention_linear_output_loss: 1.7739 - val_VH_attention_linear_output_loss: 1.7832 - val_VL_attention_linear_output_acc: 0.4913 - val_VH_attention_linear_output_acc: 0.4753\n",
      "Epoch 2633/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4690 - VL_attention_linear_output_loss: 1.7225 - VH_attention_linear_output_loss: 1.7465 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5918 - val_VL_attention_linear_output_loss: 1.7849 - val_VH_attention_linear_output_loss: 1.8068 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4715\n",
      "Epoch 2634/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4823 - VL_attention_linear_output_loss: 1.7278 - VH_attention_linear_output_loss: 1.7545 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4793 - val_loss: 3.5642 - val_VL_attention_linear_output_loss: 1.7815 - val_VH_attention_linear_output_loss: 1.7828 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4769\n",
      "Epoch 2635/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4956 - VL_attention_linear_output_loss: 1.7432 - VH_attention_linear_output_loss: 1.7524 - VL_attention_linear_output_acc: 0.4809 - VH_attention_linear_output_acc: 0.4804 - val_loss: 3.5668 - val_VL_attention_linear_output_loss: 1.7761 - val_VH_attention_linear_output_loss: 1.7906 - val_VL_attention_linear_output_acc: 0.4771 - val_VH_attention_linear_output_acc: 0.4715\n",
      "Epoch 2636/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4697 - VL_attention_linear_output_loss: 1.7165 - VH_attention_linear_output_loss: 1.7533 - VL_attention_linear_output_acc: 0.4944 - VH_attention_linear_output_acc: 0.4801 - val_loss: 3.5764 - val_VL_attention_linear_output_loss: 1.7795 - val_VH_attention_linear_output_loss: 1.7969 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4691\n",
      "Epoch 2637/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4693 - VL_attention_linear_output_loss: 1.7170 - VH_attention_linear_output_loss: 1.7523 - VL_attention_linear_output_acc: 0.4945 - VH_attention_linear_output_acc: 0.4794 - val_loss: 3.5614 - val_VL_attention_linear_output_loss: 1.7703 - val_VH_attention_linear_output_loss: 1.7911 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4742\n",
      "Epoch 2638/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4673 - VL_attention_linear_output_loss: 1.7230 - VH_attention_linear_output_loss: 1.7443 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4837 - val_loss: 3.6008 - val_VL_attention_linear_output_loss: 1.8138 - val_VH_attention_linear_output_loss: 1.7871 - val_VL_attention_linear_output_acc: 0.4629 - val_VH_attention_linear_output_acc: 0.4800\n",
      "Epoch 2639/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4711 - VL_attention_linear_output_loss: 1.7261 - VH_attention_linear_output_loss: 1.7451 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4829 - val_loss: 3.5778 - val_VL_attention_linear_output_loss: 1.7762 - val_VH_attention_linear_output_loss: 1.8016 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4679\n",
      "Epoch 2640/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4667 - VL_attention_linear_output_loss: 1.7236 - VH_attention_linear_output_loss: 1.7431 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4843 - val_loss: 3.5901 - val_VL_attention_linear_output_loss: 1.7829 - val_VH_attention_linear_output_loss: 1.8072 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4650\n",
      "Epoch 2641/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4931 - VL_attention_linear_output_loss: 1.7404 - VH_attention_linear_output_loss: 1.7526 - VL_attention_linear_output_acc: 0.4834 - VH_attention_linear_output_acc: 0.4797 - val_loss: 3.5704 - val_VL_attention_linear_output_loss: 1.7796 - val_VH_attention_linear_output_loss: 1.7907 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4734\n",
      "Epoch 2642/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4826 - VL_attention_linear_output_loss: 1.7247 - VH_attention_linear_output_loss: 1.7579 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4780 - val_loss: 3.5876 - val_VL_attention_linear_output_loss: 1.7829 - val_VH_attention_linear_output_loss: 1.8046 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4683\n",
      "Epoch 2643/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4722 - VL_attention_linear_output_loss: 1.7188 - VH_attention_linear_output_loss: 1.7534 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4792 - val_loss: 3.5614 - val_VL_attention_linear_output_loss: 1.7790 - val_VH_attention_linear_output_loss: 1.7823 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4732\n",
      "Epoch 2644/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4629 - VL_attention_linear_output_loss: 1.7200 - VH_attention_linear_output_loss: 1.7429 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4839 - val_loss: 3.5679 - val_VL_attention_linear_output_loss: 1.7759 - val_VH_attention_linear_output_loss: 1.7920 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4652\n",
      "Epoch 2645/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4717 - VL_attention_linear_output_loss: 1.7307 - VH_attention_linear_output_loss: 1.7409 - VL_attention_linear_output_acc: 0.4861 - VH_attention_linear_output_acc: 0.4837 - val_loss: 3.5542 - val_VL_attention_linear_output_loss: 1.7756 - val_VH_attention_linear_output_loss: 1.7786 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4748\n",
      "Epoch 2646/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4598 - VL_attention_linear_output_loss: 1.7194 - VH_attention_linear_output_loss: 1.7405 - VL_attention_linear_output_acc: 0.4933 - VH_attention_linear_output_acc: 0.4840 - val_loss: 3.5564 - val_VL_attention_linear_output_loss: 1.7738 - val_VH_attention_linear_output_loss: 1.7827 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4754\n",
      "Epoch 2647/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4598 - VL_attention_linear_output_loss: 1.7203 - VH_attention_linear_output_loss: 1.7394 - VL_attention_linear_output_acc: 0.4929 - VH_attention_linear_output_acc: 0.4845 - val_loss: 3.5675 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.7803 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4763\n",
      "Epoch 2648/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4570 - VL_attention_linear_output_loss: 1.7180 - VH_attention_linear_output_loss: 1.7390 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4846 - val_loss: 3.5544 - val_VL_attention_linear_output_loss: 1.7710 - val_VH_attention_linear_output_loss: 1.7834 - val_VL_attention_linear_output_acc: 0.4904 - val_VH_attention_linear_output_acc: 0.4737\n",
      "Epoch 2649/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4703 - VL_attention_linear_output_loss: 1.7246 - VH_attention_linear_output_loss: 1.7456 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5950 - val_VL_attention_linear_output_loss: 1.7806 - val_VH_attention_linear_output_loss: 1.8144 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4640\n",
      "Epoch 2650/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4727 - VL_attention_linear_output_loss: 1.7243 - VH_attention_linear_output_loss: 1.7485 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4815 - val_loss: 3.5511 - val_VL_attention_linear_output_loss: 1.7695 - val_VH_attention_linear_output_loss: 1.7816 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4744\n",
      "Epoch 2651/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4540 - VL_attention_linear_output_loss: 1.7166 - VH_attention_linear_output_loss: 1.7374 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4852 - val_loss: 3.5585 - val_VL_attention_linear_output_loss: 1.7742 - val_VH_attention_linear_output_loss: 1.7842 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4758\n",
      "Epoch 2652/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4663 - VL_attention_linear_output_loss: 1.7229 - VH_attention_linear_output_loss: 1.7434 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4827 - val_loss: 3.5671 - val_VL_attention_linear_output_loss: 1.7858 - val_VH_attention_linear_output_loss: 1.7813 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.4767\n",
      "Epoch 2653/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4715 - VL_attention_linear_output_loss: 1.7316 - VH_attention_linear_output_loss: 1.7400 - VL_attention_linear_output_acc: 0.4867 - VH_attention_linear_output_acc: 0.4846 - val_loss: 3.5671 - val_VL_attention_linear_output_loss: 1.7821 - val_VH_attention_linear_output_loss: 1.7850 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4750\n",
      "Epoch 2654/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4799 - VL_attention_linear_output_loss: 1.7341 - VH_attention_linear_output_loss: 1.7458 - VL_attention_linear_output_acc: 0.4855 - VH_attention_linear_output_acc: 0.4824 - val_loss: 3.5600 - val_VL_attention_linear_output_loss: 1.7811 - val_VH_attention_linear_output_loss: 1.7789 - val_VL_attention_linear_output_acc: 0.4854 - val_VH_attention_linear_output_acc: 0.4770\n",
      "Epoch 2655/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4565 - VL_attention_linear_output_loss: 1.7144 - VH_attention_linear_output_loss: 1.7420 - VL_attention_linear_output_acc: 0.4948 - VH_attention_linear_output_acc: 0.4834 - val_loss: 3.5620 - val_VL_attention_linear_output_loss: 1.7706 - val_VH_attention_linear_output_loss: 1.7914 - val_VL_attention_linear_output_acc: 0.4870 - val_VH_attention_linear_output_acc: 0.4752\n",
      "Epoch 2656/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4683 - VL_attention_linear_output_loss: 1.7201 - VH_attention_linear_output_loss: 1.7483 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4816 - val_loss: 3.5706 - val_VL_attention_linear_output_loss: 1.7765 - val_VH_attention_linear_output_loss: 1.7941 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4706\n",
      "Epoch 2657/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4597 - VL_attention_linear_output_loss: 1.7156 - VH_attention_linear_output_loss: 1.7441 - VL_attention_linear_output_acc: 0.4953 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5660 - val_VL_attention_linear_output_loss: 1.7796 - val_VH_attention_linear_output_loss: 1.7864 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4764\n",
      "Epoch 2658/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4738 - VL_attention_linear_output_loss: 1.7267 - VH_attention_linear_output_loss: 1.7471 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4820 - val_loss: 3.5547 - val_VL_attention_linear_output_loss: 1.7695 - val_VH_attention_linear_output_loss: 1.7853 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4753\n",
      "Epoch 2659/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4623 - VL_attention_linear_output_loss: 1.7238 - VH_attention_linear_output_loss: 1.7386 - VL_attention_linear_output_acc: 0.4920 - VH_attention_linear_output_acc: 0.4855 - val_loss: 3.5527 - val_VL_attention_linear_output_loss: 1.7735 - val_VH_attention_linear_output_loss: 1.7793 - val_VL_attention_linear_output_acc: 0.4884 - val_VH_attention_linear_output_acc: 0.4768\n",
      "Epoch 2660/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4662 - VL_attention_linear_output_loss: 1.7197 - VH_attention_linear_output_loss: 1.7465 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4819 - val_loss: 3.5634 - val_VL_attention_linear_output_loss: 1.7843 - val_VH_attention_linear_output_loss: 1.7790 - val_VL_attention_linear_output_acc: 0.4781 - val_VH_attention_linear_output_acc: 0.4762\n",
      "Epoch 2661/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4760 - VL_attention_linear_output_loss: 1.7250 - VH_attention_linear_output_loss: 1.7510 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4807 - val_loss: 3.5689 - val_VL_attention_linear_output_loss: 1.7744 - val_VH_attention_linear_output_loss: 1.7945 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4698\n",
      "Epoch 2662/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4802 - VL_attention_linear_output_loss: 1.7293 - VH_attention_linear_output_loss: 1.7509 - VL_attention_linear_output_acc: 0.4877 - VH_attention_linear_output_acc: 0.4803 - val_loss: 3.5720 - val_VL_attention_linear_output_loss: 1.7850 - val_VH_attention_linear_output_loss: 1.7870 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4727\n",
      "Epoch 2663/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4692 - VL_attention_linear_output_loss: 1.7206 - VH_attention_linear_output_loss: 1.7486 - VL_attention_linear_output_acc: 0.4932 - VH_attention_linear_output_acc: 0.4813 - val_loss: 3.5745 - val_VL_attention_linear_output_loss: 1.7938 - val_VH_attention_linear_output_loss: 1.7807 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 2664/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4694 - VL_attention_linear_output_loss: 1.7257 - VH_attention_linear_output_loss: 1.7437 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4822 - val_loss: 3.5778 - val_VL_attention_linear_output_loss: 1.7799 - val_VH_attention_linear_output_loss: 1.7978 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 2665/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4655 - VL_attention_linear_output_loss: 1.7206 - VH_attention_linear_output_loss: 1.7449 - VL_attention_linear_output_acc: 0.4928 - VH_attention_linear_output_acc: 0.4822 - val_loss: 3.5896 - val_VL_attention_linear_output_loss: 1.8033 - val_VH_attention_linear_output_loss: 1.7863 - val_VL_attention_linear_output_acc: 0.4636 - val_VH_attention_linear_output_acc: 0.4724\n",
      "Epoch 2666/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4611 - VL_attention_linear_output_loss: 1.7215 - VH_attention_linear_output_loss: 1.7396 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4839 - val_loss: 3.5760 - val_VL_attention_linear_output_loss: 1.7906 - val_VH_attention_linear_output_loss: 1.7854 - val_VL_attention_linear_output_acc: 0.4761 - val_VH_attention_linear_output_acc: 0.4756\n",
      "Epoch 2667/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4756 - VL_attention_linear_output_loss: 1.7241 - VH_attention_linear_output_loss: 1.7515 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4793 - val_loss: 3.5804 - val_VL_attention_linear_output_loss: 1.7762 - val_VH_attention_linear_output_loss: 1.8042 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4671\n",
      "Epoch 2668/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4814 - VL_attention_linear_output_loss: 1.7299 - VH_attention_linear_output_loss: 1.7515 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4798 - val_loss: 3.5924 - val_VL_attention_linear_output_loss: 1.7860 - val_VH_attention_linear_output_loss: 1.8065 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4613\n",
      "Epoch 2669/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4646 - VL_attention_linear_output_loss: 1.7202 - VH_attention_linear_output_loss: 1.7444 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4825 - val_loss: 3.5517 - val_VL_attention_linear_output_loss: 1.7709 - val_VH_attention_linear_output_loss: 1.7808 - val_VL_attention_linear_output_acc: 0.4886 - val_VH_attention_linear_output_acc: 0.4779\n",
      "Epoch 2670/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4631 - VL_attention_linear_output_loss: 1.7236 - VH_attention_linear_output_loss: 1.7396 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4847 - val_loss: 3.5681 - val_VL_attention_linear_output_loss: 1.7750 - val_VH_attention_linear_output_loss: 1.7931 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4710\n",
      "Epoch 2671/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4683 - VL_attention_linear_output_loss: 1.7240 - VH_attention_linear_output_loss: 1.7443 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4821 - val_loss: 3.5817 - val_VL_attention_linear_output_loss: 1.7785 - val_VH_attention_linear_output_loss: 1.8032 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4624\n",
      "Epoch 2672/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4725 - VL_attention_linear_output_loss: 1.7259 - VH_attention_linear_output_loss: 1.7466 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4819 - val_loss: 3.5656 - val_VL_attention_linear_output_loss: 1.7754 - val_VH_attention_linear_output_loss: 1.7902 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4736\n",
      "Epoch 2673/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4775 - VL_attention_linear_output_loss: 1.7356 - VH_attention_linear_output_loss: 1.7419 - VL_attention_linear_output_acc: 0.4839 - VH_attention_linear_output_acc: 0.4835 - val_loss: 3.5501 - val_VL_attention_linear_output_loss: 1.7710 - val_VH_attention_linear_output_loss: 1.7790 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4776\n",
      "Epoch 2674/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4699 - VL_attention_linear_output_loss: 1.7220 - VH_attention_linear_output_loss: 1.7478 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4809 - val_loss: 3.5587 - val_VL_attention_linear_output_loss: 1.7721 - val_VH_attention_linear_output_loss: 1.7867 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4711\n",
      "Epoch 2675/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4674 - VL_attention_linear_output_loss: 1.7186 - VH_attention_linear_output_loss: 1.7488 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4807 - val_loss: 3.5698 - val_VL_attention_linear_output_loss: 1.7709 - val_VH_attention_linear_output_loss: 1.7990 - val_VL_attention_linear_output_acc: 0.4860 - val_VH_attention_linear_output_acc: 0.4670\n",
      "Epoch 2676/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4620 - VL_attention_linear_output_loss: 1.7210 - VH_attention_linear_output_loss: 1.7410 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4836 - val_loss: 3.6008 - val_VL_attention_linear_output_loss: 1.8196 - val_VH_attention_linear_output_loss: 1.7811 - val_VL_attention_linear_output_acc: 0.4536 - val_VH_attention_linear_output_acc: 0.4806\n",
      "Epoch 2677/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4743 - VL_attention_linear_output_loss: 1.7292 - VH_attention_linear_output_loss: 1.7451 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4821 - val_loss: 3.5681 - val_VL_attention_linear_output_loss: 1.7756 - val_VH_attention_linear_output_loss: 1.7925 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4739\n",
      "Epoch 2678/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4709 - VL_attention_linear_output_loss: 1.7211 - VH_attention_linear_output_loss: 1.7498 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4808 - val_loss: 3.5633 - val_VL_attention_linear_output_loss: 1.7756 - val_VH_attention_linear_output_loss: 1.7877 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4731\n",
      "Epoch 2679/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4622 - VL_attention_linear_output_loss: 1.7220 - VH_attention_linear_output_loss: 1.7403 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4849 - val_loss: 3.5693 - val_VL_attention_linear_output_loss: 1.7851 - val_VH_attention_linear_output_loss: 1.7842 - val_VL_attention_linear_output_acc: 0.4775 - val_VH_attention_linear_output_acc: 0.4757\n",
      "Epoch 2680/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4558 - VL_attention_linear_output_loss: 1.7175 - VH_attention_linear_output_loss: 1.7384 - VL_attention_linear_output_acc: 0.4923 - VH_attention_linear_output_acc: 0.4849 - val_loss: 3.5736 - val_VL_attention_linear_output_loss: 1.7766 - val_VH_attention_linear_output_loss: 1.7970 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4684\n",
      "Epoch 2681/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4666 - VL_attention_linear_output_loss: 1.7219 - VH_attention_linear_output_loss: 1.7447 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4820 - val_loss: 3.5525 - val_VL_attention_linear_output_loss: 1.7716 - val_VH_attention_linear_output_loss: 1.7809 - val_VL_attention_linear_output_acc: 0.4913 - val_VH_attention_linear_output_acc: 0.4757\n",
      "Epoch 2682/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4761 - VL_attention_linear_output_loss: 1.7301 - VH_attention_linear_output_loss: 1.7459 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4824 - val_loss: 3.5480 - val_VL_attention_linear_output_loss: 1.7727 - val_VH_attention_linear_output_loss: 1.7754 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4783\n",
      "Epoch 2683/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4610 - VL_attention_linear_output_loss: 1.7180 - VH_attention_linear_output_loss: 1.7430 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4830 - val_loss: 3.5636 - val_VL_attention_linear_output_loss: 1.7757 - val_VH_attention_linear_output_loss: 1.7879 - val_VL_attention_linear_output_acc: 0.4869 - val_VH_attention_linear_output_acc: 0.4736\n",
      "Epoch 2684/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4569 - VL_attention_linear_output_loss: 1.7149 - VH_attention_linear_output_loss: 1.7421 - VL_attention_linear_output_acc: 0.4941 - VH_attention_linear_output_acc: 0.4835 - val_loss: 3.5591 - val_VL_attention_linear_output_loss: 1.7715 - val_VH_attention_linear_output_loss: 1.7876 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4726\n",
      "Epoch 2685/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4586 - VL_attention_linear_output_loss: 1.7154 - VH_attention_linear_output_loss: 1.7432 - VL_attention_linear_output_acc: 0.4944 - VH_attention_linear_output_acc: 0.4823 - val_loss: 3.5660 - val_VL_attention_linear_output_loss: 1.7811 - val_VH_attention_linear_output_loss: 1.7849 - val_VL_attention_linear_output_acc: 0.4777 - val_VH_attention_linear_output_acc: 0.4760\n",
      "Epoch 2686/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4760 - VL_attention_linear_output_loss: 1.7365 - VH_attention_linear_output_loss: 1.7395 - VL_attention_linear_output_acc: 0.4838 - VH_attention_linear_output_acc: 0.4841 - val_loss: 3.5570 - val_VL_attention_linear_output_loss: 1.7696 - val_VH_attention_linear_output_loss: 1.7874 - val_VL_attention_linear_output_acc: 0.4869 - val_VH_attention_linear_output_acc: 0.4753\n",
      "Epoch 2687/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4515 - VL_attention_linear_output_loss: 1.7122 - VH_attention_linear_output_loss: 1.7393 - VL_attention_linear_output_acc: 0.4960 - VH_attention_linear_output_acc: 0.4841 - val_loss: 3.5736 - val_VL_attention_linear_output_loss: 1.7770 - val_VH_attention_linear_output_loss: 1.7966 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 2688/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4603 - VL_attention_linear_output_loss: 1.7186 - VH_attention_linear_output_loss: 1.7417 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4839 - val_loss: 3.5817 - val_VL_attention_linear_output_loss: 1.7674 - val_VH_attention_linear_output_loss: 1.8142 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4630\n",
      "Epoch 2689/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4659 - VL_attention_linear_output_loss: 1.7242 - VH_attention_linear_output_loss: 1.7417 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4836 - val_loss: 3.5778 - val_VL_attention_linear_output_loss: 1.7729 - val_VH_attention_linear_output_loss: 1.8048 - val_VL_attention_linear_output_acc: 0.4860 - val_VH_attention_linear_output_acc: 0.4644\n",
      "Epoch 2690/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4663 - VL_attention_linear_output_loss: 1.7243 - VH_attention_linear_output_loss: 1.7419 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4831 - val_loss: 3.5512 - val_VL_attention_linear_output_loss: 1.7666 - val_VH_attention_linear_output_loss: 1.7846 - val_VL_attention_linear_output_acc: 0.4891 - val_VH_attention_linear_output_acc: 0.4730\n",
      "Epoch 2691/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4589 - VL_attention_linear_output_loss: 1.7178 - VH_attention_linear_output_loss: 1.7411 - VL_attention_linear_output_acc: 0.4920 - VH_attention_linear_output_acc: 0.4832 - val_loss: 3.5699 - val_VL_attention_linear_output_loss: 1.7893 - val_VH_attention_linear_output_loss: 1.7806 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4772\n",
      "Epoch 2692/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4677 - VL_attention_linear_output_loss: 1.7261 - VH_attention_linear_output_loss: 1.7416 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4832 - val_loss: 3.5584 - val_VL_attention_linear_output_loss: 1.7780 - val_VH_attention_linear_output_loss: 1.7804 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.4767\n",
      "Epoch 2693/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4593 - VL_attention_linear_output_loss: 1.7169 - VH_attention_linear_output_loss: 1.7424 - VL_attention_linear_output_acc: 0.4947 - VH_attention_linear_output_acc: 0.4832 - val_loss: 3.5561 - val_VL_attention_linear_output_loss: 1.7733 - val_VH_attention_linear_output_loss: 1.7827 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4726\n",
      "Epoch 2694/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4617 - VL_attention_linear_output_loss: 1.7199 - VH_attention_linear_output_loss: 1.7419 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4824 - val_loss: 3.5873 - val_VL_attention_linear_output_loss: 1.7957 - val_VH_attention_linear_output_loss: 1.7916 - val_VL_attention_linear_output_acc: 0.4712 - val_VH_attention_linear_output_acc: 0.4695\n",
      "Epoch 2695/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4684 - VL_attention_linear_output_loss: 1.7262 - VH_attention_linear_output_loss: 1.7422 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4824 - val_loss: 3.5694 - val_VL_attention_linear_output_loss: 1.7745 - val_VH_attention_linear_output_loss: 1.7949 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4724\n",
      "Epoch 2696/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4694 - VL_attention_linear_output_loss: 1.7239 - VH_attention_linear_output_loss: 1.7455 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4815 - val_loss: 3.5750 - val_VL_attention_linear_output_loss: 1.7844 - val_VH_attention_linear_output_loss: 1.7905 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4710\n",
      "Epoch 2697/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4617 - VL_attention_linear_output_loss: 1.7232 - VH_attention_linear_output_loss: 1.7385 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4850 - val_loss: 3.5522 - val_VL_attention_linear_output_loss: 1.7723 - val_VH_attention_linear_output_loss: 1.7800 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.4766\n",
      "Epoch 2698/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4755 - VL_attention_linear_output_loss: 1.7247 - VH_attention_linear_output_loss: 1.7508 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4796 - val_loss: 3.5568 - val_VL_attention_linear_output_loss: 1.7781 - val_VH_attention_linear_output_loss: 1.7786 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.4792\n",
      "Epoch 2699/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4534 - VL_attention_linear_output_loss: 1.7156 - VH_attention_linear_output_loss: 1.7378 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4848 - val_loss: 3.5752 - val_VL_attention_linear_output_loss: 1.7755 - val_VH_attention_linear_output_loss: 1.7996 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4661\n",
      "Epoch 2700/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4723 - VL_attention_linear_output_loss: 1.7267 - VH_attention_linear_output_loss: 1.7456 - VL_attention_linear_output_acc: 0.4879 - VH_attention_linear_output_acc: 0.4816 - val_loss: 3.5614 - val_VL_attention_linear_output_loss: 1.7823 - val_VH_attention_linear_output_loss: 1.7791 - val_VL_attention_linear_output_acc: 0.4768 - val_VH_attention_linear_output_acc: 0.4787\n",
      "Epoch 2701/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4652 - VL_attention_linear_output_loss: 1.7236 - VH_attention_linear_output_loss: 1.7416 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5525 - val_VL_attention_linear_output_loss: 1.7770 - val_VH_attention_linear_output_loss: 1.7755 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4754\n",
      "Epoch 2702/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4673 - VL_attention_linear_output_loss: 1.7325 - VH_attention_linear_output_loss: 1.7347 - VL_attention_linear_output_acc: 0.4853 - VH_attention_linear_output_acc: 0.4860 - val_loss: 3.5955 - val_VL_attention_linear_output_loss: 1.7684 - val_VH_attention_linear_output_loss: 1.8271 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.4504\n",
      "Epoch 2703/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4567 - VL_attention_linear_output_loss: 1.7118 - VH_attention_linear_output_loss: 1.7450 - VL_attention_linear_output_acc: 0.4961 - VH_attention_linear_output_acc: 0.4813 - val_loss: 3.5588 - val_VL_attention_linear_output_loss: 1.7683 - val_VH_attention_linear_output_loss: 1.7905 - val_VL_attention_linear_output_acc: 0.4860 - val_VH_attention_linear_output_acc: 0.4700\n",
      "Epoch 2704/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4675 - VL_attention_linear_output_loss: 1.7209 - VH_attention_linear_output_loss: 1.7466 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4808 - val_loss: 3.5612 - val_VL_attention_linear_output_loss: 1.7839 - val_VH_attention_linear_output_loss: 1.7773 - val_VL_attention_linear_output_acc: 0.4708 - val_VH_attention_linear_output_acc: 0.4804\n",
      "Epoch 2705/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4612 - VL_attention_linear_output_loss: 1.7264 - VH_attention_linear_output_loss: 1.7348 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4860 - val_loss: 3.5588 - val_VL_attention_linear_output_loss: 1.7788 - val_VH_attention_linear_output_loss: 1.7800 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4768\n",
      "Epoch 2706/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4531 - VL_attention_linear_output_loss: 1.7139 - VH_attention_linear_output_loss: 1.7392 - VL_attention_linear_output_acc: 0.4941 - VH_attention_linear_output_acc: 0.4838 - val_loss: 3.5467 - val_VL_attention_linear_output_loss: 1.7700 - val_VH_attention_linear_output_loss: 1.7767 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4774\n",
      "Epoch 2707/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4579 - VL_attention_linear_output_loss: 1.7205 - VH_attention_linear_output_loss: 1.7374 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4847 - val_loss: 3.5539 - val_VL_attention_linear_output_loss: 1.7735 - val_VH_attention_linear_output_loss: 1.7804 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4770\n",
      "Epoch 2708/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4693 - VL_attention_linear_output_loss: 1.7228 - VH_attention_linear_output_loss: 1.7465 - VL_attention_linear_output_acc: 0.4896 - VH_attention_linear_output_acc: 0.4814 - val_loss: 3.5612 - val_VL_attention_linear_output_loss: 1.7807 - val_VH_attention_linear_output_loss: 1.7804 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4757\n",
      "Epoch 2709/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4652 - VL_attention_linear_output_loss: 1.7255 - VH_attention_linear_output_loss: 1.7397 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.4839 - val_loss: 3.5515 - val_VL_attention_linear_output_loss: 1.7720 - val_VH_attention_linear_output_loss: 1.7796 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4776\n",
      "Epoch 2710/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4508 - VL_attention_linear_output_loss: 1.7148 - VH_attention_linear_output_loss: 1.7359 - VL_attention_linear_output_acc: 0.4947 - VH_attention_linear_output_acc: 0.4854 - val_loss: 3.5756 - val_VL_attention_linear_output_loss: 1.7778 - val_VH_attention_linear_output_loss: 1.7978 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4663\n",
      "Epoch 2711/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4722 - VL_attention_linear_output_loss: 1.7287 - VH_attention_linear_output_loss: 1.7435 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4822 - val_loss: 3.5611 - val_VL_attention_linear_output_loss: 1.7754 - val_VH_attention_linear_output_loss: 1.7857 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4729\n",
      "Epoch 2712/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4704 - VL_attention_linear_output_loss: 1.7286 - VH_attention_linear_output_loss: 1.7419 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4830 - val_loss: 3.5965 - val_VL_attention_linear_output_loss: 1.8078 - val_VH_attention_linear_output_loss: 1.7887 - val_VL_attention_linear_output_acc: 0.4608 - val_VH_attention_linear_output_acc: 0.4717\n",
      "Epoch 2713/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4763 - VL_attention_linear_output_loss: 1.7298 - VH_attention_linear_output_loss: 1.7465 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4811 - val_loss: 3.5508 - val_VL_attention_linear_output_loss: 1.7733 - val_VH_attention_linear_output_loss: 1.7775 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4772\n",
      "Epoch 2714/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4721 - VL_attention_linear_output_loss: 1.7320 - VH_attention_linear_output_loss: 1.7401 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4830 - val_loss: 3.5604 - val_VL_attention_linear_output_loss: 1.7736 - val_VH_attention_linear_output_loss: 1.7868 - val_VL_attention_linear_output_acc: 0.4854 - val_VH_attention_linear_output_acc: 0.4746\n",
      "Epoch 2715/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4716 - VL_attention_linear_output_loss: 1.7309 - VH_attention_linear_output_loss: 1.7407 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4834 - val_loss: 3.5688 - val_VL_attention_linear_output_loss: 1.7720 - val_VH_attention_linear_output_loss: 1.7968 - val_VL_attention_linear_output_acc: 0.4902 - val_VH_attention_linear_output_acc: 0.4728\n",
      "Epoch 2716/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4598 - VL_attention_linear_output_loss: 1.7156 - VH_attention_linear_output_loss: 1.7443 - VL_attention_linear_output_acc: 0.4958 - VH_attention_linear_output_acc: 0.4819 - val_loss: 3.5892 - val_VL_attention_linear_output_loss: 1.7994 - val_VH_attention_linear_output_loss: 1.7898 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.4738\n",
      "Epoch 2717/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4611 - VL_attention_linear_output_loss: 1.7207 - VH_attention_linear_output_loss: 1.7404 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5749 - val_VL_attention_linear_output_loss: 1.7817 - val_VH_attention_linear_output_loss: 1.7932 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.4764\n",
      "Epoch 2718/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4556 - VL_attention_linear_output_loss: 1.7197 - VH_attention_linear_output_loss: 1.7359 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4854 - val_loss: 3.5659 - val_VL_attention_linear_output_loss: 1.7842 - val_VH_attention_linear_output_loss: 1.7817 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4767\n",
      "Epoch 2719/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4745 - VL_attention_linear_output_loss: 1.7245 - VH_attention_linear_output_loss: 1.7500 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4797 - val_loss: 3.5678 - val_VL_attention_linear_output_loss: 1.7800 - val_VH_attention_linear_output_loss: 1.7878 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4733\n",
      "Epoch 2720/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4530 - VL_attention_linear_output_loss: 1.7186 - VH_attention_linear_output_loss: 1.7344 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4856 - val_loss: 3.5935 - val_VL_attention_linear_output_loss: 1.8113 - val_VH_attention_linear_output_loss: 1.7822 - val_VL_attention_linear_output_acc: 0.4562 - val_VH_attention_linear_output_acc: 0.4782\n",
      "Epoch 2721/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4670 - VL_attention_linear_output_loss: 1.7253 - VH_attention_linear_output_loss: 1.7416 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4832 - val_loss: 3.5681 - val_VL_attention_linear_output_loss: 1.7856 - val_VH_attention_linear_output_loss: 1.7825 - val_VL_attention_linear_output_acc: 0.4754 - val_VH_attention_linear_output_acc: 0.4731\n",
      "Epoch 2722/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4614 - VL_attention_linear_output_loss: 1.7200 - VH_attention_linear_output_loss: 1.7414 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4832 - val_loss: 3.5550 - val_VL_attention_linear_output_loss: 1.7678 - val_VH_attention_linear_output_loss: 1.7872 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4741\n",
      "Epoch 2723/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4590 - VL_attention_linear_output_loss: 1.7161 - VH_attention_linear_output_loss: 1.7429 - VL_attention_linear_output_acc: 0.4944 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5517 - val_VL_attention_linear_output_loss: 1.7701 - val_VH_attention_linear_output_loss: 1.7816 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4751\n",
      "Epoch 2724/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4546 - VL_attention_linear_output_loss: 1.7145 - VH_attention_linear_output_loss: 1.7400 - VL_attention_linear_output_acc: 0.4945 - VH_attention_linear_output_acc: 0.4833 - val_loss: 3.5508 - val_VL_attention_linear_output_loss: 1.7737 - val_VH_attention_linear_output_loss: 1.7771 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4780\n",
      "Epoch 2725/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4692 - VL_attention_linear_output_loss: 1.7227 - VH_attention_linear_output_loss: 1.7465 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4805 - val_loss: 3.5468 - val_VL_attention_linear_output_loss: 1.7711 - val_VH_attention_linear_output_loss: 1.7757 - val_VL_attention_linear_output_acc: 0.4870 - val_VH_attention_linear_output_acc: 0.4763\n",
      "Epoch 2726/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4474 - VL_attention_linear_output_loss: 1.7095 - VH_attention_linear_output_loss: 1.7379 - VL_attention_linear_output_acc: 0.4965 - VH_attention_linear_output_acc: 0.4848 - val_loss: 3.5495 - val_VL_attention_linear_output_loss: 1.7686 - val_VH_attention_linear_output_loss: 1.7809 - val_VL_attention_linear_output_acc: 0.4872 - val_VH_attention_linear_output_acc: 0.4718\n",
      "Epoch 2727/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4662 - VL_attention_linear_output_loss: 1.7168 - VH_attention_linear_output_loss: 1.7495 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4797 - val_loss: 3.5630 - val_VL_attention_linear_output_loss: 1.7781 - val_VH_attention_linear_output_loss: 1.7850 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4746\n",
      "Epoch 2728/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4637 - VL_attention_linear_output_loss: 1.7258 - VH_attention_linear_output_loss: 1.7379 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4841 - val_loss: 3.5756 - val_VL_attention_linear_output_loss: 1.7878 - val_VH_attention_linear_output_loss: 1.7878 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4743\n",
      "Epoch 2729/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4634 - VL_attention_linear_output_loss: 1.7159 - VH_attention_linear_output_loss: 1.7475 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4799 - val_loss: 3.5509 - val_VL_attention_linear_output_loss: 1.7706 - val_VH_attention_linear_output_loss: 1.7804 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4745\n",
      "Epoch 2730/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4601 - VL_attention_linear_output_loss: 1.7204 - VH_attention_linear_output_loss: 1.7397 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4840 - val_loss: 3.5775 - val_VL_attention_linear_output_loss: 1.7771 - val_VH_attention_linear_output_loss: 1.8004 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4667\n",
      "Epoch 2731/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4670 - VL_attention_linear_output_loss: 1.7214 - VH_attention_linear_output_loss: 1.7456 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4815 - val_loss: 3.5655 - val_VL_attention_linear_output_loss: 1.7808 - val_VH_attention_linear_output_loss: 1.7846 - val_VL_attention_linear_output_acc: 0.4805 - val_VH_attention_linear_output_acc: 0.4689\n",
      "Epoch 2732/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4630 - VL_attention_linear_output_loss: 1.7251 - VH_attention_linear_output_loss: 1.7380 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4840 - val_loss: 3.5578 - val_VL_attention_linear_output_loss: 1.7729 - val_VH_attention_linear_output_loss: 1.7849 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4776\n",
      "Epoch 2733/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4776 - VL_attention_linear_output_loss: 1.7249 - VH_attention_linear_output_loss: 1.7526 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4784 - val_loss: 3.5692 - val_VL_attention_linear_output_loss: 1.7717 - val_VH_attention_linear_output_loss: 1.7975 - val_VL_attention_linear_output_acc: 0.4854 - val_VH_attention_linear_output_acc: 0.4710\n",
      "Epoch 2734/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4586 - VL_attention_linear_output_loss: 1.7216 - VH_attention_linear_output_loss: 1.7370 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4850 - val_loss: 3.5610 - val_VL_attention_linear_output_loss: 1.7732 - val_VH_attention_linear_output_loss: 1.7878 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.4733\n",
      "Epoch 2735/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4647 - VL_attention_linear_output_loss: 1.7252 - VH_attention_linear_output_loss: 1.7395 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4836 - val_loss: 3.5668 - val_VL_attention_linear_output_loss: 1.7894 - val_VH_attention_linear_output_loss: 1.7773 - val_VL_attention_linear_output_acc: 0.4734 - val_VH_attention_linear_output_acc: 0.4813\n",
      "Epoch 2736/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4572 - VL_attention_linear_output_loss: 1.7262 - VH_attention_linear_output_loss: 1.7310 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4869 - val_loss: 3.5692 - val_VL_attention_linear_output_loss: 1.7747 - val_VH_attention_linear_output_loss: 1.7945 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.4709\n",
      "Epoch 2737/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4562 - VL_attention_linear_output_loss: 1.7216 - VH_attention_linear_output_loss: 1.7346 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.4853 - val_loss: 3.5805 - val_VL_attention_linear_output_loss: 1.7751 - val_VH_attention_linear_output_loss: 1.8054 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4672\n",
      "Epoch 2738/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4597 - VL_attention_linear_output_loss: 1.7221 - VH_attention_linear_output_loss: 1.7376 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4847 - val_loss: 3.5629 - val_VL_attention_linear_output_loss: 1.7765 - val_VH_attention_linear_output_loss: 1.7864 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4746\n",
      "Epoch 2739/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4675 - VL_attention_linear_output_loss: 1.7219 - VH_attention_linear_output_loss: 1.7455 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4805 - val_loss: 3.6064 - val_VL_attention_linear_output_loss: 1.7768 - val_VH_attention_linear_output_loss: 1.8297 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4536\n",
      "Epoch 2740/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4641 - VL_attention_linear_output_loss: 1.7232 - VH_attention_linear_output_loss: 1.7409 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4831 - val_loss: 3.5912 - val_VL_attention_linear_output_loss: 1.7683 - val_VH_attention_linear_output_loss: 1.8229 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4606\n",
      "Epoch 2741/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4581 - VL_attention_linear_output_loss: 1.7215 - VH_attention_linear_output_loss: 1.7367 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4846 - val_loss: 3.5662 - val_VL_attention_linear_output_loss: 1.7867 - val_VH_attention_linear_output_loss: 1.7795 - val_VL_attention_linear_output_acc: 0.4767 - val_VH_attention_linear_output_acc: 0.4745\n",
      "Epoch 2742/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4724 - VL_attention_linear_output_loss: 1.7236 - VH_attention_linear_output_loss: 1.7488 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4803 - val_loss: 3.5974 - val_VL_attention_linear_output_loss: 1.7715 - val_VH_attention_linear_output_loss: 1.8259 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4518\n",
      "Epoch 2743/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4652 - VL_attention_linear_output_loss: 1.7249 - VH_attention_linear_output_loss: 1.7403 - VL_attention_linear_output_acc: 0.4893 - VH_attention_linear_output_acc: 0.4830 - val_loss: 3.6314 - val_VL_attention_linear_output_loss: 1.8468 - val_VH_attention_linear_output_loss: 1.7846 - val_VL_attention_linear_output_acc: 0.4534 - val_VH_attention_linear_output_acc: 0.4811\n",
      "Epoch 2744/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4621 - VL_attention_linear_output_loss: 1.7219 - VH_attention_linear_output_loss: 1.7402 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4830 - val_loss: 3.5567 - val_VL_attention_linear_output_loss: 1.7750 - val_VH_attention_linear_output_loss: 1.7817 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4789\n",
      "Epoch 2745/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4503 - VL_attention_linear_output_loss: 1.7135 - VH_attention_linear_output_loss: 1.7369 - VL_attention_linear_output_acc: 0.4964 - VH_attention_linear_output_acc: 0.4849 - val_loss: 3.5532 - val_VL_attention_linear_output_loss: 1.7782 - val_VH_attention_linear_output_loss: 1.7750 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4758\n",
      "Epoch 2746/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4705 - VL_attention_linear_output_loss: 1.7273 - VH_attention_linear_output_loss: 1.7432 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4819 - val_loss: 3.5509 - val_VL_attention_linear_output_loss: 1.7719 - val_VH_attention_linear_output_loss: 1.7790 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4781\n",
      "Epoch 2747/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4557 - VL_attention_linear_output_loss: 1.7220 - VH_attention_linear_output_loss: 1.7337 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4857 - val_loss: 3.5610 - val_VL_attention_linear_output_loss: 1.7675 - val_VH_attention_linear_output_loss: 1.7935 - val_VL_attention_linear_output_acc: 0.4894 - val_VH_attention_linear_output_acc: 0.4699\n",
      "Epoch 2748/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4547 - VL_attention_linear_output_loss: 1.7149 - VH_attention_linear_output_loss: 1.7398 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4831 - val_loss: 3.5862 - val_VL_attention_linear_output_loss: 1.7818 - val_VH_attention_linear_output_loss: 1.8045 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4632\n",
      "Epoch 2749/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4692 - VL_attention_linear_output_loss: 1.7230 - VH_attention_linear_output_loss: 1.7462 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4803 - val_loss: 3.5548 - val_VL_attention_linear_output_loss: 1.7688 - val_VH_attention_linear_output_loss: 1.7860 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4733\n",
      "Epoch 2750/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4592 - VL_attention_linear_output_loss: 1.7243 - VH_attention_linear_output_loss: 1.7350 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4854 - val_loss: 3.5957 - val_VL_attention_linear_output_loss: 1.8038 - val_VH_attention_linear_output_loss: 1.7919 - val_VL_attention_linear_output_acc: 0.4684 - val_VH_attention_linear_output_acc: 0.4736\n",
      "Epoch 2751/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4745 - VL_attention_linear_output_loss: 1.7234 - VH_attention_linear_output_loss: 1.7511 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4796 - val_loss: 3.5673 - val_VL_attention_linear_output_loss: 1.7839 - val_VH_attention_linear_output_loss: 1.7834 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4757\n",
      "Epoch 2752/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4568 - VL_attention_linear_output_loss: 1.7149 - VH_attention_linear_output_loss: 1.7419 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4824 - val_loss: 3.6211 - val_VL_attention_linear_output_loss: 1.7930 - val_VH_attention_linear_output_loss: 1.8281 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.4584\n",
      "Epoch 2753/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4553 - VL_attention_linear_output_loss: 1.7168 - VH_attention_linear_output_loss: 1.7385 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4837 - val_loss: 3.5465 - val_VL_attention_linear_output_loss: 1.7695 - val_VH_attention_linear_output_loss: 1.7769 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4762\n",
      "Epoch 2754/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4524 - VL_attention_linear_output_loss: 1.7124 - VH_attention_linear_output_loss: 1.7400 - VL_attention_linear_output_acc: 0.4959 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5654 - val_VL_attention_linear_output_loss: 1.7783 - val_VH_attention_linear_output_loss: 1.7871 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4709\n",
      "Epoch 2755/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4666 - VL_attention_linear_output_loss: 1.7231 - VH_attention_linear_output_loss: 1.7435 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4818 - val_loss: 3.5643 - val_VL_attention_linear_output_loss: 1.7803 - val_VH_attention_linear_output_loss: 1.7840 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4706\n",
      "Epoch 2756/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4548 - VL_attention_linear_output_loss: 1.7173 - VH_attention_linear_output_loss: 1.7375 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4836 - val_loss: 3.5878 - val_VL_attention_linear_output_loss: 1.7862 - val_VH_attention_linear_output_loss: 1.8016 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.4651\n",
      "Epoch 2757/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4539 - VL_attention_linear_output_loss: 1.7194 - VH_attention_linear_output_loss: 1.7345 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4853 - val_loss: 3.5518 - val_VL_attention_linear_output_loss: 1.7733 - val_VH_attention_linear_output_loss: 1.7785 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4766\n",
      "Epoch 2758/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4654 - VL_attention_linear_output_loss: 1.7266 - VH_attention_linear_output_loss: 1.7387 - VL_attention_linear_output_acc: 0.4895 - VH_attention_linear_output_acc: 0.4843 - val_loss: 3.5653 - val_VL_attention_linear_output_loss: 1.7762 - val_VH_attention_linear_output_loss: 1.7891 - val_VL_attention_linear_output_acc: 0.4805 - val_VH_attention_linear_output_acc: 0.4706\n",
      "Epoch 2759/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4581 - VL_attention_linear_output_loss: 1.7206 - VH_attention_linear_output_loss: 1.7374 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4837 - val_loss: 3.5548 - val_VL_attention_linear_output_loss: 1.7685 - val_VH_attention_linear_output_loss: 1.7863 - val_VL_attention_linear_output_acc: 0.4894 - val_VH_attention_linear_output_acc: 0.4714\n",
      "Epoch 2760/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4647 - VL_attention_linear_output_loss: 1.7210 - VH_attention_linear_output_loss: 1.7437 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4816 - val_loss: 3.5628 - val_VL_attention_linear_output_loss: 1.7871 - val_VH_attention_linear_output_loss: 1.7757 - val_VL_attention_linear_output_acc: 0.4794 - val_VH_attention_linear_output_acc: 0.4756\n",
      "Epoch 2761/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4614 - VL_attention_linear_output_loss: 1.7257 - VH_attention_linear_output_loss: 1.7358 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4843 - val_loss: 3.5439 - val_VL_attention_linear_output_loss: 1.7680 - val_VH_attention_linear_output_loss: 1.7758 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4741\n",
      "Epoch 2762/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4552 - VL_attention_linear_output_loss: 1.7126 - VH_attention_linear_output_loss: 1.7426 - VL_attention_linear_output_acc: 0.4964 - VH_attention_linear_output_acc: 0.4821 - val_loss: 3.5415 - val_VL_attention_linear_output_loss: 1.7598 - val_VH_attention_linear_output_loss: 1.7817 - val_VL_attention_linear_output_acc: 0.4900 - val_VH_attention_linear_output_acc: 0.4761\n",
      "Epoch 2763/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4504 - VL_attention_linear_output_loss: 1.7132 - VH_attention_linear_output_loss: 1.7371 - VL_attention_linear_output_acc: 0.4959 - VH_attention_linear_output_acc: 0.4848 - val_loss: 3.5760 - val_VL_attention_linear_output_loss: 1.7692 - val_VH_attention_linear_output_loss: 1.8068 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4687\n",
      "Epoch 2764/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4610 - VL_attention_linear_output_loss: 1.7199 - VH_attention_linear_output_loss: 1.7411 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4826 - val_loss: 3.5471 - val_VL_attention_linear_output_loss: 1.7685 - val_VH_attention_linear_output_loss: 1.7786 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4794\n",
      "Epoch 2765/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4599 - VL_attention_linear_output_loss: 1.7189 - VH_attention_linear_output_loss: 1.7410 - VL_attention_linear_output_acc: 0.4923 - VH_attention_linear_output_acc: 0.4818 - val_loss: 3.5644 - val_VL_attention_linear_output_loss: 1.7676 - val_VH_attention_linear_output_loss: 1.7968 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4686\n",
      "Epoch 2766/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4738 - VL_attention_linear_output_loss: 1.7195 - VH_attention_linear_output_loss: 1.7543 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4774 - val_loss: 3.5508 - val_VL_attention_linear_output_loss: 1.7709 - val_VH_attention_linear_output_loss: 1.7799 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4748\n",
      "Epoch 2767/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4543 - VL_attention_linear_output_loss: 1.7185 - VH_attention_linear_output_loss: 1.7358 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4840 - val_loss: 3.5489 - val_VL_attention_linear_output_loss: 1.7663 - val_VH_attention_linear_output_loss: 1.7826 - val_VL_attention_linear_output_acc: 0.4886 - val_VH_attention_linear_output_acc: 0.4763\n",
      "Epoch 2768/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4531 - VL_attention_linear_output_loss: 1.7191 - VH_attention_linear_output_loss: 1.7340 - VL_attention_linear_output_acc: 0.4920 - VH_attention_linear_output_acc: 0.4853 - val_loss: 3.5411 - val_VL_attention_linear_output_loss: 1.7677 - val_VH_attention_linear_output_loss: 1.7734 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4766\n",
      "Epoch 2769/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4494 - VL_attention_linear_output_loss: 1.7121 - VH_attention_linear_output_loss: 1.7374 - VL_attention_linear_output_acc: 0.4959 - VH_attention_linear_output_acc: 0.4832 - val_loss: 3.5595 - val_VL_attention_linear_output_loss: 1.7644 - val_VH_attention_linear_output_loss: 1.7951 - val_VL_attention_linear_output_acc: 0.4900 - val_VH_attention_linear_output_acc: 0.4664\n",
      "Epoch 2770/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4561 - VL_attention_linear_output_loss: 1.7211 - VH_attention_linear_output_loss: 1.7350 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4855 - val_loss: 3.5833 - val_VL_attention_linear_output_loss: 1.7932 - val_VH_attention_linear_output_loss: 1.7901 - val_VL_attention_linear_output_acc: 0.4733 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 2771/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4750 - VL_attention_linear_output_loss: 1.7284 - VH_attention_linear_output_loss: 1.7466 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4803 - val_loss: 3.5655 - val_VL_attention_linear_output_loss: 1.7682 - val_VH_attention_linear_output_loss: 1.7972 - val_VL_attention_linear_output_acc: 0.4908 - val_VH_attention_linear_output_acc: 0.4689\n",
      "Epoch 2772/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4583 - VL_attention_linear_output_loss: 1.7160 - VH_attention_linear_output_loss: 1.7423 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4820 - val_loss: 3.5478 - val_VL_attention_linear_output_loss: 1.7676 - val_VH_attention_linear_output_loss: 1.7803 - val_VL_attention_linear_output_acc: 0.4860 - val_VH_attention_linear_output_acc: 0.4768\n",
      "Epoch 2773/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4439 - VL_attention_linear_output_loss: 1.7126 - VH_attention_linear_output_loss: 1.7313 - VL_attention_linear_output_acc: 0.4951 - VH_attention_linear_output_acc: 0.4864 - val_loss: 3.5743 - val_VL_attention_linear_output_loss: 1.7664 - val_VH_attention_linear_output_loss: 1.8079 - val_VL_attention_linear_output_acc: 0.4891 - val_VH_attention_linear_output_acc: 0.4638\n",
      "Epoch 2774/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4570 - VL_attention_linear_output_loss: 1.7203 - VH_attention_linear_output_loss: 1.7367 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4844 - val_loss: 3.5777 - val_VL_attention_linear_output_loss: 1.8043 - val_VH_attention_linear_output_loss: 1.7734 - val_VL_attention_linear_output_acc: 0.4574 - val_VH_attention_linear_output_acc: 0.4835\n",
      "Epoch 2775/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4585 - VL_attention_linear_output_loss: 1.7194 - VH_attention_linear_output_loss: 1.7391 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4842 - val_loss: 3.5682 - val_VL_attention_linear_output_loss: 1.7712 - val_VH_attention_linear_output_loss: 1.7970 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4658\n",
      "Epoch 2776/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4691 - VL_attention_linear_output_loss: 1.7273 - VH_attention_linear_output_loss: 1.7418 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4825 - val_loss: 3.5921 - val_VL_attention_linear_output_loss: 1.8141 - val_VH_attention_linear_output_loss: 1.7780 - val_VL_attention_linear_output_acc: 0.4680 - val_VH_attention_linear_output_acc: 0.4730\n",
      "Epoch 2777/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4608 - VL_attention_linear_output_loss: 1.7150 - VH_attention_linear_output_loss: 1.7458 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4802 - val_loss: 3.5594 - val_VL_attention_linear_output_loss: 1.7720 - val_VH_attention_linear_output_loss: 1.7873 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4716\n",
      "Epoch 2778/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4507 - VL_attention_linear_output_loss: 1.7176 - VH_attention_linear_output_loss: 1.7331 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4852 - val_loss: 3.5523 - val_VL_attention_linear_output_loss: 1.7743 - val_VH_attention_linear_output_loss: 1.7781 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4779\n",
      "Epoch 2779/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4616 - VL_attention_linear_output_loss: 1.7193 - VH_attention_linear_output_loss: 1.7423 - VL_attention_linear_output_acc: 0.4910 - VH_attention_linear_output_acc: 0.4815 - val_loss: 3.5920 - val_VL_attention_linear_output_loss: 1.8162 - val_VH_attention_linear_output_loss: 1.7758 - val_VL_attention_linear_output_acc: 0.4582 - val_VH_attention_linear_output_acc: 0.4756\n",
      "Epoch 2780/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4659 - VL_attention_linear_output_loss: 1.7288 - VH_attention_linear_output_loss: 1.7371 - VL_attention_linear_output_acc: 0.4877 - VH_attention_linear_output_acc: 0.4845 - val_loss: 3.5400 - val_VL_attention_linear_output_loss: 1.7646 - val_VH_attention_linear_output_loss: 1.7754 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4762\n",
      "Epoch 2781/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4513 - VL_attention_linear_output_loss: 1.7181 - VH_attention_linear_output_loss: 1.7332 - VL_attention_linear_output_acc: 0.4929 - VH_attention_linear_output_acc: 0.4854 - val_loss: 3.5474 - val_VL_attention_linear_output_loss: 1.7776 - val_VH_attention_linear_output_loss: 1.7698 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4786\n",
      "Epoch 2782/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4519 - VL_attention_linear_output_loss: 1.7177 - VH_attention_linear_output_loss: 1.7341 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4852 - val_loss: 3.5413 - val_VL_attention_linear_output_loss: 1.7624 - val_VH_attention_linear_output_loss: 1.7789 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.4748\n",
      "Epoch 2783/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4515 - VL_attention_linear_output_loss: 1.7163 - VH_attention_linear_output_loss: 1.7352 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4850 - val_loss: 3.5622 - val_VL_attention_linear_output_loss: 1.7758 - val_VH_attention_linear_output_loss: 1.7864 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4697\n",
      "Epoch 2784/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4749 - VL_attention_linear_output_loss: 1.7263 - VH_attention_linear_output_loss: 1.7486 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4799 - val_loss: 3.6059 - val_VL_attention_linear_output_loss: 1.7921 - val_VH_attention_linear_output_loss: 1.8138 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.4587\n",
      "Epoch 2785/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4660 - VL_attention_linear_output_loss: 1.7279 - VH_attention_linear_output_loss: 1.7381 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4836 - val_loss: 3.5406 - val_VL_attention_linear_output_loss: 1.7686 - val_VH_attention_linear_output_loss: 1.7720 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4760\n",
      "Epoch 2786/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4461 - VL_attention_linear_output_loss: 1.7117 - VH_attention_linear_output_loss: 1.7344 - VL_attention_linear_output_acc: 0.4956 - VH_attention_linear_output_acc: 0.4850 - val_loss: 3.5728 - val_VL_attention_linear_output_loss: 1.7669 - val_VH_attention_linear_output_loss: 1.8059 - val_VL_attention_linear_output_acc: 0.4903 - val_VH_attention_linear_output_acc: 0.4654\n",
      "Epoch 2787/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4483 - VL_attention_linear_output_loss: 1.7138 - VH_attention_linear_output_loss: 1.7345 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4854 - val_loss: 3.5429 - val_VL_attention_linear_output_loss: 1.7690 - val_VH_attention_linear_output_loss: 1.7739 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4762\n",
      "Epoch 2788/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4700 - VL_attention_linear_output_loss: 1.7209 - VH_attention_linear_output_loss: 1.7491 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4797 - val_loss: 3.5546 - val_VL_attention_linear_output_loss: 1.7723 - val_VH_attention_linear_output_loss: 1.7823 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4728\n",
      "Epoch 2789/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4547 - VL_attention_linear_output_loss: 1.7113 - VH_attention_linear_output_loss: 1.7434 - VL_attention_linear_output_acc: 0.4959 - VH_attention_linear_output_acc: 0.4825 - val_loss: 3.5517 - val_VL_attention_linear_output_loss: 1.7790 - val_VH_attention_linear_output_loss: 1.7727 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4732\n",
      "Epoch 2790/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4474 - VL_attention_linear_output_loss: 1.7183 - VH_attention_linear_output_loss: 1.7291 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4872 - val_loss: 3.5731 - val_VL_attention_linear_output_loss: 1.7893 - val_VH_attention_linear_output_loss: 1.7838 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4702\n",
      "Epoch 2791/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4610 - VL_attention_linear_output_loss: 1.7306 - VH_attention_linear_output_loss: 1.7304 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4865 - val_loss: 3.5467 - val_VL_attention_linear_output_loss: 1.7698 - val_VH_attention_linear_output_loss: 1.7770 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4762\n",
      "Epoch 2792/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4464 - VL_attention_linear_output_loss: 1.7077 - VH_attention_linear_output_loss: 1.7387 - VL_attention_linear_output_acc: 0.4975 - VH_attention_linear_output_acc: 0.4835 - val_loss: 3.5352 - val_VL_attention_linear_output_loss: 1.7647 - val_VH_attention_linear_output_loss: 1.7705 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.4799\n",
      "Epoch 2793/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4464 - VL_attention_linear_output_loss: 1.7115 - VH_attention_linear_output_loss: 1.7349 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4851 - val_loss: 3.5605 - val_VL_attention_linear_output_loss: 1.7791 - val_VH_attention_linear_output_loss: 1.7814 - val_VL_attention_linear_output_acc: 0.4764 - val_VH_attention_linear_output_acc: 0.4751\n",
      "Epoch 2794/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4788 - VL_attention_linear_output_loss: 1.7206 - VH_attention_linear_output_loss: 1.7582 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4756 - val_loss: 3.6048 - val_VL_attention_linear_output_loss: 1.7956 - val_VH_attention_linear_output_loss: 1.8092 - val_VL_attention_linear_output_acc: 0.4716 - val_VH_attention_linear_output_acc: 0.4685\n",
      "Epoch 2795/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4479 - VL_attention_linear_output_loss: 1.7140 - VH_attention_linear_output_loss: 1.7339 - VL_attention_linear_output_acc: 0.4940 - VH_attention_linear_output_acc: 0.4851 - val_loss: 3.5746 - val_VL_attention_linear_output_loss: 1.7984 - val_VH_attention_linear_output_loss: 1.7761 - val_VL_attention_linear_output_acc: 0.4651 - val_VH_attention_linear_output_acc: 0.4751\n",
      "Epoch 2796/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4485 - VL_attention_linear_output_loss: 1.7168 - VH_attention_linear_output_loss: 1.7317 - VL_attention_linear_output_acc: 0.4929 - VH_attention_linear_output_acc: 0.4864 - val_loss: 3.5541 - val_VL_attention_linear_output_loss: 1.7707 - val_VH_attention_linear_output_loss: 1.7834 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4741\n",
      "Epoch 2797/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4616 - VL_attention_linear_output_loss: 1.7250 - VH_attention_linear_output_loss: 1.7366 - VL_attention_linear_output_acc: 0.4881 - VH_attention_linear_output_acc: 0.4844 - val_loss: 3.5745 - val_VL_attention_linear_output_loss: 1.7887 - val_VH_attention_linear_output_loss: 1.7859 - val_VL_attention_linear_output_acc: 0.4745 - val_VH_attention_linear_output_acc: 0.4763\n",
      "Epoch 2798/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4535 - VL_attention_linear_output_loss: 1.7176 - VH_attention_linear_output_loss: 1.7359 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4843 - val_loss: 3.5541 - val_VL_attention_linear_output_loss: 1.7646 - val_VH_attention_linear_output_loss: 1.7895 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4719\n",
      "Epoch 2799/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4446 - VL_attention_linear_output_loss: 1.7107 - VH_attention_linear_output_loss: 1.7339 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4851 - val_loss: 3.5439 - val_VL_attention_linear_output_loss: 1.7641 - val_VH_attention_linear_output_loss: 1.7798 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4818\n",
      "Epoch 2800/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4675 - VL_attention_linear_output_loss: 1.7281 - VH_attention_linear_output_loss: 1.7394 - VL_attention_linear_output_acc: 0.4878 - VH_attention_linear_output_acc: 0.4827 - val_loss: 3.5430 - val_VL_attention_linear_output_loss: 1.7670 - val_VH_attention_linear_output_loss: 1.7760 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4792\n",
      "Epoch 2801/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4495 - VL_attention_linear_output_loss: 1.7142 - VH_attention_linear_output_loss: 1.7353 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4843 - val_loss: 3.6287 - val_VL_attention_linear_output_loss: 1.7754 - val_VH_attention_linear_output_loss: 1.8533 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4496\n",
      "Epoch 2802/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4419 - VL_attention_linear_output_loss: 1.7111 - VH_attention_linear_output_loss: 1.7308 - VL_attention_linear_output_acc: 0.4957 - VH_attention_linear_output_acc: 0.4865 - val_loss: 3.5709 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.7837 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.4700\n",
      "Epoch 2803/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4627 - VL_attention_linear_output_loss: 1.7190 - VH_attention_linear_output_loss: 1.7437 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4807 - val_loss: 3.5368 - val_VL_attention_linear_output_loss: 1.7629 - val_VH_attention_linear_output_loss: 1.7740 - val_VL_attention_linear_output_acc: 0.4901 - val_VH_attention_linear_output_acc: 0.4794\n",
      "Epoch 2804/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4550 - VL_attention_linear_output_loss: 1.7183 - VH_attention_linear_output_loss: 1.7367 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4845 - val_loss: 3.5635 - val_VL_attention_linear_output_loss: 1.7739 - val_VH_attention_linear_output_loss: 1.7896 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4667\n",
      "Epoch 2805/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4721 - VL_attention_linear_output_loss: 1.7309 - VH_attention_linear_output_loss: 1.7412 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4834 - val_loss: 3.5859 - val_VL_attention_linear_output_loss: 1.8017 - val_VH_attention_linear_output_loss: 1.7842 - val_VL_attention_linear_output_acc: 0.4620 - val_VH_attention_linear_output_acc: 0.4724\n",
      "Epoch 2806/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4545 - VL_attention_linear_output_loss: 1.7186 - VH_attention_linear_output_loss: 1.7359 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4837 - val_loss: 3.5491 - val_VL_attention_linear_output_loss: 1.7711 - val_VH_attention_linear_output_loss: 1.7780 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4771\n",
      "Epoch 2807/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4497 - VL_attention_linear_output_loss: 1.7130 - VH_attention_linear_output_loss: 1.7367 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4844 - val_loss: 3.5423 - val_VL_attention_linear_output_loss: 1.7603 - val_VH_attention_linear_output_loss: 1.7820 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.4779\n",
      "Epoch 2808/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4456 - VL_attention_linear_output_loss: 1.7105 - VH_attention_linear_output_loss: 1.7351 - VL_attention_linear_output_acc: 0.4954 - VH_attention_linear_output_acc: 0.4847 - val_loss: 3.5380 - val_VL_attention_linear_output_loss: 1.7614 - val_VH_attention_linear_output_loss: 1.7767 - val_VL_attention_linear_output_acc: 0.4905 - val_VH_attention_linear_output_acc: 0.4760\n",
      "Epoch 2809/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4663 - VL_attention_linear_output_loss: 1.7280 - VH_attention_linear_output_loss: 1.7383 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4832 - val_loss: 3.6147 - val_VL_attention_linear_output_loss: 1.7805 - val_VH_attention_linear_output_loss: 1.8342 - val_VL_attention_linear_output_acc: 0.4736 - val_VH_attention_linear_output_acc: 0.4575\n",
      "Epoch 2810/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4615 - VL_attention_linear_output_loss: 1.7263 - VH_attention_linear_output_loss: 1.7353 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4850 - val_loss: 3.5360 - val_VL_attention_linear_output_loss: 1.7654 - val_VH_attention_linear_output_loss: 1.7706 - val_VL_attention_linear_output_acc: 0.4885 - val_VH_attention_linear_output_acc: 0.4784\n",
      "Epoch 2811/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4500 - VL_attention_linear_output_loss: 1.7123 - VH_attention_linear_output_loss: 1.7377 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4838 - val_loss: 3.5479 - val_VL_attention_linear_output_loss: 1.7688 - val_VH_attention_linear_output_loss: 1.7790 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4785\n",
      "Epoch 2812/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4501 - VL_attention_linear_output_loss: 1.7174 - VH_attention_linear_output_loss: 1.7327 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4855 - val_loss: 3.5447 - val_VL_attention_linear_output_loss: 1.7697 - val_VH_attention_linear_output_loss: 1.7750 - val_VL_attention_linear_output_acc: 0.4885 - val_VH_attention_linear_output_acc: 0.4754\n",
      "Epoch 2813/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4516 - VL_attention_linear_output_loss: 1.7181 - VH_attention_linear_output_loss: 1.7335 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4855 - val_loss: 3.6264 - val_VL_attention_linear_output_loss: 1.8425 - val_VH_attention_linear_output_loss: 1.7839 - val_VL_attention_linear_output_acc: 0.4524 - val_VH_attention_linear_output_acc: 0.4730\n",
      "Epoch 2814/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4539 - VL_attention_linear_output_loss: 1.7156 - VH_attention_linear_output_loss: 1.7384 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4834 - val_loss: 3.5324 - val_VL_attention_linear_output_loss: 1.7622 - val_VH_attention_linear_output_loss: 1.7702 - val_VL_attention_linear_output_acc: 0.4893 - val_VH_attention_linear_output_acc: 0.4807\n",
      "Epoch 2815/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4542 - VL_attention_linear_output_loss: 1.7196 - VH_attention_linear_output_loss: 1.7346 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4851 - val_loss: 3.5384 - val_VL_attention_linear_output_loss: 1.7675 - val_VH_attention_linear_output_loss: 1.7709 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4752\n",
      "Epoch 2816/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4551 - VL_attention_linear_output_loss: 1.7297 - VH_attention_linear_output_loss: 1.7254 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4883 - val_loss: 3.5514 - val_VL_attention_linear_output_loss: 1.7701 - val_VH_attention_linear_output_loss: 1.7813 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4717\n",
      "Epoch 2817/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4404 - VL_attention_linear_output_loss: 1.7108 - VH_attention_linear_output_loss: 1.7296 - VL_attention_linear_output_acc: 0.4950 - VH_attention_linear_output_acc: 0.4869 - val_loss: 3.5424 - val_VL_attention_linear_output_loss: 1.7637 - val_VH_attention_linear_output_loss: 1.7787 - val_VL_attention_linear_output_acc: 0.4888 - val_VH_attention_linear_output_acc: 0.4752\n",
      "Epoch 2818/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4487 - VL_attention_linear_output_loss: 1.7208 - VH_attention_linear_output_loss: 1.7278 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4875 - val_loss: 3.5731 - val_VL_attention_linear_output_loss: 1.7797 - val_VH_attention_linear_output_loss: 1.7934 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4701\n",
      "Epoch 2819/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4447 - VL_attention_linear_output_loss: 1.7092 - VH_attention_linear_output_loss: 1.7355 - VL_attention_linear_output_acc: 0.4953 - VH_attention_linear_output_acc: 0.4848 - val_loss: 3.5368 - val_VL_attention_linear_output_loss: 1.7663 - val_VH_attention_linear_output_loss: 1.7705 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4783\n",
      "Epoch 2820/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4513 - VL_attention_linear_output_loss: 1.7129 - VH_attention_linear_output_loss: 1.7384 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4835 - val_loss: 3.5640 - val_VL_attention_linear_output_loss: 1.7818 - val_VH_attention_linear_output_loss: 1.7823 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4708\n",
      "Epoch 2821/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4456 - VL_attention_linear_output_loss: 1.7161 - VH_attention_linear_output_loss: 1.7295 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4868 - val_loss: 3.6135 - val_VL_attention_linear_output_loss: 1.8366 - val_VH_attention_linear_output_loss: 1.7769 - val_VL_attention_linear_output_acc: 0.4518 - val_VH_attention_linear_output_acc: 0.4747\n",
      "Epoch 2822/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4535 - VL_attention_linear_output_loss: 1.7184 - VH_attention_linear_output_loss: 1.7351 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4849 - val_loss: 3.5422 - val_VL_attention_linear_output_loss: 1.7673 - val_VH_attention_linear_output_loss: 1.7750 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4766\n",
      "Epoch 2823/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4596 - VL_attention_linear_output_loss: 1.7196 - VH_attention_linear_output_loss: 1.7400 - VL_attention_linear_output_acc: 0.4920 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5456 - val_VL_attention_linear_output_loss: 1.7679 - val_VH_attention_linear_output_loss: 1.7777 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4743\n",
      "Epoch 2824/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4474 - VL_attention_linear_output_loss: 1.7159 - VH_attention_linear_output_loss: 1.7315 - VL_attention_linear_output_acc: 0.4955 - VH_attention_linear_output_acc: 0.4859 - val_loss: 3.5401 - val_VL_attention_linear_output_loss: 1.7667 - val_VH_attention_linear_output_loss: 1.7734 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4772\n",
      "Epoch 2825/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4547 - VL_attention_linear_output_loss: 1.7203 - VH_attention_linear_output_loss: 1.7344 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4846 - val_loss: 3.5501 - val_VL_attention_linear_output_loss: 1.7730 - val_VH_attention_linear_output_loss: 1.7771 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4761\n",
      "Epoch 2826/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4627 - VL_attention_linear_output_loss: 1.7205 - VH_attention_linear_output_loss: 1.7422 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4822 - val_loss: 3.5793 - val_VL_attention_linear_output_loss: 1.8068 - val_VH_attention_linear_output_loss: 1.7724 - val_VL_attention_linear_output_acc: 0.4575 - val_VH_attention_linear_output_acc: 0.4771\n",
      "Epoch 2827/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4693 - VL_attention_linear_output_loss: 1.7290 - VH_attention_linear_output_loss: 1.7403 - VL_attention_linear_output_acc: 0.4868 - VH_attention_linear_output_acc: 0.4836 - val_loss: 3.6460 - val_VL_attention_linear_output_loss: 1.8425 - val_VH_attention_linear_output_loss: 1.8035 - val_VL_attention_linear_output_acc: 0.4502 - val_VH_attention_linear_output_acc: 0.4639\n",
      "Epoch 2828/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4557 - VL_attention_linear_output_loss: 1.7197 - VH_attention_linear_output_loss: 1.7360 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4843 - val_loss: 3.5449 - val_VL_attention_linear_output_loss: 1.7690 - val_VH_attention_linear_output_loss: 1.7759 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.4794\n",
      "Epoch 2829/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4520 - VL_attention_linear_output_loss: 1.7211 - VH_attention_linear_output_loss: 1.7309 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4862 - val_loss: 3.5605 - val_VL_attention_linear_output_loss: 1.7826 - val_VH_attention_linear_output_loss: 1.7778 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4765\n",
      "Epoch 2830/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4502 - VL_attention_linear_output_loss: 1.7194 - VH_attention_linear_output_loss: 1.7308 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4855 - val_loss: 3.5558 - val_VL_attention_linear_output_loss: 1.7747 - val_VH_attention_linear_output_loss: 1.7810 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4719\n",
      "Epoch 2831/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4626 - VL_attention_linear_output_loss: 1.7286 - VH_attention_linear_output_loss: 1.7339 - VL_attention_linear_output_acc: 0.4864 - VH_attention_linear_output_acc: 0.4851 - val_loss: 3.5674 - val_VL_attention_linear_output_loss: 1.7761 - val_VH_attention_linear_output_loss: 1.7913 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4721\n",
      "Epoch 2832/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4488 - VL_attention_linear_output_loss: 1.7153 - VH_attention_linear_output_loss: 1.7335 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4848 - val_loss: 3.5441 - val_VL_attention_linear_output_loss: 1.7664 - val_VH_attention_linear_output_loss: 1.7777 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4748\n",
      "Epoch 2833/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4511 - VL_attention_linear_output_loss: 1.7085 - VH_attention_linear_output_loss: 1.7426 - VL_attention_linear_output_acc: 0.4962 - VH_attention_linear_output_acc: 0.4816 - val_loss: 3.5391 - val_VL_attention_linear_output_loss: 1.7665 - val_VH_attention_linear_output_loss: 1.7726 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4782\n",
      "Epoch 2834/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4386 - VL_attention_linear_output_loss: 1.7102 - VH_attention_linear_output_loss: 1.7284 - VL_attention_linear_output_acc: 0.4946 - VH_attention_linear_output_acc: 0.4871 - val_loss: 3.5448 - val_VL_attention_linear_output_loss: 1.7740 - val_VH_attention_linear_output_loss: 1.7708 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4831\n",
      "Epoch 2835/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4457 - VL_attention_linear_output_loss: 1.7175 - VH_attention_linear_output_loss: 1.7282 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4875 - val_loss: 3.5919 - val_VL_attention_linear_output_loss: 1.8228 - val_VH_attention_linear_output_loss: 1.7691 - val_VL_attention_linear_output_acc: 0.4625 - val_VH_attention_linear_output_acc: 0.4782\n",
      "Epoch 2836/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4524 - VL_attention_linear_output_loss: 1.7122 - VH_attention_linear_output_loss: 1.7402 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4827 - val_loss: 3.5791 - val_VL_attention_linear_output_loss: 1.7724 - val_VH_attention_linear_output_loss: 1.8067 - val_VL_attention_linear_output_acc: 0.4886 - val_VH_attention_linear_output_acc: 0.4659\n",
      "Epoch 2837/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4605 - VL_attention_linear_output_loss: 1.7204 - VH_attention_linear_output_loss: 1.7402 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.4828 - val_loss: 3.5421 - val_VL_attention_linear_output_loss: 1.7645 - val_VH_attention_linear_output_loss: 1.7777 - val_VL_attention_linear_output_acc: 0.4872 - val_VH_attention_linear_output_acc: 0.4764\n",
      "Epoch 2838/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4511 - VL_attention_linear_output_loss: 1.7145 - VH_attention_linear_output_loss: 1.7366 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4837 - val_loss: 3.5370 - val_VL_attention_linear_output_loss: 1.7632 - val_VH_attention_linear_output_loss: 1.7739 - val_VL_attention_linear_output_acc: 0.4899 - val_VH_attention_linear_output_acc: 0.4811\n",
      "Epoch 2839/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4441 - VL_attention_linear_output_loss: 1.7108 - VH_attention_linear_output_loss: 1.7333 - VL_attention_linear_output_acc: 0.4953 - VH_attention_linear_output_acc: 0.4842 - val_loss: 3.5413 - val_VL_attention_linear_output_loss: 1.7683 - val_VH_attention_linear_output_loss: 1.7730 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4749\n",
      "Epoch 2840/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4460 - VL_attention_linear_output_loss: 1.7130 - VH_attention_linear_output_loss: 1.7330 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4856 - val_loss: 3.5548 - val_VL_attention_linear_output_loss: 1.7741 - val_VH_attention_linear_output_loss: 1.7807 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4739\n",
      "Epoch 2841/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4630 - VL_attention_linear_output_loss: 1.7204 - VH_attention_linear_output_loss: 1.7426 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4825 - val_loss: 3.5446 - val_VL_attention_linear_output_loss: 1.7710 - val_VH_attention_linear_output_loss: 1.7736 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4782\n",
      "Epoch 2842/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4409 - VL_attention_linear_output_loss: 1.7098 - VH_attention_linear_output_loss: 1.7311 - VL_attention_linear_output_acc: 0.4953 - VH_attention_linear_output_acc: 0.4856 - val_loss: 3.5318 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7691 - val_VL_attention_linear_output_acc: 0.4888 - val_VH_attention_linear_output_acc: 0.4768\n",
      "Epoch 2843/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4450 - VL_attention_linear_output_loss: 1.7164 - VH_attention_linear_output_loss: 1.7286 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4862 - val_loss: 3.5488 - val_VL_attention_linear_output_loss: 1.7687 - val_VH_attention_linear_output_loss: 1.7800 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4766\n",
      "Epoch 2844/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4614 - VL_attention_linear_output_loss: 1.7242 - VH_attention_linear_output_loss: 1.7372 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4833 - val_loss: 3.5450 - val_VL_attention_linear_output_loss: 1.7772 - val_VH_attention_linear_output_loss: 1.7678 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4779\n",
      "Epoch 2845/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4384 - VL_attention_linear_output_loss: 1.7129 - VH_attention_linear_output_loss: 1.7256 - VL_attention_linear_output_acc: 0.4952 - VH_attention_linear_output_acc: 0.4885 - val_loss: 3.5435 - val_VL_attention_linear_output_loss: 1.7669 - val_VH_attention_linear_output_loss: 1.7765 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4750\n",
      "Epoch 2846/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4489 - VL_attention_linear_output_loss: 1.7157 - VH_attention_linear_output_loss: 1.7332 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4853 - val_loss: 3.5629 - val_VL_attention_linear_output_loss: 1.7711 - val_VH_attention_linear_output_loss: 1.7919 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4732\n",
      "Epoch 2847/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4521 - VL_attention_linear_output_loss: 1.7189 - VH_attention_linear_output_loss: 1.7331 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4848 - val_loss: 3.5486 - val_VL_attention_linear_output_loss: 1.7737 - val_VH_attention_linear_output_loss: 1.7749 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4774\n",
      "Epoch 2848/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4673 - VL_attention_linear_output_loss: 1.7190 - VH_attention_linear_output_loss: 1.7484 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4805 - val_loss: 3.5555 - val_VL_attention_linear_output_loss: 1.7763 - val_VH_attention_linear_output_loss: 1.7792 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4801\n",
      "Epoch 2849/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4606 - VL_attention_linear_output_loss: 1.7202 - VH_attention_linear_output_loss: 1.7404 - VL_attention_linear_output_acc: 0.4910 - VH_attention_linear_output_acc: 0.4842 - val_loss: 3.5355 - val_VL_attention_linear_output_loss: 1.7670 - val_VH_attention_linear_output_loss: 1.7684 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4789\n",
      "Epoch 2850/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4477 - VL_attention_linear_output_loss: 1.7206 - VH_attention_linear_output_loss: 1.7272 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4875 - val_loss: 3.5350 - val_VL_attention_linear_output_loss: 1.7649 - val_VH_attention_linear_output_loss: 1.7702 - val_VL_attention_linear_output_acc: 0.4869 - val_VH_attention_linear_output_acc: 0.4785\n",
      "Epoch 2851/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4514 - VL_attention_linear_output_loss: 1.7267 - VH_attention_linear_output_loss: 1.7247 - VL_attention_linear_output_acc: 0.4871 - VH_attention_linear_output_acc: 0.4886 - val_loss: 3.5435 - val_VL_attention_linear_output_loss: 1.7771 - val_VH_attention_linear_output_loss: 1.7664 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4843\n",
      "Epoch 2852/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4372 - VL_attention_linear_output_loss: 1.7128 - VH_attention_linear_output_loss: 1.7244 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4892 - val_loss: 3.5434 - val_VL_attention_linear_output_loss: 1.7620 - val_VH_attention_linear_output_loss: 1.7814 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4727\n",
      "Epoch 2853/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4420 - VL_attention_linear_output_loss: 1.7083 - VH_attention_linear_output_loss: 1.7336 - VL_attention_linear_output_acc: 0.4961 - VH_attention_linear_output_acc: 0.4851 - val_loss: 3.5451 - val_VL_attention_linear_output_loss: 1.7646 - val_VH_attention_linear_output_loss: 1.7805 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4756\n",
      "Epoch 2854/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4466 - VL_attention_linear_output_loss: 1.7177 - VH_attention_linear_output_loss: 1.7289 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4870 - val_loss: 3.5585 - val_VL_attention_linear_output_loss: 1.7750 - val_VH_attention_linear_output_loss: 1.7835 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.4754\n",
      "Epoch 2855/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4605 - VL_attention_linear_output_loss: 1.7213 - VH_attention_linear_output_loss: 1.7392 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4833 - val_loss: 3.5426 - val_VL_attention_linear_output_loss: 1.7692 - val_VH_attention_linear_output_loss: 1.7735 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4811\n",
      "Epoch 2856/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4445 - VL_attention_linear_output_loss: 1.7145 - VH_attention_linear_output_loss: 1.7300 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4869 - val_loss: 3.5714 - val_VL_attention_linear_output_loss: 1.7719 - val_VH_attention_linear_output_loss: 1.7996 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4663\n",
      "Epoch 2857/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4606 - VL_attention_linear_output_loss: 1.7246 - VH_attention_linear_output_loss: 1.7360 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4848 - val_loss: 3.5765 - val_VL_attention_linear_output_loss: 1.7738 - val_VH_attention_linear_output_loss: 1.8027 - val_VL_attention_linear_output_acc: 0.4891 - val_VH_attention_linear_output_acc: 0.4677\n",
      "Epoch 2858/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4530 - VL_attention_linear_output_loss: 1.7179 - VH_attention_linear_output_loss: 1.7351 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4852 - val_loss: 3.5870 - val_VL_attention_linear_output_loss: 1.8169 - val_VH_attention_linear_output_loss: 1.7701 - val_VL_attention_linear_output_acc: 0.4629 - val_VH_attention_linear_output_acc: 0.4763\n",
      "Epoch 2859/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4511 - VL_attention_linear_output_loss: 1.7209 - VH_attention_linear_output_loss: 1.7303 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.4866 - val_loss: 3.5698 - val_VL_attention_linear_output_loss: 1.7913 - val_VH_attention_linear_output_loss: 1.7785 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4760\n",
      "Epoch 2860/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4516 - VL_attention_linear_output_loss: 1.7173 - VH_attention_linear_output_loss: 1.7343 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4845 - val_loss: 3.5636 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.7764 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.4731\n",
      "Epoch 2861/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4479 - VL_attention_linear_output_loss: 1.7168 - VH_attention_linear_output_loss: 1.7311 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4849 - val_loss: 3.5859 - val_VL_attention_linear_output_loss: 1.8063 - val_VH_attention_linear_output_loss: 1.7796 - val_VL_attention_linear_output_acc: 0.4654 - val_VH_attention_linear_output_acc: 0.4730\n",
      "Epoch 2862/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4486 - VL_attention_linear_output_loss: 1.7227 - VH_attention_linear_output_loss: 1.7259 - VL_attention_linear_output_acc: 0.4896 - VH_attention_linear_output_acc: 0.4880 - val_loss: 3.5647 - val_VL_attention_linear_output_loss: 1.7810 - val_VH_attention_linear_output_loss: 1.7837 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4732\n",
      "Epoch 2863/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4419 - VL_attention_linear_output_loss: 1.7157 - VH_attention_linear_output_loss: 1.7262 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4878 - val_loss: 3.5319 - val_VL_attention_linear_output_loss: 1.7622 - val_VH_attention_linear_output_loss: 1.7698 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.4770\n",
      "Epoch 2864/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4415 - VL_attention_linear_output_loss: 1.7152 - VH_attention_linear_output_loss: 1.7263 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4878 - val_loss: 3.5512 - val_VL_attention_linear_output_loss: 1.7809 - val_VH_attention_linear_output_loss: 1.7703 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4809\n",
      "Epoch 2865/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4530 - VL_attention_linear_output_loss: 1.7176 - VH_attention_linear_output_loss: 1.7354 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4844 - val_loss: 3.5980 - val_VL_attention_linear_output_loss: 1.7988 - val_VH_attention_linear_output_loss: 1.7992 - val_VL_attention_linear_output_acc: 0.4678 - val_VH_attention_linear_output_acc: 0.4670\n",
      "Epoch 2866/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4518 - VL_attention_linear_output_loss: 1.7183 - VH_attention_linear_output_loss: 1.7335 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4848 - val_loss: 3.5448 - val_VL_attention_linear_output_loss: 1.7722 - val_VH_attention_linear_output_loss: 1.7726 - val_VL_attention_linear_output_acc: 0.4782 - val_VH_attention_linear_output_acc: 0.4787\n",
      "Epoch 2867/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4490 - VL_attention_linear_output_loss: 1.7125 - VH_attention_linear_output_loss: 1.7365 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4839 - val_loss: 3.5521 - val_VL_attention_linear_output_loss: 1.7725 - val_VH_attention_linear_output_loss: 1.7796 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4752\n",
      "Epoch 2868/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4532 - VL_attention_linear_output_loss: 1.7211 - VH_attention_linear_output_loss: 1.7321 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4850 - val_loss: 3.5807 - val_VL_attention_linear_output_loss: 1.7753 - val_VH_attention_linear_output_loss: 1.8054 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4682\n",
      "Epoch 2869/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4538 - VL_attention_linear_output_loss: 1.7119 - VH_attention_linear_output_loss: 1.7419 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4820 - val_loss: 3.5429 - val_VL_attention_linear_output_loss: 1.7721 - val_VH_attention_linear_output_loss: 1.7707 - val_VL_attention_linear_output_acc: 0.4804 - val_VH_attention_linear_output_acc: 0.4776\n",
      "Epoch 2870/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4447 - VL_attention_linear_output_loss: 1.7184 - VH_attention_linear_output_loss: 1.7263 - VL_attention_linear_output_acc: 0.4910 - VH_attention_linear_output_acc: 0.4874 - val_loss: 3.5602 - val_VL_attention_linear_output_loss: 1.7859 - val_VH_attention_linear_output_loss: 1.7744 - val_VL_attention_linear_output_acc: 0.4658 - val_VH_attention_linear_output_acc: 0.4789\n",
      "Epoch 2871/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4654 - VL_attention_linear_output_loss: 1.7223 - VH_attention_linear_output_loss: 1.7430 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4815 - val_loss: 3.5983 - val_VL_attention_linear_output_loss: 1.7858 - val_VH_attention_linear_output_loss: 1.8125 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4618\n",
      "Epoch 2872/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4456 - VL_attention_linear_output_loss: 1.7173 - VH_attention_linear_output_loss: 1.7282 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4871 - val_loss: 3.5407 - val_VL_attention_linear_output_loss: 1.7731 - val_VH_attention_linear_output_loss: 1.7676 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4793\n",
      "Epoch 2873/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4591 - VL_attention_linear_output_loss: 1.7220 - VH_attention_linear_output_loss: 1.7371 - VL_attention_linear_output_acc: 0.4893 - VH_attention_linear_output_acc: 0.4839 - val_loss: 3.5637 - val_VL_attention_linear_output_loss: 1.7750 - val_VH_attention_linear_output_loss: 1.7887 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4700\n",
      "Epoch 2874/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4525 - VL_attention_linear_output_loss: 1.7154 - VH_attention_linear_output_loss: 1.7371 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4836 - val_loss: 3.5886 - val_VL_attention_linear_output_loss: 1.7844 - val_VH_attention_linear_output_loss: 1.8041 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.4615\n",
      "Epoch 2875/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4502 - VL_attention_linear_output_loss: 1.7167 - VH_attention_linear_output_loss: 1.7335 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4854 - val_loss: 3.5776 - val_VL_attention_linear_output_loss: 1.7822 - val_VH_attention_linear_output_loss: 1.7954 - val_VL_attention_linear_output_acc: 0.4768 - val_VH_attention_linear_output_acc: 0.4679\n",
      "Epoch 2876/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4523 - VL_attention_linear_output_loss: 1.7152 - VH_attention_linear_output_loss: 1.7371 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.4837 - val_loss: 3.5564 - val_VL_attention_linear_output_loss: 1.7742 - val_VH_attention_linear_output_loss: 1.7822 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4731\n",
      "Epoch 2877/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4573 - VL_attention_linear_output_loss: 1.7294 - VH_attention_linear_output_loss: 1.7279 - VL_attention_linear_output_acc: 0.4865 - VH_attention_linear_output_acc: 0.4863 - val_loss: 3.5407 - val_VL_attention_linear_output_loss: 1.7682 - val_VH_attention_linear_output_loss: 1.7724 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4763\n",
      "Epoch 2878/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4292 - VL_attention_linear_output_loss: 1.7055 - VH_attention_linear_output_loss: 1.7237 - VL_attention_linear_output_acc: 0.4968 - VH_attention_linear_output_acc: 0.4887 - val_loss: 3.5391 - val_VL_attention_linear_output_loss: 1.7674 - val_VH_attention_linear_output_loss: 1.7717 - val_VL_attention_linear_output_acc: 0.4858 - val_VH_attention_linear_output_acc: 0.4790\n",
      "Epoch 2879/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4350 - VL_attention_linear_output_loss: 1.7049 - VH_attention_linear_output_loss: 1.7301 - VL_attention_linear_output_acc: 0.4973 - VH_attention_linear_output_acc: 0.4858 - val_loss: 3.5403 - val_VL_attention_linear_output_loss: 1.7650 - val_VH_attention_linear_output_loss: 1.7752 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4761\n",
      "Epoch 2880/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4581 - VL_attention_linear_output_loss: 1.7194 - VH_attention_linear_output_loss: 1.7387 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4825 - val_loss: 3.5565 - val_VL_attention_linear_output_loss: 1.7721 - val_VH_attention_linear_output_loss: 1.7843 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4726\n",
      "Epoch 2881/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4578 - VL_attention_linear_output_loss: 1.7229 - VH_attention_linear_output_loss: 1.7349 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4843 - val_loss: 3.5562 - val_VL_attention_linear_output_loss: 1.7679 - val_VH_attention_linear_output_loss: 1.7882 - val_VL_attention_linear_output_acc: 0.4925 - val_VH_attention_linear_output_acc: 0.4721\n",
      "Epoch 2882/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4519 - VL_attention_linear_output_loss: 1.7170 - VH_attention_linear_output_loss: 1.7349 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4840 - val_loss: 3.5463 - val_VL_attention_linear_output_loss: 1.7719 - val_VH_attention_linear_output_loss: 1.7745 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4729\n",
      "Epoch 2883/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4439 - VL_attention_linear_output_loss: 1.7145 - VH_attention_linear_output_loss: 1.7294 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4864 - val_loss: 3.5412 - val_VL_attention_linear_output_loss: 1.7716 - val_VH_attention_linear_output_loss: 1.7696 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4824\n",
      "Epoch 2884/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4534 - VL_attention_linear_output_loss: 1.7198 - VH_attention_linear_output_loss: 1.7336 - VL_attention_linear_output_acc: 0.4894 - VH_attention_linear_output_acc: 0.4847 - val_loss: 3.6240 - val_VL_attention_linear_output_loss: 1.7775 - val_VH_attention_linear_output_loss: 1.8465 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4452\n",
      "Epoch 2885/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4430 - VL_attention_linear_output_loss: 1.7127 - VH_attention_linear_output_loss: 1.7303 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4861 - val_loss: 3.5328 - val_VL_attention_linear_output_loss: 1.7596 - val_VH_attention_linear_output_loss: 1.7732 - val_VL_attention_linear_output_acc: 0.4867 - val_VH_attention_linear_output_acc: 0.4743\n",
      "Epoch 2886/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4478 - VL_attention_linear_output_loss: 1.7142 - VH_attention_linear_output_loss: 1.7337 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.4851 - val_loss: 3.5428 - val_VL_attention_linear_output_loss: 1.7697 - val_VH_attention_linear_output_loss: 1.7732 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4804\n",
      "Epoch 2887/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4471 - VL_attention_linear_output_loss: 1.7141 - VH_attention_linear_output_loss: 1.7330 - VL_attention_linear_output_acc: 0.4928 - VH_attention_linear_output_acc: 0.4849 - val_loss: 3.5484 - val_VL_attention_linear_output_loss: 1.7690 - val_VH_attention_linear_output_loss: 1.7794 - val_VL_attention_linear_output_acc: 0.4828 - val_VH_attention_linear_output_acc: 0.4757\n",
      "Epoch 2888/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4515 - VL_attention_linear_output_loss: 1.7154 - VH_attention_linear_output_loss: 1.7362 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4830 - val_loss: 3.5467 - val_VL_attention_linear_output_loss: 1.7753 - val_VH_attention_linear_output_loss: 1.7714 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4805\n",
      "Epoch 2889/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4521 - VL_attention_linear_output_loss: 1.7200 - VH_attention_linear_output_loss: 1.7321 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4859 - val_loss: 3.5529 - val_VL_attention_linear_output_loss: 1.7779 - val_VH_attention_linear_output_loss: 1.7749 - val_VL_attention_linear_output_acc: 0.4804 - val_VH_attention_linear_output_acc: 0.4772\n",
      "Epoch 2890/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4491 - VL_attention_linear_output_loss: 1.7227 - VH_attention_linear_output_loss: 1.7265 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4877 - val_loss: 3.5590 - val_VL_attention_linear_output_loss: 1.7864 - val_VH_attention_linear_output_loss: 1.7727 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.4785\n",
      "Epoch 2891/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4472 - VL_attention_linear_output_loss: 1.7132 - VH_attention_linear_output_loss: 1.7340 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4851 - val_loss: 3.5554 - val_VL_attention_linear_output_loss: 1.7797 - val_VH_attention_linear_output_loss: 1.7756 - val_VL_attention_linear_output_acc: 0.4757 - val_VH_attention_linear_output_acc: 0.4734\n",
      "Epoch 2892/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4365 - VL_attention_linear_output_loss: 1.7122 - VH_attention_linear_output_loss: 1.7244 - VL_attention_linear_output_acc: 0.4932 - VH_attention_linear_output_acc: 0.4875 - val_loss: 3.5342 - val_VL_attention_linear_output_loss: 1.7590 - val_VH_attention_linear_output_loss: 1.7752 - val_VL_attention_linear_output_acc: 0.4908 - val_VH_attention_linear_output_acc: 0.4799\n",
      "Epoch 2893/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4650 - VL_attention_linear_output_loss: 1.7189 - VH_attention_linear_output_loss: 1.7461 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.4811 - val_loss: 3.5645 - val_VL_attention_linear_output_loss: 1.7836 - val_VH_attention_linear_output_loss: 1.7809 - val_VL_attention_linear_output_acc: 0.4741 - val_VH_attention_linear_output_acc: 0.4755\n",
      "Epoch 2894/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4387 - VL_attention_linear_output_loss: 1.7165 - VH_attention_linear_output_loss: 1.7222 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4888 - val_loss: 3.5586 - val_VL_attention_linear_output_loss: 1.7711 - val_VH_attention_linear_output_loss: 1.7875 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4763\n",
      "Epoch 2895/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4471 - VL_attention_linear_output_loss: 1.7156 - VH_attention_linear_output_loss: 1.7315 - VL_attention_linear_output_acc: 0.4928 - VH_attention_linear_output_acc: 0.4860 - val_loss: 3.5390 - val_VL_attention_linear_output_loss: 1.7689 - val_VH_attention_linear_output_loss: 1.7701 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4773\n",
      "Epoch 2896/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4594 - VL_attention_linear_output_loss: 1.7216 - VH_attention_linear_output_loss: 1.7378 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4829 - val_loss: 3.5424 - val_VL_attention_linear_output_loss: 1.7619 - val_VH_attention_linear_output_loss: 1.7805 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.4750\n",
      "Epoch 2897/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4423 - VL_attention_linear_output_loss: 1.7079 - VH_attention_linear_output_loss: 1.7343 - VL_attention_linear_output_acc: 0.4945 - VH_attention_linear_output_acc: 0.4845 - val_loss: 3.5517 - val_VL_attention_linear_output_loss: 1.7677 - val_VH_attention_linear_output_loss: 1.7840 - val_VL_attention_linear_output_acc: 0.4890 - val_VH_attention_linear_output_acc: 0.4696\n",
      "Epoch 2898/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4405 - VL_attention_linear_output_loss: 1.7075 - VH_attention_linear_output_loss: 1.7330 - VL_attention_linear_output_acc: 0.4954 - VH_attention_linear_output_acc: 0.4853 - val_loss: 3.5424 - val_VL_attention_linear_output_loss: 1.7641 - val_VH_attention_linear_output_loss: 1.7783 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4743\n",
      "Epoch 2899/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4464 - VL_attention_linear_output_loss: 1.7158 - VH_attention_linear_output_loss: 1.7306 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4862 - val_loss: 3.5982 - val_VL_attention_linear_output_loss: 1.7834 - val_VH_attention_linear_output_loss: 1.8148 - val_VL_attention_linear_output_acc: 0.4625 - val_VH_attention_linear_output_acc: 0.4644\n",
      "Epoch 2900/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4518 - VL_attention_linear_output_loss: 1.7164 - VH_attention_linear_output_loss: 1.7354 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4842 - val_loss: 3.5473 - val_VL_attention_linear_output_loss: 1.7622 - val_VH_attention_linear_output_loss: 1.7852 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4779\n",
      "Epoch 2901/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4376 - VL_attention_linear_output_loss: 1.7087 - VH_attention_linear_output_loss: 1.7290 - VL_attention_linear_output_acc: 0.4944 - VH_attention_linear_output_acc: 0.4865 - val_loss: 3.5608 - val_VL_attention_linear_output_loss: 1.7921 - val_VH_attention_linear_output_loss: 1.7686 - val_VL_attention_linear_output_acc: 0.4700 - val_VH_attention_linear_output_acc: 0.4788\n",
      "Epoch 2902/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4511 - VL_attention_linear_output_loss: 1.7182 - VH_attention_linear_output_loss: 1.7328 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4851 - val_loss: 3.5549 - val_VL_attention_linear_output_loss: 1.7802 - val_VH_attention_linear_output_loss: 1.7747 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.4778\n",
      "Epoch 2903/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4486 - VL_attention_linear_output_loss: 1.7211 - VH_attention_linear_output_loss: 1.7275 - VL_attention_linear_output_acc: 0.4895 - VH_attention_linear_output_acc: 0.4877 - val_loss: 3.5575 - val_VL_attention_linear_output_loss: 1.7912 - val_VH_attention_linear_output_loss: 1.7664 - val_VL_attention_linear_output_acc: 0.4692 - val_VH_attention_linear_output_acc: 0.4827\n",
      "Epoch 2904/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4475 - VL_attention_linear_output_loss: 1.7163 - VH_attention_linear_output_loss: 1.7313 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4861 - val_loss: 3.5876 - val_VL_attention_linear_output_loss: 1.8144 - val_VH_attention_linear_output_loss: 1.7731 - val_VL_attention_linear_output_acc: 0.4647 - val_VH_attention_linear_output_acc: 0.4780\n",
      "Epoch 2905/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4525 - VL_attention_linear_output_loss: 1.7238 - VH_attention_linear_output_loss: 1.7286 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4873 - val_loss: 3.5419 - val_VL_attention_linear_output_loss: 1.7699 - val_VH_attention_linear_output_loss: 1.7720 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4792\n",
      "Epoch 2906/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4341 - VL_attention_linear_output_loss: 1.7103 - VH_attention_linear_output_loss: 1.7238 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4887 - val_loss: 3.5687 - val_VL_attention_linear_output_loss: 1.7662 - val_VH_attention_linear_output_loss: 1.8025 - val_VL_attention_linear_output_acc: 0.4883 - val_VH_attention_linear_output_acc: 0.4647\n",
      "Epoch 2907/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4431 - VL_attention_linear_output_loss: 1.7135 - VH_attention_linear_output_loss: 1.7296 - VL_attention_linear_output_acc: 0.4923 - VH_attention_linear_output_acc: 0.4868 - val_loss: 3.5931 - val_VL_attention_linear_output_loss: 1.7742 - val_VH_attention_linear_output_loss: 1.8189 - val_VL_attention_linear_output_acc: 0.4779 - val_VH_attention_linear_output_acc: 0.4546\n",
      "Epoch 2908/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4402 - VL_attention_linear_output_loss: 1.7127 - VH_attention_linear_output_loss: 1.7274 - VL_attention_linear_output_acc: 0.4932 - VH_attention_linear_output_acc: 0.4876 - val_loss: 3.6551 - val_VL_attention_linear_output_loss: 1.8851 - val_VH_attention_linear_output_loss: 1.7701 - val_VL_attention_linear_output_acc: 0.4384 - val_VH_attention_linear_output_acc: 0.4750\n",
      "Epoch 2909/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4490 - VL_attention_linear_output_loss: 1.7210 - VH_attention_linear_output_loss: 1.7279 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4873 - val_loss: 3.5779 - val_VL_attention_linear_output_loss: 1.7955 - val_VH_attention_linear_output_loss: 1.7823 - val_VL_attention_linear_output_acc: 0.4692 - val_VH_attention_linear_output_acc: 0.4785\n",
      "Epoch 2910/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4561 - VL_attention_linear_output_loss: 1.7178 - VH_attention_linear_output_loss: 1.7383 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4847 - val_loss: 3.5367 - val_VL_attention_linear_output_loss: 1.7600 - val_VH_attention_linear_output_loss: 1.7767 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.4714\n",
      "Epoch 2911/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4514 - VL_attention_linear_output_loss: 1.7175 - VH_attention_linear_output_loss: 1.7338 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4845 - val_loss: 3.5617 - val_VL_attention_linear_output_loss: 1.7785 - val_VH_attention_linear_output_loss: 1.7832 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4718\n",
      "Epoch 2912/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4329 - VL_attention_linear_output_loss: 1.7112 - VH_attention_linear_output_loss: 1.7216 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4893 - val_loss: 3.5341 - val_VL_attention_linear_output_loss: 1.7589 - val_VH_attention_linear_output_loss: 1.7752 - val_VL_attention_linear_output_acc: 0.4890 - val_VH_attention_linear_output_acc: 0.4791\n",
      "Epoch 2913/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4356 - VL_attention_linear_output_loss: 1.7097 - VH_attention_linear_output_loss: 1.7259 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4872 - val_loss: 3.5641 - val_VL_attention_linear_output_loss: 1.7860 - val_VH_attention_linear_output_loss: 1.7781 - val_VL_attention_linear_output_acc: 0.4777 - val_VH_attention_linear_output_acc: 0.4754\n",
      "Epoch 2914/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4703 - VL_attention_linear_output_loss: 1.7323 - VH_attention_linear_output_loss: 1.7380 - VL_attention_linear_output_acc: 0.4852 - VH_attention_linear_output_acc: 0.4838 - val_loss: 3.5386 - val_VL_attention_linear_output_loss: 1.7702 - val_VH_attention_linear_output_loss: 1.7684 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4752\n",
      "Epoch 2915/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4236 - VL_attention_linear_output_loss: 1.7061 - VH_attention_linear_output_loss: 1.7175 - VL_attention_linear_output_acc: 0.4965 - VH_attention_linear_output_acc: 0.4918 - val_loss: 3.5477 - val_VL_attention_linear_output_loss: 1.7693 - val_VH_attention_linear_output_loss: 1.7784 - val_VL_attention_linear_output_acc: 0.4841 - val_VH_attention_linear_output_acc: 0.4750\n",
      "Epoch 2916/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4405 - VL_attention_linear_output_loss: 1.7165 - VH_attention_linear_output_loss: 1.7239 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4894 - val_loss: 3.5839 - val_VL_attention_linear_output_loss: 1.7823 - val_VH_attention_linear_output_loss: 1.8016 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4663\n",
      "Epoch 2917/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4428 - VL_attention_linear_output_loss: 1.7103 - VH_attention_linear_output_loss: 1.7325 - VL_attention_linear_output_acc: 0.4947 - VH_attention_linear_output_acc: 0.4860 - val_loss: 3.5557 - val_VL_attention_linear_output_loss: 1.7638 - val_VH_attention_linear_output_loss: 1.7919 - val_VL_attention_linear_output_acc: 0.4890 - val_VH_attention_linear_output_acc: 0.4666\n",
      "Epoch 2918/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4521 - VL_attention_linear_output_loss: 1.7186 - VH_attention_linear_output_loss: 1.7336 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4850 - val_loss: 3.5430 - val_VL_attention_linear_output_loss: 1.7751 - val_VH_attention_linear_output_loss: 1.7680 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4786\n",
      "Epoch 2919/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4420 - VL_attention_linear_output_loss: 1.7155 - VH_attention_linear_output_loss: 1.7265 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4881 - val_loss: 3.5429 - val_VL_attention_linear_output_loss: 1.7660 - val_VH_attention_linear_output_loss: 1.7769 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.4785\n",
      "Epoch 2920/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4523 - VL_attention_linear_output_loss: 1.7187 - VH_attention_linear_output_loss: 1.7336 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4859 - val_loss: 3.5712 - val_VL_attention_linear_output_loss: 1.7747 - val_VH_attention_linear_output_loss: 1.7964 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4680\n",
      "Epoch 2921/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4453 - VL_attention_linear_output_loss: 1.7121 - VH_attention_linear_output_loss: 1.7331 - VL_attention_linear_output_acc: 0.4929 - VH_attention_linear_output_acc: 0.4853 - val_loss: 3.5410 - val_VL_attention_linear_output_loss: 1.7702 - val_VH_attention_linear_output_loss: 1.7708 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4779\n",
      "Epoch 2922/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4348 - VL_attention_linear_output_loss: 1.7106 - VH_attention_linear_output_loss: 1.7242 - VL_attention_linear_output_acc: 0.4940 - VH_attention_linear_output_acc: 0.4889 - val_loss: 3.5943 - val_VL_attention_linear_output_loss: 1.7604 - val_VH_attention_linear_output_loss: 1.8339 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.4548\n",
      "Epoch 2923/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4426 - VL_attention_linear_output_loss: 1.7157 - VH_attention_linear_output_loss: 1.7269 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4872 - val_loss: 3.5830 - val_VL_attention_linear_output_loss: 1.8020 - val_VH_attention_linear_output_loss: 1.7810 - val_VL_attention_linear_output_acc: 0.4616 - val_VH_attention_linear_output_acc: 0.4764\n",
      "Epoch 2924/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4469 - VL_attention_linear_output_loss: 1.7177 - VH_attention_linear_output_loss: 1.7293 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4868 - val_loss: 3.5909 - val_VL_attention_linear_output_loss: 1.7831 - val_VH_attention_linear_output_loss: 1.8077 - val_VL_attention_linear_output_acc: 0.4764 - val_VH_attention_linear_output_acc: 0.4648\n",
      "Epoch 2925/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4560 - VL_attention_linear_output_loss: 1.7222 - VH_attention_linear_output_loss: 1.7338 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4847 - val_loss: 3.5501 - val_VL_attention_linear_output_loss: 1.7721 - val_VH_attention_linear_output_loss: 1.7780 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4784\n",
      "Epoch 2926/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4381 - VL_attention_linear_output_loss: 1.7151 - VH_attention_linear_output_loss: 1.7229 - VL_attention_linear_output_acc: 0.4910 - VH_attention_linear_output_acc: 0.4892 - val_loss: 3.5304 - val_VL_attention_linear_output_loss: 1.7634 - val_VH_attention_linear_output_loss: 1.7670 - val_VL_attention_linear_output_acc: 0.4892 - val_VH_attention_linear_output_acc: 0.4830\n",
      "Epoch 2927/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4370 - VL_attention_linear_output_loss: 1.7110 - VH_attention_linear_output_loss: 1.7260 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4886 - val_loss: 3.5519 - val_VL_attention_linear_output_loss: 1.7820 - val_VH_attention_linear_output_loss: 1.7699 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.4785\n",
      "Epoch 2928/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4493 - VL_attention_linear_output_loss: 1.7232 - VH_attention_linear_output_loss: 1.7261 - VL_attention_linear_output_acc: 0.4880 - VH_attention_linear_output_acc: 0.4881 - val_loss: 3.5665 - val_VL_attention_linear_output_loss: 1.7862 - val_VH_attention_linear_output_loss: 1.7802 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4757\n",
      "Epoch 2929/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4309 - VL_attention_linear_output_loss: 1.7070 - VH_attention_linear_output_loss: 1.7239 - VL_attention_linear_output_acc: 0.4949 - VH_attention_linear_output_acc: 0.4890 - val_loss: 3.5327 - val_VL_attention_linear_output_loss: 1.7629 - val_VH_attention_linear_output_loss: 1.7698 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4831\n",
      "Epoch 2930/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4347 - VL_attention_linear_output_loss: 1.7090 - VH_attention_linear_output_loss: 1.7257 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4896 - val_loss: 3.5619 - val_VL_attention_linear_output_loss: 1.7782 - val_VH_attention_linear_output_loss: 1.7837 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4717\n",
      "Epoch 2931/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4413 - VL_attention_linear_output_loss: 1.7158 - VH_attention_linear_output_loss: 1.7255 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4887 - val_loss: 3.5353 - val_VL_attention_linear_output_loss: 1.7639 - val_VH_attention_linear_output_loss: 1.7714 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.4805\n",
      "Epoch 2932/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4458 - VL_attention_linear_output_loss: 1.7183 - VH_attention_linear_output_loss: 1.7275 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4883 - val_loss: 3.5468 - val_VL_attention_linear_output_loss: 1.7845 - val_VH_attention_linear_output_loss: 1.7623 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4787\n",
      "Epoch 2933/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4384 - VL_attention_linear_output_loss: 1.7154 - VH_attention_linear_output_loss: 1.7230 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4896 - val_loss: 3.5914 - val_VL_attention_linear_output_loss: 1.8187 - val_VH_attention_linear_output_loss: 1.7726 - val_VL_attention_linear_output_acc: 0.4677 - val_VH_attention_linear_output_acc: 0.4760\n",
      "Epoch 2934/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4509 - VL_attention_linear_output_loss: 1.7163 - VH_attention_linear_output_loss: 1.7346 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4852 - val_loss: 3.5594 - val_VL_attention_linear_output_loss: 1.7897 - val_VH_attention_linear_output_loss: 1.7697 - val_VL_attention_linear_output_acc: 0.4757 - val_VH_attention_linear_output_acc: 0.4756\n",
      "Epoch 2935/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4501 - VL_attention_linear_output_loss: 1.7222 - VH_attention_linear_output_loss: 1.7279 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4882 - val_loss: 3.5396 - val_VL_attention_linear_output_loss: 1.7637 - val_VH_attention_linear_output_loss: 1.7759 - val_VL_attention_linear_output_acc: 0.4901 - val_VH_attention_linear_output_acc: 0.4775\n",
      "Epoch 2936/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4344 - VL_attention_linear_output_loss: 1.7084 - VH_attention_linear_output_loss: 1.7260 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4882 - val_loss: 3.5406 - val_VL_attention_linear_output_loss: 1.7651 - val_VH_attention_linear_output_loss: 1.7755 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4790\n",
      "Epoch 2937/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4419 - VL_attention_linear_output_loss: 1.7150 - VH_attention_linear_output_loss: 1.7269 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4879 - val_loss: 3.5333 - val_VL_attention_linear_output_loss: 1.7649 - val_VH_attention_linear_output_loss: 1.7683 - val_VL_attention_linear_output_acc: 0.4888 - val_VH_attention_linear_output_acc: 0.4810\n",
      "Epoch 2938/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4450 - VL_attention_linear_output_loss: 1.7162 - VH_attention_linear_output_loss: 1.7288 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4873 - val_loss: 3.5420 - val_VL_attention_linear_output_loss: 1.7710 - val_VH_attention_linear_output_loss: 1.7710 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.4795\n",
      "Epoch 2939/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4353 - VL_attention_linear_output_loss: 1.7052 - VH_attention_linear_output_loss: 1.7302 - VL_attention_linear_output_acc: 0.4954 - VH_attention_linear_output_acc: 0.4865 - val_loss: 3.5403 - val_VL_attention_linear_output_loss: 1.7666 - val_VH_attention_linear_output_loss: 1.7737 - val_VL_attention_linear_output_acc: 0.4895 - val_VH_attention_linear_output_acc: 0.4803\n",
      "Epoch 2940/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4474 - VL_attention_linear_output_loss: 1.7104 - VH_attention_linear_output_loss: 1.7370 - VL_attention_linear_output_acc: 0.4941 - VH_attention_linear_output_acc: 0.4843 - val_loss: 3.5393 - val_VL_attention_linear_output_loss: 1.7747 - val_VH_attention_linear_output_loss: 1.7646 - val_VL_attention_linear_output_acc: 0.4766 - val_VH_attention_linear_output_acc: 0.4791\n",
      "Epoch 2941/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4424 - VL_attention_linear_output_loss: 1.7189 - VH_attention_linear_output_loss: 1.7235 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4901 - val_loss: 3.5422 - val_VL_attention_linear_output_loss: 1.7761 - val_VH_attention_linear_output_loss: 1.7661 - val_VL_attention_linear_output_acc: 0.4816 - val_VH_attention_linear_output_acc: 0.4827\n",
      "Epoch 2942/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4408 - VL_attention_linear_output_loss: 1.7130 - VH_attention_linear_output_loss: 1.7277 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4874 - val_loss: 3.5455 - val_VL_attention_linear_output_loss: 1.7681 - val_VH_attention_linear_output_loss: 1.7774 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4771\n",
      "Epoch 2943/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4537 - VL_attention_linear_output_loss: 1.7269 - VH_attention_linear_output_loss: 1.7268 - VL_attention_linear_output_acc: 0.4859 - VH_attention_linear_output_acc: 0.4881 - val_loss: 3.5439 - val_VL_attention_linear_output_loss: 1.7682 - val_VH_attention_linear_output_loss: 1.7758 - val_VL_attention_linear_output_acc: 0.4854 - val_VH_attention_linear_output_acc: 0.4787\n",
      "Epoch 2944/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4350 - VL_attention_linear_output_loss: 1.7064 - VH_attention_linear_output_loss: 1.7286 - VL_attention_linear_output_acc: 0.4947 - VH_attention_linear_output_acc: 0.4871 - val_loss: 3.5418 - val_VL_attention_linear_output_loss: 1.7671 - val_VH_attention_linear_output_loss: 1.7747 - val_VL_attention_linear_output_acc: 0.4899 - val_VH_attention_linear_output_acc: 0.4825\n",
      "Epoch 2945/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4391 - VL_attention_linear_output_loss: 1.7091 - VH_attention_linear_output_loss: 1.7299 - VL_attention_linear_output_acc: 0.4938 - VH_attention_linear_output_acc: 0.4874 - val_loss: 3.5458 - val_VL_attention_linear_output_loss: 1.7730 - val_VH_attention_linear_output_loss: 1.7728 - val_VL_attention_linear_output_acc: 0.4750 - val_VH_attention_linear_output_acc: 0.4789\n",
      "Epoch 2946/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4315 - VL_attention_linear_output_loss: 1.7087 - VH_attention_linear_output_loss: 1.7229 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4901 - val_loss: 3.5296 - val_VL_attention_linear_output_loss: 1.7647 - val_VH_attention_linear_output_loss: 1.7649 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.4806\n",
      "Epoch 2947/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4502 - VL_attention_linear_output_loss: 1.7235 - VH_attention_linear_output_loss: 1.7266 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4889 - val_loss: 3.5708 - val_VL_attention_linear_output_loss: 1.7786 - val_VH_attention_linear_output_loss: 1.7922 - val_VL_attention_linear_output_acc: 0.4748 - val_VH_attention_linear_output_acc: 0.4701\n",
      "Epoch 2948/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4442 - VL_attention_linear_output_loss: 1.7201 - VH_attention_linear_output_loss: 1.7240 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4893 - val_loss: 3.6002 - val_VL_attention_linear_output_loss: 1.8359 - val_VH_attention_linear_output_loss: 1.7643 - val_VL_attention_linear_output_acc: 0.4467 - val_VH_attention_linear_output_acc: 0.4795\n",
      "Epoch 2949/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4439 - VL_attention_linear_output_loss: 1.7180 - VH_attention_linear_output_loss: 1.7259 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4895 - val_loss: 3.5386 - val_VL_attention_linear_output_loss: 1.7669 - val_VH_attention_linear_output_loss: 1.7717 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4788\n",
      "Epoch 2950/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4525 - VL_attention_linear_output_loss: 1.7209 - VH_attention_linear_output_loss: 1.7316 - VL_attention_linear_output_acc: 0.4894 - VH_attention_linear_output_acc: 0.4864 - val_loss: 3.6058 - val_VL_attention_linear_output_loss: 1.8250 - val_VH_attention_linear_output_loss: 1.7808 - val_VL_attention_linear_output_acc: 0.4537 - val_VH_attention_linear_output_acc: 0.4785\n",
      "Epoch 2951/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4455 - VL_attention_linear_output_loss: 1.7247 - VH_attention_linear_output_loss: 1.7208 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4903 - val_loss: 3.5454 - val_VL_attention_linear_output_loss: 1.7685 - val_VH_attention_linear_output_loss: 1.7770 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4752\n",
      "Epoch 2952/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4397 - VL_attention_linear_output_loss: 1.7105 - VH_attention_linear_output_loss: 1.7292 - VL_attention_linear_output_acc: 0.4956 - VH_attention_linear_output_acc: 0.4876 - val_loss: 3.5357 - val_VL_attention_linear_output_loss: 1.7669 - val_VH_attention_linear_output_loss: 1.7688 - val_VL_attention_linear_output_acc: 0.4894 - val_VH_attention_linear_output_acc: 0.4774\n",
      "Epoch 2953/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4295 - VL_attention_linear_output_loss: 1.7049 - VH_attention_linear_output_loss: 1.7246 - VL_attention_linear_output_acc: 0.4958 - VH_attention_linear_output_acc: 0.4892 - val_loss: 3.5323 - val_VL_attention_linear_output_loss: 1.7703 - val_VH_attention_linear_output_loss: 1.7620 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4823\n",
      "Epoch 2954/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4455 - VL_attention_linear_output_loss: 1.7213 - VH_attention_linear_output_loss: 1.7242 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4896 - val_loss: 3.5255 - val_VL_attention_linear_output_loss: 1.7631 - val_VH_attention_linear_output_loss: 1.7623 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4781\n",
      "Epoch 2955/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4421 - VL_attention_linear_output_loss: 1.7194 - VH_attention_linear_output_loss: 1.7228 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4909 - val_loss: 3.5529 - val_VL_attention_linear_output_loss: 1.7847 - val_VH_attention_linear_output_loss: 1.7682 - val_VL_attention_linear_output_acc: 0.4725 - val_VH_attention_linear_output_acc: 0.4801\n",
      "Epoch 2956/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4440 - VL_attention_linear_output_loss: 1.7232 - VH_attention_linear_output_loss: 1.7207 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4904 - val_loss: 3.5371 - val_VL_attention_linear_output_loss: 1.7684 - val_VH_attention_linear_output_loss: 1.7687 - val_VL_attention_linear_output_acc: 0.4882 - val_VH_attention_linear_output_acc: 0.4835\n",
      "Epoch 2957/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4493 - VL_attention_linear_output_loss: 1.7171 - VH_attention_linear_output_loss: 1.7322 - VL_attention_linear_output_acc: 0.4893 - VH_attention_linear_output_acc: 0.4866 - val_loss: 3.5370 - val_VL_attention_linear_output_loss: 1.7686 - val_VH_attention_linear_output_loss: 1.7685 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4795\n",
      "Epoch 2958/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4388 - VL_attention_linear_output_loss: 1.7148 - VH_attention_linear_output_loss: 1.7240 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4903 - val_loss: 3.5413 - val_VL_attention_linear_output_loss: 1.7738 - val_VH_attention_linear_output_loss: 1.7676 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4792\n",
      "Epoch 2959/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4299 - VL_attention_linear_output_loss: 1.7135 - VH_attention_linear_output_loss: 1.7164 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4935 - val_loss: 3.5584 - val_VL_attention_linear_output_loss: 1.7950 - val_VH_attention_linear_output_loss: 1.7634 - val_VL_attention_linear_output_acc: 0.4650 - val_VH_attention_linear_output_acc: 0.4853\n",
      "Epoch 2960/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4341 - VL_attention_linear_output_loss: 1.7130 - VH_attention_linear_output_loss: 1.7212 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4911 - val_loss: 3.5433 - val_VL_attention_linear_output_loss: 1.7727 - val_VH_attention_linear_output_loss: 1.7706 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4838\n",
      "Epoch 2961/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4572 - VL_attention_linear_output_loss: 1.7212 - VH_attention_linear_output_loss: 1.7360 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4853 - val_loss: 3.5600 - val_VL_attention_linear_output_loss: 1.7784 - val_VH_attention_linear_output_loss: 1.7815 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4781\n",
      "Epoch 2962/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4309 - VL_attention_linear_output_loss: 1.7120 - VH_attention_linear_output_loss: 1.7189 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4922 - val_loss: 3.5237 - val_VL_attention_linear_output_loss: 1.7620 - val_VH_attention_linear_output_loss: 1.7617 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4826\n",
      "Epoch 2963/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4292 - VL_attention_linear_output_loss: 1.7082 - VH_attention_linear_output_loss: 1.7210 - VL_attention_linear_output_acc: 0.4941 - VH_attention_linear_output_acc: 0.4919 - val_loss: 3.5478 - val_VL_attention_linear_output_loss: 1.7743 - val_VH_attention_linear_output_loss: 1.7735 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4746\n",
      "Epoch 2964/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4574 - VL_attention_linear_output_loss: 1.7221 - VH_attention_linear_output_loss: 1.7354 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4849 - val_loss: 3.5530 - val_VL_attention_linear_output_loss: 1.7927 - val_VH_attention_linear_output_loss: 1.7603 - val_VL_attention_linear_output_acc: 0.4667 - val_VH_attention_linear_output_acc: 0.4812\n",
      "Epoch 2965/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4297 - VL_attention_linear_output_loss: 1.7114 - VH_attention_linear_output_loss: 1.7183 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4923 - val_loss: 3.5644 - val_VL_attention_linear_output_loss: 1.8041 - val_VH_attention_linear_output_loss: 1.7604 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.4817\n",
      "Epoch 2966/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4485 - VL_attention_linear_output_loss: 1.7162 - VH_attention_linear_output_loss: 1.7323 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4860 - val_loss: 3.5623 - val_VL_attention_linear_output_loss: 1.7736 - val_VH_attention_linear_output_loss: 1.7887 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4733\n",
      "Epoch 2967/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4398 - VL_attention_linear_output_loss: 1.7173 - VH_attention_linear_output_loss: 1.7225 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4902 - val_loss: 3.5537 - val_VL_attention_linear_output_loss: 1.7845 - val_VH_attention_linear_output_loss: 1.7692 - val_VL_attention_linear_output_acc: 0.4730 - val_VH_attention_linear_output_acc: 0.4785\n",
      "Epoch 2968/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4565 - VL_attention_linear_output_loss: 1.7214 - VH_attention_linear_output_loss: 1.7351 - VL_attention_linear_output_acc: 0.4881 - VH_attention_linear_output_acc: 0.4852 - val_loss: 3.5583 - val_VL_attention_linear_output_loss: 1.7663 - val_VH_attention_linear_output_loss: 1.7919 - val_VL_attention_linear_output_acc: 0.4912 - val_VH_attention_linear_output_acc: 0.4695\n",
      "Epoch 2969/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4322 - VL_attention_linear_output_loss: 1.7118 - VH_attention_linear_output_loss: 1.7205 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4914 - val_loss: 3.5456 - val_VL_attention_linear_output_loss: 1.7804 - val_VH_attention_linear_output_loss: 1.7651 - val_VL_attention_linear_output_acc: 0.4730 - val_VH_attention_linear_output_acc: 0.4850\n",
      "Epoch 2970/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4411 - VL_attention_linear_output_loss: 1.7212 - VH_attention_linear_output_loss: 1.7199 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4921 - val_loss: 3.5420 - val_VL_attention_linear_output_loss: 1.7679 - val_VH_attention_linear_output_loss: 1.7741 - val_VL_attention_linear_output_acc: 0.4889 - val_VH_attention_linear_output_acc: 0.4786\n",
      "Epoch 2971/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4288 - VL_attention_linear_output_loss: 1.7082 - VH_attention_linear_output_loss: 1.7206 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4915 - val_loss: 3.5325 - val_VL_attention_linear_output_loss: 1.7643 - val_VH_attention_linear_output_loss: 1.7682 - val_VL_attention_linear_output_acc: 0.4889 - val_VH_attention_linear_output_acc: 0.4836\n",
      "Epoch 2972/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4487 - VL_attention_linear_output_loss: 1.7219 - VH_attention_linear_output_loss: 1.7268 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4893 - val_loss: 3.5385 - val_VL_attention_linear_output_loss: 1.7787 - val_VH_attention_linear_output_loss: 1.7598 - val_VL_attention_linear_output_acc: 0.4782 - val_VH_attention_linear_output_acc: 0.4845\n",
      "Epoch 2973/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4526 - VL_attention_linear_output_loss: 1.7171 - VH_attention_linear_output_loss: 1.7355 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4849 - val_loss: 3.5690 - val_VL_attention_linear_output_loss: 1.7630 - val_VH_attention_linear_output_loss: 1.8060 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4677\n",
      "Epoch 2974/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4306 - VL_attention_linear_output_loss: 1.7076 - VH_attention_linear_output_loss: 1.7230 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4907 - val_loss: 3.5327 - val_VL_attention_linear_output_loss: 1.7679 - val_VH_attention_linear_output_loss: 1.7648 - val_VL_attention_linear_output_acc: 0.4885 - val_VH_attention_linear_output_acc: 0.4803\n",
      "Epoch 2975/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4335 - VL_attention_linear_output_loss: 1.7128 - VH_attention_linear_output_loss: 1.7208 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4916 - val_loss: 3.5348 - val_VL_attention_linear_output_loss: 1.7668 - val_VH_attention_linear_output_loss: 1.7681 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4778\n",
      "Epoch 2976/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4448 - VL_attention_linear_output_loss: 1.7121 - VH_attention_linear_output_loss: 1.7327 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4861 - val_loss: 3.5483 - val_VL_attention_linear_output_loss: 1.7749 - val_VH_attention_linear_output_loss: 1.7734 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4835\n",
      "Epoch 2977/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4342 - VL_attention_linear_output_loss: 1.7141 - VH_attention_linear_output_loss: 1.7201 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4921 - val_loss: 3.5523 - val_VL_attention_linear_output_loss: 1.7799 - val_VH_attention_linear_output_loss: 1.7724 - val_VL_attention_linear_output_acc: 0.4718 - val_VH_attention_linear_output_acc: 0.4814\n",
      "Epoch 2978/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4394 - VL_attention_linear_output_loss: 1.7166 - VH_attention_linear_output_loss: 1.7228 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4909 - val_loss: 3.5714 - val_VL_attention_linear_output_loss: 1.7972 - val_VH_attention_linear_output_loss: 1.7742 - val_VL_attention_linear_output_acc: 0.4676 - val_VH_attention_linear_output_acc: 0.4748\n",
      "Epoch 2979/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4412 - VL_attention_linear_output_loss: 1.7108 - VH_attention_linear_output_loss: 1.7304 - VL_attention_linear_output_acc: 0.4940 - VH_attention_linear_output_acc: 0.4877 - val_loss: 3.5504 - val_VL_attention_linear_output_loss: 1.7733 - val_VH_attention_linear_output_loss: 1.7771 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4744\n",
      "Epoch 2980/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4479 - VL_attention_linear_output_loss: 1.7235 - VH_attention_linear_output_loss: 1.7243 - VL_attention_linear_output_acc: 0.4876 - VH_attention_linear_output_acc: 0.4892 - val_loss: 3.5563 - val_VL_attention_linear_output_loss: 1.7950 - val_VH_attention_linear_output_loss: 1.7613 - val_VL_attention_linear_output_acc: 0.4724 - val_VH_attention_linear_output_acc: 0.4885\n",
      "Epoch 2981/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4272 - VL_attention_linear_output_loss: 1.7075 - VH_attention_linear_output_loss: 1.7196 - VL_attention_linear_output_acc: 0.4955 - VH_attention_linear_output_acc: 0.4921 - val_loss: 3.5458 - val_VL_attention_linear_output_loss: 1.7739 - val_VH_attention_linear_output_loss: 1.7719 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4741\n",
      "Epoch 2982/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4418 - VL_attention_linear_output_loss: 1.7139 - VH_attention_linear_output_loss: 1.7279 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4885 - val_loss: 3.5600 - val_VL_attention_linear_output_loss: 1.7750 - val_VH_attention_linear_output_loss: 1.7849 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4795\n",
      "Epoch 2983/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4343 - VL_attention_linear_output_loss: 1.7086 - VH_attention_linear_output_loss: 1.7257 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4887 - val_loss: 3.5583 - val_VL_attention_linear_output_loss: 1.7713 - val_VH_attention_linear_output_loss: 1.7870 - val_VL_attention_linear_output_acc: 0.4820 - val_VH_attention_linear_output_acc: 0.4780\n",
      "Epoch 2984/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4373 - VL_attention_linear_output_loss: 1.7111 - VH_attention_linear_output_loss: 1.7262 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4892 - val_loss: 3.5362 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7734 - val_VL_attention_linear_output_acc: 0.4872 - val_VH_attention_linear_output_acc: 0.4817\n",
      "Epoch 2985/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4496 - VL_attention_linear_output_loss: 1.7158 - VH_attention_linear_output_loss: 1.7338 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4858 - val_loss: 3.5349 - val_VL_attention_linear_output_loss: 1.7664 - val_VH_attention_linear_output_loss: 1.7685 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4848\n",
      "Epoch 2986/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4324 - VL_attention_linear_output_loss: 1.7114 - VH_attention_linear_output_loss: 1.7210 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4919 - val_loss: 3.5634 - val_VL_attention_linear_output_loss: 1.7851 - val_VH_attention_linear_output_loss: 1.7783 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.4770\n",
      "Epoch 2987/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4576 - VL_attention_linear_output_loss: 1.7238 - VH_attention_linear_output_loss: 1.7338 - VL_attention_linear_output_acc: 0.4862 - VH_attention_linear_output_acc: 0.4870 - val_loss: 3.6400 - val_VL_attention_linear_output_loss: 1.8026 - val_VH_attention_linear_output_loss: 1.8374 - val_VL_attention_linear_output_acc: 0.4656 - val_VH_attention_linear_output_acc: 0.4492\n",
      "Epoch 2988/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4343 - VL_attention_linear_output_loss: 1.7105 - VH_attention_linear_output_loss: 1.7238 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4907 - val_loss: 3.5387 - val_VL_attention_linear_output_loss: 1.7695 - val_VH_attention_linear_output_loss: 1.7692 - val_VL_attention_linear_output_acc: 0.4776 - val_VH_attention_linear_output_acc: 0.4797\n",
      "Epoch 2989/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4427 - VL_attention_linear_output_loss: 1.7122 - VH_attention_linear_output_loss: 1.7305 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4880 - val_loss: 3.5934 - val_VL_attention_linear_output_loss: 1.7867 - val_VH_attention_linear_output_loss: 1.8067 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4674\n",
      "Epoch 2990/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4432 - VL_attention_linear_output_loss: 1.7224 - VH_attention_linear_output_loss: 1.7209 - VL_attention_linear_output_acc: 0.4877 - VH_attention_linear_output_acc: 0.4927 - val_loss: 3.5538 - val_VL_attention_linear_output_loss: 1.7697 - val_VH_attention_linear_output_loss: 1.7841 - val_VL_attention_linear_output_acc: 0.4885 - val_VH_attention_linear_output_acc: 0.4718\n",
      "Epoch 2991/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4501 - VL_attention_linear_output_loss: 1.7116 - VH_attention_linear_output_loss: 1.7384 - VL_attention_linear_output_acc: 0.4929 - VH_attention_linear_output_acc: 0.4840 - val_loss: 3.5311 - val_VL_attention_linear_output_loss: 1.7693 - val_VH_attention_linear_output_loss: 1.7618 - val_VL_attention_linear_output_acc: 0.4882 - val_VH_attention_linear_output_acc: 0.4863\n",
      "Epoch 2992/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4380 - VL_attention_linear_output_loss: 1.7083 - VH_attention_linear_output_loss: 1.7297 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4885 - val_loss: 3.5489 - val_VL_attention_linear_output_loss: 1.7829 - val_VH_attention_linear_output_loss: 1.7660 - val_VL_attention_linear_output_acc: 0.4738 - val_VH_attention_linear_output_acc: 0.4868\n",
      "Epoch 2993/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4274 - VL_attention_linear_output_loss: 1.7104 - VH_attention_linear_output_loss: 1.7169 - VL_attention_linear_output_acc: 0.4932 - VH_attention_linear_output_acc: 0.4937 - val_loss: 3.5400 - val_VL_attention_linear_output_loss: 1.7697 - val_VH_attention_linear_output_loss: 1.7703 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4854\n",
      "Epoch 2994/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4343 - VL_attention_linear_output_loss: 1.7148 - VH_attention_linear_output_loss: 1.7195 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4920 - val_loss: 3.5338 - val_VL_attention_linear_output_loss: 1.7606 - val_VH_attention_linear_output_loss: 1.7733 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4834\n",
      "Epoch 2995/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4327 - VL_attention_linear_output_loss: 1.7096 - VH_attention_linear_output_loss: 1.7232 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4905 - val_loss: 3.5571 - val_VL_attention_linear_output_loss: 1.7772 - val_VH_attention_linear_output_loss: 1.7799 - val_VL_attention_linear_output_acc: 0.4755 - val_VH_attention_linear_output_acc: 0.4780\n",
      "Epoch 2996/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4464 - VL_attention_linear_output_loss: 1.7246 - VH_attention_linear_output_loss: 1.7218 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4917 - val_loss: 3.5401 - val_VL_attention_linear_output_loss: 1.7700 - val_VH_attention_linear_output_loss: 1.7701 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4807\n",
      "Epoch 2997/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4346 - VL_attention_linear_output_loss: 1.7024 - VH_attention_linear_output_loss: 1.7322 - VL_attention_linear_output_acc: 0.4969 - VH_attention_linear_output_acc: 0.4868 - val_loss: 3.5294 - val_VL_attention_linear_output_loss: 1.7657 - val_VH_attention_linear_output_loss: 1.7638 - val_VL_attention_linear_output_acc: 0.4828 - val_VH_attention_linear_output_acc: 0.4832\n",
      "Epoch 2998/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4213 - VL_attention_linear_output_loss: 1.7030 - VH_attention_linear_output_loss: 1.7182 - VL_attention_linear_output_acc: 0.4979 - VH_attention_linear_output_acc: 0.4925 - val_loss: 3.5446 - val_VL_attention_linear_output_loss: 1.7728 - val_VH_attention_linear_output_loss: 1.7718 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4775\n",
      "Epoch 2999/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4233 - VL_attention_linear_output_loss: 1.7062 - VH_attention_linear_output_loss: 1.7171 - VL_attention_linear_output_acc: 0.4940 - VH_attention_linear_output_acc: 0.4932 - val_loss: 3.5245 - val_VL_attention_linear_output_loss: 1.7634 - val_VH_attention_linear_output_loss: 1.7611 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4874\n",
      "Epoch 3000/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4225 - VL_attention_linear_output_loss: 1.7059 - VH_attention_linear_output_loss: 1.7166 - VL_attention_linear_output_acc: 0.4956 - VH_attention_linear_output_acc: 0.4936 - val_loss: 3.5349 - val_VL_attention_linear_output_loss: 1.7716 - val_VH_attention_linear_output_loss: 1.7633 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4829\n",
      "Epoch 3001/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4364 - VL_attention_linear_output_loss: 1.7113 - VH_attention_linear_output_loss: 1.7251 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4896 - val_loss: 3.5310 - val_VL_attention_linear_output_loss: 1.7671 - val_VH_attention_linear_output_loss: 1.7639 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4835\n",
      "Epoch 3002/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4370 - VL_attention_linear_output_loss: 1.7111 - VH_attention_linear_output_loss: 1.7259 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4901 - val_loss: 3.5390 - val_VL_attention_linear_output_loss: 1.7622 - val_VH_attention_linear_output_loss: 1.7769 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4793\n",
      "Epoch 3003/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4285 - VL_attention_linear_output_loss: 1.7125 - VH_attention_linear_output_loss: 1.7160 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.4936 - val_loss: 3.5594 - val_VL_attention_linear_output_loss: 1.7941 - val_VH_attention_linear_output_loss: 1.7653 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4830\n",
      "Epoch 3004/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4296 - VL_attention_linear_output_loss: 1.7074 - VH_attention_linear_output_loss: 1.7223 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4910 - val_loss: 3.5333 - val_VL_attention_linear_output_loss: 1.7638 - val_VH_attention_linear_output_loss: 1.7695 - val_VL_attention_linear_output_acc: 0.4892 - val_VH_attention_linear_output_acc: 0.4842\n",
      "Epoch 3005/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4318 - VL_attention_linear_output_loss: 1.7126 - VH_attention_linear_output_loss: 1.7192 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4928 - val_loss: 3.5393 - val_VL_attention_linear_output_loss: 1.7660 - val_VH_attention_linear_output_loss: 1.7733 - val_VL_attention_linear_output_acc: 0.4893 - val_VH_attention_linear_output_acc: 0.4745\n",
      "Epoch 3006/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4387 - VL_attention_linear_output_loss: 1.7130 - VH_attention_linear_output_loss: 1.7257 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4899 - val_loss: 3.5339 - val_VL_attention_linear_output_loss: 1.7602 - val_VH_attention_linear_output_loss: 1.7737 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4792\n",
      "Epoch 3007/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4247 - VL_attention_linear_output_loss: 1.7077 - VH_attention_linear_output_loss: 1.7170 - VL_attention_linear_output_acc: 0.4947 - VH_attention_linear_output_acc: 0.4935 - val_loss: 3.5609 - val_VL_attention_linear_output_loss: 1.7806 - val_VH_attention_linear_output_loss: 1.7803 - val_VL_attention_linear_output_acc: 0.4781 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 3008/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4469 - VL_attention_linear_output_loss: 1.7119 - VH_attention_linear_output_loss: 1.7350 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4859 - val_loss: 3.5689 - val_VL_attention_linear_output_loss: 1.8093 - val_VH_attention_linear_output_loss: 1.7595 - val_VL_attention_linear_output_acc: 0.4649 - val_VH_attention_linear_output_acc: 0.4835\n",
      "Epoch 3009/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4320 - VL_attention_linear_output_loss: 1.7154 - VH_attention_linear_output_loss: 1.7166 - VL_attention_linear_output_acc: 0.4906 - VH_attention_linear_output_acc: 0.4930 - val_loss: 3.5348 - val_VL_attention_linear_output_loss: 1.7669 - val_VH_attention_linear_output_loss: 1.7679 - val_VL_attention_linear_output_acc: 0.4910 - val_VH_attention_linear_output_acc: 0.4832\n",
      "Epoch 3010/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4244 - VL_attention_linear_output_loss: 1.7086 - VH_attention_linear_output_loss: 1.7158 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4940 - val_loss: 3.5328 - val_VL_attention_linear_output_loss: 1.7723 - val_VH_attention_linear_output_loss: 1.7605 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4830\n",
      "Epoch 3011/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4397 - VL_attention_linear_output_loss: 1.7116 - VH_attention_linear_output_loss: 1.7281 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.4893 - val_loss: 3.5746 - val_VL_attention_linear_output_loss: 1.7810 - val_VH_attention_linear_output_loss: 1.7936 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4743\n",
      "Epoch 3012/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4278 - VL_attention_linear_output_loss: 1.7080 - VH_attention_linear_output_loss: 1.7198 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4927 - val_loss: 3.5236 - val_VL_attention_linear_output_loss: 1.7621 - val_VH_attention_linear_output_loss: 1.7615 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4883\n",
      "Epoch 3013/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4298 - VL_attention_linear_output_loss: 1.7104 - VH_attention_linear_output_loss: 1.7194 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4930 - val_loss: 3.5253 - val_VL_attention_linear_output_loss: 1.7557 - val_VH_attention_linear_output_loss: 1.7696 - val_VL_attention_linear_output_acc: 0.4886 - val_VH_attention_linear_output_acc: 0.4837\n",
      "Epoch 3014/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4273 - VL_attention_linear_output_loss: 1.7036 - VH_attention_linear_output_loss: 1.7236 - VL_attention_linear_output_acc: 0.4962 - VH_attention_linear_output_acc: 0.4904 - val_loss: 3.5515 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7888 - val_VL_attention_linear_output_acc: 0.4885 - val_VH_attention_linear_output_acc: 0.4711\n",
      "Epoch 3015/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4280 - VL_attention_linear_output_loss: 1.7049 - VH_attention_linear_output_loss: 1.7231 - VL_attention_linear_output_acc: 0.4950 - VH_attention_linear_output_acc: 0.4911 - val_loss: 3.5285 - val_VL_attention_linear_output_loss: 1.7635 - val_VH_attention_linear_output_loss: 1.7650 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4872\n",
      "Epoch 3016/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4333 - VL_attention_linear_output_loss: 1.7145 - VH_attention_linear_output_loss: 1.7187 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4925 - val_loss: 3.5542 - val_VL_attention_linear_output_loss: 1.7916 - val_VH_attention_linear_output_loss: 1.7626 - val_VL_attention_linear_output_acc: 0.4725 - val_VH_attention_linear_output_acc: 0.4825\n",
      "Epoch 3017/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4411 - VL_attention_linear_output_loss: 1.7169 - VH_attention_linear_output_loss: 1.7242 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4902 - val_loss: 3.5462 - val_VL_attention_linear_output_loss: 1.7727 - val_VH_attention_linear_output_loss: 1.7735 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4762\n",
      "Epoch 3018/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4254 - VL_attention_linear_output_loss: 1.7048 - VH_attention_linear_output_loss: 1.7206 - VL_attention_linear_output_acc: 0.4956 - VH_attention_linear_output_acc: 0.4914 - val_loss: 3.5278 - val_VL_attention_linear_output_loss: 1.7699 - val_VH_attention_linear_output_loss: 1.7579 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4802\n",
      "Epoch 3019/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4305 - VL_attention_linear_output_loss: 1.7068 - VH_attention_linear_output_loss: 1.7237 - VL_attention_linear_output_acc: 0.4952 - VH_attention_linear_output_acc: 0.4903 - val_loss: 3.6105 - val_VL_attention_linear_output_loss: 1.7963 - val_VH_attention_linear_output_loss: 1.8143 - val_VL_attention_linear_output_acc: 0.4710 - val_VH_attention_linear_output_acc: 0.4638\n",
      "Epoch 3020/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4360 - VL_attention_linear_output_loss: 1.7124 - VH_attention_linear_output_loss: 1.7236 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4904 - val_loss: 3.5375 - val_VL_attention_linear_output_loss: 1.7632 - val_VH_attention_linear_output_loss: 1.7743 - val_VL_attention_linear_output_acc: 0.4884 - val_VH_attention_linear_output_acc: 0.4811\n",
      "Epoch 3021/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4231 - VL_attention_linear_output_loss: 1.7068 - VH_attention_linear_output_loss: 1.7164 - VL_attention_linear_output_acc: 0.4947 - VH_attention_linear_output_acc: 0.4937 - val_loss: 3.5616 - val_VL_attention_linear_output_loss: 1.7685 - val_VH_attention_linear_output_loss: 1.7931 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4734\n",
      "Epoch 3022/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4421 - VL_attention_linear_output_loss: 1.7162 - VH_attention_linear_output_loss: 1.7260 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4897 - val_loss: 3.5654 - val_VL_attention_linear_output_loss: 1.7974 - val_VH_attention_linear_output_loss: 1.7680 - val_VL_attention_linear_output_acc: 0.4667 - val_VH_attention_linear_output_acc: 0.4807\n",
      "Epoch 3023/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4438 - VL_attention_linear_output_loss: 1.7212 - VH_attention_linear_output_loss: 1.7226 - VL_attention_linear_output_acc: 0.4877 - VH_attention_linear_output_acc: 0.4919 - val_loss: 3.5529 - val_VL_attention_linear_output_loss: 1.7843 - val_VH_attention_linear_output_loss: 1.7686 - val_VL_attention_linear_output_acc: 0.4686 - val_VH_attention_linear_output_acc: 0.4811\n",
      "Epoch 3024/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4419 - VL_attention_linear_output_loss: 1.7181 - VH_attention_linear_output_loss: 1.7238 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4909 - val_loss: 3.5390 - val_VL_attention_linear_output_loss: 1.7738 - val_VH_attention_linear_output_loss: 1.7652 - val_VL_attention_linear_output_acc: 0.4828 - val_VH_attention_linear_output_acc: 0.4842\n",
      "Epoch 3025/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4282 - VL_attention_linear_output_loss: 1.7125 - VH_attention_linear_output_loss: 1.7157 - VL_attention_linear_output_acc: 0.4923 - VH_attention_linear_output_acc: 0.4943 - val_loss: 3.5517 - val_VL_attention_linear_output_loss: 1.7720 - val_VH_attention_linear_output_loss: 1.7797 - val_VL_attention_linear_output_acc: 0.4822 - val_VH_attention_linear_output_acc: 0.4792\n",
      "Epoch 3026/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4251 - VL_attention_linear_output_loss: 1.7048 - VH_attention_linear_output_loss: 1.7204 - VL_attention_linear_output_acc: 0.4963 - VH_attention_linear_output_acc: 0.4921 - val_loss: 3.5994 - val_VL_attention_linear_output_loss: 1.7654 - val_VH_attention_linear_output_loss: 1.8340 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4535\n",
      "Epoch 3027/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4345 - VL_attention_linear_output_loss: 1.7076 - VH_attention_linear_output_loss: 1.7269 - VL_attention_linear_output_acc: 0.4933 - VH_attention_linear_output_acc: 0.4893 - val_loss: 3.5352 - val_VL_attention_linear_output_loss: 1.7729 - val_VH_attention_linear_output_loss: 1.7623 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4842\n",
      "Epoch 3028/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4366 - VL_attention_linear_output_loss: 1.7146 - VH_attention_linear_output_loss: 1.7220 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4910 - val_loss: 3.5836 - val_VL_attention_linear_output_loss: 1.7712 - val_VH_attention_linear_output_loss: 1.8124 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4659\n",
      "Epoch 3029/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4336 - VL_attention_linear_output_loss: 1.7067 - VH_attention_linear_output_loss: 1.7269 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4892 - val_loss: 3.5511 - val_VL_attention_linear_output_loss: 1.7915 - val_VH_attention_linear_output_loss: 1.7597 - val_VL_attention_linear_output_acc: 0.4668 - val_VH_attention_linear_output_acc: 0.4877\n",
      "Epoch 3030/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4289 - VL_attention_linear_output_loss: 1.7086 - VH_attention_linear_output_loss: 1.7203 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4919 - val_loss: 3.5553 - val_VL_attention_linear_output_loss: 1.7719 - val_VH_attention_linear_output_loss: 1.7834 - val_VL_attention_linear_output_acc: 0.4775 - val_VH_attention_linear_output_acc: 0.4749\n",
      "Epoch 3031/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4451 - VL_attention_linear_output_loss: 1.7156 - VH_attention_linear_output_loss: 1.7294 - VL_attention_linear_output_acc: 0.4896 - VH_attention_linear_output_acc: 0.4898 - val_loss: 3.7082 - val_VL_attention_linear_output_loss: 1.9143 - val_VH_attention_linear_output_loss: 1.7939 - val_VL_attention_linear_output_acc: 0.4138 - val_VH_attention_linear_output_acc: 0.4718\n",
      "Epoch 3032/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4249 - VL_attention_linear_output_loss: 1.7086 - VH_attention_linear_output_loss: 1.7163 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4938 - val_loss: 3.5321 - val_VL_attention_linear_output_loss: 1.7607 - val_VH_attention_linear_output_loss: 1.7714 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4817\n",
      "Epoch 3033/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4238 - VL_attention_linear_output_loss: 1.7042 - VH_attention_linear_output_loss: 1.7196 - VL_attention_linear_output_acc: 0.4956 - VH_attention_linear_output_acc: 0.4920 - val_loss: 3.5312 - val_VL_attention_linear_output_loss: 1.7632 - val_VH_attention_linear_output_loss: 1.7679 - val_VL_attention_linear_output_acc: 0.4897 - val_VH_attention_linear_output_acc: 0.4851\n",
      "Epoch 3034/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4210 - VL_attention_linear_output_loss: 1.7048 - VH_attention_linear_output_loss: 1.7161 - VL_attention_linear_output_acc: 0.4963 - VH_attention_linear_output_acc: 0.4938 - val_loss: 3.5925 - val_VL_attention_linear_output_loss: 1.7690 - val_VH_attention_linear_output_loss: 1.8235 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4644\n",
      "Epoch 3035/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4336 - VL_attention_linear_output_loss: 1.7077 - VH_attention_linear_output_loss: 1.7259 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4903 - val_loss: 3.5608 - val_VL_attention_linear_output_loss: 1.7845 - val_VH_attention_linear_output_loss: 1.7763 - val_VL_attention_linear_output_acc: 0.4810 - val_VH_attention_linear_output_acc: 0.4750\n",
      "Epoch 3036/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4297 - VL_attention_linear_output_loss: 1.7140 - VH_attention_linear_output_loss: 1.7156 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4939 - val_loss: 3.5903 - val_VL_attention_linear_output_loss: 1.7677 - val_VH_attention_linear_output_loss: 1.8225 - val_VL_attention_linear_output_acc: 0.4884 - val_VH_attention_linear_output_acc: 0.4636\n",
      "Epoch 3037/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4315 - VL_attention_linear_output_loss: 1.7082 - VH_attention_linear_output_loss: 1.7233 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.4904 - val_loss: 3.5442 - val_VL_attention_linear_output_loss: 1.7736 - val_VH_attention_linear_output_loss: 1.7706 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4774\n",
      "Epoch 3038/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4331 - VL_attention_linear_output_loss: 1.7086 - VH_attention_linear_output_loss: 1.7245 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.4899 - val_loss: 3.5286 - val_VL_attention_linear_output_loss: 1.7633 - val_VH_attention_linear_output_loss: 1.7653 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4866\n",
      "Epoch 3039/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4344 - VL_attention_linear_output_loss: 1.7083 - VH_attention_linear_output_loss: 1.7261 - VL_attention_linear_output_acc: 0.4944 - VH_attention_linear_output_acc: 0.4895 - val_loss: 3.5492 - val_VL_attention_linear_output_loss: 1.7725 - val_VH_attention_linear_output_loss: 1.7767 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4799\n",
      "Epoch 3040/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4367 - VL_attention_linear_output_loss: 1.7137 - VH_attention_linear_output_loss: 1.7229 - VL_attention_linear_output_acc: 0.4900 - VH_attention_linear_output_acc: 0.4916 - val_loss: 3.5276 - val_VL_attention_linear_output_loss: 1.7607 - val_VH_attention_linear_output_loss: 1.7670 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4815\n",
      "Epoch 3041/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4304 - VL_attention_linear_output_loss: 1.7064 - VH_attention_linear_output_loss: 1.7240 - VL_attention_linear_output_acc: 0.4944 - VH_attention_linear_output_acc: 0.4905 - val_loss: 3.5440 - val_VL_attention_linear_output_loss: 1.7675 - val_VH_attention_linear_output_loss: 1.7765 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4824\n",
      "Epoch 3042/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4264 - VL_attention_linear_output_loss: 1.7052 - VH_attention_linear_output_loss: 1.7213 - VL_attention_linear_output_acc: 0.4950 - VH_attention_linear_output_acc: 0.4910 - val_loss: 3.5444 - val_VL_attention_linear_output_loss: 1.7719 - val_VH_attention_linear_output_loss: 1.7725 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4807\n",
      "Epoch 3043/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4221 - VL_attention_linear_output_loss: 1.7057 - VH_attention_linear_output_loss: 1.7164 - VL_attention_linear_output_acc: 0.4947 - VH_attention_linear_output_acc: 0.4938 - val_loss: 3.5408 - val_VL_attention_linear_output_loss: 1.7809 - val_VH_attention_linear_output_loss: 1.7599 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4846\n",
      "Epoch 3044/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4461 - VL_attention_linear_output_loss: 1.7236 - VH_attention_linear_output_loss: 1.7225 - VL_attention_linear_output_acc: 0.4866 - VH_attention_linear_output_acc: 0.4912 - val_loss: 3.5831 - val_VL_attention_linear_output_loss: 1.7619 - val_VH_attention_linear_output_loss: 1.8213 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4637\n",
      "Epoch 3045/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4197 - VL_attention_linear_output_loss: 1.6994 - VH_attention_linear_output_loss: 1.7203 - VL_attention_linear_output_acc: 0.4978 - VH_attention_linear_output_acc: 0.4918 - val_loss: 3.5356 - val_VL_attention_linear_output_loss: 1.7645 - val_VH_attention_linear_output_loss: 1.7711 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.4812\n",
      "Epoch 3046/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4387 - VL_attention_linear_output_loss: 1.7151 - VH_attention_linear_output_loss: 1.7236 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.4904 - val_loss: 3.5572 - val_VL_attention_linear_output_loss: 1.7664 - val_VH_attention_linear_output_loss: 1.7908 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4743\n",
      "Epoch 3047/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4383 - VL_attention_linear_output_loss: 1.7135 - VH_attention_linear_output_loss: 1.7248 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4901 - val_loss: 3.5247 - val_VL_attention_linear_output_loss: 1.7616 - val_VH_attention_linear_output_loss: 1.7631 - val_VL_attention_linear_output_acc: 0.4889 - val_VH_attention_linear_output_acc: 0.4863\n",
      "Epoch 3048/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4351 - VL_attention_linear_output_loss: 1.7136 - VH_attention_linear_output_loss: 1.7215 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4908 - val_loss: 3.5440 - val_VL_attention_linear_output_loss: 1.7677 - val_VH_attention_linear_output_loss: 1.7763 - val_VL_attention_linear_output_acc: 0.4884 - val_VH_attention_linear_output_acc: 0.4792\n",
      "Epoch 3049/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4340 - VL_attention_linear_output_loss: 1.7095 - VH_attention_linear_output_loss: 1.7246 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4905 - val_loss: 3.5524 - val_VL_attention_linear_output_loss: 1.7693 - val_VH_attention_linear_output_loss: 1.7831 - val_VL_attention_linear_output_acc: 0.4814 - val_VH_attention_linear_output_acc: 0.4744\n",
      "Epoch 3050/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4372 - VL_attention_linear_output_loss: 1.7129 - VH_attention_linear_output_loss: 1.7243 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4904 - val_loss: 3.5538 - val_VL_attention_linear_output_loss: 1.7868 - val_VH_attention_linear_output_loss: 1.7670 - val_VL_attention_linear_output_acc: 0.4756 - val_VH_attention_linear_output_acc: 0.4827\n",
      "Epoch 3051/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4302 - VL_attention_linear_output_loss: 1.7142 - VH_attention_linear_output_loss: 1.7160 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4929 - val_loss: 3.5288 - val_VL_attention_linear_output_loss: 1.7693 - val_VH_attention_linear_output_loss: 1.7596 - val_VL_attention_linear_output_acc: 0.4799 - val_VH_attention_linear_output_acc: 0.4890\n",
      "Epoch 3052/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4224 - VL_attention_linear_output_loss: 1.7055 - VH_attention_linear_output_loss: 1.7169 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4927 - val_loss: 3.5464 - val_VL_attention_linear_output_loss: 1.7724 - val_VH_attention_linear_output_loss: 1.7740 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4795\n",
      "Epoch 3053/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4302 - VL_attention_linear_output_loss: 1.7091 - VH_attention_linear_output_loss: 1.7210 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4910 - val_loss: 3.5325 - val_VL_attention_linear_output_loss: 1.7664 - val_VH_attention_linear_output_loss: 1.7661 - val_VL_attention_linear_output_acc: 0.4899 - val_VH_attention_linear_output_acc: 0.4780\n",
      "Epoch 3054/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4288 - VL_attention_linear_output_loss: 1.7061 - VH_attention_linear_output_loss: 1.7227 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4907 - val_loss: 3.5335 - val_VL_attention_linear_output_loss: 1.7687 - val_VH_attention_linear_output_loss: 1.7648 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4792\n",
      "Epoch 3055/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4358 - VL_attention_linear_output_loss: 1.7082 - VH_attention_linear_output_loss: 1.7276 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4887 - val_loss: 3.5266 - val_VL_attention_linear_output_loss: 1.7656 - val_VH_attention_linear_output_loss: 1.7609 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4842\n",
      "Epoch 3056/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4311 - VL_attention_linear_output_loss: 1.7096 - VH_attention_linear_output_loss: 1.7215 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4914 - val_loss: 3.5403 - val_VL_attention_linear_output_loss: 1.7664 - val_VH_attention_linear_output_loss: 1.7740 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.4799\n",
      "Epoch 3057/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4320 - VL_attention_linear_output_loss: 1.7148 - VH_attention_linear_output_loss: 1.7171 - VL_attention_linear_output_acc: 0.4896 - VH_attention_linear_output_acc: 0.4932 - val_loss: 3.5345 - val_VL_attention_linear_output_loss: 1.7697 - val_VH_attention_linear_output_loss: 1.7648 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4804\n",
      "Epoch 3058/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4323 - VL_attention_linear_output_loss: 1.7084 - VH_attention_linear_output_loss: 1.7239 - VL_attention_linear_output_acc: 0.4938 - VH_attention_linear_output_acc: 0.4904 - val_loss: 3.5197 - val_VL_attention_linear_output_loss: 1.7653 - val_VH_attention_linear_output_loss: 1.7544 - val_VL_attention_linear_output_acc: 0.4911 - val_VH_attention_linear_output_acc: 0.4887\n",
      "Epoch 3059/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4272 - VL_attention_linear_output_loss: 1.7132 - VH_attention_linear_output_loss: 1.7140 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4939 - val_loss: 3.5457 - val_VL_attention_linear_output_loss: 1.7695 - val_VH_attention_linear_output_loss: 1.7762 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4830\n",
      "Epoch 3060/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4407 - VL_attention_linear_output_loss: 1.7204 - VH_attention_linear_output_loss: 1.7202 - VL_attention_linear_output_acc: 0.4875 - VH_attention_linear_output_acc: 0.4917 - val_loss: 3.5365 - val_VL_attention_linear_output_loss: 1.7637 - val_VH_attention_linear_output_loss: 1.7728 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4812\n",
      "Epoch 3061/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4309 - VL_attention_linear_output_loss: 1.7117 - VH_attention_linear_output_loss: 1.7192 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4916 - val_loss: 3.5744 - val_VL_attention_linear_output_loss: 1.8172 - val_VH_attention_linear_output_loss: 1.7572 - val_VL_attention_linear_output_acc: 0.4591 - val_VH_attention_linear_output_acc: 0.4846\n",
      "Epoch 3062/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4320 - VL_attention_linear_output_loss: 1.7109 - VH_attention_linear_output_loss: 1.7212 - VL_attention_linear_output_acc: 0.4910 - VH_attention_linear_output_acc: 0.4913 - val_loss: 3.5308 - val_VL_attention_linear_output_loss: 1.7717 - val_VH_attention_linear_output_loss: 1.7592 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4805\n",
      "Epoch 3063/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4234 - VL_attention_linear_output_loss: 1.7058 - VH_attention_linear_output_loss: 1.7176 - VL_attention_linear_output_acc: 0.4946 - VH_attention_linear_output_acc: 0.4919 - val_loss: 3.5328 - val_VL_attention_linear_output_loss: 1.7699 - val_VH_attention_linear_output_loss: 1.7629 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4868\n",
      "Epoch 3064/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4372 - VL_attention_linear_output_loss: 1.7109 - VH_attention_linear_output_loss: 1.7263 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4887 - val_loss: 3.5776 - val_VL_attention_linear_output_loss: 1.7663 - val_VH_attention_linear_output_loss: 1.8112 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.4622\n",
      "Epoch 3065/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4376 - VL_attention_linear_output_loss: 1.7108 - VH_attention_linear_output_loss: 1.7268 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4894 - val_loss: 3.5275 - val_VL_attention_linear_output_loss: 1.7630 - val_VH_attention_linear_output_loss: 1.7645 - val_VL_attention_linear_output_acc: 0.4886 - val_VH_attention_linear_output_acc: 0.4836\n",
      "Epoch 3066/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4299 - VL_attention_linear_output_loss: 1.7106 - VH_attention_linear_output_loss: 1.7193 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4913 - val_loss: 3.6226 - val_VL_attention_linear_output_loss: 1.8517 - val_VH_attention_linear_output_loss: 1.7709 - val_VL_attention_linear_output_acc: 0.4480 - val_VH_attention_linear_output_acc: 0.4808\n",
      "Epoch 3067/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4415 - VL_attention_linear_output_loss: 1.7199 - VH_attention_linear_output_loss: 1.7216 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4912 - val_loss: 3.5435 - val_VL_attention_linear_output_loss: 1.7752 - val_VH_attention_linear_output_loss: 1.7682 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4794\n",
      "Epoch 3068/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4422 - VL_attention_linear_output_loss: 1.7086 - VH_attention_linear_output_loss: 1.7336 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4862 - val_loss: 3.5391 - val_VL_attention_linear_output_loss: 1.7842 - val_VH_attention_linear_output_loss: 1.7549 - val_VL_attention_linear_output_acc: 0.4708 - val_VH_attention_linear_output_acc: 0.4858\n",
      "Epoch 3069/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4237 - VL_attention_linear_output_loss: 1.7094 - VH_attention_linear_output_loss: 1.7143 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4943 - val_loss: 3.5420 - val_VL_attention_linear_output_loss: 1.7709 - val_VH_attention_linear_output_loss: 1.7712 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4822\n",
      "Epoch 3070/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4290 - VL_attention_linear_output_loss: 1.7121 - VH_attention_linear_output_loss: 1.7169 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4920 - val_loss: 3.5369 - val_VL_attention_linear_output_loss: 1.7682 - val_VH_attention_linear_output_loss: 1.7688 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4823\n",
      "Epoch 3071/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4356 - VL_attention_linear_output_loss: 1.7154 - VH_attention_linear_output_loss: 1.7201 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4909 - val_loss: 3.5355 - val_VL_attention_linear_output_loss: 1.7747 - val_VH_attention_linear_output_loss: 1.7608 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.4820\n",
      "Epoch 3072/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4339 - VL_attention_linear_output_loss: 1.7099 - VH_attention_linear_output_loss: 1.7239 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4901 - val_loss: 3.5524 - val_VL_attention_linear_output_loss: 1.7684 - val_VH_attention_linear_output_loss: 1.7840 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4745\n",
      "Epoch 3073/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4327 - VL_attention_linear_output_loss: 1.7065 - VH_attention_linear_output_loss: 1.7262 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4894 - val_loss: 3.5233 - val_VL_attention_linear_output_loss: 1.7684 - val_VH_attention_linear_output_loss: 1.7550 - val_VL_attention_linear_output_acc: 0.4875 - val_VH_attention_linear_output_acc: 0.4874\n",
      "Epoch 3074/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4184 - VL_attention_linear_output_loss: 1.7059 - VH_attention_linear_output_loss: 1.7125 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4936 - val_loss: 3.5330 - val_VL_attention_linear_output_loss: 1.7677 - val_VH_attention_linear_output_loss: 1.7653 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4807\n",
      "Epoch 3075/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4359 - VL_attention_linear_output_loss: 1.7157 - VH_attention_linear_output_loss: 1.7202 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4912 - val_loss: 3.5891 - val_VL_attention_linear_output_loss: 1.7901 - val_VH_attention_linear_output_loss: 1.7991 - val_VL_attention_linear_output_acc: 0.4770 - val_VH_attention_linear_output_acc: 0.4653\n",
      "Epoch 3076/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4307 - VL_attention_linear_output_loss: 1.7136 - VH_attention_linear_output_loss: 1.7171 - VL_attention_linear_output_acc: 0.4887 - VH_attention_linear_output_acc: 0.4919 - val_loss: 3.5696 - val_VL_attention_linear_output_loss: 1.7684 - val_VH_attention_linear_output_loss: 1.8011 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4711\n",
      "Epoch 3077/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4232 - VL_attention_linear_output_loss: 1.7101 - VH_attention_linear_output_loss: 1.7130 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4948 - val_loss: 3.5246 - val_VL_attention_linear_output_loss: 1.7633 - val_VH_attention_linear_output_loss: 1.7613 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4846\n",
      "Epoch 3078/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4297 - VL_attention_linear_output_loss: 1.7104 - VH_attention_linear_output_loss: 1.7193 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4917 - val_loss: 3.5202 - val_VL_attention_linear_output_loss: 1.7621 - val_VH_attention_linear_output_loss: 1.7581 - val_VL_attention_linear_output_acc: 0.4890 - val_VH_attention_linear_output_acc: 0.4877\n",
      "Epoch 3079/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4164 - VL_attention_linear_output_loss: 1.7020 - VH_attention_linear_output_loss: 1.7144 - VL_attention_linear_output_acc: 0.4971 - VH_attention_linear_output_acc: 0.4928 - val_loss: 3.5698 - val_VL_attention_linear_output_loss: 1.7729 - val_VH_attention_linear_output_loss: 1.7969 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4678\n",
      "Epoch 3080/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4326 - VL_attention_linear_output_loss: 1.7096 - VH_attention_linear_output_loss: 1.7230 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4899 - val_loss: 3.5233 - val_VL_attention_linear_output_loss: 1.7606 - val_VH_attention_linear_output_loss: 1.7627 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4820\n",
      "Epoch 3081/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4266 - VL_attention_linear_output_loss: 1.7085 - VH_attention_linear_output_loss: 1.7181 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4920 - val_loss: 3.5618 - val_VL_attention_linear_output_loss: 1.7646 - val_VH_attention_linear_output_loss: 1.7972 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.4737\n",
      "Epoch 3082/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4520 - VL_attention_linear_output_loss: 1.7212 - VH_attention_linear_output_loss: 1.7308 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4869 - val_loss: 3.5767 - val_VL_attention_linear_output_loss: 1.7982 - val_VH_attention_linear_output_loss: 1.7785 - val_VL_attention_linear_output_acc: 0.4680 - val_VH_attention_linear_output_acc: 0.4765\n",
      "Epoch 3083/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4345 - VL_attention_linear_output_loss: 1.7088 - VH_attention_linear_output_loss: 1.7257 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4885 - val_loss: 3.5618 - val_VL_attention_linear_output_loss: 1.7779 - val_VH_attention_linear_output_loss: 1.7839 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4663\n",
      "Epoch 3084/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4327 - VL_attention_linear_output_loss: 1.7069 - VH_attention_linear_output_loss: 1.7258 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4881 - val_loss: 3.5263 - val_VL_attention_linear_output_loss: 1.7671 - val_VH_attention_linear_output_loss: 1.7593 - val_VL_attention_linear_output_acc: 0.4869 - val_VH_attention_linear_output_acc: 0.4802\n",
      "Epoch 3085/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4124 - VL_attention_linear_output_loss: 1.7010 - VH_attention_linear_output_loss: 1.7114 - VL_attention_linear_output_acc: 0.4972 - VH_attention_linear_output_acc: 0.4942 - val_loss: 3.5326 - val_VL_attention_linear_output_loss: 1.7719 - val_VH_attention_linear_output_loss: 1.7607 - val_VL_attention_linear_output_acc: 0.4729 - val_VH_attention_linear_output_acc: 0.4824\n",
      "Epoch 3086/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4365 - VL_attention_linear_output_loss: 1.7199 - VH_attention_linear_output_loss: 1.7166 - VL_attention_linear_output_acc: 0.4857 - VH_attention_linear_output_acc: 0.4923 - val_loss: 3.5516 - val_VL_attention_linear_output_loss: 1.7855 - val_VH_attention_linear_output_loss: 1.7661 - val_VL_attention_linear_output_acc: 0.4760 - val_VH_attention_linear_output_acc: 0.4825\n",
      "Epoch 3087/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4303 - VL_attention_linear_output_loss: 1.7132 - VH_attention_linear_output_loss: 1.7171 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4923 - val_loss: 3.5241 - val_VL_attention_linear_output_loss: 1.7660 - val_VH_attention_linear_output_loss: 1.7581 - val_VL_attention_linear_output_acc: 0.4904 - val_VH_attention_linear_output_acc: 0.4791\n",
      "Epoch 3088/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4259 - VL_attention_linear_output_loss: 1.7089 - VH_attention_linear_output_loss: 1.7170 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.4921 - val_loss: 3.5308 - val_VL_attention_linear_output_loss: 1.7727 - val_VH_attention_linear_output_loss: 1.7581 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4819\n",
      "Epoch 3089/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4312 - VL_attention_linear_output_loss: 1.7175 - VH_attention_linear_output_loss: 1.7137 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4928 - val_loss: 3.5563 - val_VL_attention_linear_output_loss: 1.7647 - val_VH_attention_linear_output_loss: 1.7916 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4759\n",
      "Epoch 3090/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4244 - VL_attention_linear_output_loss: 1.7104 - VH_attention_linear_output_loss: 1.7139 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.4930 - val_loss: 3.5205 - val_VL_attention_linear_output_loss: 1.7606 - val_VH_attention_linear_output_loss: 1.7599 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.4860\n",
      "Epoch 3091/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4165 - VL_attention_linear_output_loss: 1.7070 - VH_attention_linear_output_loss: 1.7095 - VL_attention_linear_output_acc: 0.4944 - VH_attention_linear_output_acc: 0.4954 - val_loss: 3.5711 - val_VL_attention_linear_output_loss: 1.8064 - val_VH_attention_linear_output_loss: 1.7647 - val_VL_attention_linear_output_acc: 0.4723 - val_VH_attention_linear_output_acc: 0.4822\n",
      "Epoch 3092/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4306 - VL_attention_linear_output_loss: 1.7127 - VH_attention_linear_output_loss: 1.7179 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4921 - val_loss: 3.5346 - val_VL_attention_linear_output_loss: 1.7632 - val_VH_attention_linear_output_loss: 1.7714 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4756\n",
      "Epoch 3093/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4283 - VL_attention_linear_output_loss: 1.7097 - VH_attention_linear_output_loss: 1.7186 - VL_attention_linear_output_acc: 0.4928 - VH_attention_linear_output_acc: 0.4915 - val_loss: 3.5370 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7742 - val_VL_attention_linear_output_acc: 0.4860 - val_VH_attention_linear_output_acc: 0.4775\n",
      "Epoch 3094/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4218 - VL_attention_linear_output_loss: 1.7042 - VH_attention_linear_output_loss: 1.7176 - VL_attention_linear_output_acc: 0.4953 - VH_attention_linear_output_acc: 0.4920 - val_loss: 3.5494 - val_VL_attention_linear_output_loss: 1.7691 - val_VH_attention_linear_output_loss: 1.7803 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4732\n",
      "Epoch 3095/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4221 - VL_attention_linear_output_loss: 1.7023 - VH_attention_linear_output_loss: 1.7198 - VL_attention_linear_output_acc: 0.4957 - VH_attention_linear_output_acc: 0.4908 - val_loss: 3.5192 - val_VL_attention_linear_output_loss: 1.7598 - val_VH_attention_linear_output_loss: 1.7595 - val_VL_attention_linear_output_acc: 0.4870 - val_VH_attention_linear_output_acc: 0.4827\n",
      "Epoch 3096/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4196 - VL_attention_linear_output_loss: 1.7117 - VH_attention_linear_output_loss: 1.7079 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4946 - val_loss: 3.5312 - val_VL_attention_linear_output_loss: 1.7652 - val_VH_attention_linear_output_loss: 1.7660 - val_VL_attention_linear_output_acc: 0.4889 - val_VH_attention_linear_output_acc: 0.4820\n",
      "Epoch 3097/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4158 - VL_attention_linear_output_loss: 1.7018 - VH_attention_linear_output_loss: 1.7140 - VL_attention_linear_output_acc: 0.4959 - VH_attention_linear_output_acc: 0.4929 - val_loss: 3.5172 - val_VL_attention_linear_output_loss: 1.7636 - val_VH_attention_linear_output_loss: 1.7536 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4850\n",
      "Epoch 3098/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4180 - VL_attention_linear_output_loss: 1.7053 - VH_attention_linear_output_loss: 1.7127 - VL_attention_linear_output_acc: 0.4933 - VH_attention_linear_output_acc: 0.4932 - val_loss: 3.5740 - val_VL_attention_linear_output_loss: 1.8070 - val_VH_attention_linear_output_loss: 1.7670 - val_VL_attention_linear_output_acc: 0.4678 - val_VH_attention_linear_output_acc: 0.4775\n",
      "Epoch 3099/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4165 - VL_attention_linear_output_loss: 1.7094 - VH_attention_linear_output_loss: 1.7071 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4948 - val_loss: 3.5257 - val_VL_attention_linear_output_loss: 1.7704 - val_VH_attention_linear_output_loss: 1.7553 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4839\n",
      "Epoch 3100/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4191 - VL_attention_linear_output_loss: 1.7032 - VH_attention_linear_output_loss: 1.7159 - VL_attention_linear_output_acc: 0.4964 - VH_attention_linear_output_acc: 0.4916 - val_loss: 3.5301 - val_VL_attention_linear_output_loss: 1.7642 - val_VH_attention_linear_output_loss: 1.7659 - val_VL_attention_linear_output_acc: 0.4816 - val_VH_attention_linear_output_acc: 0.4833\n",
      "Epoch 3101/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4212 - VL_attention_linear_output_loss: 1.7051 - VH_attention_linear_output_loss: 1.7161 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4913 - val_loss: 3.5209 - val_VL_attention_linear_output_loss: 1.7643 - val_VH_attention_linear_output_loss: 1.7567 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4818\n",
      "Epoch 3102/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4128 - VL_attention_linear_output_loss: 1.7073 - VH_attention_linear_output_loss: 1.7055 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4959 - val_loss: 3.5166 - val_VL_attention_linear_output_loss: 1.7619 - val_VH_attention_linear_output_loss: 1.7547 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4831\n",
      "Epoch 3103/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4255 - VL_attention_linear_output_loss: 1.7106 - VH_attention_linear_output_loss: 1.7149 - VL_attention_linear_output_acc: 0.4915 - VH_attention_linear_output_acc: 0.4927 - val_loss: 3.5541 - val_VL_attention_linear_output_loss: 1.7895 - val_VH_attention_linear_output_loss: 1.7646 - val_VL_attention_linear_output_acc: 0.4685 - val_VH_attention_linear_output_acc: 0.4786\n",
      "Epoch 3104/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4426 - VL_attention_linear_output_loss: 1.7185 - VH_attention_linear_output_loss: 1.7242 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4886 - val_loss: 3.5180 - val_VL_attention_linear_output_loss: 1.7627 - val_VH_attention_linear_output_loss: 1.7553 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3105/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4114 - VL_attention_linear_output_loss: 1.7020 - VH_attention_linear_output_loss: 1.7094 - VL_attention_linear_output_acc: 0.4955 - VH_attention_linear_output_acc: 0.4944 - val_loss: 3.5369 - val_VL_attention_linear_output_loss: 1.7710 - val_VH_attention_linear_output_loss: 1.7659 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4783\n",
      "Epoch 3106/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4407 - VL_attention_linear_output_loss: 1.7233 - VH_attention_linear_output_loss: 1.7174 - VL_attention_linear_output_acc: 0.4873 - VH_attention_linear_output_acc: 0.4914 - val_loss: 3.5442 - val_VL_attention_linear_output_loss: 1.7766 - val_VH_attention_linear_output_loss: 1.7675 - val_VL_attention_linear_output_acc: 0.4707 - val_VH_attention_linear_output_acc: 0.4760\n",
      "Epoch 3107/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4264 - VL_attention_linear_output_loss: 1.7132 - VH_attention_linear_output_loss: 1.7132 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4924 - val_loss: 3.5231 - val_VL_attention_linear_output_loss: 1.7625 - val_VH_attention_linear_output_loss: 1.7605 - val_VL_attention_linear_output_acc: 0.4875 - val_VH_attention_linear_output_acc: 0.4791\n",
      "Epoch 3108/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4361 - VL_attention_linear_output_loss: 1.7174 - VH_attention_linear_output_loss: 1.7187 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4904 - val_loss: 3.5314 - val_VL_attention_linear_output_loss: 1.7653 - val_VH_attention_linear_output_loss: 1.7660 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4835\n",
      "Epoch 3109/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4152 - VL_attention_linear_output_loss: 1.7012 - VH_attention_linear_output_loss: 1.7139 - VL_attention_linear_output_acc: 0.4959 - VH_attention_linear_output_acc: 0.4924 - val_loss: 3.5409 - val_VL_attention_linear_output_loss: 1.7676 - val_VH_attention_linear_output_loss: 1.7733 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4775\n",
      "Epoch 3110/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4221 - VL_attention_linear_output_loss: 1.7076 - VH_attention_linear_output_loss: 1.7146 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4910 - val_loss: 3.5282 - val_VL_attention_linear_output_loss: 1.7689 - val_VH_attention_linear_output_loss: 1.7593 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4862\n",
      "Epoch 3111/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4279 - VL_attention_linear_output_loss: 1.7102 - VH_attention_linear_output_loss: 1.7177 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4902 - val_loss: 3.5603 - val_VL_attention_linear_output_loss: 1.7649 - val_VH_attention_linear_output_loss: 1.7953 - val_VL_attention_linear_output_acc: 0.4890 - val_VH_attention_linear_output_acc: 0.4607\n",
      "Epoch 3112/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4333 - VL_attention_linear_output_loss: 1.7184 - VH_attention_linear_output_loss: 1.7149 - VL_attention_linear_output_acc: 0.4879 - VH_attention_linear_output_acc: 0.4923 - val_loss: 3.5682 - val_VL_attention_linear_output_loss: 1.8126 - val_VH_attention_linear_output_loss: 1.7556 - val_VL_attention_linear_output_acc: 0.4659 - val_VH_attention_linear_output_acc: 0.4803\n",
      "Epoch 3113/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4221 - VL_attention_linear_output_loss: 1.7096 - VH_attention_linear_output_loss: 1.7125 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4921 - val_loss: 3.5630 - val_VL_attention_linear_output_loss: 1.7997 - val_VH_attention_linear_output_loss: 1.7632 - val_VL_attention_linear_output_acc: 0.4643 - val_VH_attention_linear_output_acc: 0.4767\n",
      "Epoch 3114/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4305 - VL_attention_linear_output_loss: 1.7123 - VH_attention_linear_output_loss: 1.7182 - VL_attention_linear_output_acc: 0.4910 - VH_attention_linear_output_acc: 0.4903 - val_loss: 3.5364 - val_VL_attention_linear_output_loss: 1.7734 - val_VH_attention_linear_output_loss: 1.7630 - val_VL_attention_linear_output_acc: 0.4796 - val_VH_attention_linear_output_acc: 0.4806\n",
      "Epoch 3115/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4237 - VL_attention_linear_output_loss: 1.7033 - VH_attention_linear_output_loss: 1.7203 - VL_attention_linear_output_acc: 0.4951 - VH_attention_linear_output_acc: 0.4896 - val_loss: 3.5426 - val_VL_attention_linear_output_loss: 1.7747 - val_VH_attention_linear_output_loss: 1.7679 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4756\n",
      "Epoch 3116/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4285 - VL_attention_linear_output_loss: 1.7169 - VH_attention_linear_output_loss: 1.7115 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4929 - val_loss: 3.5722 - val_VL_attention_linear_output_loss: 1.8056 - val_VH_attention_linear_output_loss: 1.7666 - val_VL_attention_linear_output_acc: 0.4632 - val_VH_attention_linear_output_acc: 0.4790\n",
      "Epoch 3117/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4316 - VL_attention_linear_output_loss: 1.7078 - VH_attention_linear_output_loss: 1.7238 - VL_attention_linear_output_acc: 0.4929 - VH_attention_linear_output_acc: 0.4873 - val_loss: 3.5317 - val_VL_attention_linear_output_loss: 1.7671 - val_VH_attention_linear_output_loss: 1.7647 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4821\n",
      "Epoch 3118/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4356 - VL_attention_linear_output_loss: 1.7072 - VH_attention_linear_output_loss: 1.7283 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4869 - val_loss: 3.5761 - val_VL_attention_linear_output_loss: 1.8011 - val_VH_attention_linear_output_loss: 1.7750 - val_VL_attention_linear_output_acc: 0.4709 - val_VH_attention_linear_output_acc: 0.4768\n",
      "Epoch 3119/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4374 - VL_attention_linear_output_loss: 1.7165 - VH_attention_linear_output_loss: 1.7209 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4892 - val_loss: 3.5340 - val_VL_attention_linear_output_loss: 1.7698 - val_VH_attention_linear_output_loss: 1.7642 - val_VL_attention_linear_output_acc: 0.4807 - val_VH_attention_linear_output_acc: 0.4825\n",
      "Epoch 3120/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4195 - VL_attention_linear_output_loss: 1.7050 - VH_attention_linear_output_loss: 1.7146 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4916 - val_loss: 3.5222 - val_VL_attention_linear_output_loss: 1.7643 - val_VH_attention_linear_output_loss: 1.7579 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4795\n",
      "Epoch 3121/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4121 - VL_attention_linear_output_loss: 1.6996 - VH_attention_linear_output_loss: 1.7125 - VL_attention_linear_output_acc: 0.4971 - VH_attention_linear_output_acc: 0.4924 - val_loss: 3.5264 - val_VL_attention_linear_output_loss: 1.7652 - val_VH_attention_linear_output_loss: 1.7612 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4829\n",
      "Epoch 3122/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4148 - VL_attention_linear_output_loss: 1.7031 - VH_attention_linear_output_loss: 1.7117 - VL_attention_linear_output_acc: 0.4957 - VH_attention_linear_output_acc: 0.4922 - val_loss: 3.5333 - val_VL_attention_linear_output_loss: 1.7633 - val_VH_attention_linear_output_loss: 1.7700 - val_VL_attention_linear_output_acc: 0.4886 - val_VH_attention_linear_output_acc: 0.4788\n",
      "Epoch 3123/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4276 - VL_attention_linear_output_loss: 1.7139 - VH_attention_linear_output_loss: 1.7137 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4915 - val_loss: 3.5321 - val_VL_attention_linear_output_loss: 1.7757 - val_VH_attention_linear_output_loss: 1.7564 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4872\n",
      "Epoch 3124/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4302 - VL_attention_linear_output_loss: 1.7105 - VH_attention_linear_output_loss: 1.7197 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4894 - val_loss: 3.6465 - val_VL_attention_linear_output_loss: 1.8329 - val_VH_attention_linear_output_loss: 1.8136 - val_VL_attention_linear_output_acc: 0.4551 - val_VH_attention_linear_output_acc: 0.4645\n",
      "Epoch 3125/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4360 - VL_attention_linear_output_loss: 1.7143 - VH_attention_linear_output_loss: 1.7217 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4890 - val_loss: 3.5397 - val_VL_attention_linear_output_loss: 1.7639 - val_VH_attention_linear_output_loss: 1.7758 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4765\n",
      "Epoch 3126/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4272 - VL_attention_linear_output_loss: 1.7095 - VH_attention_linear_output_loss: 1.7177 - VL_attention_linear_output_acc: 0.4928 - VH_attention_linear_output_acc: 0.4901 - val_loss: 3.5227 - val_VL_attention_linear_output_loss: 1.7646 - val_VH_attention_linear_output_loss: 1.7581 - val_VL_attention_linear_output_acc: 0.4867 - val_VH_attention_linear_output_acc: 0.4829\n",
      "Epoch 3127/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4145 - VL_attention_linear_output_loss: 1.7070 - VH_attention_linear_output_loss: 1.7075 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4941 - val_loss: 3.5231 - val_VL_attention_linear_output_loss: 1.7687 - val_VH_attention_linear_output_loss: 1.7545 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4801\n",
      "Epoch 3128/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4269 - VL_attention_linear_output_loss: 1.7124 - VH_attention_linear_output_loss: 1.7145 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4914 - val_loss: 3.5513 - val_VL_attention_linear_output_loss: 1.7842 - val_VH_attention_linear_output_loss: 1.7670 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.4777\n",
      "Epoch 3129/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4208 - VL_attention_linear_output_loss: 1.7072 - VH_attention_linear_output_loss: 1.7136 - VL_attention_linear_output_acc: 0.4923 - VH_attention_linear_output_acc: 0.4910 - val_loss: 3.5685 - val_VL_attention_linear_output_loss: 1.8108 - val_VH_attention_linear_output_loss: 1.7577 - val_VL_attention_linear_output_acc: 0.4612 - val_VH_attention_linear_output_acc: 0.4830\n",
      "Epoch 3130/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4157 - VL_attention_linear_output_loss: 1.7035 - VH_attention_linear_output_loss: 1.7122 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4924 - val_loss: 3.5130 - val_VL_attention_linear_output_loss: 1.7576 - val_VH_attention_linear_output_loss: 1.7553 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4827\n",
      "Epoch 3131/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4156 - VL_attention_linear_output_loss: 1.7044 - VH_attention_linear_output_loss: 1.7112 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4931 - val_loss: 3.5326 - val_VL_attention_linear_output_loss: 1.7748 - val_VH_attention_linear_output_loss: 1.7578 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4853\n",
      "Epoch 3132/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4260 - VL_attention_linear_output_loss: 1.7114 - VH_attention_linear_output_loss: 1.7146 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4911 - val_loss: 3.5409 - val_VL_attention_linear_output_loss: 1.7730 - val_VH_attention_linear_output_loss: 1.7678 - val_VL_attention_linear_output_acc: 0.4788 - val_VH_attention_linear_output_acc: 0.4785\n",
      "Epoch 3133/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4282 - VL_attention_linear_output_loss: 1.7138 - VH_attention_linear_output_loss: 1.7144 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4918 - val_loss: 3.5456 - val_VL_attention_linear_output_loss: 1.7906 - val_VH_attention_linear_output_loss: 1.7550 - val_VL_attention_linear_output_acc: 0.4724 - val_VH_attention_linear_output_acc: 0.4817\n",
      "Epoch 3134/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4262 - VL_attention_linear_output_loss: 1.7114 - VH_attention_linear_output_loss: 1.7148 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.4912 - val_loss: 3.5182 - val_VL_attention_linear_output_loss: 1.7640 - val_VH_attention_linear_output_loss: 1.7542 - val_VL_attention_linear_output_acc: 0.4888 - val_VH_attention_linear_output_acc: 0.4850\n",
      "Epoch 3135/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4150 - VL_attention_linear_output_loss: 1.7066 - VH_attention_linear_output_loss: 1.7084 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4931 - val_loss: 3.5285 - val_VL_attention_linear_output_loss: 1.7651 - val_VH_attention_linear_output_loss: 1.7634 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4821\n",
      "Epoch 3136/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4167 - VL_attention_linear_output_loss: 1.7028 - VH_attention_linear_output_loss: 1.7139 - VL_attention_linear_output_acc: 0.4944 - VH_attention_linear_output_acc: 0.4915 - val_loss: 3.5189 - val_VL_attention_linear_output_loss: 1.7645 - val_VH_attention_linear_output_loss: 1.7544 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4830\n",
      "Epoch 3137/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4178 - VL_attention_linear_output_loss: 1.7112 - VH_attention_linear_output_loss: 1.7066 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4942 - val_loss: 3.5317 - val_VL_attention_linear_output_loss: 1.7747 - val_VH_attention_linear_output_loss: 1.7571 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4803\n",
      "Epoch 3138/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4121 - VL_attention_linear_output_loss: 1.7034 - VH_attention_linear_output_loss: 1.7087 - VL_attention_linear_output_acc: 0.4954 - VH_attention_linear_output_acc: 0.4929 - val_loss: 3.5539 - val_VL_attention_linear_output_loss: 1.7801 - val_VH_attention_linear_output_loss: 1.7738 - val_VL_attention_linear_output_acc: 0.4742 - val_VH_attention_linear_output_acc: 0.4804\n",
      "Epoch 3139/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4261 - VL_attention_linear_output_loss: 1.7112 - VH_attention_linear_output_loss: 1.7150 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4914 - val_loss: 3.5317 - val_VL_attention_linear_output_loss: 1.7604 - val_VH_attention_linear_output_loss: 1.7713 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4794\n",
      "Epoch 3140/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4263 - VL_attention_linear_output_loss: 1.7046 - VH_attention_linear_output_loss: 1.7217 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4884 - val_loss: 3.5304 - val_VL_attention_linear_output_loss: 1.7645 - val_VH_attention_linear_output_loss: 1.7659 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4803\n",
      "Epoch 3141/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4213 - VL_attention_linear_output_loss: 1.7142 - VH_attention_linear_output_loss: 1.7070 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4942 - val_loss: 3.5168 - val_VL_attention_linear_output_loss: 1.7618 - val_VH_attention_linear_output_loss: 1.7550 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4806\n",
      "Epoch 3142/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4164 - VL_attention_linear_output_loss: 1.7086 - VH_attention_linear_output_loss: 1.7078 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4936 - val_loss: 3.5417 - val_VL_attention_linear_output_loss: 1.7784 - val_VH_attention_linear_output_loss: 1.7633 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4788\n",
      "Epoch 3143/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4229 - VL_attention_linear_output_loss: 1.7102 - VH_attention_linear_output_loss: 1.7127 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4919 - val_loss: 3.5689 - val_VL_attention_linear_output_loss: 1.7617 - val_VH_attention_linear_output_loss: 1.8072 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4655\n",
      "Epoch 3144/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4330 - VL_attention_linear_output_loss: 1.7077 - VH_attention_linear_output_loss: 1.7254 - VL_attention_linear_output_acc: 0.4908 - VH_attention_linear_output_acc: 0.4876 - val_loss: 3.5208 - val_VL_attention_linear_output_loss: 1.7646 - val_VH_attention_linear_output_loss: 1.7562 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4854\n",
      "Epoch 3145/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4135 - VL_attention_linear_output_loss: 1.7034 - VH_attention_linear_output_loss: 1.7102 - VL_attention_linear_output_acc: 0.4940 - VH_attention_linear_output_acc: 0.4933 - val_loss: 3.5446 - val_VL_attention_linear_output_loss: 1.7653 - val_VH_attention_linear_output_loss: 1.7794 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4732\n",
      "Epoch 3146/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4351 - VL_attention_linear_output_loss: 1.7176 - VH_attention_linear_output_loss: 1.7175 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4895 - val_loss: 3.5240 - val_VL_attention_linear_output_loss: 1.7635 - val_VH_attention_linear_output_loss: 1.7605 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4815\n",
      "Epoch 3147/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4137 - VL_attention_linear_output_loss: 1.7000 - VH_attention_linear_output_loss: 1.7137 - VL_attention_linear_output_acc: 0.4976 - VH_attention_linear_output_acc: 0.4913 - val_loss: 3.5228 - val_VL_attention_linear_output_loss: 1.7693 - val_VH_attention_linear_output_loss: 1.7535 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4856\n",
      "Epoch 3148/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4106 - VL_attention_linear_output_loss: 1.7044 - VH_attention_linear_output_loss: 1.7062 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4940 - val_loss: 3.5356 - val_VL_attention_linear_output_loss: 1.7623 - val_VH_attention_linear_output_loss: 1.7733 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4754\n",
      "Epoch 3149/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4215 - VL_attention_linear_output_loss: 1.7167 - VH_attention_linear_output_loss: 1.7048 - VL_attention_linear_output_acc: 0.4873 - VH_attention_linear_output_acc: 0.4948 - val_loss: 3.5270 - val_VL_attention_linear_output_loss: 1.7671 - val_VH_attention_linear_output_loss: 1.7599 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4816\n",
      "Epoch 3150/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4140 - VL_attention_linear_output_loss: 1.7032 - VH_attention_linear_output_loss: 1.7107 - VL_attention_linear_output_acc: 0.4953 - VH_attention_linear_output_acc: 0.4925 - val_loss: 3.5293 - val_VL_attention_linear_output_loss: 1.7615 - val_VH_attention_linear_output_loss: 1.7678 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.4752\n",
      "Epoch 3151/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4216 - VL_attention_linear_output_loss: 1.7035 - VH_attention_linear_output_loss: 1.7181 - VL_attention_linear_output_acc: 0.4938 - VH_attention_linear_output_acc: 0.4903 - val_loss: 3.5142 - val_VL_attention_linear_output_loss: 1.7638 - val_VH_attention_linear_output_loss: 1.7505 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3152/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4171 - VL_attention_linear_output_loss: 1.7064 - VH_attention_linear_output_loss: 1.7107 - VL_attention_linear_output_acc: 0.4928 - VH_attention_linear_output_acc: 0.4925 - val_loss: 3.5291 - val_VL_attention_linear_output_loss: 1.7653 - val_VH_attention_linear_output_loss: 1.7639 - val_VL_attention_linear_output_acc: 0.4895 - val_VH_attention_linear_output_acc: 0.4832\n",
      "Epoch 3153/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4234 - VL_attention_linear_output_loss: 1.7069 - VH_attention_linear_output_loss: 1.7166 - VL_attention_linear_output_acc: 0.4929 - VH_attention_linear_output_acc: 0.4904 - val_loss: 3.5302 - val_VL_attention_linear_output_loss: 1.7755 - val_VH_attention_linear_output_loss: 1.7548 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4817\n",
      "Epoch 3154/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4240 - VL_attention_linear_output_loss: 1.7015 - VH_attention_linear_output_loss: 1.7224 - VL_attention_linear_output_acc: 0.4967 - VH_attention_linear_output_acc: 0.4872 - val_loss: 3.5221 - val_VL_attention_linear_output_loss: 1.7598 - val_VH_attention_linear_output_loss: 1.7623 - val_VL_attention_linear_output_acc: 0.4903 - val_VH_attention_linear_output_acc: 0.4830\n",
      "Epoch 3155/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4250 - VL_attention_linear_output_loss: 1.7079 - VH_attention_linear_output_loss: 1.7171 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4902 - val_loss: 3.5220 - val_VL_attention_linear_output_loss: 1.7667 - val_VH_attention_linear_output_loss: 1.7554 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4804\n",
      "Epoch 3156/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4163 - VL_attention_linear_output_loss: 1.7056 - VH_attention_linear_output_loss: 1.7107 - VL_attention_linear_output_acc: 0.4928 - VH_attention_linear_output_acc: 0.4926 - val_loss: 3.5479 - val_VL_attention_linear_output_loss: 1.7845 - val_VH_attention_linear_output_loss: 1.7634 - val_VL_attention_linear_output_acc: 0.4715 - val_VH_attention_linear_output_acc: 0.4799\n",
      "Epoch 3157/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4240 - VL_attention_linear_output_loss: 1.7139 - VH_attention_linear_output_loss: 1.7101 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4927 - val_loss: 3.5347 - val_VL_attention_linear_output_loss: 1.7663 - val_VH_attention_linear_output_loss: 1.7684 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4767\n",
      "Epoch 3158/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4215 - VL_attention_linear_output_loss: 1.7086 - VH_attention_linear_output_loss: 1.7129 - VL_attention_linear_output_acc: 0.4920 - VH_attention_linear_output_acc: 0.4911 - val_loss: 3.5389 - val_VL_attention_linear_output_loss: 1.7634 - val_VH_attention_linear_output_loss: 1.7755 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4745\n",
      "Epoch 3159/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4249 - VL_attention_linear_output_loss: 1.7140 - VH_attention_linear_output_loss: 1.7109 - VL_attention_linear_output_acc: 0.4888 - VH_attention_linear_output_acc: 0.4923 - val_loss: 3.5681 - val_VL_attention_linear_output_loss: 1.8035 - val_VH_attention_linear_output_loss: 1.7646 - val_VL_attention_linear_output_acc: 0.4703 - val_VH_attention_linear_output_acc: 0.4822\n",
      "Epoch 3160/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4313 - VL_attention_linear_output_loss: 1.7054 - VH_attention_linear_output_loss: 1.7259 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4869 - val_loss: 3.5177 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7549 - val_VL_attention_linear_output_acc: 0.4886 - val_VH_attention_linear_output_acc: 0.4844\n",
      "Epoch 3161/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4152 - VL_attention_linear_output_loss: 1.7035 - VH_attention_linear_output_loss: 1.7117 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4920 - val_loss: 3.5146 - val_VL_attention_linear_output_loss: 1.7623 - val_VH_attention_linear_output_loss: 1.7522 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4869\n",
      "Epoch 3162/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4185 - VL_attention_linear_output_loss: 1.7089 - VH_attention_linear_output_loss: 1.7097 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4928 - val_loss: 3.5232 - val_VL_attention_linear_output_loss: 1.7639 - val_VH_attention_linear_output_loss: 1.7593 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4806\n",
      "Epoch 3163/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4259 - VL_attention_linear_output_loss: 1.7101 - VH_attention_linear_output_loss: 1.7158 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4903 - val_loss: 3.5708 - val_VL_attention_linear_output_loss: 1.7763 - val_VH_attention_linear_output_loss: 1.7945 - val_VL_attention_linear_output_acc: 0.4766 - val_VH_attention_linear_output_acc: 0.4680\n",
      "Epoch 3164/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4295 - VL_attention_linear_output_loss: 1.7067 - VH_attention_linear_output_loss: 1.7228 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.4875 - val_loss: 3.5190 - val_VL_attention_linear_output_loss: 1.7643 - val_VH_attention_linear_output_loss: 1.7548 - val_VL_attention_linear_output_acc: 0.4908 - val_VH_attention_linear_output_acc: 0.4835\n",
      "Epoch 3165/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4406 - VL_attention_linear_output_loss: 1.7242 - VH_attention_linear_output_loss: 1.7164 - VL_attention_linear_output_acc: 0.4844 - VH_attention_linear_output_acc: 0.4903 - val_loss: 3.5542 - val_VL_attention_linear_output_loss: 1.8048 - val_VH_attention_linear_output_loss: 1.7494 - val_VL_attention_linear_output_acc: 0.4580 - val_VH_attention_linear_output_acc: 0.4857\n",
      "Epoch 3166/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4122 - VL_attention_linear_output_loss: 1.7058 - VH_attention_linear_output_loss: 1.7064 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4947 - val_loss: 3.5715 - val_VL_attention_linear_output_loss: 1.8099 - val_VH_attention_linear_output_loss: 1.7616 - val_VL_attention_linear_output_acc: 0.4610 - val_VH_attention_linear_output_acc: 0.4800\n",
      "Epoch 3167/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4211 - VL_attention_linear_output_loss: 1.7080 - VH_attention_linear_output_loss: 1.7131 - VL_attention_linear_output_acc: 0.4933 - VH_attention_linear_output_acc: 0.4916 - val_loss: 3.5401 - val_VL_attention_linear_output_loss: 1.7682 - val_VH_attention_linear_output_loss: 1.7720 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4763\n",
      "Epoch 3168/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4294 - VL_attention_linear_output_loss: 1.7132 - VH_attention_linear_output_loss: 1.7162 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4898 - val_loss: 3.5277 - val_VL_attention_linear_output_loss: 1.7689 - val_VH_attention_linear_output_loss: 1.7589 - val_VL_attention_linear_output_acc: 0.4870 - val_VH_attention_linear_output_acc: 0.4812\n",
      "Epoch 3169/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4213 - VL_attention_linear_output_loss: 1.7011 - VH_attention_linear_output_loss: 1.7202 - VL_attention_linear_output_acc: 0.4967 - VH_attention_linear_output_acc: 0.4884 - val_loss: 3.5579 - val_VL_attention_linear_output_loss: 1.7690 - val_VH_attention_linear_output_loss: 1.7889 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4679\n",
      "Epoch 3170/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4114 - VL_attention_linear_output_loss: 1.7002 - VH_attention_linear_output_loss: 1.7112 - VL_attention_linear_output_acc: 0.4953 - VH_attention_linear_output_acc: 0.4930 - val_loss: 3.5387 - val_VL_attention_linear_output_loss: 1.7662 - val_VH_attention_linear_output_loss: 1.7724 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4764\n",
      "Epoch 3171/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4118 - VL_attention_linear_output_loss: 1.7059 - VH_attention_linear_output_loss: 1.7058 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4941 - val_loss: 3.5411 - val_VL_attention_linear_output_loss: 1.7818 - val_VH_attention_linear_output_loss: 1.7593 - val_VL_attention_linear_output_acc: 0.4790 - val_VH_attention_linear_output_acc: 0.4808\n",
      "Epoch 3172/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4185 - VL_attention_linear_output_loss: 1.7086 - VH_attention_linear_output_loss: 1.7099 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4927 - val_loss: 3.5796 - val_VL_attention_linear_output_loss: 1.8076 - val_VH_attention_linear_output_loss: 1.7720 - val_VL_attention_linear_output_acc: 0.4640 - val_VH_attention_linear_output_acc: 0.4733\n",
      "Epoch 3173/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4236 - VL_attention_linear_output_loss: 1.7090 - VH_attention_linear_output_loss: 1.7146 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4903 - val_loss: 3.5873 - val_VL_attention_linear_output_loss: 1.7634 - val_VH_attention_linear_output_loss: 1.8239 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4577\n",
      "Epoch 3174/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4185 - VL_attention_linear_output_loss: 1.7030 - VH_attention_linear_output_loss: 1.7155 - VL_attention_linear_output_acc: 0.4947 - VH_attention_linear_output_acc: 0.4911 - val_loss: 3.5219 - val_VL_attention_linear_output_loss: 1.7667 - val_VH_attention_linear_output_loss: 1.7551 - val_VL_attention_linear_output_acc: 0.4860 - val_VH_attention_linear_output_acc: 0.4861\n",
      "Epoch 3175/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4179 - VL_attention_linear_output_loss: 1.7074 - VH_attention_linear_output_loss: 1.7105 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4927 - val_loss: 3.5201 - val_VL_attention_linear_output_loss: 1.7654 - val_VH_attention_linear_output_loss: 1.7546 - val_VL_attention_linear_output_acc: 0.4858 - val_VH_attention_linear_output_acc: 0.4848\n",
      "Epoch 3176/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4281 - VL_attention_linear_output_loss: 1.7175 - VH_attention_linear_output_loss: 1.7105 - VL_attention_linear_output_acc: 0.4872 - VH_attention_linear_output_acc: 0.4924 - val_loss: 3.5303 - val_VL_attention_linear_output_loss: 1.7705 - val_VH_attention_linear_output_loss: 1.7598 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4831\n",
      "Epoch 3177/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4196 - VL_attention_linear_output_loss: 1.7017 - VH_attention_linear_output_loss: 1.7179 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4897 - val_loss: 3.5375 - val_VL_attention_linear_output_loss: 1.7666 - val_VH_attention_linear_output_loss: 1.7709 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4777\n",
      "Epoch 3178/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4209 - VL_attention_linear_output_loss: 1.7104 - VH_attention_linear_output_loss: 1.7105 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4934 - val_loss: 3.5226 - val_VL_attention_linear_output_loss: 1.7587 - val_VH_attention_linear_output_loss: 1.7639 - val_VL_attention_linear_output_acc: 0.4899 - val_VH_attention_linear_output_acc: 0.4803\n",
      "Epoch 3179/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4215 - VL_attention_linear_output_loss: 1.7050 - VH_attention_linear_output_loss: 1.7165 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4900 - val_loss: 3.5232 - val_VL_attention_linear_output_loss: 1.7630 - val_VH_attention_linear_output_loss: 1.7603 - val_VL_attention_linear_output_acc: 0.4858 - val_VH_attention_linear_output_acc: 0.4814\n",
      "Epoch 3180/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4207 - VL_attention_linear_output_loss: 1.7116 - VH_attention_linear_output_loss: 1.7091 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4932 - val_loss: 3.5536 - val_VL_attention_linear_output_loss: 1.7705 - val_VH_attention_linear_output_loss: 1.7832 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4714\n",
      "Epoch 3181/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4199 - VL_attention_linear_output_loss: 1.7017 - VH_attention_linear_output_loss: 1.7182 - VL_attention_linear_output_acc: 0.4954 - VH_attention_linear_output_acc: 0.4895 - val_loss: 3.5396 - val_VL_attention_linear_output_loss: 1.7788 - val_VH_attention_linear_output_loss: 1.7608 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4815\n",
      "Epoch 3182/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4280 - VL_attention_linear_output_loss: 1.7045 - VH_attention_linear_output_loss: 1.7235 - VL_attention_linear_output_acc: 0.4948 - VH_attention_linear_output_acc: 0.4880 - val_loss: 3.5236 - val_VL_attention_linear_output_loss: 1.7681 - val_VH_attention_linear_output_loss: 1.7555 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4815\n",
      "Epoch 3183/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4208 - VL_attention_linear_output_loss: 1.7092 - VH_attention_linear_output_loss: 1.7115 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4912 - val_loss: 3.5259 - val_VL_attention_linear_output_loss: 1.7619 - val_VH_attention_linear_output_loss: 1.7640 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4803\n",
      "Epoch 3184/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4198 - VL_attention_linear_output_loss: 1.7124 - VH_attention_linear_output_loss: 1.7073 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4942 - val_loss: 3.5219 - val_VL_attention_linear_output_loss: 1.7577 - val_VH_attention_linear_output_loss: 1.7643 - val_VL_attention_linear_output_acc: 0.4908 - val_VH_attention_linear_output_acc: 0.4793\n",
      "Epoch 3185/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4303 - VL_attention_linear_output_loss: 1.7117 - VH_attention_linear_output_loss: 1.7186 - VL_attention_linear_output_acc: 0.4894 - VH_attention_linear_output_acc: 0.4896 - val_loss: 3.5238 - val_VL_attention_linear_output_loss: 1.7615 - val_VH_attention_linear_output_loss: 1.7623 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4800\n",
      "Epoch 3186/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4234 - VL_attention_linear_output_loss: 1.7087 - VH_attention_linear_output_loss: 1.7146 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4910 - val_loss: 3.5261 - val_VL_attention_linear_output_loss: 1.7698 - val_VH_attention_linear_output_loss: 1.7563 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4807\n",
      "Epoch 3187/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4049 - VL_attention_linear_output_loss: 1.7037 - VH_attention_linear_output_loss: 1.7012 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4965 - val_loss: 3.6268 - val_VL_attention_linear_output_loss: 1.8538 - val_VH_attention_linear_output_loss: 1.7730 - val_VL_attention_linear_output_acc: 0.4425 - val_VH_attention_linear_output_acc: 0.4755\n",
      "Epoch 3188/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4115 - VL_attention_linear_output_loss: 1.7056 - VH_attention_linear_output_loss: 1.7059 - VL_attention_linear_output_acc: 0.4933 - VH_attention_linear_output_acc: 0.4940 - val_loss: 3.5171 - val_VL_attention_linear_output_loss: 1.7565 - val_VH_attention_linear_output_loss: 1.7607 - val_VL_attention_linear_output_acc: 0.4921 - val_VH_attention_linear_output_acc: 0.4831\n",
      "Epoch 3189/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4087 - VL_attention_linear_output_loss: 1.6979 - VH_attention_linear_output_loss: 1.7108 - VL_attention_linear_output_acc: 0.4974 - VH_attention_linear_output_acc: 0.4923 - val_loss: 3.5153 - val_VL_attention_linear_output_loss: 1.7626 - val_VH_attention_linear_output_loss: 1.7527 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4845\n",
      "Epoch 3190/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4110 - VL_attention_linear_output_loss: 1.6991 - VH_attention_linear_output_loss: 1.7118 - VL_attention_linear_output_acc: 0.4963 - VH_attention_linear_output_acc: 0.4923 - val_loss: 3.5282 - val_VL_attention_linear_output_loss: 1.7670 - val_VH_attention_linear_output_loss: 1.7612 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4834\n",
      "Epoch 3191/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4180 - VL_attention_linear_output_loss: 1.7063 - VH_attention_linear_output_loss: 1.7117 - VL_attention_linear_output_acc: 0.4933 - VH_attention_linear_output_acc: 0.4922 - val_loss: 3.5321 - val_VL_attention_linear_output_loss: 1.7746 - val_VH_attention_linear_output_loss: 1.7576 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4800\n",
      "Epoch 3192/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4104 - VL_attention_linear_output_loss: 1.7053 - VH_attention_linear_output_loss: 1.7051 - VL_attention_linear_output_acc: 0.4941 - VH_attention_linear_output_acc: 0.4951 - val_loss: 3.5203 - val_VL_attention_linear_output_loss: 1.7717 - val_VH_attention_linear_output_loss: 1.7486 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4873\n",
      "Epoch 3193/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4323 - VL_attention_linear_output_loss: 1.7142 - VH_attention_linear_output_loss: 1.7181 - VL_attention_linear_output_acc: 0.4885 - VH_attention_linear_output_acc: 0.4902 - val_loss: 3.5454 - val_VL_attention_linear_output_loss: 1.7780 - val_VH_attention_linear_output_loss: 1.7674 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.4799\n",
      "Epoch 3194/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4188 - VL_attention_linear_output_loss: 1.7075 - VH_attention_linear_output_loss: 1.7113 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4920 - val_loss: 3.5083 - val_VL_attention_linear_output_loss: 1.7583 - val_VH_attention_linear_output_loss: 1.7500 - val_VL_attention_linear_output_acc: 0.4913 - val_VH_attention_linear_output_acc: 0.4833\n",
      "Epoch 3195/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4101 - VL_attention_linear_output_loss: 1.7034 - VH_attention_linear_output_loss: 1.7067 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4941 - val_loss: 3.5325 - val_VL_attention_linear_output_loss: 1.7659 - val_VH_attention_linear_output_loss: 1.7667 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4793\n",
      "Epoch 3196/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4155 - VL_attention_linear_output_loss: 1.7010 - VH_attention_linear_output_loss: 1.7144 - VL_attention_linear_output_acc: 0.4961 - VH_attention_linear_output_acc: 0.4911 - val_loss: 3.5272 - val_VL_attention_linear_output_loss: 1.7612 - val_VH_attention_linear_output_loss: 1.7659 - val_VL_attention_linear_output_acc: 0.4884 - val_VH_attention_linear_output_acc: 0.4806\n",
      "Epoch 3197/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4364 - VL_attention_linear_output_loss: 1.7193 - VH_attention_linear_output_loss: 1.7171 - VL_attention_linear_output_acc: 0.4874 - VH_attention_linear_output_acc: 0.4903 - val_loss: 3.5290 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7662 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.4784\n",
      "Epoch 3198/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4116 - VL_attention_linear_output_loss: 1.6982 - VH_attention_linear_output_loss: 1.7134 - VL_attention_linear_output_acc: 0.4960 - VH_attention_linear_output_acc: 0.4912 - val_loss: 3.5488 - val_VL_attention_linear_output_loss: 1.7682 - val_VH_attention_linear_output_loss: 1.7806 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.4768\n",
      "Epoch 3199/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4019 - VL_attention_linear_output_loss: 1.6962 - VH_attention_linear_output_loss: 1.7057 - VL_attention_linear_output_acc: 0.4983 - VH_attention_linear_output_acc: 0.4949 - val_loss: 3.5240 - val_VL_attention_linear_output_loss: 1.7585 - val_VH_attention_linear_output_loss: 1.7655 - val_VL_attention_linear_output_acc: 0.4911 - val_VH_attention_linear_output_acc: 0.4781\n",
      "Epoch 3200/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4204 - VL_attention_linear_output_loss: 1.6977 - VH_attention_linear_output_loss: 1.7227 - VL_attention_linear_output_acc: 0.4970 - VH_attention_linear_output_acc: 0.4884 - val_loss: 3.5192 - val_VL_attention_linear_output_loss: 1.7602 - val_VH_attention_linear_output_loss: 1.7590 - val_VL_attention_linear_output_acc: 0.4899 - val_VH_attention_linear_output_acc: 0.4837\n",
      "Epoch 3201/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4097 - VL_attention_linear_output_loss: 1.7009 - VH_attention_linear_output_loss: 1.7088 - VL_attention_linear_output_acc: 0.4959 - VH_attention_linear_output_acc: 0.4932 - val_loss: 3.5134 - val_VL_attention_linear_output_loss: 1.7591 - val_VH_attention_linear_output_loss: 1.7543 - val_VL_attention_linear_output_acc: 0.4888 - val_VH_attention_linear_output_acc: 0.4845\n",
      "Epoch 3202/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4063 - VL_attention_linear_output_loss: 1.7013 - VH_attention_linear_output_loss: 1.7050 - VL_attention_linear_output_acc: 0.4952 - VH_attention_linear_output_acc: 0.4946 - val_loss: 3.5175 - val_VL_attention_linear_output_loss: 1.7635 - val_VH_attention_linear_output_loss: 1.7540 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.4829\n",
      "Epoch 3203/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4328 - VL_attention_linear_output_loss: 1.7140 - VH_attention_linear_output_loss: 1.7189 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4904 - val_loss: 3.5390 - val_VL_attention_linear_output_loss: 1.7725 - val_VH_attention_linear_output_loss: 1.7665 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4771\n",
      "Epoch 3204/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4283 - VL_attention_linear_output_loss: 1.7067 - VH_attention_linear_output_loss: 1.7216 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4905 - val_loss: 3.5400 - val_VL_attention_linear_output_loss: 1.7696 - val_VH_attention_linear_output_loss: 1.7704 - val_VL_attention_linear_output_acc: 0.4858 - val_VH_attention_linear_output_acc: 0.4770\n",
      "Epoch 3205/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4156 - VL_attention_linear_output_loss: 1.7050 - VH_attention_linear_output_loss: 1.7106 - VL_attention_linear_output_acc: 0.4938 - VH_attention_linear_output_acc: 0.4932 - val_loss: 3.5327 - val_VL_attention_linear_output_loss: 1.7716 - val_VH_attention_linear_output_loss: 1.7611 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4798\n",
      "Epoch 3206/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4281 - VL_attention_linear_output_loss: 1.7116 - VH_attention_linear_output_loss: 1.7166 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4904 - val_loss: 3.5388 - val_VL_attention_linear_output_loss: 1.7854 - val_VH_attention_linear_output_loss: 1.7534 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4857\n",
      "Epoch 3207/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4184 - VL_attention_linear_output_loss: 1.7076 - VH_attention_linear_output_loss: 1.7108 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4925 - val_loss: 3.5261 - val_VL_attention_linear_output_loss: 1.7671 - val_VH_attention_linear_output_loss: 1.7590 - val_VL_attention_linear_output_acc: 0.4867 - val_VH_attention_linear_output_acc: 0.4846\n",
      "Epoch 3208/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4218 - VL_attention_linear_output_loss: 1.7119 - VH_attention_linear_output_loss: 1.7099 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4930 - val_loss: 3.5249 - val_VL_attention_linear_output_loss: 1.7621 - val_VH_attention_linear_output_loss: 1.7628 - val_VL_attention_linear_output_acc: 0.4810 - val_VH_attention_linear_output_acc: 0.4751\n",
      "Epoch 3209/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4135 - VL_attention_linear_output_loss: 1.7019 - VH_attention_linear_output_loss: 1.7116 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4931 - val_loss: 3.5235 - val_VL_attention_linear_output_loss: 1.7675 - val_VH_attention_linear_output_loss: 1.7560 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4779\n",
      "Epoch 3210/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4070 - VL_attention_linear_output_loss: 1.7039 - VH_attention_linear_output_loss: 1.7031 - VL_attention_linear_output_acc: 0.4946 - VH_attention_linear_output_acc: 0.4963 - val_loss: 3.5884 - val_VL_attention_linear_output_loss: 1.8227 - val_VH_attention_linear_output_loss: 1.7656 - val_VL_attention_linear_output_acc: 0.4588 - val_VH_attention_linear_output_acc: 0.4821\n",
      "Epoch 3211/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4252 - VL_attention_linear_output_loss: 1.7108 - VH_attention_linear_output_loss: 1.7144 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4921 - val_loss: 3.5382 - val_VL_attention_linear_output_loss: 1.7783 - val_VH_attention_linear_output_loss: 1.7599 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4818\n",
      "Epoch 3212/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4170 - VL_attention_linear_output_loss: 1.7016 - VH_attention_linear_output_loss: 1.7155 - VL_attention_linear_output_acc: 0.4951 - VH_attention_linear_output_acc: 0.4923 - val_loss: 3.5506 - val_VL_attention_linear_output_loss: 1.7992 - val_VH_attention_linear_output_loss: 1.7514 - val_VL_attention_linear_output_acc: 0.4625 - val_VH_attention_linear_output_acc: 0.4844\n",
      "Epoch 3213/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4181 - VL_attention_linear_output_loss: 1.7124 - VH_attention_linear_output_loss: 1.7058 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4957 - val_loss: 3.5309 - val_VL_attention_linear_output_loss: 1.7610 - val_VH_attention_linear_output_loss: 1.7700 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4808\n",
      "Epoch 3214/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4161 - VL_attention_linear_output_loss: 1.7040 - VH_attention_linear_output_loss: 1.7120 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4929 - val_loss: 3.5152 - val_VL_attention_linear_output_loss: 1.7621 - val_VH_attention_linear_output_loss: 1.7531 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4850\n",
      "Epoch 3215/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4039 - VL_attention_linear_output_loss: 1.6983 - VH_attention_linear_output_loss: 1.7055 - VL_attention_linear_output_acc: 0.4970 - VH_attention_linear_output_acc: 0.4950 - val_loss: 3.5526 - val_VL_attention_linear_output_loss: 1.7929 - val_VH_attention_linear_output_loss: 1.7597 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.4798\n",
      "Epoch 3216/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4208 - VL_attention_linear_output_loss: 1.7085 - VH_attention_linear_output_loss: 1.7123 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4924 - val_loss: 3.5391 - val_VL_attention_linear_output_loss: 1.7759 - val_VH_attention_linear_output_loss: 1.7632 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4785\n",
      "Epoch 3217/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4226 - VL_attention_linear_output_loss: 1.7142 - VH_attention_linear_output_loss: 1.7084 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4939 - val_loss: 3.5196 - val_VL_attention_linear_output_loss: 1.7636 - val_VH_attention_linear_output_loss: 1.7559 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4871\n",
      "Epoch 3218/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4072 - VL_attention_linear_output_loss: 1.7003 - VH_attention_linear_output_loss: 1.7069 - VL_attention_linear_output_acc: 0.4950 - VH_attention_linear_output_acc: 0.4945 - val_loss: 3.5414 - val_VL_attention_linear_output_loss: 1.7708 - val_VH_attention_linear_output_loss: 1.7706 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4820\n",
      "Epoch 3219/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4149 - VL_attention_linear_output_loss: 1.7048 - VH_attention_linear_output_loss: 1.7101 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.4935 - val_loss: 3.5281 - val_VL_attention_linear_output_loss: 1.7668 - val_VH_attention_linear_output_loss: 1.7613 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4800\n",
      "Epoch 3220/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4206 - VL_attention_linear_output_loss: 1.7079 - VH_attention_linear_output_loss: 1.7127 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4923 - val_loss: 3.5276 - val_VL_attention_linear_output_loss: 1.7609 - val_VH_attention_linear_output_loss: 1.7668 - val_VL_attention_linear_output_acc: 0.4867 - val_VH_attention_linear_output_acc: 0.4793\n",
      "Epoch 3221/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4070 - VL_attention_linear_output_loss: 1.6997 - VH_attention_linear_output_loss: 1.7072 - VL_attention_linear_output_acc: 0.4959 - VH_attention_linear_output_acc: 0.4942 - val_loss: 3.5286 - val_VL_attention_linear_output_loss: 1.7708 - val_VH_attention_linear_output_loss: 1.7578 - val_VL_attention_linear_output_acc: 0.4804 - val_VH_attention_linear_output_acc: 0.4812\n",
      "Epoch 3222/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4152 - VL_attention_linear_output_loss: 1.7054 - VH_attention_linear_output_loss: 1.7098 - VL_attention_linear_output_acc: 0.4938 - VH_attention_linear_output_acc: 0.4928 - val_loss: 3.5355 - val_VL_attention_linear_output_loss: 1.7869 - val_VH_attention_linear_output_loss: 1.7486 - val_VL_attention_linear_output_acc: 0.4598 - val_VH_attention_linear_output_acc: 0.4910\n",
      "Epoch 3223/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4116 - VL_attention_linear_output_loss: 1.7092 - VH_attention_linear_output_loss: 1.7024 - VL_attention_linear_output_acc: 0.4896 - VH_attention_linear_output_acc: 0.4961 - val_loss: 3.5442 - val_VL_attention_linear_output_loss: 1.7656 - val_VH_attention_linear_output_loss: 1.7785 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4738\n",
      "Epoch 3224/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4167 - VL_attention_linear_output_loss: 1.7082 - VH_attention_linear_output_loss: 1.7085 - VL_attention_linear_output_acc: 0.4923 - VH_attention_linear_output_acc: 0.4937 - val_loss: 3.5243 - val_VL_attention_linear_output_loss: 1.7607 - val_VH_attention_linear_output_loss: 1.7635 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4779\n",
      "Epoch 3225/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4174 - VL_attention_linear_output_loss: 1.7027 - VH_attention_linear_output_loss: 1.7147 - VL_attention_linear_output_acc: 0.4932 - VH_attention_linear_output_acc: 0.4917 - val_loss: 3.5143 - val_VL_attention_linear_output_loss: 1.7655 - val_VH_attention_linear_output_loss: 1.7488 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4847\n",
      "Epoch 3226/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4024 - VL_attention_linear_output_loss: 1.7012 - VH_attention_linear_output_loss: 1.7012 - VL_attention_linear_output_acc: 0.4945 - VH_attention_linear_output_acc: 0.4969 - val_loss: 3.5288 - val_VL_attention_linear_output_loss: 1.7663 - val_VH_attention_linear_output_loss: 1.7625 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4788\n",
      "Epoch 3227/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4170 - VL_attention_linear_output_loss: 1.7116 - VH_attention_linear_output_loss: 1.7054 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4948 - val_loss: 3.5640 - val_VL_attention_linear_output_loss: 1.8142 - val_VH_attention_linear_output_loss: 1.7498 - val_VL_attention_linear_output_acc: 0.4571 - val_VH_attention_linear_output_acc: 0.4844\n",
      "Epoch 3228/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4103 - VL_attention_linear_output_loss: 1.7021 - VH_attention_linear_output_loss: 1.7081 - VL_attention_linear_output_acc: 0.4949 - VH_attention_linear_output_acc: 0.4940 - val_loss: 3.5204 - val_VL_attention_linear_output_loss: 1.7601 - val_VH_attention_linear_output_loss: 1.7603 - val_VL_attention_linear_output_acc: 0.4897 - val_VH_attention_linear_output_acc: 0.4842\n",
      "Epoch 3229/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4096 - VL_attention_linear_output_loss: 1.7029 - VH_attention_linear_output_loss: 1.7067 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4943 - val_loss: 3.5285 - val_VL_attention_linear_output_loss: 1.7742 - val_VH_attention_linear_output_loss: 1.7543 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4851\n",
      "Epoch 3230/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4155 - VL_attention_linear_output_loss: 1.7078 - VH_attention_linear_output_loss: 1.7077 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.4947 - val_loss: 3.5238 - val_VL_attention_linear_output_loss: 1.7691 - val_VH_attention_linear_output_loss: 1.7546 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4867\n",
      "Epoch 3231/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4239 - VL_attention_linear_output_loss: 1.7034 - VH_attention_linear_output_loss: 1.7205 - VL_attention_linear_output_acc: 0.4941 - VH_attention_linear_output_acc: 0.4890 - val_loss: 3.5860 - val_VL_attention_linear_output_loss: 1.7892 - val_VH_attention_linear_output_loss: 1.7968 - val_VL_attention_linear_output_acc: 0.4759 - val_VH_attention_linear_output_acc: 0.4634\n",
      "Epoch 3232/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4135 - VL_attention_linear_output_loss: 1.6997 - VH_attention_linear_output_loss: 1.7138 - VL_attention_linear_output_acc: 0.4969 - VH_attention_linear_output_acc: 0.4923 - val_loss: 3.5180 - val_VL_attention_linear_output_loss: 1.7655 - val_VH_attention_linear_output_loss: 1.7525 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3233/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4228 - VL_attention_linear_output_loss: 1.7155 - VH_attention_linear_output_loss: 1.7073 - VL_attention_linear_output_acc: 0.4883 - VH_attention_linear_output_acc: 0.4941 - val_loss: 3.5364 - val_VL_attention_linear_output_loss: 1.7728 - val_VH_attention_linear_output_loss: 1.7636 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4803\n",
      "Epoch 3234/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3993 - VL_attention_linear_output_loss: 1.6980 - VH_attention_linear_output_loss: 1.7013 - VL_attention_linear_output_acc: 0.4961 - VH_attention_linear_output_acc: 0.4968 - val_loss: 3.5455 - val_VL_attention_linear_output_loss: 1.7671 - val_VH_attention_linear_output_loss: 1.7784 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4696\n",
      "Epoch 3235/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4155 - VL_attention_linear_output_loss: 1.7073 - VH_attention_linear_output_loss: 1.7082 - VL_attention_linear_output_acc: 0.4919 - VH_attention_linear_output_acc: 0.4940 - val_loss: 3.5260 - val_VL_attention_linear_output_loss: 1.7666 - val_VH_attention_linear_output_loss: 1.7594 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4825\n",
      "Epoch 3236/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4236 - VL_attention_linear_output_loss: 1.7051 - VH_attention_linear_output_loss: 1.7185 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4900 - val_loss: 3.5384 - val_VL_attention_linear_output_loss: 1.7738 - val_VH_attention_linear_output_loss: 1.7646 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4800\n",
      "Epoch 3237/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4146 - VL_attention_linear_output_loss: 1.7123 - VH_attention_linear_output_loss: 1.7023 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4966 - val_loss: 3.5300 - val_VL_attention_linear_output_loss: 1.7671 - val_VH_attention_linear_output_loss: 1.7629 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4793\n",
      "Epoch 3238/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4127 - VL_attention_linear_output_loss: 1.7002 - VH_attention_linear_output_loss: 1.7125 - VL_attention_linear_output_acc: 0.4950 - VH_attention_linear_output_acc: 0.4926 - val_loss: 3.5179 - val_VL_attention_linear_output_loss: 1.7657 - val_VH_attention_linear_output_loss: 1.7522 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4861\n",
      "Epoch 3239/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4142 - VL_attention_linear_output_loss: 1.7043 - VH_attention_linear_output_loss: 1.7098 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4937 - val_loss: 3.5214 - val_VL_attention_linear_output_loss: 1.7638 - val_VH_attention_linear_output_loss: 1.7577 - val_VL_attention_linear_output_acc: 0.4892 - val_VH_attention_linear_output_acc: 0.4836\n",
      "Epoch 3240/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4276 - VL_attention_linear_output_loss: 1.7098 - VH_attention_linear_output_loss: 1.7178 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4900 - val_loss: 3.5539 - val_VL_attention_linear_output_loss: 1.7785 - val_VH_attention_linear_output_loss: 1.7753 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4777\n",
      "Epoch 3241/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4195 - VL_attention_linear_output_loss: 1.7020 - VH_attention_linear_output_loss: 1.7175 - VL_attention_linear_output_acc: 0.4944 - VH_attention_linear_output_acc: 0.4909 - val_loss: 3.5320 - val_VL_attention_linear_output_loss: 1.7816 - val_VH_attention_linear_output_loss: 1.7505 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.4839\n",
      "Epoch 3242/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4062 - VL_attention_linear_output_loss: 1.7042 - VH_attention_linear_output_loss: 1.7021 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4965 - val_loss: 3.5355 - val_VL_attention_linear_output_loss: 1.7710 - val_VH_attention_linear_output_loss: 1.7645 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4801\n",
      "Epoch 3243/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4135 - VL_attention_linear_output_loss: 1.7019 - VH_attention_linear_output_loss: 1.7116 - VL_attention_linear_output_acc: 0.4943 - VH_attention_linear_output_acc: 0.4925 - val_loss: 3.5217 - val_VL_attention_linear_output_loss: 1.7673 - val_VH_attention_linear_output_loss: 1.7544 - val_VL_attention_linear_output_acc: 0.4804 - val_VH_attention_linear_output_acc: 0.4851\n",
      "Epoch 3244/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4138 - VL_attention_linear_output_loss: 1.7056 - VH_attention_linear_output_loss: 1.7082 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4938 - val_loss: 3.5542 - val_VL_attention_linear_output_loss: 1.7776 - val_VH_attention_linear_output_loss: 1.7766 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4768\n",
      "Epoch 3245/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4200 - VL_attention_linear_output_loss: 1.7093 - VH_attention_linear_output_loss: 1.7107 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4936 - val_loss: 3.5057 - val_VL_attention_linear_output_loss: 1.7595 - val_VH_attention_linear_output_loss: 1.7462 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4872\n",
      "Epoch 3246/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4040 - VL_attention_linear_output_loss: 1.6959 - VH_attention_linear_output_loss: 1.7081 - VL_attention_linear_output_acc: 0.4973 - VH_attention_linear_output_acc: 0.4950 - val_loss: 3.5409 - val_VL_attention_linear_output_loss: 1.7643 - val_VH_attention_linear_output_loss: 1.7766 - val_VL_attention_linear_output_acc: 0.4811 - val_VH_attention_linear_output_acc: 0.4749\n",
      "Epoch 3247/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4057 - VL_attention_linear_output_loss: 1.7005 - VH_attention_linear_output_loss: 1.7052 - VL_attention_linear_output_acc: 0.4953 - VH_attention_linear_output_acc: 0.4957 - val_loss: 3.5457 - val_VL_attention_linear_output_loss: 1.7648 - val_VH_attention_linear_output_loss: 1.7809 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4729\n",
      "Epoch 3248/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4215 - VL_attention_linear_output_loss: 1.7106 - VH_attention_linear_output_loss: 1.7109 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4930 - val_loss: 3.5160 - val_VL_attention_linear_output_loss: 1.7624 - val_VH_attention_linear_output_loss: 1.7536 - val_VL_attention_linear_output_acc: 0.4872 - val_VH_attention_linear_output_acc: 0.4873\n",
      "Epoch 3249/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4072 - VL_attention_linear_output_loss: 1.7025 - VH_attention_linear_output_loss: 1.7047 - VL_attention_linear_output_acc: 0.4955 - VH_attention_linear_output_acc: 0.4956 - val_loss: 3.5395 - val_VL_attention_linear_output_loss: 1.7644 - val_VH_attention_linear_output_loss: 1.7751 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4718\n",
      "Epoch 3250/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4164 - VL_attention_linear_output_loss: 1.7027 - VH_attention_linear_output_loss: 1.7136 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4921 - val_loss: 3.5220 - val_VL_attention_linear_output_loss: 1.7669 - val_VH_attention_linear_output_loss: 1.7550 - val_VL_attention_linear_output_acc: 0.4823 - val_VH_attention_linear_output_acc: 0.4875\n",
      "Epoch 3251/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4015 - VL_attention_linear_output_loss: 1.6989 - VH_attention_linear_output_loss: 1.7025 - VL_attention_linear_output_acc: 0.4958 - VH_attention_linear_output_acc: 0.4966 - val_loss: 3.5316 - val_VL_attention_linear_output_loss: 1.7583 - val_VH_attention_linear_output_loss: 1.7733 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4749\n",
      "Epoch 3252/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4166 - VL_attention_linear_output_loss: 1.7028 - VH_attention_linear_output_loss: 1.7138 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4918 - val_loss: 3.5328 - val_VL_attention_linear_output_loss: 1.7668 - val_VH_attention_linear_output_loss: 1.7660 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.4830\n",
      "Epoch 3253/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4122 - VL_attention_linear_output_loss: 1.7095 - VH_attention_linear_output_loss: 1.7027 - VL_attention_linear_output_acc: 0.4889 - VH_attention_linear_output_acc: 0.4965 - val_loss: 3.5498 - val_VL_attention_linear_output_loss: 1.7941 - val_VH_attention_linear_output_loss: 1.7557 - val_VL_attention_linear_output_acc: 0.4718 - val_VH_attention_linear_output_acc: 0.4826\n",
      "Epoch 3254/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4227 - VL_attention_linear_output_loss: 1.7091 - VH_attention_linear_output_loss: 1.7136 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4924 - val_loss: 3.5105 - val_VL_attention_linear_output_loss: 1.7597 - val_VH_attention_linear_output_loss: 1.7508 - val_VL_attention_linear_output_acc: 0.4869 - val_VH_attention_linear_output_acc: 0.4857\n",
      "Epoch 3255/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4015 - VL_attention_linear_output_loss: 1.6950 - VH_attention_linear_output_loss: 1.7065 - VL_attention_linear_output_acc: 0.4961 - VH_attention_linear_output_acc: 0.4951 - val_loss: 3.5252 - val_VL_attention_linear_output_loss: 1.7740 - val_VH_attention_linear_output_loss: 1.7512 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.4854\n",
      "Epoch 3256/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4109 - VL_attention_linear_output_loss: 1.7022 - VH_attention_linear_output_loss: 1.7087 - VL_attention_linear_output_acc: 0.4949 - VH_attention_linear_output_acc: 0.4943 - val_loss: 3.5291 - val_VL_attention_linear_output_loss: 1.7624 - val_VH_attention_linear_output_loss: 1.7667 - val_VL_attention_linear_output_acc: 0.4886 - val_VH_attention_linear_output_acc: 0.4804\n",
      "Epoch 3257/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4140 - VL_attention_linear_output_loss: 1.7024 - VH_attention_linear_output_loss: 1.7117 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4926 - val_loss: 3.5261 - val_VL_attention_linear_output_loss: 1.7767 - val_VH_attention_linear_output_loss: 1.7494 - val_VL_attention_linear_output_acc: 0.4762 - val_VH_attention_linear_output_acc: 0.4898\n",
      "Epoch 3258/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4111 - VL_attention_linear_output_loss: 1.7103 - VH_attention_linear_output_loss: 1.7008 - VL_attention_linear_output_acc: 0.4890 - VH_attention_linear_output_acc: 0.4975 - val_loss: 3.5065 - val_VL_attention_linear_output_loss: 1.7599 - val_VH_attention_linear_output_loss: 1.7466 - val_VL_attention_linear_output_acc: 0.4880 - val_VH_attention_linear_output_acc: 0.4902\n",
      "Epoch 3259/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4012 - VL_attention_linear_output_loss: 1.7009 - VH_attention_linear_output_loss: 1.7004 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4971 - val_loss: 3.5591 - val_VL_attention_linear_output_loss: 1.8056 - val_VH_attention_linear_output_loss: 1.7535 - val_VL_attention_linear_output_acc: 0.4568 - val_VH_attention_linear_output_acc: 0.4866\n",
      "Epoch 3260/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4238 - VL_attention_linear_output_loss: 1.7070 - VH_attention_linear_output_loss: 1.7168 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4913 - val_loss: 3.5517 - val_VL_attention_linear_output_loss: 1.7621 - val_VH_attention_linear_output_loss: 1.7895 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4691\n",
      "Epoch 3261/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4268 - VL_attention_linear_output_loss: 1.7024 - VH_attention_linear_output_loss: 1.7244 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4891 - val_loss: 3.5181 - val_VL_attention_linear_output_loss: 1.7623 - val_VH_attention_linear_output_loss: 1.7559 - val_VL_attention_linear_output_acc: 0.4870 - val_VH_attention_linear_output_acc: 0.4849\n",
      "Epoch 3262/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4119 - VL_attention_linear_output_loss: 1.7096 - VH_attention_linear_output_loss: 1.7022 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4971 - val_loss: 3.5237 - val_VL_attention_linear_output_loss: 1.7693 - val_VH_attention_linear_output_loss: 1.7544 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4874\n",
      "Epoch 3263/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4113 - VL_attention_linear_output_loss: 1.7077 - VH_attention_linear_output_loss: 1.7037 - VL_attention_linear_output_acc: 0.4905 - VH_attention_linear_output_acc: 0.4970 - val_loss: 3.5162 - val_VL_attention_linear_output_loss: 1.7647 - val_VH_attention_linear_output_loss: 1.7515 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4849\n",
      "Epoch 3264/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4008 - VL_attention_linear_output_loss: 1.7017 - VH_attention_linear_output_loss: 1.6990 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4978 - val_loss: 3.5363 - val_VL_attention_linear_output_loss: 1.7879 - val_VH_attention_linear_output_loss: 1.7484 - val_VL_attention_linear_output_acc: 0.4677 - val_VH_attention_linear_output_acc: 0.4899\n",
      "Epoch 3265/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4065 - VL_attention_linear_output_loss: 1.7020 - VH_attention_linear_output_loss: 1.7045 - VL_attention_linear_output_acc: 0.4950 - VH_attention_linear_output_acc: 0.4960 - val_loss: 3.5078 - val_VL_attention_linear_output_loss: 1.7577 - val_VH_attention_linear_output_loss: 1.7502 - val_VL_attention_linear_output_acc: 0.4905 - val_VH_attention_linear_output_acc: 0.4860\n",
      "Epoch 3266/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3984 - VL_attention_linear_output_loss: 1.6973 - VH_attention_linear_output_loss: 1.7011 - VL_attention_linear_output_acc: 0.4969 - VH_attention_linear_output_acc: 0.4975 - val_loss: 3.5102 - val_VL_attention_linear_output_loss: 1.7608 - val_VH_attention_linear_output_loss: 1.7494 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4880\n",
      "Epoch 3267/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4077 - VL_attention_linear_output_loss: 1.7005 - VH_attention_linear_output_loss: 1.7072 - VL_attention_linear_output_acc: 0.4946 - VH_attention_linear_output_acc: 0.4947 - val_loss: 3.5140 - val_VL_attention_linear_output_loss: 1.7638 - val_VH_attention_linear_output_loss: 1.7502 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4845\n",
      "Epoch 3268/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3962 - VL_attention_linear_output_loss: 1.7039 - VH_attention_linear_output_loss: 1.6923 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.5008 - val_loss: 3.5176 - val_VL_attention_linear_output_loss: 1.7711 - val_VH_attention_linear_output_loss: 1.7465 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4844\n",
      "Epoch 3269/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4012 - VL_attention_linear_output_loss: 1.7018 - VH_attention_linear_output_loss: 1.6994 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4978 - val_loss: 3.5177 - val_VL_attention_linear_output_loss: 1.7614 - val_VH_attention_linear_output_loss: 1.7564 - val_VL_attention_linear_output_acc: 0.4892 - val_VH_attention_linear_output_acc: 0.4871\n",
      "Epoch 3270/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4068 - VL_attention_linear_output_loss: 1.7012 - VH_attention_linear_output_loss: 1.7057 - VL_attention_linear_output_acc: 0.4951 - VH_attention_linear_output_acc: 0.4953 - val_loss: 3.5163 - val_VL_attention_linear_output_loss: 1.7639 - val_VH_attention_linear_output_loss: 1.7524 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4855\n",
      "Epoch 3271/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4224 - VL_attention_linear_output_loss: 1.7140 - VH_attention_linear_output_loss: 1.7084 - VL_attention_linear_output_acc: 0.4880 - VH_attention_linear_output_acc: 0.4951 - val_loss: 3.5392 - val_VL_attention_linear_output_loss: 1.7902 - val_VH_attention_linear_output_loss: 1.7490 - val_VL_attention_linear_output_acc: 0.4705 - val_VH_attention_linear_output_acc: 0.4871\n",
      "Epoch 3272/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4130 - VL_attention_linear_output_loss: 1.7076 - VH_attention_linear_output_loss: 1.7054 - VL_attention_linear_output_acc: 0.4901 - VH_attention_linear_output_acc: 0.4962 - val_loss: 3.5111 - val_VL_attention_linear_output_loss: 1.7582 - val_VH_attention_linear_output_loss: 1.7529 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4868\n",
      "Epoch 3273/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4075 - VL_attention_linear_output_loss: 1.6971 - VH_attention_linear_output_loss: 1.7104 - VL_attention_linear_output_acc: 0.4977 - VH_attention_linear_output_acc: 0.4932 - val_loss: 3.5381 - val_VL_attention_linear_output_loss: 1.7651 - val_VH_attention_linear_output_loss: 1.7730 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.4792\n",
      "Epoch 3274/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3991 - VL_attention_linear_output_loss: 1.7036 - VH_attention_linear_output_loss: 1.6954 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.5003 - val_loss: 3.5051 - val_VL_attention_linear_output_loss: 1.7582 - val_VH_attention_linear_output_loss: 1.7468 - val_VL_attention_linear_output_acc: 0.4869 - val_VH_attention_linear_output_acc: 0.4880\n",
      "Epoch 3275/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4013 - VL_attention_linear_output_loss: 1.7027 - VH_attention_linear_output_loss: 1.6985 - VL_attention_linear_output_acc: 0.4933 - VH_attention_linear_output_acc: 0.4985 - val_loss: 3.5119 - val_VL_attention_linear_output_loss: 1.7623 - val_VH_attention_linear_output_loss: 1.7496 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4840\n",
      "Epoch 3276/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4028 - VL_attention_linear_output_loss: 1.7052 - VH_attention_linear_output_loss: 1.6975 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4991 - val_loss: 3.5272 - val_VL_attention_linear_output_loss: 1.7719 - val_VH_attention_linear_output_loss: 1.7553 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4835\n",
      "Epoch 3277/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3987 - VL_attention_linear_output_loss: 1.6994 - VH_attention_linear_output_loss: 1.6993 - VL_attention_linear_output_acc: 0.4946 - VH_attention_linear_output_acc: 0.4978 - val_loss: 3.5306 - val_VL_attention_linear_output_loss: 1.7674 - val_VH_attention_linear_output_loss: 1.7632 - val_VL_attention_linear_output_acc: 0.4769 - val_VH_attention_linear_output_acc: 0.4829\n",
      "Epoch 3278/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4135 - VL_attention_linear_output_loss: 1.7053 - VH_attention_linear_output_loss: 1.7082 - VL_attention_linear_output_acc: 0.4920 - VH_attention_linear_output_acc: 0.4946 - val_loss: 3.5477 - val_VL_attention_linear_output_loss: 1.7936 - val_VH_attention_linear_output_loss: 1.7541 - val_VL_attention_linear_output_acc: 0.4654 - val_VH_attention_linear_output_acc: 0.4854\n",
      "Epoch 3279/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4027 - VL_attention_linear_output_loss: 1.6996 - VH_attention_linear_output_loss: 1.7032 - VL_attention_linear_output_acc: 0.4950 - VH_attention_linear_output_acc: 0.4966 - val_loss: 3.5297 - val_VL_attention_linear_output_loss: 1.7795 - val_VH_attention_linear_output_loss: 1.7501 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4871\n",
      "Epoch 3280/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4109 - VL_attention_linear_output_loss: 1.7093 - VH_attention_linear_output_loss: 1.7016 - VL_attention_linear_output_acc: 0.4904 - VH_attention_linear_output_acc: 0.4977 - val_loss: 3.5329 - val_VL_attention_linear_output_loss: 1.7603 - val_VH_attention_linear_output_loss: 1.7725 - val_VL_attention_linear_output_acc: 0.4904 - val_VH_attention_linear_output_acc: 0.4791\n",
      "Epoch 3281/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4102 - VL_attention_linear_output_loss: 1.7028 - VH_attention_linear_output_loss: 1.7074 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4950 - val_loss: 3.5434 - val_VL_attention_linear_output_loss: 1.7717 - val_VH_attention_linear_output_loss: 1.7717 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.4783\n",
      "Epoch 3282/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4017 - VL_attention_linear_output_loss: 1.6966 - VH_attention_linear_output_loss: 1.7051 - VL_attention_linear_output_acc: 0.4970 - VH_attention_linear_output_acc: 0.4965 - val_loss: 3.5629 - val_VL_attention_linear_output_loss: 1.8122 - val_VH_attention_linear_output_loss: 1.7506 - val_VL_attention_linear_output_acc: 0.4495 - val_VH_attention_linear_output_acc: 0.4849\n",
      "Epoch 3283/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4041 - VL_attention_linear_output_loss: 1.7002 - VH_attention_linear_output_loss: 1.7039 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4964 - val_loss: 3.5331 - val_VL_attention_linear_output_loss: 1.7614 - val_VH_attention_linear_output_loss: 1.7718 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4845\n",
      "Epoch 3284/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4141 - VL_attention_linear_output_loss: 1.7060 - VH_attention_linear_output_loss: 1.7081 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4951 - val_loss: 3.5372 - val_VL_attention_linear_output_loss: 1.7732 - val_VH_attention_linear_output_loss: 1.7640 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4841\n",
      "Epoch 3285/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3976 - VL_attention_linear_output_loss: 1.6978 - VH_attention_linear_output_loss: 1.6998 - VL_attention_linear_output_acc: 0.4959 - VH_attention_linear_output_acc: 0.4979 - val_loss: 3.5145 - val_VL_attention_linear_output_loss: 1.7633 - val_VH_attention_linear_output_loss: 1.7512 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4825\n",
      "Epoch 3286/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4118 - VL_attention_linear_output_loss: 1.6987 - VH_attention_linear_output_loss: 1.7131 - VL_attention_linear_output_acc: 0.4960 - VH_attention_linear_output_acc: 0.4927 - val_loss: 3.5275 - val_VL_attention_linear_output_loss: 1.7630 - val_VH_attention_linear_output_loss: 1.7645 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4858\n",
      "Epoch 3287/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4137 - VL_attention_linear_output_loss: 1.7047 - VH_attention_linear_output_loss: 1.7090 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4947 - val_loss: 3.5289 - val_VL_attention_linear_output_loss: 1.7748 - val_VH_attention_linear_output_loss: 1.7541 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4842\n",
      "Epoch 3288/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3998 - VL_attention_linear_output_loss: 1.7003 - VH_attention_linear_output_loss: 1.6995 - VL_attention_linear_output_acc: 0.4952 - VH_attention_linear_output_acc: 0.4988 - val_loss: 3.5530 - val_VL_attention_linear_output_loss: 1.7818 - val_VH_attention_linear_output_loss: 1.7712 - val_VL_attention_linear_output_acc: 0.4759 - val_VH_attention_linear_output_acc: 0.4809\n",
      "Epoch 3289/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3997 - VL_attention_linear_output_loss: 1.6995 - VH_attention_linear_output_loss: 1.7003 - VL_attention_linear_output_acc: 0.4947 - VH_attention_linear_output_acc: 0.4982 - val_loss: 3.5416 - val_VL_attention_linear_output_loss: 1.7827 - val_VH_attention_linear_output_loss: 1.7590 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.4853\n",
      "Epoch 3290/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4227 - VL_attention_linear_output_loss: 1.7137 - VH_attention_linear_output_loss: 1.7089 - VL_attention_linear_output_acc: 0.4878 - VH_attention_linear_output_acc: 0.4944 - val_loss: 3.5492 - val_VL_attention_linear_output_loss: 1.7872 - val_VH_attention_linear_output_loss: 1.7619 - val_VL_attention_linear_output_acc: 0.4677 - val_VH_attention_linear_output_acc: 0.4831\n",
      "Epoch 3291/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4163 - VL_attention_linear_output_loss: 1.7123 - VH_attention_linear_output_loss: 1.7040 - VL_attention_linear_output_acc: 0.4891 - VH_attention_linear_output_acc: 0.4973 - val_loss: 3.5638 - val_VL_attention_linear_output_loss: 1.7597 - val_VH_attention_linear_output_loss: 1.8041 - val_VL_attention_linear_output_acc: 0.4901 - val_VH_attention_linear_output_acc: 0.4686\n",
      "Epoch 3292/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4024 - VL_attention_linear_output_loss: 1.6970 - VH_attention_linear_output_loss: 1.7054 - VL_attention_linear_output_acc: 0.4956 - VH_attention_linear_output_acc: 0.4963 - val_loss: 3.5172 - val_VL_attention_linear_output_loss: 1.7594 - val_VH_attention_linear_output_loss: 1.7578 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4817\n",
      "Epoch 3293/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3942 - VL_attention_linear_output_loss: 1.6971 - VH_attention_linear_output_loss: 1.6971 - VL_attention_linear_output_acc: 0.4951 - VH_attention_linear_output_acc: 0.4993 - val_loss: 3.5199 - val_VL_attention_linear_output_loss: 1.7584 - val_VH_attention_linear_output_loss: 1.7615 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4828\n",
      "Epoch 3294/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3988 - VL_attention_linear_output_loss: 1.6961 - VH_attention_linear_output_loss: 1.7028 - VL_attention_linear_output_acc: 0.4959 - VH_attention_linear_output_acc: 0.4971 - val_loss: 3.5137 - val_VL_attention_linear_output_loss: 1.7622 - val_VH_attention_linear_output_loss: 1.7515 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4848\n",
      "Epoch 3295/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4024 - VL_attention_linear_output_loss: 1.7016 - VH_attention_linear_output_loss: 1.7008 - VL_attention_linear_output_acc: 0.4920 - VH_attention_linear_output_acc: 0.4978 - val_loss: 3.5408 - val_VL_attention_linear_output_loss: 1.7873 - val_VH_attention_linear_output_loss: 1.7535 - val_VL_attention_linear_output_acc: 0.4735 - val_VH_attention_linear_output_acc: 0.4911\n",
      "Epoch 3296/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4173 - VL_attention_linear_output_loss: 1.7102 - VH_attention_linear_output_loss: 1.7070 - VL_attention_linear_output_acc: 0.4882 - VH_attention_linear_output_acc: 0.4957 - val_loss: 3.5181 - val_VL_attention_linear_output_loss: 1.7543 - val_VH_attention_linear_output_loss: 1.7638 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4815\n",
      "Epoch 3297/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3940 - VL_attention_linear_output_loss: 1.6961 - VH_attention_linear_output_loss: 1.6979 - VL_attention_linear_output_acc: 0.4966 - VH_attention_linear_output_acc: 0.4991 - val_loss: 3.5540 - val_VL_attention_linear_output_loss: 1.7878 - val_VH_attention_linear_output_loss: 1.7662 - val_VL_attention_linear_output_acc: 0.4641 - val_VH_attention_linear_output_acc: 0.4805\n",
      "Epoch 3298/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4130 - VL_attention_linear_output_loss: 1.7035 - VH_attention_linear_output_loss: 1.7095 - VL_attention_linear_output_acc: 0.4922 - VH_attention_linear_output_acc: 0.4950 - val_loss: 3.5441 - val_VL_attention_linear_output_loss: 1.7680 - val_VH_attention_linear_output_loss: 1.7760 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4778\n",
      "Epoch 3299/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4044 - VL_attention_linear_output_loss: 1.6984 - VH_attention_linear_output_loss: 1.7060 - VL_attention_linear_output_acc: 0.4949 - VH_attention_linear_output_acc: 0.4960 - val_loss: 3.5165 - val_VL_attention_linear_output_loss: 1.7652 - val_VH_attention_linear_output_loss: 1.7513 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4863\n",
      "Epoch 3300/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4154 - VL_attention_linear_output_loss: 1.7065 - VH_attention_linear_output_loss: 1.7089 - VL_attention_linear_output_acc: 0.4918 - VH_attention_linear_output_acc: 0.4954 - val_loss: 3.5360 - val_VL_attention_linear_output_loss: 1.7728 - val_VH_attention_linear_output_loss: 1.7632 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4847\n",
      "Epoch 3301/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3941 - VL_attention_linear_output_loss: 1.6964 - VH_attention_linear_output_loss: 1.6977 - VL_attention_linear_output_acc: 0.4973 - VH_attention_linear_output_acc: 0.4996 - val_loss: 3.5139 - val_VL_attention_linear_output_loss: 1.7581 - val_VH_attention_linear_output_loss: 1.7558 - val_VL_attention_linear_output_acc: 0.4885 - val_VH_attention_linear_output_acc: 0.4870\n",
      "Epoch 3302/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4090 - VL_attention_linear_output_loss: 1.7076 - VH_attention_linear_output_loss: 1.7015 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4983 - val_loss: 3.5105 - val_VL_attention_linear_output_loss: 1.7582 - val_VH_attention_linear_output_loss: 1.7522 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.4853\n",
      "Epoch 3303/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4020 - VL_attention_linear_output_loss: 1.6994 - VH_attention_linear_output_loss: 1.7025 - VL_attention_linear_output_acc: 0.4945 - VH_attention_linear_output_acc: 0.4974 - val_loss: 3.5098 - val_VL_attention_linear_output_loss: 1.7561 - val_VH_attention_linear_output_loss: 1.7537 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4863\n",
      "Epoch 3304/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3984 - VL_attention_linear_output_loss: 1.6962 - VH_attention_linear_output_loss: 1.7022 - VL_attention_linear_output_acc: 0.4965 - VH_attention_linear_output_acc: 0.4977 - val_loss: 3.5205 - val_VL_attention_linear_output_loss: 1.7668 - val_VH_attention_linear_output_loss: 1.7537 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.4864\n",
      "Epoch 3305/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4234 - VL_attention_linear_output_loss: 1.7198 - VH_attention_linear_output_loss: 1.7037 - VL_attention_linear_output_acc: 0.4848 - VH_attention_linear_output_acc: 0.4968 - val_loss: 3.5141 - val_VL_attention_linear_output_loss: 1.7591 - val_VH_attention_linear_output_loss: 1.7550 - val_VL_attention_linear_output_acc: 0.4888 - val_VH_attention_linear_output_acc: 0.4837\n",
      "Epoch 3306/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4069 - VL_attention_linear_output_loss: 1.6986 - VH_attention_linear_output_loss: 1.7083 - VL_attention_linear_output_acc: 0.4951 - VH_attention_linear_output_acc: 0.4951 - val_loss: 3.5409 - val_VL_attention_linear_output_loss: 1.7591 - val_VH_attention_linear_output_loss: 1.7818 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.4801\n",
      "Epoch 3307/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4034 - VL_attention_linear_output_loss: 1.6975 - VH_attention_linear_output_loss: 1.7060 - VL_attention_linear_output_acc: 0.4955 - VH_attention_linear_output_acc: 0.4969 - val_loss: 3.5281 - val_VL_attention_linear_output_loss: 1.7657 - val_VH_attention_linear_output_loss: 1.7624 - val_VL_attention_linear_output_acc: 0.4867 - val_VH_attention_linear_output_acc: 0.4839\n",
      "Epoch 3308/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3968 - VL_attention_linear_output_loss: 1.6993 - VH_attention_linear_output_loss: 1.6975 - VL_attention_linear_output_acc: 0.4937 - VH_attention_linear_output_acc: 0.4993 - val_loss: 3.5589 - val_VL_attention_linear_output_loss: 1.7790 - val_VH_attention_linear_output_loss: 1.7799 - val_VL_attention_linear_output_acc: 0.4767 - val_VH_attention_linear_output_acc: 0.4789\n",
      "Epoch 3309/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4133 - VL_attention_linear_output_loss: 1.7034 - VH_attention_linear_output_loss: 1.7099 - VL_attention_linear_output_acc: 0.4912 - VH_attention_linear_output_acc: 0.4949 - val_loss: 3.5412 - val_VL_attention_linear_output_loss: 1.7676 - val_VH_attention_linear_output_loss: 1.7736 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4787\n",
      "Epoch 3310/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4078 - VL_attention_linear_output_loss: 1.7055 - VH_attention_linear_output_loss: 1.7024 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4979 - val_loss: 3.5164 - val_VL_attention_linear_output_loss: 1.7608 - val_VH_attention_linear_output_loss: 1.7556 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3311/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3917 - VL_attention_linear_output_loss: 1.6948 - VH_attention_linear_output_loss: 1.6968 - VL_attention_linear_output_acc: 0.4968 - VH_attention_linear_output_acc: 0.5000 - val_loss: 3.5620 - val_VL_attention_linear_output_loss: 1.7920 - val_VH_attention_linear_output_loss: 1.7700 - val_VL_attention_linear_output_acc: 0.4683 - val_VH_attention_linear_output_acc: 0.4809\n",
      "Epoch 3312/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4082 - VL_attention_linear_output_loss: 1.7045 - VH_attention_linear_output_loss: 1.7037 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.4970 - val_loss: 3.5336 - val_VL_attention_linear_output_loss: 1.7704 - val_VH_attention_linear_output_loss: 1.7632 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4843\n",
      "Epoch 3313/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4087 - VL_attention_linear_output_loss: 1.7014 - VH_attention_linear_output_loss: 1.7073 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4952 - val_loss: 3.5595 - val_VL_attention_linear_output_loss: 1.7959 - val_VH_attention_linear_output_loss: 1.7636 - val_VL_attention_linear_output_acc: 0.4708 - val_VH_attention_linear_output_acc: 0.4794\n",
      "Epoch 3314/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4120 - VL_attention_linear_output_loss: 1.7091 - VH_attention_linear_output_loss: 1.7028 - VL_attention_linear_output_acc: 0.4898 - VH_attention_linear_output_acc: 0.4969 - val_loss: 3.5229 - val_VL_attention_linear_output_loss: 1.7650 - val_VH_attention_linear_output_loss: 1.7579 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4809\n",
      "Epoch 3315/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4102 - VL_attention_linear_output_loss: 1.7080 - VH_attention_linear_output_loss: 1.7022 - VL_attention_linear_output_acc: 0.4902 - VH_attention_linear_output_acc: 0.4971 - val_loss: 3.5350 - val_VL_attention_linear_output_loss: 1.7784 - val_VH_attention_linear_output_loss: 1.7566 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4851\n",
      "Epoch 3316/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3935 - VL_attention_linear_output_loss: 1.6949 - VH_attention_linear_output_loss: 1.6987 - VL_attention_linear_output_acc: 0.4961 - VH_attention_linear_output_acc: 0.4993 - val_loss: 3.5144 - val_VL_attention_linear_output_loss: 1.7600 - val_VH_attention_linear_output_loss: 1.7545 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4887\n",
      "Epoch 3317/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4139 - VL_attention_linear_output_loss: 1.7045 - VH_attention_linear_output_loss: 1.7094 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.4955 - val_loss: 3.5150 - val_VL_attention_linear_output_loss: 1.7615 - val_VH_attention_linear_output_loss: 1.7535 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4853\n",
      "Epoch 3318/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3997 - VL_attention_linear_output_loss: 1.6989 - VH_attention_linear_output_loss: 1.7008 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4983 - val_loss: 3.5179 - val_VL_attention_linear_output_loss: 1.7608 - val_VH_attention_linear_output_loss: 1.7571 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4854\n",
      "Epoch 3319/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4007 - VL_attention_linear_output_loss: 1.6997 - VH_attention_linear_output_loss: 1.7010 - VL_attention_linear_output_acc: 0.4948 - VH_attention_linear_output_acc: 0.4987 - val_loss: 3.5405 - val_VL_attention_linear_output_loss: 1.7654 - val_VH_attention_linear_output_loss: 1.7751 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4810\n",
      "Epoch 3320/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4184 - VL_attention_linear_output_loss: 1.7065 - VH_attention_linear_output_loss: 1.7119 - VL_attention_linear_output_acc: 0.4897 - VH_attention_linear_output_acc: 0.4942 - val_loss: 3.5850 - val_VL_attention_linear_output_loss: 1.7777 - val_VH_attention_linear_output_loss: 1.8073 - val_VL_attention_linear_output_acc: 0.4788 - val_VH_attention_linear_output_acc: 0.4683\n",
      "Epoch 3321/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4036 - VL_attention_linear_output_loss: 1.7042 - VH_attention_linear_output_loss: 1.6993 - VL_attention_linear_output_acc: 0.4911 - VH_attention_linear_output_acc: 0.4991 - val_loss: 3.5130 - val_VL_attention_linear_output_loss: 1.7588 - val_VH_attention_linear_output_loss: 1.7542 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4877\n",
      "Epoch 3322/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4107 - VL_attention_linear_output_loss: 1.7033 - VH_attention_linear_output_loss: 1.7075 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4964 - val_loss: 3.5729 - val_VL_attention_linear_output_loss: 1.7709 - val_VH_attention_linear_output_loss: 1.8019 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4630\n",
      "Epoch 3323/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4138 - VL_attention_linear_output_loss: 1.7094 - VH_attention_linear_output_loss: 1.7044 - VL_attention_linear_output_acc: 0.4886 - VH_attention_linear_output_acc: 0.4968 - val_loss: 3.5297 - val_VL_attention_linear_output_loss: 1.7580 - val_VH_attention_linear_output_loss: 1.7717 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.4800\n",
      "Epoch 3324/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3999 - VL_attention_linear_output_loss: 1.6955 - VH_attention_linear_output_loss: 1.7044 - VL_attention_linear_output_acc: 0.4950 - VH_attention_linear_output_acc: 0.4975 - val_loss: 3.5139 - val_VL_attention_linear_output_loss: 1.7605 - val_VH_attention_linear_output_loss: 1.7534 - val_VL_attention_linear_output_acc: 0.4883 - val_VH_attention_linear_output_acc: 0.4859\n",
      "Epoch 3325/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3997 - VL_attention_linear_output_loss: 1.6983 - VH_attention_linear_output_loss: 1.7015 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4991 - val_loss: 3.5385 - val_VL_attention_linear_output_loss: 1.7720 - val_VH_attention_linear_output_loss: 1.7664 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.4786\n",
      "Epoch 3326/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4017 - VL_attention_linear_output_loss: 1.6995 - VH_attention_linear_output_loss: 1.7022 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4979 - val_loss: 3.6051 - val_VL_attention_linear_output_loss: 1.7704 - val_VH_attention_linear_output_loss: 1.8347 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4593\n",
      "Epoch 3327/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4050 - VL_attention_linear_output_loss: 1.7037 - VH_attention_linear_output_loss: 1.7012 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4983 - val_loss: 3.5118 - val_VL_attention_linear_output_loss: 1.7633 - val_VH_attention_linear_output_loss: 1.7485 - val_VL_attention_linear_output_acc: 0.4854 - val_VH_attention_linear_output_acc: 0.4911\n",
      "Epoch 3328/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4046 - VL_attention_linear_output_loss: 1.7029 - VH_attention_linear_output_loss: 1.7017 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.4983 - val_loss: 3.5423 - val_VL_attention_linear_output_loss: 1.7865 - val_VH_attention_linear_output_loss: 1.7558 - val_VL_attention_linear_output_acc: 0.4743 - val_VH_attention_linear_output_acc: 0.4863\n",
      "Epoch 3329/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3993 - VL_attention_linear_output_loss: 1.7021 - VH_attention_linear_output_loss: 1.6972 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.5000 - val_loss: 3.5169 - val_VL_attention_linear_output_loss: 1.7608 - val_VH_attention_linear_output_loss: 1.7561 - val_VL_attention_linear_output_acc: 0.4890 - val_VH_attention_linear_output_acc: 0.4872\n",
      "Epoch 3330/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4036 - VL_attention_linear_output_loss: 1.7031 - VH_attention_linear_output_loss: 1.7005 - VL_attention_linear_output_acc: 0.4925 - VH_attention_linear_output_acc: 0.4988 - val_loss: 3.5273 - val_VL_attention_linear_output_loss: 1.7664 - val_VH_attention_linear_output_loss: 1.7609 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4832\n",
      "Epoch 3331/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4112 - VL_attention_linear_output_loss: 1.7032 - VH_attention_linear_output_loss: 1.7080 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.4956 - val_loss: 3.5591 - val_VL_attention_linear_output_loss: 1.8008 - val_VH_attention_linear_output_loss: 1.7583 - val_VL_attention_linear_output_acc: 0.4617 - val_VH_attention_linear_output_acc: 0.4853\n",
      "Epoch 3332/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3933 - VL_attention_linear_output_loss: 1.6948 - VH_attention_linear_output_loss: 1.6985 - VL_attention_linear_output_acc: 0.4963 - VH_attention_linear_output_acc: 0.4995 - val_loss: 3.5101 - val_VL_attention_linear_output_loss: 1.7669 - val_VH_attention_linear_output_loss: 1.7432 - val_VL_attention_linear_output_acc: 0.4792 - val_VH_attention_linear_output_acc: 0.4911\n",
      "Epoch 3333/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4051 - VL_attention_linear_output_loss: 1.7012 - VH_attention_linear_output_loss: 1.7040 - VL_attention_linear_output_acc: 0.4936 - VH_attention_linear_output_acc: 0.4976 - val_loss: 3.5108 - val_VL_attention_linear_output_loss: 1.7612 - val_VH_attention_linear_output_loss: 1.7497 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.4930\n",
      "Epoch 3334/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4123 - VL_attention_linear_output_loss: 1.7083 - VH_attention_linear_output_loss: 1.7040 - VL_attention_linear_output_acc: 0.4893 - VH_attention_linear_output_acc: 0.4980 - val_loss: 3.5246 - val_VL_attention_linear_output_loss: 1.7719 - val_VH_attention_linear_output_loss: 1.7527 - val_VL_attention_linear_output_acc: 0.4773 - val_VH_attention_linear_output_acc: 0.4882\n",
      "Epoch 3335/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4033 - VL_attention_linear_output_loss: 1.6941 - VH_attention_linear_output_loss: 1.7091 - VL_attention_linear_output_acc: 0.4968 - VH_attention_linear_output_acc: 0.4952 - val_loss: 3.5563 - val_VL_attention_linear_output_loss: 1.7665 - val_VH_attention_linear_output_loss: 1.7899 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4689\n",
      "Epoch 3336/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4061 - VL_attention_linear_output_loss: 1.7002 - VH_attention_linear_output_loss: 1.7059 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4967 - val_loss: 3.5435 - val_VL_attention_linear_output_loss: 1.7957 - val_VH_attention_linear_output_loss: 1.7478 - val_VL_attention_linear_output_acc: 0.4665 - val_VH_attention_linear_output_acc: 0.4889\n",
      "Epoch 3337/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3989 - VL_attention_linear_output_loss: 1.7043 - VH_attention_linear_output_loss: 1.6946 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.5010 - val_loss: 3.5185 - val_VL_attention_linear_output_loss: 1.7652 - val_VH_attention_linear_output_loss: 1.7533 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4902\n",
      "Epoch 3338/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4080 - VL_attention_linear_output_loss: 1.7011 - VH_attention_linear_output_loss: 1.7069 - VL_attention_linear_output_acc: 0.4931 - VH_attention_linear_output_acc: 0.4962 - val_loss: 3.5623 - val_VL_attention_linear_output_loss: 1.8017 - val_VH_attention_linear_output_loss: 1.7606 - val_VL_attention_linear_output_acc: 0.4676 - val_VH_attention_linear_output_acc: 0.4882\n",
      "Epoch 3339/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4117 - VL_attention_linear_output_loss: 1.7078 - VH_attention_linear_output_loss: 1.7039 - VL_attention_linear_output_acc: 0.4899 - VH_attention_linear_output_acc: 0.4974 - val_loss: 3.5072 - val_VL_attention_linear_output_loss: 1.7617 - val_VH_attention_linear_output_loss: 1.7455 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4895\n",
      "Epoch 3340/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3988 - VL_attention_linear_output_loss: 1.7041 - VH_attention_linear_output_loss: 1.6947 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.5007 - val_loss: 3.5573 - val_VL_attention_linear_output_loss: 1.7602 - val_VH_attention_linear_output_loss: 1.7971 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4693\n",
      "Epoch 3341/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4053 - VL_attention_linear_output_loss: 1.7010 - VH_attention_linear_output_loss: 1.7043 - VL_attention_linear_output_acc: 0.4932 - VH_attention_linear_output_acc: 0.4973 - val_loss: 3.5243 - val_VL_attention_linear_output_loss: 1.7590 - val_VH_attention_linear_output_loss: 1.7653 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.4819\n",
      "Epoch 3342/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3995 - VL_attention_linear_output_loss: 1.6999 - VH_attention_linear_output_loss: 1.6996 - VL_attention_linear_output_acc: 0.4940 - VH_attention_linear_output_acc: 0.4991 - val_loss: 3.5216 - val_VL_attention_linear_output_loss: 1.7680 - val_VH_attention_linear_output_loss: 1.7536 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4878\n",
      "Epoch 3343/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4030 - VL_attention_linear_output_loss: 1.7083 - VH_attention_linear_output_loss: 1.6946 - VL_attention_linear_output_acc: 0.4884 - VH_attention_linear_output_acc: 0.5009 - val_loss: 3.5516 - val_VL_attention_linear_output_loss: 1.7844 - val_VH_attention_linear_output_loss: 1.7672 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4827\n",
      "Epoch 3344/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4056 - VL_attention_linear_output_loss: 1.7037 - VH_attention_linear_output_loss: 1.7019 - VL_attention_linear_output_acc: 0.4909 - VH_attention_linear_output_acc: 0.4981 - val_loss: 3.5076 - val_VL_attention_linear_output_loss: 1.7584 - val_VH_attention_linear_output_loss: 1.7493 - val_VL_attention_linear_output_acc: 0.4872 - val_VH_attention_linear_output_acc: 0.4892\n",
      "Epoch 3345/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3982 - VL_attention_linear_output_loss: 1.6915 - VH_attention_linear_output_loss: 1.7068 - VL_attention_linear_output_acc: 0.4974 - VH_attention_linear_output_acc: 0.4967 - val_loss: 3.5440 - val_VL_attention_linear_output_loss: 1.7579 - val_VH_attention_linear_output_loss: 1.7860 - val_VL_attention_linear_output_acc: 0.4894 - val_VH_attention_linear_output_acc: 0.4706\n",
      "Epoch 3346/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3963 - VL_attention_linear_output_loss: 1.6943 - VH_attention_linear_output_loss: 1.7020 - VL_attention_linear_output_acc: 0.4958 - VH_attention_linear_output_acc: 0.4977 - val_loss: 3.5152 - val_VL_attention_linear_output_loss: 1.7644 - val_VH_attention_linear_output_loss: 1.7509 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.4883\n",
      "Epoch 3347/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3993 - VL_attention_linear_output_loss: 1.7034 - VH_attention_linear_output_loss: 1.6959 - VL_attention_linear_output_acc: 0.4903 - VH_attention_linear_output_acc: 0.5005 - val_loss: 3.5249 - val_VL_attention_linear_output_loss: 1.7675 - val_VH_attention_linear_output_loss: 1.7575 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.4874\n",
      "Epoch 3348/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4075 - VL_attention_linear_output_loss: 1.7055 - VH_attention_linear_output_loss: 1.7020 - VL_attention_linear_output_acc: 0.4913 - VH_attention_linear_output_acc: 0.4978 - val_loss: 3.5150 - val_VL_attention_linear_output_loss: 1.7580 - val_VH_attention_linear_output_loss: 1.7570 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4894\n",
      "Epoch 3349/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3941 - VL_attention_linear_output_loss: 1.6943 - VH_attention_linear_output_loss: 1.6998 - VL_attention_linear_output_acc: 0.4960 - VH_attention_linear_output_acc: 0.4993 - val_loss: 3.5211 - val_VL_attention_linear_output_loss: 1.7636 - val_VH_attention_linear_output_loss: 1.7575 - val_VL_attention_linear_output_acc: 0.4831 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3350/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4106 - VL_attention_linear_output_loss: 1.7124 - VH_attention_linear_output_loss: 1.6982 - VL_attention_linear_output_acc: 0.4870 - VH_attention_linear_output_acc: 0.4994 - val_loss: 3.5250 - val_VL_attention_linear_output_loss: 1.7664 - val_VH_attention_linear_output_loss: 1.7586 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4845\n",
      "Epoch 3351/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3879 - VL_attention_linear_output_loss: 1.6915 - VH_attention_linear_output_loss: 1.6964 - VL_attention_linear_output_acc: 0.4975 - VH_attention_linear_output_acc: 0.5008 - val_loss: 3.5155 - val_VL_attention_linear_output_loss: 1.7590 - val_VH_attention_linear_output_loss: 1.7565 - val_VL_attention_linear_output_acc: 0.4889 - val_VH_attention_linear_output_acc: 0.4870\n",
      "Epoch 3352/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4133 - VL_attention_linear_output_loss: 1.7055 - VH_attention_linear_output_loss: 1.7077 - VL_attention_linear_output_acc: 0.4892 - VH_attention_linear_output_acc: 0.4964 - val_loss: 3.5122 - val_VL_attention_linear_output_loss: 1.7577 - val_VH_attention_linear_output_loss: 1.7545 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.4896\n",
      "Epoch 3353/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3936 - VL_attention_linear_output_loss: 1.6923 - VH_attention_linear_output_loss: 1.7013 - VL_attention_linear_output_acc: 0.4964 - VH_attention_linear_output_acc: 0.4987 - val_loss: 3.5084 - val_VL_attention_linear_output_loss: 1.7553 - val_VH_attention_linear_output_loss: 1.7531 - val_VL_attention_linear_output_acc: 0.4899 - val_VH_attention_linear_output_acc: 0.4846\n",
      "Epoch 3354/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4036 - VL_attention_linear_output_loss: 1.6960 - VH_attention_linear_output_loss: 1.7076 - VL_attention_linear_output_acc: 0.4952 - VH_attention_linear_output_acc: 0.4963 - val_loss: 3.5239 - val_VL_attention_linear_output_loss: 1.7588 - val_VH_attention_linear_output_loss: 1.7651 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4839\n",
      "Epoch 3355/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3979 - VL_attention_linear_output_loss: 1.6955 - VH_attention_linear_output_loss: 1.7023 - VL_attention_linear_output_acc: 0.4954 - VH_attention_linear_output_acc: 0.4982 - val_loss: 3.5195 - val_VL_attention_linear_output_loss: 1.7630 - val_VH_attention_linear_output_loss: 1.7566 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4880\n",
      "Epoch 3356/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4040 - VL_attention_linear_output_loss: 1.6984 - VH_attention_linear_output_loss: 1.7056 - VL_attention_linear_output_acc: 0.4932 - VH_attention_linear_output_acc: 0.4973 - val_loss: 3.5152 - val_VL_attention_linear_output_loss: 1.7645 - val_VH_attention_linear_output_loss: 1.7506 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4912\n",
      "Epoch 3357/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4071 - VL_attention_linear_output_loss: 1.7002 - VH_attention_linear_output_loss: 1.7069 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4968 - val_loss: 3.5249 - val_VL_attention_linear_output_loss: 1.7727 - val_VH_attention_linear_output_loss: 1.7522 - val_VL_attention_linear_output_acc: 0.4819 - val_VH_attention_linear_output_acc: 0.4873\n",
      "Epoch 3358/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3970 - VL_attention_linear_output_loss: 1.6987 - VH_attention_linear_output_loss: 1.6983 - VL_attention_linear_output_acc: 0.4948 - VH_attention_linear_output_acc: 0.5006 - val_loss: 3.5404 - val_VL_attention_linear_output_loss: 1.7888 - val_VH_attention_linear_output_loss: 1.7515 - val_VL_attention_linear_output_acc: 0.4710 - val_VH_attention_linear_output_acc: 0.4906\n",
      "Epoch 3359/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3976 - VL_attention_linear_output_loss: 1.6992 - VH_attention_linear_output_loss: 1.6984 - VL_attention_linear_output_acc: 0.4942 - VH_attention_linear_output_acc: 0.4995 - val_loss: 3.5058 - val_VL_attention_linear_output_loss: 1.7566 - val_VH_attention_linear_output_loss: 1.7492 - val_VL_attention_linear_output_acc: 0.4906 - val_VH_attention_linear_output_acc: 0.4905\n",
      "Epoch 3360/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3969 - VL_attention_linear_output_loss: 1.7010 - VH_attention_linear_output_loss: 1.6959 - VL_attention_linear_output_acc: 0.4927 - VH_attention_linear_output_acc: 0.5013 - val_loss: 3.5062 - val_VL_attention_linear_output_loss: 1.7581 - val_VH_attention_linear_output_loss: 1.7481 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4898\n",
      "Epoch 3361/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4010 - VL_attention_linear_output_loss: 1.7001 - VH_attention_linear_output_loss: 1.7009 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.4995 - val_loss: 3.5120 - val_VL_attention_linear_output_loss: 1.7594 - val_VH_attention_linear_output_loss: 1.7527 - val_VL_attention_linear_output_acc: 0.4893 - val_VH_attention_linear_output_acc: 0.4877\n",
      "Epoch 3362/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3850 - VL_attention_linear_output_loss: 1.6925 - VH_attention_linear_output_loss: 1.6925 - VL_attention_linear_output_acc: 0.4981 - VH_attention_linear_output_acc: 0.5016 - val_loss: 3.5076 - val_VL_attention_linear_output_loss: 1.7611 - val_VH_attention_linear_output_loss: 1.7465 - val_VL_attention_linear_output_acc: 0.4854 - val_VH_attention_linear_output_acc: 0.4902\n",
      "Epoch 3363/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4042 - VL_attention_linear_output_loss: 1.7015 - VH_attention_linear_output_loss: 1.7027 - VL_attention_linear_output_acc: 0.4916 - VH_attention_linear_output_acc: 0.4980 - val_loss: 3.5492 - val_VL_attention_linear_output_loss: 1.7869 - val_VH_attention_linear_output_loss: 1.7624 - val_VL_attention_linear_output_acc: 0.4719 - val_VH_attention_linear_output_acc: 0.4831\n",
      "Epoch 3364/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3994 - VL_attention_linear_output_loss: 1.7036 - VH_attention_linear_output_loss: 1.6958 - VL_attention_linear_output_acc: 0.4917 - VH_attention_linear_output_acc: 0.5012 - val_loss: 3.5378 - val_VL_attention_linear_output_loss: 1.7643 - val_VH_attention_linear_output_loss: 1.7736 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4805\n",
      "Epoch 3365/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4016 - VL_attention_linear_output_loss: 1.6987 - VH_attention_linear_output_loss: 1.7029 - VL_attention_linear_output_acc: 0.4930 - VH_attention_linear_output_acc: 0.4978 - val_loss: 3.5764 - val_VL_attention_linear_output_loss: 1.8100 - val_VH_attention_linear_output_loss: 1.7663 - val_VL_attention_linear_output_acc: 0.4544 - val_VH_attention_linear_output_acc: 0.4808\n",
      "Epoch 3366/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3997 - VL_attention_linear_output_loss: 1.7006 - VH_attention_linear_output_loss: 1.6991 - VL_attention_linear_output_acc: 0.4924 - VH_attention_linear_output_acc: 0.4993 - val_loss: 3.5182 - val_VL_attention_linear_output_loss: 1.7585 - val_VH_attention_linear_output_loss: 1.7597 - val_VL_attention_linear_output_acc: 0.4896 - val_VH_attention_linear_output_acc: 0.4814\n",
      "Epoch 3367/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3921 - VL_attention_linear_output_loss: 1.6919 - VH_attention_linear_output_loss: 1.7001 - VL_attention_linear_output_acc: 0.4968 - VH_attention_linear_output_acc: 0.4987 - val_loss: 3.5304 - val_VL_attention_linear_output_loss: 1.7678 - val_VH_attention_linear_output_loss: 1.7627 - val_VL_attention_linear_output_acc: 0.4854 - val_VH_attention_linear_output_acc: 0.4836\n",
      "Epoch 3368/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3910 - VL_attention_linear_output_loss: 1.6948 - VH_attention_linear_output_loss: 1.6962 - VL_attention_linear_output_acc: 0.4966 - VH_attention_linear_output_acc: 0.5009 - val_loss: 3.5535 - val_VL_attention_linear_output_loss: 1.7975 - val_VH_attention_linear_output_loss: 1.7559 - val_VL_attention_linear_output_acc: 0.4678 - val_VH_attention_linear_output_acc: 0.4840\n",
      "Epoch 3369/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4074 - VL_attention_linear_output_loss: 1.7010 - VH_attention_linear_output_loss: 1.7063 - VL_attention_linear_output_acc: 0.4926 - VH_attention_linear_output_acc: 0.4973 - val_loss: 3.5280 - val_VL_attention_linear_output_loss: 1.7744 - val_VH_attention_linear_output_loss: 1.7536 - val_VL_attention_linear_output_acc: 0.4794 - val_VH_attention_linear_output_acc: 0.4905\n",
      "Epoch 3370/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4149 - VL_attention_linear_output_loss: 1.7100 - VH_attention_linear_output_loss: 1.7049 - VL_attention_linear_output_acc: 0.4907 - VH_attention_linear_output_acc: 0.4974 - val_loss: 3.5562 - val_VL_attention_linear_output_loss: 1.7856 - val_VH_attention_linear_output_loss: 1.7705 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.4795\n",
      "Epoch 3371/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3931 - VL_attention_linear_output_loss: 1.6967 - VH_attention_linear_output_loss: 1.6964 - VL_attention_linear_output_acc: 0.4955 - VH_attention_linear_output_acc: 0.5005 - val_loss: 3.5127 - val_VL_attention_linear_output_loss: 1.7586 - val_VH_attention_linear_output_loss: 1.7541 - val_VL_attention_linear_output_acc: 0.4884 - val_VH_attention_linear_output_acc: 0.4870\n",
      "Epoch 3372/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3884 - VL_attention_linear_output_loss: 1.6943 - VH_attention_linear_output_loss: 1.6941 - VL_attention_linear_output_acc: 0.4970 - VH_attention_linear_output_acc: 0.5014 - val_loss: 3.5266 - val_VL_attention_linear_output_loss: 1.7612 - val_VH_attention_linear_output_loss: 1.7654 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4806\n",
      "Epoch 3373/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4094 - VL_attention_linear_output_loss: 1.6966 - VH_attention_linear_output_loss: 1.7128 - VL_attention_linear_output_acc: 0.4954 - VH_attention_linear_output_acc: 0.4944 - val_loss: 3.6133 - val_VL_attention_linear_output_loss: 1.7942 - val_VH_attention_linear_output_loss: 1.8191 - val_VL_attention_linear_output_acc: 0.4734 - val_VH_attention_linear_output_acc: 0.4560\n",
      "Epoch 3374/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4086 - VL_attention_linear_output_loss: 1.7058 - VH_attention_linear_output_loss: 1.7028 - VL_attention_linear_output_acc: 0.4934 - VH_attention_linear_output_acc: 0.4980 - val_loss: 3.5753 - val_VL_attention_linear_output_loss: 1.7946 - val_VH_attention_linear_output_loss: 1.7807 - val_VL_attention_linear_output_acc: 0.4735 - val_VH_attention_linear_output_acc: 0.4718\n",
      "Epoch 3375/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3944 - VL_attention_linear_output_loss: 1.7020 - VH_attention_linear_output_loss: 1.6924 - VL_attention_linear_output_acc: 0.4933 - VH_attention_linear_output_acc: 0.5019 - val_loss: 3.5332 - val_VL_attention_linear_output_loss: 1.7651 - val_VH_attention_linear_output_loss: 1.7681 - val_VL_attention_linear_output_acc: 0.4902 - val_VH_attention_linear_output_acc: 0.4814\n",
      "Epoch 3376/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4052 - VL_attention_linear_output_loss: 1.6966 - VH_attention_linear_output_loss: 1.7086 - VL_attention_linear_output_acc: 0.4975 - VH_attention_linear_output_acc: 0.4965 - val_loss: 3.5572 - val_VL_attention_linear_output_loss: 1.7557 - val_VH_attention_linear_output_loss: 1.8014 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4710\n",
      "Epoch 3377/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3846 - VL_attention_linear_output_loss: 1.6906 - VH_attention_linear_output_loss: 1.6940 - VL_attention_linear_output_acc: 0.4988 - VH_attention_linear_output_acc: 0.5018 - val_loss: 3.5846 - val_VL_attention_linear_output_loss: 1.7631 - val_VH_attention_linear_output_loss: 1.8215 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4537\n",
      "Epoch 3378/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3998 - VL_attention_linear_output_loss: 1.6969 - VH_attention_linear_output_loss: 1.7029 - VL_attention_linear_output_acc: 0.4965 - VH_attention_linear_output_acc: 0.4986 - val_loss: 3.5110 - val_VL_attention_linear_output_loss: 1.7584 - val_VH_attention_linear_output_loss: 1.7526 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4866\n",
      "Epoch 3379/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3995 - VL_attention_linear_output_loss: 1.6949 - VH_attention_linear_output_loss: 1.7045 - VL_attention_linear_output_acc: 0.4986 - VH_attention_linear_output_acc: 0.4967 - val_loss: 3.5069 - val_VL_attention_linear_output_loss: 1.7573 - val_VH_attention_linear_output_loss: 1.7496 - val_VL_attention_linear_output_acc: 0.4884 - val_VH_attention_linear_output_acc: 0.4899\n",
      "Epoch 3380/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3905 - VL_attention_linear_output_loss: 1.6929 - VH_attention_linear_output_loss: 1.6976 - VL_attention_linear_output_acc: 0.4977 - VH_attention_linear_output_acc: 0.5002 - val_loss: 3.4964 - val_VL_attention_linear_output_loss: 1.7531 - val_VH_attention_linear_output_loss: 1.7433 - val_VL_attention_linear_output_acc: 0.4937 - val_VH_attention_linear_output_acc: 0.4924\n",
      "Epoch 3381/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3845 - VL_attention_linear_output_loss: 1.6931 - VH_attention_linear_output_loss: 1.6914 - VL_attention_linear_output_acc: 0.5002 - VH_attention_linear_output_acc: 0.5028 - val_loss: 3.5529 - val_VL_attention_linear_output_loss: 1.7598 - val_VH_attention_linear_output_loss: 1.7932 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.4713\n",
      "Epoch 3382/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4170 - VL_attention_linear_output_loss: 1.7081 - VH_attention_linear_output_loss: 1.7089 - VL_attention_linear_output_acc: 0.4921 - VH_attention_linear_output_acc: 0.4958 - val_loss: 3.5153 - val_VL_attention_linear_output_loss: 1.7573 - val_VH_attention_linear_output_loss: 1.7580 - val_VL_attention_linear_output_acc: 0.4912 - val_VH_attention_linear_output_acc: 0.4844\n",
      "Epoch 3383/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3850 - VL_attention_linear_output_loss: 1.6904 - VH_attention_linear_output_loss: 1.6946 - VL_attention_linear_output_acc: 0.5020 - VH_attention_linear_output_acc: 0.5017 - val_loss: 3.5978 - val_VL_attention_linear_output_loss: 1.8094 - val_VH_attention_linear_output_loss: 1.7884 - val_VL_attention_linear_output_acc: 0.4605 - val_VH_attention_linear_output_acc: 0.4695\n",
      "Epoch 3384/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4039 - VL_attention_linear_output_loss: 1.6928 - VH_attention_linear_output_loss: 1.7112 - VL_attention_linear_output_acc: 0.5009 - VH_attention_linear_output_acc: 0.4948 - val_loss: 3.5028 - val_VL_attention_linear_output_loss: 1.7561 - val_VH_attention_linear_output_loss: 1.7467 - val_VL_attention_linear_output_acc: 0.4936 - val_VH_attention_linear_output_acc: 0.4932\n",
      "Epoch 3385/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3837 - VL_attention_linear_output_loss: 1.6910 - VH_attention_linear_output_loss: 1.6926 - VL_attention_linear_output_acc: 0.5006 - VH_attention_linear_output_acc: 0.5022 - val_loss: 3.5235 - val_VL_attention_linear_output_loss: 1.7604 - val_VH_attention_linear_output_loss: 1.7631 - val_VL_attention_linear_output_acc: 0.4882 - val_VH_attention_linear_output_acc: 0.4846\n",
      "Epoch 3386/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3822 - VL_attention_linear_output_loss: 1.6891 - VH_attention_linear_output_loss: 1.6930 - VL_attention_linear_output_acc: 0.5022 - VH_attention_linear_output_acc: 0.5024 - val_loss: 3.5278 - val_VL_attention_linear_output_loss: 1.7829 - val_VH_attention_linear_output_loss: 1.7449 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.4906\n",
      "Epoch 3387/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3934 - VL_attention_linear_output_loss: 1.6951 - VH_attention_linear_output_loss: 1.6982 - VL_attention_linear_output_acc: 0.4989 - VH_attention_linear_output_acc: 0.4999 - val_loss: 3.5561 - val_VL_attention_linear_output_loss: 1.7682 - val_VH_attention_linear_output_loss: 1.7878 - val_VL_attention_linear_output_acc: 0.4892 - val_VH_attention_linear_output_acc: 0.4708\n",
      "Epoch 3388/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4117 - VL_attention_linear_output_loss: 1.7057 - VH_attention_linear_output_loss: 1.7060 - VL_attention_linear_output_acc: 0.4947 - VH_attention_linear_output_acc: 0.4971 - val_loss: 3.5146 - val_VL_attention_linear_output_loss: 1.7682 - val_VH_attention_linear_output_loss: 1.7464 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.4915\n",
      "Epoch 3389/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4077 - VL_attention_linear_output_loss: 1.7078 - VH_attention_linear_output_loss: 1.6999 - VL_attention_linear_output_acc: 0.4939 - VH_attention_linear_output_acc: 0.4993 - val_loss: 3.5239 - val_VL_attention_linear_output_loss: 1.7808 - val_VH_attention_linear_output_loss: 1.7431 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4920\n",
      "Epoch 3390/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4009 - VL_attention_linear_output_loss: 1.6956 - VH_attention_linear_output_loss: 1.7053 - VL_attention_linear_output_acc: 0.4988 - VH_attention_linear_output_acc: 0.4974 - val_loss: 3.5019 - val_VL_attention_linear_output_loss: 1.7563 - val_VH_attention_linear_output_loss: 1.7456 - val_VL_attention_linear_output_acc: 0.4936 - val_VH_attention_linear_output_acc: 0.4897\n",
      "Epoch 3391/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3900 - VL_attention_linear_output_loss: 1.6945 - VH_attention_linear_output_loss: 1.6956 - VL_attention_linear_output_acc: 0.4996 - VH_attention_linear_output_acc: 0.5011 - val_loss: 3.5300 - val_VL_attention_linear_output_loss: 1.7697 - val_VH_attention_linear_output_loss: 1.7603 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.4857\n",
      "Epoch 3392/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3952 - VL_attention_linear_output_loss: 1.6916 - VH_attention_linear_output_loss: 1.7036 - VL_attention_linear_output_acc: 0.5011 - VH_attention_linear_output_acc: 0.4975 - val_loss: 3.5530 - val_VL_attention_linear_output_loss: 1.7843 - val_VH_attention_linear_output_loss: 1.7687 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.4807\n",
      "Epoch 3393/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3970 - VL_attention_linear_output_loss: 1.6997 - VH_attention_linear_output_loss: 1.6973 - VL_attention_linear_output_acc: 0.4969 - VH_attention_linear_output_acc: 0.5001 - val_loss: 3.5100 - val_VL_attention_linear_output_loss: 1.7621 - val_VH_attention_linear_output_loss: 1.7478 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.4884\n",
      "Epoch 3394/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4075 - VL_attention_linear_output_loss: 1.7052 - VH_attention_linear_output_loss: 1.7023 - VL_attention_linear_output_acc: 0.4944 - VH_attention_linear_output_acc: 0.4984 - val_loss: 3.5318 - val_VL_attention_linear_output_loss: 1.7646 - val_VH_attention_linear_output_loss: 1.7671 - val_VL_attention_linear_output_acc: 0.4839 - val_VH_attention_linear_output_acc: 0.4855\n",
      "Epoch 3395/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3989 - VL_attention_linear_output_loss: 1.6977 - VH_attention_linear_output_loss: 1.7012 - VL_attention_linear_output_acc: 0.4988 - VH_attention_linear_output_acc: 0.4988 - val_loss: 3.5992 - val_VL_attention_linear_output_loss: 1.7660 - val_VH_attention_linear_output_loss: 1.8332 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4520\n",
      "Epoch 3396/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4290 - VL_attention_linear_output_loss: 1.7143 - VH_attention_linear_output_loss: 1.7147 - VL_attention_linear_output_acc: 0.4914 - VH_attention_linear_output_acc: 0.4939 - val_loss: 3.5224 - val_VL_attention_linear_output_loss: 1.7670 - val_VH_attention_linear_output_loss: 1.7554 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4866\n",
      "Epoch 3397/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3875 - VL_attention_linear_output_loss: 1.6930 - VH_attention_linear_output_loss: 1.6945 - VL_attention_linear_output_acc: 0.5018 - VH_attention_linear_output_acc: 0.5016 - val_loss: 3.5453 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7825 - val_VL_attention_linear_output_acc: 0.4940 - val_VH_attention_linear_output_acc: 0.4761\n",
      "Epoch 3398/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3928 - VL_attention_linear_output_loss: 1.6979 - VH_attention_linear_output_loss: 1.6949 - VL_attention_linear_output_acc: 0.4994 - VH_attention_linear_output_acc: 0.5002 - val_loss: 3.5014 - val_VL_attention_linear_output_loss: 1.7566 - val_VH_attention_linear_output_loss: 1.7449 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.4914\n",
      "Epoch 3399/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3939 - VL_attention_linear_output_loss: 1.6963 - VH_attention_linear_output_loss: 1.6975 - VL_attention_linear_output_acc: 0.4997 - VH_attention_linear_output_acc: 0.5002 - val_loss: 3.5123 - val_VL_attention_linear_output_loss: 1.7592 - val_VH_attention_linear_output_loss: 1.7531 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.4883\n",
      "Epoch 3400/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4032 - VL_attention_linear_output_loss: 1.7028 - VH_attention_linear_output_loss: 1.7004 - VL_attention_linear_output_acc: 0.4965 - VH_attention_linear_output_acc: 0.4995 - val_loss: 3.5299 - val_VL_attention_linear_output_loss: 1.7647 - val_VH_attention_linear_output_loss: 1.7652 - val_VL_attention_linear_output_acc: 0.4889 - val_VH_attention_linear_output_acc: 0.4844\n",
      "Epoch 3401/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3863 - VL_attention_linear_output_loss: 1.6938 - VH_attention_linear_output_loss: 1.6925 - VL_attention_linear_output_acc: 0.5004 - VH_attention_linear_output_acc: 0.5020 - val_loss: 3.5075 - val_VL_attention_linear_output_loss: 1.7611 - val_VH_attention_linear_output_loss: 1.7464 - val_VL_attention_linear_output_acc: 0.4921 - val_VH_attention_linear_output_acc: 0.4909\n",
      "Epoch 3402/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3871 - VL_attention_linear_output_loss: 1.6896 - VH_attention_linear_output_loss: 1.6975 - VL_attention_linear_output_acc: 0.5029 - VH_attention_linear_output_acc: 0.4997 - val_loss: 3.5192 - val_VL_attention_linear_output_loss: 1.7590 - val_VH_attention_linear_output_loss: 1.7602 - val_VL_attention_linear_output_acc: 0.4942 - val_VH_attention_linear_output_acc: 0.4874\n",
      "Epoch 3403/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3920 - VL_attention_linear_output_loss: 1.6961 - VH_attention_linear_output_loss: 1.6959 - VL_attention_linear_output_acc: 0.5015 - VH_attention_linear_output_acc: 0.5007 - val_loss: 3.5265 - val_VL_attention_linear_output_loss: 1.7629 - val_VH_attention_linear_output_loss: 1.7636 - val_VL_attention_linear_output_acc: 0.4912 - val_VH_attention_linear_output_acc: 0.4839\n",
      "Epoch 3404/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4085 - VL_attention_linear_output_loss: 1.7020 - VH_attention_linear_output_loss: 1.7065 - VL_attention_linear_output_acc: 0.4960 - VH_attention_linear_output_acc: 0.4973 - val_loss: 3.4945 - val_VL_attention_linear_output_loss: 1.7517 - val_VH_attention_linear_output_loss: 1.7428 - val_VL_attention_linear_output_acc: 0.4936 - val_VH_attention_linear_output_acc: 0.4938\n",
      "Epoch 3405/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3854 - VL_attention_linear_output_loss: 1.6917 - VH_attention_linear_output_loss: 1.6937 - VL_attention_linear_output_acc: 0.5029 - VH_attention_linear_output_acc: 0.5017 - val_loss: 3.5100 - val_VL_attention_linear_output_loss: 1.7591 - val_VH_attention_linear_output_loss: 1.7509 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4888\n",
      "Epoch 3406/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3970 - VL_attention_linear_output_loss: 1.7030 - VH_attention_linear_output_loss: 1.6940 - VL_attention_linear_output_acc: 0.4948 - VH_attention_linear_output_acc: 0.5018 - val_loss: 3.5233 - val_VL_attention_linear_output_loss: 1.7729 - val_VH_attention_linear_output_loss: 1.7504 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4890\n",
      "Epoch 3407/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3941 - VL_attention_linear_output_loss: 1.6947 - VH_attention_linear_output_loss: 1.6994 - VL_attention_linear_output_acc: 0.5010 - VH_attention_linear_output_acc: 0.4996 - val_loss: 3.5073 - val_VL_attention_linear_output_loss: 1.7521 - val_VH_attention_linear_output_loss: 1.7552 - val_VL_attention_linear_output_acc: 0.4981 - val_VH_attention_linear_output_acc: 0.4877\n",
      "Epoch 3408/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3849 - VL_attention_linear_output_loss: 1.6880 - VH_attention_linear_output_loss: 1.6969 - VL_attention_linear_output_acc: 0.5040 - VH_attention_linear_output_acc: 0.5005 - val_loss: 3.5115 - val_VL_attention_linear_output_loss: 1.7662 - val_VH_attention_linear_output_loss: 1.7453 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4886\n",
      "Epoch 3409/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3924 - VL_attention_linear_output_loss: 1.6960 - VH_attention_linear_output_loss: 1.6964 - VL_attention_linear_output_acc: 0.4992 - VH_attention_linear_output_acc: 0.5010 - val_loss: 3.5002 - val_VL_attention_linear_output_loss: 1.7563 - val_VH_attention_linear_output_loss: 1.7439 - val_VL_attention_linear_output_acc: 0.4949 - val_VH_attention_linear_output_acc: 0.4922\n",
      "Epoch 3410/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3873 - VL_attention_linear_output_loss: 1.6901 - VH_attention_linear_output_loss: 1.6972 - VL_attention_linear_output_acc: 0.5029 - VH_attention_linear_output_acc: 0.5001 - val_loss: 3.5014 - val_VL_attention_linear_output_loss: 1.7538 - val_VH_attention_linear_output_loss: 1.7476 - val_VL_attention_linear_output_acc: 0.4939 - val_VH_attention_linear_output_acc: 0.4929\n",
      "Epoch 3411/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3877 - VL_attention_linear_output_loss: 1.6921 - VH_attention_linear_output_loss: 1.6955 - VL_attention_linear_output_acc: 0.5014 - VH_attention_linear_output_acc: 0.5003 - val_loss: 3.5073 - val_VL_attention_linear_output_loss: 1.7619 - val_VH_attention_linear_output_loss: 1.7454 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4918\n",
      "Epoch 3412/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4064 - VL_attention_linear_output_loss: 1.7041 - VH_attention_linear_output_loss: 1.7024 - VL_attention_linear_output_acc: 0.4959 - VH_attention_linear_output_acc: 0.4984 - val_loss: 3.5497 - val_VL_attention_linear_output_loss: 1.7738 - val_VH_attention_linear_output_loss: 1.7759 - val_VL_attention_linear_output_acc: 0.4893 - val_VH_attention_linear_output_acc: 0.4794\n",
      "Epoch 3413/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4120 - VL_attention_linear_output_loss: 1.7011 - VH_attention_linear_output_loss: 1.7108 - VL_attention_linear_output_acc: 0.4975 - VH_attention_linear_output_acc: 0.4950 - val_loss: 3.5112 - val_VL_attention_linear_output_loss: 1.7667 - val_VH_attention_linear_output_loss: 1.7445 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4883\n",
      "Epoch 3414/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3886 - VL_attention_linear_output_loss: 1.6983 - VH_attention_linear_output_loss: 1.6903 - VL_attention_linear_output_acc: 0.4994 - VH_attention_linear_output_acc: 0.5027 - val_loss: 3.5313 - val_VL_attention_linear_output_loss: 1.7871 - val_VH_attention_linear_output_loss: 1.7442 - val_VL_attention_linear_output_acc: 0.4813 - val_VH_attention_linear_output_acc: 0.4912\n",
      "Epoch 3415/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3790 - VL_attention_linear_output_loss: 1.6923 - VH_attention_linear_output_loss: 1.6867 - VL_attention_linear_output_acc: 0.5019 - VH_attention_linear_output_acc: 0.5042 - val_loss: 3.5093 - val_VL_attention_linear_output_loss: 1.7590 - val_VH_attention_linear_output_loss: 1.7503 - val_VL_attention_linear_output_acc: 0.4929 - val_VH_attention_linear_output_acc: 0.4894\n",
      "Epoch 3416/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3976 - VL_attention_linear_output_loss: 1.7051 - VH_attention_linear_output_loss: 1.6925 - VL_attention_linear_output_acc: 0.4975 - VH_attention_linear_output_acc: 0.5015 - val_loss: 3.5151 - val_VL_attention_linear_output_loss: 1.7712 - val_VH_attention_linear_output_loss: 1.7439 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.4926\n",
      "Epoch 3417/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3836 - VL_attention_linear_output_loss: 1.6941 - VH_attention_linear_output_loss: 1.6895 - VL_attention_linear_output_acc: 0.5023 - VH_attention_linear_output_acc: 0.5027 - val_loss: 3.5098 - val_VL_attention_linear_output_loss: 1.7611 - val_VH_attention_linear_output_loss: 1.7488 - val_VL_attention_linear_output_acc: 0.4929 - val_VH_attention_linear_output_acc: 0.4904\n",
      "Epoch 3418/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3925 - VL_attention_linear_output_loss: 1.7010 - VH_attention_linear_output_loss: 1.6915 - VL_attention_linear_output_acc: 0.4979 - VH_attention_linear_output_acc: 0.5020 - val_loss: 3.6023 - val_VL_attention_linear_output_loss: 1.8536 - val_VH_attention_linear_output_loss: 1.7486 - val_VL_attention_linear_output_acc: 0.4439 - val_VH_attention_linear_output_acc: 0.4878\n",
      "Epoch 3419/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3864 - VL_attention_linear_output_loss: 1.6947 - VH_attention_linear_output_loss: 1.6917 - VL_attention_linear_output_acc: 0.5007 - VH_attention_linear_output_acc: 0.5020 - val_loss: 3.5275 - val_VL_attention_linear_output_loss: 1.7624 - val_VH_attention_linear_output_loss: 1.7651 - val_VL_attention_linear_output_acc: 0.4890 - val_VH_attention_linear_output_acc: 0.4853\n",
      "Epoch 3420/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4043 - VL_attention_linear_output_loss: 1.6998 - VH_attention_linear_output_loss: 1.7045 - VL_attention_linear_output_acc: 0.4992 - VH_attention_linear_output_acc: 0.4969 - val_loss: 3.5162 - val_VL_attention_linear_output_loss: 1.7521 - val_VH_attention_linear_output_loss: 1.7642 - val_VL_attention_linear_output_acc: 0.4953 - val_VH_attention_linear_output_acc: 0.4837\n",
      "Epoch 3421/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3873 - VL_attention_linear_output_loss: 1.6917 - VH_attention_linear_output_loss: 1.6956 - VL_attention_linear_output_acc: 0.5015 - VH_attention_linear_output_acc: 0.5011 - val_loss: 3.5120 - val_VL_attention_linear_output_loss: 1.7592 - val_VH_attention_linear_output_loss: 1.7528 - val_VL_attention_linear_output_acc: 0.4908 - val_VH_attention_linear_output_acc: 0.4856\n",
      "Epoch 3422/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3962 - VL_attention_linear_output_loss: 1.6990 - VH_attention_linear_output_loss: 1.6972 - VL_attention_linear_output_acc: 0.4991 - VH_attention_linear_output_acc: 0.4999 - val_loss: 3.5084 - val_VL_attention_linear_output_loss: 1.7547 - val_VH_attention_linear_output_loss: 1.7538 - val_VL_attention_linear_output_acc: 0.4947 - val_VH_attention_linear_output_acc: 0.4856\n",
      "Epoch 3423/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3955 - VL_attention_linear_output_loss: 1.6974 - VH_attention_linear_output_loss: 1.6982 - VL_attention_linear_output_acc: 0.4995 - VH_attention_linear_output_acc: 0.4993 - val_loss: 3.5369 - val_VL_attention_linear_output_loss: 1.7739 - val_VH_attention_linear_output_loss: 1.7630 - val_VL_attention_linear_output_acc: 0.4804 - val_VH_attention_linear_output_acc: 0.4831\n",
      "Epoch 3424/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4034 - VL_attention_linear_output_loss: 1.6969 - VH_attention_linear_output_loss: 1.7065 - VL_attention_linear_output_acc: 0.4989 - VH_attention_linear_output_acc: 0.4966 - val_loss: 3.5039 - val_VL_attention_linear_output_loss: 1.7527 - val_VH_attention_linear_output_loss: 1.7512 - val_VL_attention_linear_output_acc: 0.4975 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3425/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3788 - VL_attention_linear_output_loss: 1.6869 - VH_attention_linear_output_loss: 1.6919 - VL_attention_linear_output_acc: 0.5049 - VH_attention_linear_output_acc: 0.5021 - val_loss: 3.5032 - val_VL_attention_linear_output_loss: 1.7541 - val_VH_attention_linear_output_loss: 1.7492 - val_VL_attention_linear_output_acc: 0.4934 - val_VH_attention_linear_output_acc: 0.4881\n",
      "Epoch 3426/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3928 - VL_attention_linear_output_loss: 1.6962 - VH_attention_linear_output_loss: 1.6966 - VL_attention_linear_output_acc: 0.4995 - VH_attention_linear_output_acc: 0.5003 - val_loss: 3.5054 - val_VL_attention_linear_output_loss: 1.7619 - val_VH_attention_linear_output_loss: 1.7435 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.4909\n",
      "Epoch 3427/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3948 - VL_attention_linear_output_loss: 1.7055 - VH_attention_linear_output_loss: 1.6894 - VL_attention_linear_output_acc: 0.4935 - VH_attention_linear_output_acc: 0.5031 - val_loss: 3.5397 - val_VL_attention_linear_output_loss: 1.7758 - val_VH_attention_linear_output_loss: 1.7640 - val_VL_attention_linear_output_acc: 0.4904 - val_VH_attention_linear_output_acc: 0.4810\n",
      "Epoch 3428/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3874 - VL_attention_linear_output_loss: 1.6899 - VH_attention_linear_output_loss: 1.6974 - VL_attention_linear_output_acc: 0.5039 - VH_attention_linear_output_acc: 0.4999 - val_loss: 3.5693 - val_VL_attention_linear_output_loss: 1.7544 - val_VH_attention_linear_output_loss: 1.8149 - val_VL_attention_linear_output_acc: 0.4971 - val_VH_attention_linear_output_acc: 0.4669\n",
      "Epoch 3429/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3856 - VL_attention_linear_output_loss: 1.6918 - VH_attention_linear_output_loss: 1.6938 - VL_attention_linear_output_acc: 0.5031 - VH_attention_linear_output_acc: 0.5015 - val_loss: 3.5008 - val_VL_attention_linear_output_loss: 1.7579 - val_VH_attention_linear_output_loss: 1.7429 - val_VL_attention_linear_output_acc: 0.4945 - val_VH_attention_linear_output_acc: 0.4928\n",
      "Epoch 3430/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3772 - VL_attention_linear_output_loss: 1.6900 - VH_attention_linear_output_loss: 1.6871 - VL_attention_linear_output_acc: 0.5029 - VH_attention_linear_output_acc: 0.5036 - val_loss: 3.5347 - val_VL_attention_linear_output_loss: 1.7695 - val_VH_attention_linear_output_loss: 1.7652 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4837\n",
      "Epoch 3431/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3869 - VL_attention_linear_output_loss: 1.6987 - VH_attention_linear_output_loss: 1.6883 - VL_attention_linear_output_acc: 0.4997 - VH_attention_linear_output_acc: 0.5032 - val_loss: 3.5188 - val_VL_attention_linear_output_loss: 1.7658 - val_VH_attention_linear_output_loss: 1.7530 - val_VL_attention_linear_output_acc: 0.4870 - val_VH_attention_linear_output_acc: 0.4906\n",
      "Epoch 3432/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4092 - VL_attention_linear_output_loss: 1.7031 - VH_attention_linear_output_loss: 1.7061 - VL_attention_linear_output_acc: 0.4957 - VH_attention_linear_output_acc: 0.4970 - val_loss: 3.5112 - val_VL_attention_linear_output_loss: 1.7616 - val_VH_attention_linear_output_loss: 1.7496 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.4871\n",
      "Epoch 3433/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3844 - VL_attention_linear_output_loss: 1.6965 - VH_attention_linear_output_loss: 1.6879 - VL_attention_linear_output_acc: 0.4994 - VH_attention_linear_output_acc: 0.5039 - val_loss: 3.5059 - val_VL_attention_linear_output_loss: 1.7616 - val_VH_attention_linear_output_loss: 1.7442 - val_VL_attention_linear_output_acc: 0.4921 - val_VH_attention_linear_output_acc: 0.4912\n",
      "Epoch 3434/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3980 - VL_attention_linear_output_loss: 1.6986 - VH_attention_linear_output_loss: 1.6994 - VL_attention_linear_output_acc: 0.4985 - VH_attention_linear_output_acc: 0.4994 - val_loss: 3.5277 - val_VL_attention_linear_output_loss: 1.7725 - val_VH_attention_linear_output_loss: 1.7553 - val_VL_attention_linear_output_acc: 0.4913 - val_VH_attention_linear_output_acc: 0.4879\n",
      "Epoch 3435/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4024 - VL_attention_linear_output_loss: 1.7022 - VH_attention_linear_output_loss: 1.7002 - VL_attention_linear_output_acc: 0.4969 - VH_attention_linear_output_acc: 0.4988 - val_loss: 3.5126 - val_VL_attention_linear_output_loss: 1.7568 - val_VH_attention_linear_output_loss: 1.7558 - val_VL_attention_linear_output_acc: 0.4907 - val_VH_attention_linear_output_acc: 0.4873\n",
      "Epoch 3436/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3872 - VL_attention_linear_output_loss: 1.6943 - VH_attention_linear_output_loss: 1.6929 - VL_attention_linear_output_acc: 0.5006 - VH_attention_linear_output_acc: 0.5010 - val_loss: 3.5144 - val_VL_attention_linear_output_loss: 1.7675 - val_VH_attention_linear_output_loss: 1.7469 - val_VL_attention_linear_output_acc: 0.4889 - val_VH_attention_linear_output_acc: 0.4915\n",
      "Epoch 3437/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3894 - VL_attention_linear_output_loss: 1.6973 - VH_attention_linear_output_loss: 1.6920 - VL_attention_linear_output_acc: 0.5001 - VH_attention_linear_output_acc: 0.5024 - val_loss: 3.5085 - val_VL_attention_linear_output_loss: 1.7537 - val_VH_attention_linear_output_loss: 1.7547 - val_VL_attention_linear_output_acc: 0.4953 - val_VH_attention_linear_output_acc: 0.4879\n",
      "Epoch 3438/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3898 - VL_attention_linear_output_loss: 1.6953 - VH_attention_linear_output_loss: 1.6944 - VL_attention_linear_output_acc: 0.4992 - VH_attention_linear_output_acc: 0.5011 - val_loss: 3.5198 - val_VL_attention_linear_output_loss: 1.7746 - val_VH_attention_linear_output_loss: 1.7452 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4902\n",
      "Epoch 3439/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3889 - VL_attention_linear_output_loss: 1.6925 - VH_attention_linear_output_loss: 1.6964 - VL_attention_linear_output_acc: 0.5019 - VH_attention_linear_output_acc: 0.5004 - val_loss: 3.5045 - val_VL_attention_linear_output_loss: 1.7575 - val_VH_attention_linear_output_loss: 1.7470 - val_VL_attention_linear_output_acc: 0.4940 - val_VH_attention_linear_output_acc: 0.4892\n",
      "Epoch 3440/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3878 - VL_attention_linear_output_loss: 1.6936 - VH_attention_linear_output_loss: 1.6942 - VL_attention_linear_output_acc: 0.5017 - VH_attention_linear_output_acc: 0.5013 - val_loss: 3.5176 - val_VL_attention_linear_output_loss: 1.7671 - val_VH_attention_linear_output_loss: 1.7505 - val_VL_attention_linear_output_acc: 0.4872 - val_VH_attention_linear_output_acc: 0.4903\n",
      "Epoch 3441/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4005 - VL_attention_linear_output_loss: 1.7001 - VH_attention_linear_output_loss: 1.7005 - VL_attention_linear_output_acc: 0.4990 - VH_attention_linear_output_acc: 0.4984 - val_loss: 3.5225 - val_VL_attention_linear_output_loss: 1.7767 - val_VH_attention_linear_output_loss: 1.7458 - val_VL_attention_linear_output_acc: 0.4869 - val_VH_attention_linear_output_acc: 0.4917\n",
      "Epoch 3442/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4000 - VL_attention_linear_output_loss: 1.7052 - VH_attention_linear_output_loss: 1.6947 - VL_attention_linear_output_acc: 0.4963 - VH_attention_linear_output_acc: 0.5003 - val_loss: 3.5092 - val_VL_attention_linear_output_loss: 1.7583 - val_VH_attention_linear_output_loss: 1.7510 - val_VL_attention_linear_output_acc: 0.4927 - val_VH_attention_linear_output_acc: 0.4882\n",
      "Epoch 3443/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3925 - VL_attention_linear_output_loss: 1.6917 - VH_attention_linear_output_loss: 1.7008 - VL_attention_linear_output_acc: 0.5025 - VH_attention_linear_output_acc: 0.4982 - val_loss: 3.5328 - val_VL_attention_linear_output_loss: 1.7549 - val_VH_attention_linear_output_loss: 1.7780 - val_VL_attention_linear_output_acc: 0.4942 - val_VH_attention_linear_output_acc: 0.4745\n",
      "Epoch 3444/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3975 - VL_attention_linear_output_loss: 1.7017 - VH_attention_linear_output_loss: 1.6957 - VL_attention_linear_output_acc: 0.4969 - VH_attention_linear_output_acc: 0.5016 - val_loss: 3.5593 - val_VL_attention_linear_output_loss: 1.7975 - val_VH_attention_linear_output_loss: 1.7618 - val_VL_attention_linear_output_acc: 0.4743 - val_VH_attention_linear_output_acc: 0.4836\n",
      "Epoch 3445/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3932 - VL_attention_linear_output_loss: 1.6918 - VH_attention_linear_output_loss: 1.7014 - VL_attention_linear_output_acc: 0.5024 - VH_attention_linear_output_acc: 0.4988 - val_loss: 3.5004 - val_VL_attention_linear_output_loss: 1.7531 - val_VH_attention_linear_output_loss: 1.7472 - val_VL_attention_linear_output_acc: 0.4913 - val_VH_attention_linear_output_acc: 0.4899\n",
      "Epoch 3446/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3859 - VL_attention_linear_output_loss: 1.6929 - VH_attention_linear_output_loss: 1.6929 - VL_attention_linear_output_acc: 0.5020 - VH_attention_linear_output_acc: 0.5014 - val_loss: 3.4991 - val_VL_attention_linear_output_loss: 1.7573 - val_VH_attention_linear_output_loss: 1.7418 - val_VL_attention_linear_output_acc: 0.4921 - val_VH_attention_linear_output_acc: 0.4925\n",
      "Epoch 3447/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3927 - VL_attention_linear_output_loss: 1.6978 - VH_attention_linear_output_loss: 1.6949 - VL_attention_linear_output_acc: 0.4985 - VH_attention_linear_output_acc: 0.5006 - val_loss: 3.5291 - val_VL_attention_linear_output_loss: 1.7796 - val_VH_attention_linear_output_loss: 1.7494 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4900\n",
      "Epoch 3448/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3921 - VL_attention_linear_output_loss: 1.6956 - VH_attention_linear_output_loss: 1.6965 - VL_attention_linear_output_acc: 0.5011 - VH_attention_linear_output_acc: 0.4994 - val_loss: 3.4999 - val_VL_attention_linear_output_loss: 1.7544 - val_VH_attention_linear_output_loss: 1.7455 - val_VL_attention_linear_output_acc: 0.4928 - val_VH_attention_linear_output_acc: 0.4907\n",
      "Epoch 3449/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3869 - VL_attention_linear_output_loss: 1.6934 - VH_attention_linear_output_loss: 1.6935 - VL_attention_linear_output_acc: 0.5010 - VH_attention_linear_output_acc: 0.5009 - val_loss: 3.5073 - val_VL_attention_linear_output_loss: 1.7638 - val_VH_attention_linear_output_loss: 1.7435 - val_VL_attention_linear_output_acc: 0.4901 - val_VH_attention_linear_output_acc: 0.4919\n",
      "Epoch 3450/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3864 - VL_attention_linear_output_loss: 1.6978 - VH_attention_linear_output_loss: 1.6885 - VL_attention_linear_output_acc: 0.5000 - VH_attention_linear_output_acc: 0.5034 - val_loss: 3.5382 - val_VL_attention_linear_output_loss: 1.7943 - val_VH_attention_linear_output_loss: 1.7439 - val_VL_attention_linear_output_acc: 0.4763 - val_VH_attention_linear_output_acc: 0.4901\n",
      "Epoch 3451/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4081 - VL_attention_linear_output_loss: 1.7074 - VH_attention_linear_output_loss: 1.7007 - VL_attention_linear_output_acc: 0.4950 - VH_attention_linear_output_acc: 0.4986 - val_loss: 3.5072 - val_VL_attention_linear_output_loss: 1.7586 - val_VH_attention_linear_output_loss: 1.7486 - val_VL_attention_linear_output_acc: 0.4925 - val_VH_attention_linear_output_acc: 0.4903\n",
      "Epoch 3452/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3994 - VL_attention_linear_output_loss: 1.6992 - VH_attention_linear_output_loss: 1.7002 - VL_attention_linear_output_acc: 0.4980 - VH_attention_linear_output_acc: 0.4986 - val_loss: 3.5339 - val_VL_attention_linear_output_loss: 1.7703 - val_VH_attention_linear_output_loss: 1.7636 - val_VL_attention_linear_output_acc: 0.4890 - val_VH_attention_linear_output_acc: 0.4808\n",
      "Epoch 3453/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3847 - VL_attention_linear_output_loss: 1.6917 - VH_attention_linear_output_loss: 1.6930 - VL_attention_linear_output_acc: 0.5033 - VH_attention_linear_output_acc: 0.5014 - val_loss: 3.5527 - val_VL_attention_linear_output_loss: 1.7690 - val_VH_attention_linear_output_loss: 1.7837 - val_VL_attention_linear_output_acc: 0.4895 - val_VH_attention_linear_output_acc: 0.4742\n",
      "Epoch 3454/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4011 - VL_attention_linear_output_loss: 1.7017 - VH_attention_linear_output_loss: 1.6994 - VL_attention_linear_output_acc: 0.4971 - VH_attention_linear_output_acc: 0.4988 - val_loss: 3.5298 - val_VL_attention_linear_output_loss: 1.7621 - val_VH_attention_linear_output_loss: 1.7677 - val_VL_attention_linear_output_acc: 0.4889 - val_VH_attention_linear_output_acc: 0.4818\n",
      "Epoch 3455/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3998 - VL_attention_linear_output_loss: 1.6985 - VH_attention_linear_output_loss: 1.7013 - VL_attention_linear_output_acc: 0.4989 - VH_attention_linear_output_acc: 0.4989 - val_loss: 3.5039 - val_VL_attention_linear_output_loss: 1.7540 - val_VH_attention_linear_output_loss: 1.7499 - val_VL_attention_linear_output_acc: 0.4964 - val_VH_attention_linear_output_acc: 0.4903\n",
      "Epoch 3456/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4009 - VL_attention_linear_output_loss: 1.7004 - VH_attention_linear_output_loss: 1.7004 - VL_attention_linear_output_acc: 0.4976 - VH_attention_linear_output_acc: 0.4988 - val_loss: 3.5577 - val_VL_attention_linear_output_loss: 1.7563 - val_VH_attention_linear_output_loss: 1.8014 - val_VL_attention_linear_output_acc: 0.4946 - val_VH_attention_linear_output_acc: 0.4694\n",
      "Epoch 3457/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3874 - VL_attention_linear_output_loss: 1.6930 - VH_attention_linear_output_loss: 1.6944 - VL_attention_linear_output_acc: 0.5027 - VH_attention_linear_output_acc: 0.5005 - val_loss: 3.5035 - val_VL_attention_linear_output_loss: 1.7603 - val_VH_attention_linear_output_loss: 1.7432 - val_VL_attention_linear_output_acc: 0.4875 - val_VH_attention_linear_output_acc: 0.4925\n",
      "Epoch 3458/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3815 - VL_attention_linear_output_loss: 1.6882 - VH_attention_linear_output_loss: 1.6934 - VL_attention_linear_output_acc: 0.5020 - VH_attention_linear_output_acc: 0.5012 - val_loss: 3.5308 - val_VL_attention_linear_output_loss: 1.7637 - val_VH_attention_linear_output_loss: 1.7671 - val_VL_attention_linear_output_acc: 0.4894 - val_VH_attention_linear_output_acc: 0.4835\n",
      "Epoch 3459/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3983 - VL_attention_linear_output_loss: 1.6963 - VH_attention_linear_output_loss: 1.7020 - VL_attention_linear_output_acc: 0.5004 - VH_attention_linear_output_acc: 0.4979 - val_loss: 3.5100 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7472 - val_VL_attention_linear_output_acc: 0.4894 - val_VH_attention_linear_output_acc: 0.4908\n",
      "Epoch 3460/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3918 - VL_attention_linear_output_loss: 1.6967 - VH_attention_linear_output_loss: 1.6951 - VL_attention_linear_output_acc: 0.5007 - VH_attention_linear_output_acc: 0.5001 - val_loss: 3.5367 - val_VL_attention_linear_output_loss: 1.7568 - val_VH_attention_linear_output_loss: 1.7799 - val_VL_attention_linear_output_acc: 0.4963 - val_VH_attention_linear_output_acc: 0.4776\n",
      "Epoch 3461/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3918 - VL_attention_linear_output_loss: 1.6957 - VH_attention_linear_output_loss: 1.6962 - VL_attention_linear_output_acc: 0.4997 - VH_attention_linear_output_acc: 0.5002 - val_loss: 3.5196 - val_VL_attention_linear_output_loss: 1.7646 - val_VH_attention_linear_output_loss: 1.7550 - val_VL_attention_linear_output_acc: 0.4931 - val_VH_attention_linear_output_acc: 0.4859\n",
      "Epoch 3462/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4043 - VL_attention_linear_output_loss: 1.7014 - VH_attention_linear_output_loss: 1.7028 - VL_attention_linear_output_acc: 0.4978 - VH_attention_linear_output_acc: 0.4977 - val_loss: 3.5112 - val_VL_attention_linear_output_loss: 1.7577 - val_VH_attention_linear_output_loss: 1.7535 - val_VL_attention_linear_output_acc: 0.4933 - val_VH_attention_linear_output_acc: 0.4848\n",
      "Epoch 3463/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3967 - VL_attention_linear_output_loss: 1.6955 - VH_attention_linear_output_loss: 1.7012 - VL_attention_linear_output_acc: 0.5005 - VH_attention_linear_output_acc: 0.4977 - val_loss: 3.5260 - val_VL_attention_linear_output_loss: 1.7656 - val_VH_attention_linear_output_loss: 1.7603 - val_VL_attention_linear_output_acc: 0.4904 - val_VH_attention_linear_output_acc: 0.4852\n",
      "Epoch 3464/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3997 - VL_attention_linear_output_loss: 1.6950 - VH_attention_linear_output_loss: 1.7047 - VL_attention_linear_output_acc: 0.5000 - VH_attention_linear_output_acc: 0.4968 - val_loss: 3.5093 - val_VL_attention_linear_output_loss: 1.7566 - val_VH_attention_linear_output_loss: 1.7527 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.4899\n",
      "Epoch 3465/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3922 - VL_attention_linear_output_loss: 1.7014 - VH_attention_linear_output_loss: 1.6908 - VL_attention_linear_output_acc: 0.4972 - VH_attention_linear_output_acc: 0.5026 - val_loss: 3.5035 - val_VL_attention_linear_output_loss: 1.7644 - val_VH_attention_linear_output_loss: 1.7391 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4943\n",
      "Epoch 3466/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3950 - VL_attention_linear_output_loss: 1.6962 - VH_attention_linear_output_loss: 1.6988 - VL_attention_linear_output_acc: 0.4998 - VH_attention_linear_output_acc: 0.4992 - val_loss: 3.5146 - val_VL_attention_linear_output_loss: 1.7669 - val_VH_attention_linear_output_loss: 1.7477 - val_VL_attention_linear_output_acc: 0.4890 - val_VH_attention_linear_output_acc: 0.4893\n",
      "Epoch 3467/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3847 - VL_attention_linear_output_loss: 1.6931 - VH_attention_linear_output_loss: 1.6915 - VL_attention_linear_output_acc: 0.5012 - VH_attention_linear_output_acc: 0.5014 - val_loss: 3.5183 - val_VL_attention_linear_output_loss: 1.7674 - val_VH_attention_linear_output_loss: 1.7508 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.4899\n",
      "Epoch 3468/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3861 - VL_attention_linear_output_loss: 1.6962 - VH_attention_linear_output_loss: 1.6899 - VL_attention_linear_output_acc: 0.5004 - VH_attention_linear_output_acc: 0.5023 - val_loss: 3.4951 - val_VL_attention_linear_output_loss: 1.7528 - val_VH_attention_linear_output_loss: 1.7423 - val_VL_attention_linear_output_acc: 0.4911 - val_VH_attention_linear_output_acc: 0.4901\n",
      "Epoch 3469/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3742 - VL_attention_linear_output_loss: 1.6887 - VH_attention_linear_output_loss: 1.6855 - VL_attention_linear_output_acc: 0.5029 - VH_attention_linear_output_acc: 0.5042 - val_loss: 3.5105 - val_VL_attention_linear_output_loss: 1.7599 - val_VH_attention_linear_output_loss: 1.7506 - val_VL_attention_linear_output_acc: 0.4963 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3470/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3809 - VL_attention_linear_output_loss: 1.6874 - VH_attention_linear_output_loss: 1.6935 - VL_attention_linear_output_acc: 0.5050 - VH_attention_linear_output_acc: 0.5006 - val_loss: 3.5262 - val_VL_attention_linear_output_loss: 1.7627 - val_VH_attention_linear_output_loss: 1.7635 - val_VL_attention_linear_output_acc: 0.4943 - val_VH_attention_linear_output_acc: 0.4867\n",
      "Epoch 3471/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3925 - VL_attention_linear_output_loss: 1.6972 - VH_attention_linear_output_loss: 1.6953 - VL_attention_linear_output_acc: 0.5003 - VH_attention_linear_output_acc: 0.5002 - val_loss: 3.4952 - val_VL_attention_linear_output_loss: 1.7534 - val_VH_attention_linear_output_loss: 1.7417 - val_VL_attention_linear_output_acc: 0.4946 - val_VH_attention_linear_output_acc: 0.4910\n",
      "Epoch 3472/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3760 - VL_attention_linear_output_loss: 1.6899 - VH_attention_linear_output_loss: 1.6860 - VL_attention_linear_output_acc: 0.5030 - VH_attention_linear_output_acc: 0.5039 - val_loss: 3.5025 - val_VL_attention_linear_output_loss: 1.7621 - val_VH_attention_linear_output_loss: 1.7403 - val_VL_attention_linear_output_acc: 0.4914 - val_VH_attention_linear_output_acc: 0.4931\n",
      "Epoch 3473/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3913 - VL_attention_linear_output_loss: 1.6991 - VH_attention_linear_output_loss: 1.6922 - VL_attention_linear_output_acc: 0.4993 - VH_attention_linear_output_acc: 0.5017 - val_loss: 3.5223 - val_VL_attention_linear_output_loss: 1.7594 - val_VH_attention_linear_output_loss: 1.7629 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.4848\n",
      "Epoch 3474/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4078 - VL_attention_linear_output_loss: 1.7028 - VH_attention_linear_output_loss: 1.7050 - VL_attention_linear_output_acc: 0.4960 - VH_attention_linear_output_acc: 0.4974 - val_loss: 3.5380 - val_VL_attention_linear_output_loss: 1.7808 - val_VH_attention_linear_output_loss: 1.7572 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3475/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3837 - VL_attention_linear_output_loss: 1.6960 - VH_attention_linear_output_loss: 1.6877 - VL_attention_linear_output_acc: 0.4999 - VH_attention_linear_output_acc: 0.5027 - val_loss: 3.5149 - val_VL_attention_linear_output_loss: 1.7682 - val_VH_attention_linear_output_loss: 1.7467 - val_VL_attention_linear_output_acc: 0.4935 - val_VH_attention_linear_output_acc: 0.4897\n",
      "Epoch 3476/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4018 - VL_attention_linear_output_loss: 1.7040 - VH_attention_linear_output_loss: 1.6978 - VL_attention_linear_output_acc: 0.4974 - VH_attention_linear_output_acc: 0.4997 - val_loss: 3.5725 - val_VL_attention_linear_output_loss: 1.8137 - val_VH_attention_linear_output_loss: 1.7588 - val_VL_attention_linear_output_acc: 0.4672 - val_VH_attention_linear_output_acc: 0.4886\n",
      "Epoch 3477/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3999 - VL_attention_linear_output_loss: 1.7065 - VH_attention_linear_output_loss: 1.6934 - VL_attention_linear_output_acc: 0.4974 - VH_attention_linear_output_acc: 0.5014 - val_loss: 3.5085 - val_VL_attention_linear_output_loss: 1.7596 - val_VH_attention_linear_output_loss: 1.7489 - val_VL_attention_linear_output_acc: 0.4888 - val_VH_attention_linear_output_acc: 0.4916\n",
      "Epoch 3478/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3804 - VL_attention_linear_output_loss: 1.6949 - VH_attention_linear_output_loss: 1.6855 - VL_attention_linear_output_acc: 0.5011 - VH_attention_linear_output_acc: 0.5040 - val_loss: 3.5032 - val_VL_attention_linear_output_loss: 1.7540 - val_VH_attention_linear_output_loss: 1.7492 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.4876\n",
      "Epoch 3479/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.4006 - VL_attention_linear_output_loss: 1.6956 - VH_attention_linear_output_loss: 1.7050 - VL_attention_linear_output_acc: 0.4997 - VH_attention_linear_output_acc: 0.4958 - val_loss: 3.5112 - val_VL_attention_linear_output_loss: 1.7657 - val_VH_attention_linear_output_loss: 1.7454 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.4901\n",
      "Epoch 3480/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3837 - VL_attention_linear_output_loss: 1.6942 - VH_attention_linear_output_loss: 1.6895 - VL_attention_linear_output_acc: 0.5002 - VH_attention_linear_output_acc: 0.5023 - val_loss: 3.4947 - val_VL_attention_linear_output_loss: 1.7535 - val_VH_attention_linear_output_loss: 1.7413 - val_VL_attention_linear_output_acc: 0.4957 - val_VH_attention_linear_output_acc: 0.4932\n",
      "Epoch 3481/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3838 - VL_attention_linear_output_loss: 1.6931 - VH_attention_linear_output_loss: 1.6907 - VL_attention_linear_output_acc: 0.5013 - VH_attention_linear_output_acc: 0.5024 - val_loss: 3.5025 - val_VL_attention_linear_output_loss: 1.7542 - val_VH_attention_linear_output_loss: 1.7484 - val_VL_attention_linear_output_acc: 0.4896 - val_VH_attention_linear_output_acc: 0.4880\n",
      "Epoch 3482/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3813 - VL_attention_linear_output_loss: 1.6941 - VH_attention_linear_output_loss: 1.6872 - VL_attention_linear_output_acc: 0.5004 - VH_attention_linear_output_acc: 0.5032 - val_loss: 3.5138 - val_VL_attention_linear_output_loss: 1.7540 - val_VH_attention_linear_output_loss: 1.7598 - val_VL_attention_linear_output_acc: 0.4991 - val_VH_attention_linear_output_acc: 0.4874\n",
      "Epoch 3483/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3887 - VL_attention_linear_output_loss: 1.6922 - VH_attention_linear_output_loss: 1.6965 - VL_attention_linear_output_acc: 0.5017 - VH_attention_linear_output_acc: 0.5002 - val_loss: 3.5218 - val_VL_attention_linear_output_loss: 1.7753 - val_VH_attention_linear_output_loss: 1.7465 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4907\n",
      "Epoch 3484/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3826 - VL_attention_linear_output_loss: 1.6968 - VH_attention_linear_output_loss: 1.6857 - VL_attention_linear_output_acc: 0.5001 - VH_attention_linear_output_acc: 0.5036 - val_loss: 3.5150 - val_VL_attention_linear_output_loss: 1.7613 - val_VH_attention_linear_output_loss: 1.7537 - val_VL_attention_linear_output_acc: 0.4893 - val_VH_attention_linear_output_acc: 0.4855\n",
      "Epoch 3485/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3818 - VL_attention_linear_output_loss: 1.6904 - VH_attention_linear_output_loss: 1.6914 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5018 - val_loss: 3.5020 - val_VL_attention_linear_output_loss: 1.7590 - val_VH_attention_linear_output_loss: 1.7430 - val_VL_attention_linear_output_acc: 0.4917 - val_VH_attention_linear_output_acc: 0.4920\n",
      "Epoch 3486/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3905 - VL_attention_linear_output_loss: 1.6917 - VH_attention_linear_output_loss: 1.6988 - VL_attention_linear_output_acc: 0.5011 - VH_attention_linear_output_acc: 0.4982 - val_loss: 3.5788 - val_VL_attention_linear_output_loss: 1.8127 - val_VH_attention_linear_output_loss: 1.7661 - val_VL_attention_linear_output_acc: 0.4599 - val_VH_attention_linear_output_acc: 0.4818\n",
      "Epoch 3487/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3957 - VL_attention_linear_output_loss: 1.7000 - VH_attention_linear_output_loss: 1.6957 - VL_attention_linear_output_acc: 0.4984 - VH_attention_linear_output_acc: 0.5003 - val_loss: 3.5148 - val_VL_attention_linear_output_loss: 1.7728 - val_VH_attention_linear_output_loss: 1.7420 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4937\n",
      "Epoch 3488/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3981 - VL_attention_linear_output_loss: 1.6961 - VH_attention_linear_output_loss: 1.7020 - VL_attention_linear_output_acc: 0.4998 - VH_attention_linear_output_acc: 0.4977 - val_loss: 3.5099 - val_VL_attention_linear_output_loss: 1.7571 - val_VH_attention_linear_output_loss: 1.7528 - val_VL_attention_linear_output_acc: 0.4917 - val_VH_attention_linear_output_acc: 0.4881\n",
      "Epoch 3489/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3758 - VL_attention_linear_output_loss: 1.6860 - VH_attention_linear_output_loss: 1.6898 - VL_attention_linear_output_acc: 0.5052 - VH_attention_linear_output_acc: 0.5026 - val_loss: 3.5264 - val_VL_attention_linear_output_loss: 1.7636 - val_VH_attention_linear_output_loss: 1.7629 - val_VL_attention_linear_output_acc: 0.4905 - val_VH_attention_linear_output_acc: 0.4823\n",
      "Epoch 3490/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3885 - VL_attention_linear_output_loss: 1.6952 - VH_attention_linear_output_loss: 1.6933 - VL_attention_linear_output_acc: 0.5001 - VH_attention_linear_output_acc: 0.5008 - val_loss: 3.5435 - val_VL_attention_linear_output_loss: 1.7738 - val_VH_attention_linear_output_loss: 1.7697 - val_VL_attention_linear_output_acc: 0.4897 - val_VH_attention_linear_output_acc: 0.4800\n",
      "Epoch 3491/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3929 - VL_attention_linear_output_loss: 1.6968 - VH_attention_linear_output_loss: 1.6961 - VL_attention_linear_output_acc: 0.5017 - VH_attention_linear_output_acc: 0.5005 - val_loss: 3.4976 - val_VL_attention_linear_output_loss: 1.7549 - val_VH_attention_linear_output_loss: 1.7427 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.4933\n",
      "Epoch 3492/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3788 - VL_attention_linear_output_loss: 1.6873 - VH_attention_linear_output_loss: 1.6916 - VL_attention_linear_output_acc: 0.5034 - VH_attention_linear_output_acc: 0.5020 - val_loss: 3.5138 - val_VL_attention_linear_output_loss: 1.7547 - val_VH_attention_linear_output_loss: 1.7591 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.4838\n",
      "Epoch 3493/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3796 - VL_attention_linear_output_loss: 1.6847 - VH_attention_linear_output_loss: 1.6949 - VL_attention_linear_output_acc: 0.5062 - VH_attention_linear_output_acc: 0.5006 - val_loss: 3.5010 - val_VL_attention_linear_output_loss: 1.7591 - val_VH_attention_linear_output_loss: 1.7419 - val_VL_attention_linear_output_acc: 0.4933 - val_VH_attention_linear_output_acc: 0.4907\n",
      "Epoch 3494/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3754 - VL_attention_linear_output_loss: 1.6928 - VH_attention_linear_output_loss: 1.6826 - VL_attention_linear_output_acc: 0.5009 - VH_attention_linear_output_acc: 0.5054 - val_loss: 3.5102 - val_VL_attention_linear_output_loss: 1.7564 - val_VH_attention_linear_output_loss: 1.7538 - val_VL_attention_linear_output_acc: 0.4926 - val_VH_attention_linear_output_acc: 0.4877\n",
      "Epoch 3495/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3859 - VL_attention_linear_output_loss: 1.6935 - VH_attention_linear_output_loss: 1.6924 - VL_attention_linear_output_acc: 0.5004 - VH_attention_linear_output_acc: 0.5007 - val_loss: 3.5284 - val_VL_attention_linear_output_loss: 1.7596 - val_VH_attention_linear_output_loss: 1.7687 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.4791\n",
      "Epoch 3496/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3871 - VL_attention_linear_output_loss: 1.6970 - VH_attention_linear_output_loss: 1.6901 - VL_attention_linear_output_acc: 0.4992 - VH_attention_linear_output_acc: 0.5023 - val_loss: 3.5045 - val_VL_attention_linear_output_loss: 1.7558 - val_VH_attention_linear_output_loss: 1.7487 - val_VL_attention_linear_output_acc: 0.4932 - val_VH_attention_linear_output_acc: 0.4867\n",
      "Epoch 3497/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3933 - VL_attention_linear_output_loss: 1.7028 - VH_attention_linear_output_loss: 1.6906 - VL_attention_linear_output_acc: 0.4976 - VH_attention_linear_output_acc: 0.5021 - val_loss: 3.5102 - val_VL_attention_linear_output_loss: 1.7558 - val_VH_attention_linear_output_loss: 1.7545 - val_VL_attention_linear_output_acc: 0.4952 - val_VH_attention_linear_output_acc: 0.4856\n",
      "Epoch 3498/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3836 - VL_attention_linear_output_loss: 1.6899 - VH_attention_linear_output_loss: 1.6937 - VL_attention_linear_output_acc: 0.5033 - VH_attention_linear_output_acc: 0.5007 - val_loss: 3.4944 - val_VL_attention_linear_output_loss: 1.7549 - val_VH_attention_linear_output_loss: 1.7395 - val_VL_attention_linear_output_acc: 0.4903 - val_VH_attention_linear_output_acc: 0.4926\n",
      "Epoch 3499/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3940 - VL_attention_linear_output_loss: 1.6873 - VH_attention_linear_output_loss: 1.7067 - VL_attention_linear_output_acc: 0.5028 - VH_attention_linear_output_acc: 0.4952 - val_loss: 3.5254 - val_VL_attention_linear_output_loss: 1.7743 - val_VH_attention_linear_output_loss: 1.7511 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.4901\n",
      "Epoch 3500/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3762 - VL_attention_linear_output_loss: 1.6924 - VH_attention_linear_output_loss: 1.6838 - VL_attention_linear_output_acc: 0.5015 - VH_attention_linear_output_acc: 0.5049 - val_loss: 3.5162 - val_VL_attention_linear_output_loss: 1.7640 - val_VH_attention_linear_output_loss: 1.7522 - val_VL_attention_linear_output_acc: 0.4929 - val_VH_attention_linear_output_acc: 0.4861\n",
      "Epoch 3501/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3898 - VL_attention_linear_output_loss: 1.6962 - VH_attention_linear_output_loss: 1.6936 - VL_attention_linear_output_acc: 0.4997 - VH_attention_linear_output_acc: 0.5013 - val_loss: 3.5210 - val_VL_attention_linear_output_loss: 1.7694 - val_VH_attention_linear_output_loss: 1.7516 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4893\n",
      "Epoch 3502/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3911 - VL_attention_linear_output_loss: 1.7016 - VH_attention_linear_output_loss: 1.6895 - VL_attention_linear_output_acc: 0.4969 - VH_attention_linear_output_acc: 0.5022 - val_loss: 3.5094 - val_VL_attention_linear_output_loss: 1.7636 - val_VH_attention_linear_output_loss: 1.7458 - val_VL_attention_linear_output_acc: 0.4880 - val_VH_attention_linear_output_acc: 0.4905\n",
      "Epoch 3503/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3925 - VL_attention_linear_output_loss: 1.6998 - VH_attention_linear_output_loss: 1.6927 - VL_attention_linear_output_acc: 0.4980 - VH_attention_linear_output_acc: 0.5014 - val_loss: 3.5039 - val_VL_attention_linear_output_loss: 1.7542 - val_VH_attention_linear_output_loss: 1.7496 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.4876\n",
      "Epoch 3504/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3707 - VL_attention_linear_output_loss: 1.6862 - VH_attention_linear_output_loss: 1.6844 - VL_attention_linear_output_acc: 0.5045 - VH_attention_linear_output_acc: 0.5045 - val_loss: 3.4974 - val_VL_attention_linear_output_loss: 1.7546 - val_VH_attention_linear_output_loss: 1.7428 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4915\n",
      "Epoch 3505/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3771 - VL_attention_linear_output_loss: 1.6868 - VH_attention_linear_output_loss: 1.6903 - VL_attention_linear_output_acc: 0.5046 - VH_attention_linear_output_acc: 0.5020 - val_loss: 3.5026 - val_VL_attention_linear_output_loss: 1.7561 - val_VH_attention_linear_output_loss: 1.7465 - val_VL_attention_linear_output_acc: 0.4953 - val_VH_attention_linear_output_acc: 0.4891\n",
      "Epoch 3506/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3900 - VL_attention_linear_output_loss: 1.6925 - VH_attention_linear_output_loss: 1.6975 - VL_attention_linear_output_acc: 0.5015 - VH_attention_linear_output_acc: 0.4986 - val_loss: 3.5289 - val_VL_attention_linear_output_loss: 1.7603 - val_VH_attention_linear_output_loss: 1.7686 - val_VL_attention_linear_output_acc: 0.4911 - val_VH_attention_linear_output_acc: 0.4812\n",
      "Epoch 3507/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3930 - VL_attention_linear_output_loss: 1.6974 - VH_attention_linear_output_loss: 1.6956 - VL_attention_linear_output_acc: 0.4989 - VH_attention_linear_output_acc: 0.5001 - val_loss: 3.5379 - val_VL_attention_linear_output_loss: 1.7608 - val_VH_attention_linear_output_loss: 1.7771 - val_VL_attention_linear_output_acc: 0.4861 - val_VH_attention_linear_output_acc: 0.4775\n",
      "Epoch 3508/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3865 - VL_attention_linear_output_loss: 1.6941 - VH_attention_linear_output_loss: 1.6924 - VL_attention_linear_output_acc: 0.5003 - VH_attention_linear_output_acc: 0.5016 - val_loss: 3.5075 - val_VL_attention_linear_output_loss: 1.7568 - val_VH_attention_linear_output_loss: 1.7506 - val_VL_attention_linear_output_acc: 0.4931 - val_VH_attention_linear_output_acc: 0.4872\n",
      "Epoch 3509/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3927 - VL_attention_linear_output_loss: 1.6923 - VH_attention_linear_output_loss: 1.7005 - VL_attention_linear_output_acc: 0.5022 - VH_attention_linear_output_acc: 0.4973 - val_loss: 3.5185 - val_VL_attention_linear_output_loss: 1.7627 - val_VH_attention_linear_output_loss: 1.7559 - val_VL_attention_linear_output_acc: 0.4946 - val_VH_attention_linear_output_acc: 0.4881\n",
      "Epoch 3510/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3851 - VL_attention_linear_output_loss: 1.6957 - VH_attention_linear_output_loss: 1.6894 - VL_attention_linear_output_acc: 0.5012 - VH_attention_linear_output_acc: 0.5022 - val_loss: 3.6176 - val_VL_attention_linear_output_loss: 1.8435 - val_VH_attention_linear_output_loss: 1.7741 - val_VL_attention_linear_output_acc: 0.4567 - val_VH_attention_linear_output_acc: 0.4822\n",
      "Epoch 3511/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3813 - VL_attention_linear_output_loss: 1.6881 - VH_attention_linear_output_loss: 1.6933 - VL_attention_linear_output_acc: 0.5041 - VH_attention_linear_output_acc: 0.5007 - val_loss: 3.5037 - val_VL_attention_linear_output_loss: 1.7566 - val_VH_attention_linear_output_loss: 1.7471 - val_VL_attention_linear_output_acc: 0.4917 - val_VH_attention_linear_output_acc: 0.4892\n",
      "Epoch 3512/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3887 - VL_attention_linear_output_loss: 1.6914 - VH_attention_linear_output_loss: 1.6973 - VL_attention_linear_output_acc: 0.5018 - VH_attention_linear_output_acc: 0.4998 - val_loss: 3.5282 - val_VL_attention_linear_output_loss: 1.7757 - val_VH_attention_linear_output_loss: 1.7525 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4904\n",
      "Epoch 3513/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3947 - VL_attention_linear_output_loss: 1.6969 - VH_attention_linear_output_loss: 1.6978 - VL_attention_linear_output_acc: 0.5000 - VH_attention_linear_output_acc: 0.4994 - val_loss: 3.5021 - val_VL_attention_linear_output_loss: 1.7632 - val_VH_attention_linear_output_loss: 1.7389 - val_VL_attention_linear_output_acc: 0.4921 - val_VH_attention_linear_output_acc: 0.4919\n",
      "Epoch 3514/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3985 - VL_attention_linear_output_loss: 1.6985 - VH_attention_linear_output_loss: 1.6999 - VL_attention_linear_output_acc: 0.4989 - VH_attention_linear_output_acc: 0.4988 - val_loss: 3.5396 - val_VL_attention_linear_output_loss: 1.7826 - val_VH_attention_linear_output_loss: 1.7570 - val_VL_attention_linear_output_acc: 0.4738 - val_VH_attention_linear_output_acc: 0.4885\n",
      "Epoch 3515/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3901 - VL_attention_linear_output_loss: 1.6964 - VH_attention_linear_output_loss: 1.6937 - VL_attention_linear_output_acc: 0.5011 - VH_attention_linear_output_acc: 0.5009 - val_loss: 3.4932 - val_VL_attention_linear_output_loss: 1.7531 - val_VH_attention_linear_output_loss: 1.7401 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.4916\n",
      "Epoch 3516/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3689 - VL_attention_linear_output_loss: 1.6859 - VH_attention_linear_output_loss: 1.6830 - VL_attention_linear_output_acc: 0.5050 - VH_attention_linear_output_acc: 0.5048 - val_loss: 3.5124 - val_VL_attention_linear_output_loss: 1.7674 - val_VH_attention_linear_output_loss: 1.7450 - val_VL_attention_linear_output_acc: 0.4860 - val_VH_attention_linear_output_acc: 0.4883\n",
      "Epoch 3517/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3814 - VL_attention_linear_output_loss: 1.6930 - VH_attention_linear_output_loss: 1.6884 - VL_attention_linear_output_acc: 0.5017 - VH_attention_linear_output_acc: 0.5029 - val_loss: 3.5121 - val_VL_attention_linear_output_loss: 1.7624 - val_VH_attention_linear_output_loss: 1.7497 - val_VL_attention_linear_output_acc: 0.4957 - val_VH_attention_linear_output_acc: 0.4874\n",
      "Epoch 3518/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3832 - VL_attention_linear_output_loss: 1.6944 - VH_attention_linear_output_loss: 1.6888 - VL_attention_linear_output_acc: 0.5009 - VH_attention_linear_output_acc: 0.5026 - val_loss: 3.5106 - val_VL_attention_linear_output_loss: 1.7683 - val_VH_attention_linear_output_loss: 1.7423 - val_VL_attention_linear_output_acc: 0.4893 - val_VH_attention_linear_output_acc: 0.4936\n",
      "Epoch 3519/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3810 - VL_attention_linear_output_loss: 1.6957 - VH_attention_linear_output_loss: 1.6853 - VL_attention_linear_output_acc: 0.5005 - VH_attention_linear_output_acc: 0.5039 - val_loss: 3.5119 - val_VL_attention_linear_output_loss: 1.7613 - val_VH_attention_linear_output_loss: 1.7506 - val_VL_attention_linear_output_acc: 0.4892 - val_VH_attention_linear_output_acc: 0.4871\n",
      "Epoch 3520/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3853 - VL_attention_linear_output_loss: 1.6951 - VH_attention_linear_output_loss: 1.6901 - VL_attention_linear_output_acc: 0.4998 - VH_attention_linear_output_acc: 0.5024 - val_loss: 3.5007 - val_VL_attention_linear_output_loss: 1.7512 - val_VH_attention_linear_output_loss: 1.7495 - val_VL_attention_linear_output_acc: 0.4960 - val_VH_attention_linear_output_acc: 0.4864\n",
      "Epoch 3521/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3930 - VL_attention_linear_output_loss: 1.6996 - VH_attention_linear_output_loss: 1.6934 - VL_attention_linear_output_acc: 0.4982 - VH_attention_linear_output_acc: 0.5005 - val_loss: 3.5217 - val_VL_attention_linear_output_loss: 1.7784 - val_VH_attention_linear_output_loss: 1.7432 - val_VL_attention_linear_output_acc: 0.4832 - val_VH_attention_linear_output_acc: 0.4926\n",
      "Epoch 3522/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3795 - VL_attention_linear_output_loss: 1.6948 - VH_attention_linear_output_loss: 1.6847 - VL_attention_linear_output_acc: 0.5001 - VH_attention_linear_output_acc: 0.5051 - val_loss: 3.4948 - val_VL_attention_linear_output_loss: 1.7561 - val_VH_attention_linear_output_loss: 1.7387 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.4928\n",
      "Epoch 3523/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3745 - VL_attention_linear_output_loss: 1.6857 - VH_attention_linear_output_loss: 1.6888 - VL_attention_linear_output_acc: 0.5058 - VH_attention_linear_output_acc: 0.5026 - val_loss: 3.5107 - val_VL_attention_linear_output_loss: 1.7626 - val_VH_attention_linear_output_loss: 1.7481 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.4915\n",
      "Epoch 3524/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3799 - VL_attention_linear_output_loss: 1.6931 - VH_attention_linear_output_loss: 1.6868 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5039 - val_loss: 3.5367 - val_VL_attention_linear_output_loss: 1.7671 - val_VH_attention_linear_output_loss: 1.7696 - val_VL_attention_linear_output_acc: 0.4889 - val_VH_attention_linear_output_acc: 0.4825\n",
      "Epoch 3525/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3997 - VL_attention_linear_output_loss: 1.6998 - VH_attention_linear_output_loss: 1.6998 - VL_attention_linear_output_acc: 0.4979 - VH_attention_linear_output_acc: 0.4985 - val_loss: 3.5477 - val_VL_attention_linear_output_loss: 1.7638 - val_VH_attention_linear_output_loss: 1.7839 - val_VL_attention_linear_output_acc: 0.4892 - val_VH_attention_linear_output_acc: 0.4740\n",
      "Epoch 3526/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3782 - VL_attention_linear_output_loss: 1.6930 - VH_attention_linear_output_loss: 1.6852 - VL_attention_linear_output_acc: 0.5017 - VH_attention_linear_output_acc: 0.5041 - val_loss: 3.5419 - val_VL_attention_linear_output_loss: 1.7980 - val_VH_attention_linear_output_loss: 1.7439 - val_VL_attention_linear_output_acc: 0.4730 - val_VH_attention_linear_output_acc: 0.4928\n",
      "Epoch 3527/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3772 - VL_attention_linear_output_loss: 1.6865 - VH_attention_linear_output_loss: 1.6907 - VL_attention_linear_output_acc: 0.5054 - VH_attention_linear_output_acc: 0.5019 - val_loss: 3.5106 - val_VL_attention_linear_output_loss: 1.7537 - val_VH_attention_linear_output_loss: 1.7569 - val_VL_attention_linear_output_acc: 0.4931 - val_VH_attention_linear_output_acc: 0.4828\n",
      "Epoch 3528/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3763 - VL_attention_linear_output_loss: 1.6881 - VH_attention_linear_output_loss: 1.6883 - VL_attention_linear_output_acc: 0.5026 - VH_attention_linear_output_acc: 0.5020 - val_loss: 3.5219 - val_VL_attention_linear_output_loss: 1.7561 - val_VH_attention_linear_output_loss: 1.7658 - val_VL_attention_linear_output_acc: 0.4912 - val_VH_attention_linear_output_acc: 0.4832\n",
      "Epoch 3529/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3861 - VL_attention_linear_output_loss: 1.6954 - VH_attention_linear_output_loss: 1.6907 - VL_attention_linear_output_acc: 0.5006 - VH_attention_linear_output_acc: 0.5019 - val_loss: 3.5138 - val_VL_attention_linear_output_loss: 1.7637 - val_VH_attention_linear_output_loss: 1.7500 - val_VL_attention_linear_output_acc: 0.4894 - val_VH_attention_linear_output_acc: 0.4884\n",
      "Epoch 3530/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3796 - VL_attention_linear_output_loss: 1.6834 - VH_attention_linear_output_loss: 1.6962 - VL_attention_linear_output_acc: 0.5053 - VH_attention_linear_output_acc: 0.4996 - val_loss: 3.5178 - val_VL_attention_linear_output_loss: 1.7597 - val_VH_attention_linear_output_loss: 1.7581 - val_VL_attention_linear_output_acc: 0.4918 - val_VH_attention_linear_output_acc: 0.4864\n",
      "Epoch 3531/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3898 - VL_attention_linear_output_loss: 1.6864 - VH_attention_linear_output_loss: 1.7034 - VL_attention_linear_output_acc: 0.5051 - VH_attention_linear_output_acc: 0.4968 - val_loss: 3.5148 - val_VL_attention_linear_output_loss: 1.7557 - val_VH_attention_linear_output_loss: 1.7591 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4872\n",
      "Epoch 3532/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3770 - VL_attention_linear_output_loss: 1.6908 - VH_attention_linear_output_loss: 1.6862 - VL_attention_linear_output_acc: 0.5026 - VH_attention_linear_output_acc: 0.5035 - val_loss: 3.5022 - val_VL_attention_linear_output_loss: 1.7529 - val_VH_attention_linear_output_loss: 1.7493 - val_VL_attention_linear_output_acc: 0.4946 - val_VH_attention_linear_output_acc: 0.4894\n",
      "Epoch 3533/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3764 - VL_attention_linear_output_loss: 1.6921 - VH_attention_linear_output_loss: 1.6843 - VL_attention_linear_output_acc: 0.5026 - VH_attention_linear_output_acc: 0.5042 - val_loss: 3.5462 - val_VL_attention_linear_output_loss: 1.7593 - val_VH_attention_linear_output_loss: 1.7869 - val_VL_attention_linear_output_acc: 0.4924 - val_VH_attention_linear_output_acc: 0.4675\n",
      "Epoch 3534/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3914 - VL_attention_linear_output_loss: 1.6950 - VH_attention_linear_output_loss: 1.6963 - VL_attention_linear_output_acc: 0.5008 - VH_attention_linear_output_acc: 0.4998 - val_loss: 3.5182 - val_VL_attention_linear_output_loss: 1.7643 - val_VH_attention_linear_output_loss: 1.7538 - val_VL_attention_linear_output_acc: 0.4908 - val_VH_attention_linear_output_acc: 0.4860\n",
      "Epoch 3535/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3939 - VL_attention_linear_output_loss: 1.7003 - VH_attention_linear_output_loss: 1.6936 - VL_attention_linear_output_acc: 0.4977 - VH_attention_linear_output_acc: 0.5005 - val_loss: 3.5622 - val_VL_attention_linear_output_loss: 1.7970 - val_VH_attention_linear_output_loss: 1.7652 - val_VL_attention_linear_output_acc: 0.4801 - val_VH_attention_linear_output_acc: 0.4797\n",
      "Epoch 3536/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3851 - VL_attention_linear_output_loss: 1.6957 - VH_attention_linear_output_loss: 1.6894 - VL_attention_linear_output_acc: 0.5008 - VH_attention_linear_output_acc: 0.5030 - val_loss: 3.5109 - val_VL_attention_linear_output_loss: 1.7551 - val_VH_attention_linear_output_loss: 1.7557 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.4866\n",
      "Epoch 3537/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3757 - VL_attention_linear_output_loss: 1.6884 - VH_attention_linear_output_loss: 1.6873 - VL_attention_linear_output_acc: 0.5038 - VH_attention_linear_output_acc: 0.5024 - val_loss: 3.5184 - val_VL_attention_linear_output_loss: 1.7768 - val_VH_attention_linear_output_loss: 1.7416 - val_VL_attention_linear_output_acc: 0.4875 - val_VH_attention_linear_output_acc: 0.4897\n",
      "Epoch 3538/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3843 - VL_attention_linear_output_loss: 1.6913 - VH_attention_linear_output_loss: 1.6930 - VL_attention_linear_output_acc: 0.5026 - VH_attention_linear_output_acc: 0.5006 - val_loss: 3.5253 - val_VL_attention_linear_output_loss: 1.7762 - val_VH_attention_linear_output_loss: 1.7491 - val_VL_attention_linear_output_acc: 0.4789 - val_VH_attention_linear_output_acc: 0.4918\n",
      "Epoch 3539/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3853 - VL_attention_linear_output_loss: 1.6944 - VH_attention_linear_output_loss: 1.6909 - VL_attention_linear_output_acc: 0.5010 - VH_attention_linear_output_acc: 0.5012 - val_loss: 3.5103 - val_VL_attention_linear_output_loss: 1.7656 - val_VH_attention_linear_output_loss: 1.7447 - val_VL_attention_linear_output_acc: 0.4793 - val_VH_attention_linear_output_acc: 0.4917\n",
      "Epoch 3540/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3720 - VL_attention_linear_output_loss: 1.6845 - VH_attention_linear_output_loss: 1.6875 - VL_attention_linear_output_acc: 0.5062 - VH_attention_linear_output_acc: 0.5025 - val_loss: 3.5697 - val_VL_attention_linear_output_loss: 1.7592 - val_VH_attention_linear_output_loss: 1.8105 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.4673\n",
      "Epoch 3541/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3839 - VL_attention_linear_output_loss: 1.6870 - VH_attention_linear_output_loss: 1.6968 - VL_attention_linear_output_acc: 0.5035 - VH_attention_linear_output_acc: 0.4982 - val_loss: 3.5003 - val_VL_attention_linear_output_loss: 1.7612 - val_VH_attention_linear_output_loss: 1.7391 - val_VL_attention_linear_output_acc: 0.4924 - val_VH_attention_linear_output_acc: 0.4916\n",
      "Epoch 3542/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3905 - VL_attention_linear_output_loss: 1.7002 - VH_attention_linear_output_loss: 1.6903 - VL_attention_linear_output_acc: 0.4983 - VH_attention_linear_output_acc: 0.5014 - val_loss: 3.5328 - val_VL_attention_linear_output_loss: 1.7547 - val_VH_attention_linear_output_loss: 1.7781 - val_VL_attention_linear_output_acc: 0.4960 - val_VH_attention_linear_output_acc: 0.4775\n",
      "Epoch 3543/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3789 - VL_attention_linear_output_loss: 1.6847 - VH_attention_linear_output_loss: 1.6943 - VL_attention_linear_output_acc: 0.5058 - VH_attention_linear_output_acc: 0.4998 - val_loss: 3.5014 - val_VL_attention_linear_output_loss: 1.7608 - val_VH_attention_linear_output_loss: 1.7406 - val_VL_attention_linear_output_acc: 0.4971 - val_VH_attention_linear_output_acc: 0.4906\n",
      "Epoch 3544/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3898 - VL_attention_linear_output_loss: 1.6924 - VH_attention_linear_output_loss: 1.6973 - VL_attention_linear_output_acc: 0.5016 - VH_attention_linear_output_acc: 0.4991 - val_loss: 3.5165 - val_VL_attention_linear_output_loss: 1.7571 - val_VH_attention_linear_output_loss: 1.7594 - val_VL_attention_linear_output_acc: 0.4937 - val_VH_attention_linear_output_acc: 0.4850\n",
      "Epoch 3545/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3823 - VL_attention_linear_output_loss: 1.6908 - VH_attention_linear_output_loss: 1.6915 - VL_attention_linear_output_acc: 0.5022 - VH_attention_linear_output_acc: 0.5011 - val_loss: 3.5291 - val_VL_attention_linear_output_loss: 1.7722 - val_VH_attention_linear_output_loss: 1.7569 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4816\n",
      "Epoch 3546/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3805 - VL_attention_linear_output_loss: 1.6927 - VH_attention_linear_output_loss: 1.6878 - VL_attention_linear_output_acc: 0.5011 - VH_attention_linear_output_acc: 0.5026 - val_loss: 3.5070 - val_VL_attention_linear_output_loss: 1.7550 - val_VH_attention_linear_output_loss: 1.7519 - val_VL_attention_linear_output_acc: 0.4914 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3547/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3822 - VL_attention_linear_output_loss: 1.6846 - VH_attention_linear_output_loss: 1.6976 - VL_attention_linear_output_acc: 0.5061 - VH_attention_linear_output_acc: 0.4990 - val_loss: 3.5352 - val_VL_attention_linear_output_loss: 1.7665 - val_VH_attention_linear_output_loss: 1.7688 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.4815\n",
      "Epoch 3548/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3818 - VL_attention_linear_output_loss: 1.6911 - VH_attention_linear_output_loss: 1.6907 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5015 - val_loss: 3.5301 - val_VL_attention_linear_output_loss: 1.7705 - val_VH_attention_linear_output_loss: 1.7596 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.4849\n",
      "Epoch 3549/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3855 - VL_attention_linear_output_loss: 1.6891 - VH_attention_linear_output_loss: 1.6964 - VL_attention_linear_output_acc: 0.5045 - VH_attention_linear_output_acc: 0.4999 - val_loss: 3.4973 - val_VL_attention_linear_output_loss: 1.7514 - val_VH_attention_linear_output_loss: 1.7459 - val_VL_attention_linear_output_acc: 0.5000 - val_VH_attention_linear_output_acc: 0.4881\n",
      "Epoch 3550/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3732 - VL_attention_linear_output_loss: 1.6886 - VH_attention_linear_output_loss: 1.6846 - VL_attention_linear_output_acc: 0.5027 - VH_attention_linear_output_acc: 0.5039 - val_loss: 3.5191 - val_VL_attention_linear_output_loss: 1.7769 - val_VH_attention_linear_output_loss: 1.7422 - val_VL_attention_linear_output_acc: 0.4785 - val_VH_attention_linear_output_acc: 0.4889\n",
      "Epoch 3551/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3844 - VL_attention_linear_output_loss: 1.6969 - VH_attention_linear_output_loss: 1.6875 - VL_attention_linear_output_acc: 0.5001 - VH_attention_linear_output_acc: 0.5026 - val_loss: 3.4959 - val_VL_attention_linear_output_loss: 1.7558 - val_VH_attention_linear_output_loss: 1.7401 - val_VL_attention_linear_output_acc: 0.4937 - val_VH_attention_linear_output_acc: 0.4909\n",
      "Epoch 3552/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3829 - VL_attention_linear_output_loss: 1.6889 - VH_attention_linear_output_loss: 1.6940 - VL_attention_linear_output_acc: 0.5051 - VH_attention_linear_output_acc: 0.5000 - val_loss: 3.5247 - val_VL_attention_linear_output_loss: 1.7714 - val_VH_attention_linear_output_loss: 1.7533 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4898\n",
      "Epoch 3553/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3911 - VL_attention_linear_output_loss: 1.7003 - VH_attention_linear_output_loss: 1.6909 - VL_attention_linear_output_acc: 0.4990 - VH_attention_linear_output_acc: 0.5015 - val_loss: 3.5017 - val_VL_attention_linear_output_loss: 1.7522 - val_VH_attention_linear_output_loss: 1.7495 - val_VL_attention_linear_output_acc: 0.4956 - val_VH_attention_linear_output_acc: 0.4891\n",
      "Epoch 3554/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3834 - VL_attention_linear_output_loss: 1.6916 - VH_attention_linear_output_loss: 1.6918 - VL_attention_linear_output_acc: 0.5025 - VH_attention_linear_output_acc: 0.5014 - val_loss: 3.4976 - val_VL_attention_linear_output_loss: 1.7532 - val_VH_attention_linear_output_loss: 1.7444 - val_VL_attention_linear_output_acc: 0.4956 - val_VH_attention_linear_output_acc: 0.4900\n",
      "Epoch 3555/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3962 - VL_attention_linear_output_loss: 1.7059 - VH_attention_linear_output_loss: 1.6903 - VL_attention_linear_output_acc: 0.4957 - VH_attention_linear_output_acc: 0.5018 - val_loss: 3.4983 - val_VL_attention_linear_output_loss: 1.7557 - val_VH_attention_linear_output_loss: 1.7426 - val_VL_attention_linear_output_acc: 0.4923 - val_VH_attention_linear_output_acc: 0.4920\n",
      "Epoch 3556/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3780 - VL_attention_linear_output_loss: 1.6881 - VH_attention_linear_output_loss: 1.6899 - VL_attention_linear_output_acc: 0.5047 - VH_attention_linear_output_acc: 0.5015 - val_loss: 3.5263 - val_VL_attention_linear_output_loss: 1.7629 - val_VH_attention_linear_output_loss: 1.7634 - val_VL_attention_linear_output_acc: 0.4930 - val_VH_attention_linear_output_acc: 0.4826\n",
      "Epoch 3557/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3734 - VL_attention_linear_output_loss: 1.6874 - VH_attention_linear_output_loss: 1.6859 - VL_attention_linear_output_acc: 0.5052 - VH_attention_linear_output_acc: 0.5035 - val_loss: 3.5088 - val_VL_attention_linear_output_loss: 1.7642 - val_VH_attention_linear_output_loss: 1.7445 - val_VL_attention_linear_output_acc: 0.4838 - val_VH_attention_linear_output_acc: 0.4917\n",
      "Epoch 3558/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3824 - VL_attention_linear_output_loss: 1.6948 - VH_attention_linear_output_loss: 1.6876 - VL_attention_linear_output_acc: 0.5012 - VH_attention_linear_output_acc: 0.5023 - val_loss: 3.5445 - val_VL_attention_linear_output_loss: 1.7964 - val_VH_attention_linear_output_loss: 1.7482 - val_VL_attention_linear_output_acc: 0.4713 - val_VH_attention_linear_output_acc: 0.4905\n",
      "Epoch 3559/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3834 - VL_attention_linear_output_loss: 1.6916 - VH_attention_linear_output_loss: 1.6918 - VL_attention_linear_output_acc: 0.5017 - VH_attention_linear_output_acc: 0.5002 - val_loss: 3.5551 - val_VL_attention_linear_output_loss: 1.7540 - val_VH_attention_linear_output_loss: 1.8011 - val_VL_attention_linear_output_acc: 0.4966 - val_VH_attention_linear_output_acc: 0.4687\n",
      "Epoch 3560/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3899 - VL_attention_linear_output_loss: 1.6966 - VH_attention_linear_output_loss: 1.6933 - VL_attention_linear_output_acc: 0.5002 - VH_attention_linear_output_acc: 0.5005 - val_loss: 3.5007 - val_VL_attention_linear_output_loss: 1.7563 - val_VH_attention_linear_output_loss: 1.7444 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.4890\n",
      "Epoch 3561/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3778 - VL_attention_linear_output_loss: 1.6885 - VH_attention_linear_output_loss: 1.6893 - VL_attention_linear_output_acc: 0.5031 - VH_attention_linear_output_acc: 0.5017 - val_loss: 3.5091 - val_VL_attention_linear_output_loss: 1.7551 - val_VH_attention_linear_output_loss: 1.7539 - val_VL_attention_linear_output_acc: 0.4964 - val_VH_attention_linear_output_acc: 0.4868\n",
      "Epoch 3562/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3950 - VL_attention_linear_output_loss: 1.6932 - VH_attention_linear_output_loss: 1.7018 - VL_attention_linear_output_acc: 0.5015 - VH_attention_linear_output_acc: 0.4976 - val_loss: 3.5513 - val_VL_attention_linear_output_loss: 1.7810 - val_VH_attention_linear_output_loss: 1.7703 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4844\n",
      "Epoch 3563/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3883 - VL_attention_linear_output_loss: 1.6922 - VH_attention_linear_output_loss: 1.6961 - VL_attention_linear_output_acc: 0.5015 - VH_attention_linear_output_acc: 0.5011 - val_loss: 3.5580 - val_VL_attention_linear_output_loss: 1.7909 - val_VH_attention_linear_output_loss: 1.7670 - val_VL_attention_linear_output_acc: 0.4814 - val_VH_attention_linear_output_acc: 0.4856\n",
      "Epoch 3564/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3966 - VL_attention_linear_output_loss: 1.6988 - VH_attention_linear_output_loss: 1.6978 - VL_attention_linear_output_acc: 0.5002 - VH_attention_linear_output_acc: 0.5004 - val_loss: 3.5058 - val_VL_attention_linear_output_loss: 1.7521 - val_VH_attention_linear_output_loss: 1.7538 - val_VL_attention_linear_output_acc: 0.4958 - val_VH_attention_linear_output_acc: 0.4883\n",
      "Epoch 3565/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3965 - VL_attention_linear_output_loss: 1.7017 - VH_attention_linear_output_loss: 1.6947 - VL_attention_linear_output_acc: 0.4970 - VH_attention_linear_output_acc: 0.4999 - val_loss: 3.5066 - val_VL_attention_linear_output_loss: 1.7643 - val_VH_attention_linear_output_loss: 1.7423 - val_VL_attention_linear_output_acc: 0.4906 - val_VH_attention_linear_output_acc: 0.4910\n",
      "Epoch 3566/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3869 - VL_attention_linear_output_loss: 1.6942 - VH_attention_linear_output_loss: 1.6927 - VL_attention_linear_output_acc: 0.5011 - VH_attention_linear_output_acc: 0.5013 - val_loss: 3.5026 - val_VL_attention_linear_output_loss: 1.7592 - val_VH_attention_linear_output_loss: 1.7434 - val_VL_attention_linear_output_acc: 0.4883 - val_VH_attention_linear_output_acc: 0.4895\n",
      "Epoch 3567/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3768 - VL_attention_linear_output_loss: 1.6847 - VH_attention_linear_output_loss: 1.6921 - VL_attention_linear_output_acc: 0.5052 - VH_attention_linear_output_acc: 0.5013 - val_loss: 3.5115 - val_VL_attention_linear_output_loss: 1.7535 - val_VH_attention_linear_output_loss: 1.7579 - val_VL_attention_linear_output_acc: 0.4917 - val_VH_attention_linear_output_acc: 0.4835\n",
      "Epoch 3568/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3909 - VL_attention_linear_output_loss: 1.7026 - VH_attention_linear_output_loss: 1.6883 - VL_attention_linear_output_acc: 0.4971 - VH_attention_linear_output_acc: 0.5026 - val_loss: 3.5146 - val_VL_attention_linear_output_loss: 1.7726 - val_VH_attention_linear_output_loss: 1.7421 - val_VL_attention_linear_output_acc: 0.4777 - val_VH_attention_linear_output_acc: 0.4917\n",
      "Epoch 3569/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3958 - VL_attention_linear_output_loss: 1.6927 - VH_attention_linear_output_loss: 1.7032 - VL_attention_linear_output_acc: 0.5032 - VH_attention_linear_output_acc: 0.4976 - val_loss: 3.4992 - val_VL_attention_linear_output_loss: 1.7588 - val_VH_attention_linear_output_loss: 1.7403 - val_VL_attention_linear_output_acc: 0.4940 - val_VH_attention_linear_output_acc: 0.4935\n",
      "Epoch 3570/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3802 - VL_attention_linear_output_loss: 1.6932 - VH_attention_linear_output_loss: 1.6869 - VL_attention_linear_output_acc: 0.5013 - VH_attention_linear_output_acc: 0.5026 - val_loss: 3.5569 - val_VL_attention_linear_output_loss: 1.7832 - val_VH_attention_linear_output_loss: 1.7737 - val_VL_attention_linear_output_acc: 0.4773 - val_VH_attention_linear_output_acc: 0.4808\n",
      "Epoch 3571/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3676 - VL_attention_linear_output_loss: 1.6849 - VH_attention_linear_output_loss: 1.6827 - VL_attention_linear_output_acc: 0.5054 - VH_attention_linear_output_acc: 0.5044 - val_loss: 3.5444 - val_VL_attention_linear_output_loss: 1.7849 - val_VH_attention_linear_output_loss: 1.7595 - val_VL_attention_linear_output_acc: 0.4743 - val_VH_attention_linear_output_acc: 0.4833\n",
      "Epoch 3572/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3908 - VL_attention_linear_output_loss: 1.6978 - VH_attention_linear_output_loss: 1.6930 - VL_attention_linear_output_acc: 0.4991 - VH_attention_linear_output_acc: 0.5005 - val_loss: 3.5249 - val_VL_attention_linear_output_loss: 1.7609 - val_VH_attention_linear_output_loss: 1.7640 - val_VL_attention_linear_output_acc: 0.4912 - val_VH_attention_linear_output_acc: 0.4835\n",
      "Epoch 3573/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3837 - VL_attention_linear_output_loss: 1.6995 - VH_attention_linear_output_loss: 1.6842 - VL_attention_linear_output_acc: 0.4979 - VH_attention_linear_output_acc: 0.5039 - val_loss: 3.5105 - val_VL_attention_linear_output_loss: 1.7535 - val_VH_attention_linear_output_loss: 1.7569 - val_VL_attention_linear_output_acc: 0.4956 - val_VH_attention_linear_output_acc: 0.4841\n",
      "Epoch 3574/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3690 - VL_attention_linear_output_loss: 1.6876 - VH_attention_linear_output_loss: 1.6813 - VL_attention_linear_output_acc: 0.5036 - VH_attention_linear_output_acc: 0.5049 - val_loss: 3.4948 - val_VL_attention_linear_output_loss: 1.7528 - val_VH_attention_linear_output_loss: 1.7420 - val_VL_attention_linear_output_acc: 0.4979 - val_VH_attention_linear_output_acc: 0.4935\n",
      "Epoch 3575/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3688 - VL_attention_linear_output_loss: 1.6814 - VH_attention_linear_output_loss: 1.6874 - VL_attention_linear_output_acc: 0.5070 - VH_attention_linear_output_acc: 0.5026 - val_loss: 3.5115 - val_VL_attention_linear_output_loss: 1.7616 - val_VH_attention_linear_output_loss: 1.7498 - val_VL_attention_linear_output_acc: 0.4922 - val_VH_attention_linear_output_acc: 0.4890\n",
      "Epoch 3576/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3848 - VL_attention_linear_output_loss: 1.6946 - VH_attention_linear_output_loss: 1.6901 - VL_attention_linear_output_acc: 0.5006 - VH_attention_linear_output_acc: 0.5015 - val_loss: 3.5186 - val_VL_attention_linear_output_loss: 1.7652 - val_VH_attention_linear_output_loss: 1.7534 - val_VL_attention_linear_output_acc: 0.4906 - val_VH_attention_linear_output_acc: 0.4848\n",
      "Epoch 3577/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3719 - VL_attention_linear_output_loss: 1.6906 - VH_attention_linear_output_loss: 1.6812 - VL_attention_linear_output_acc: 0.5014 - VH_attention_linear_output_acc: 0.5057 - val_loss: 3.5268 - val_VL_attention_linear_output_loss: 1.7805 - val_VH_attention_linear_output_loss: 1.7463 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4869\n",
      "Epoch 3578/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3920 - VL_attention_linear_output_loss: 1.6960 - VH_attention_linear_output_loss: 1.6960 - VL_attention_linear_output_acc: 0.4999 - VH_attention_linear_output_acc: 0.4992 - val_loss: 3.5083 - val_VL_attention_linear_output_loss: 1.7547 - val_VH_attention_linear_output_loss: 1.7536 - val_VL_attention_linear_output_acc: 0.4947 - val_VH_attention_linear_output_acc: 0.4842\n",
      "Epoch 3579/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3744 - VL_attention_linear_output_loss: 1.6838 - VH_attention_linear_output_loss: 1.6906 - VL_attention_linear_output_acc: 0.5064 - VH_attention_linear_output_acc: 0.5015 - val_loss: 3.5042 - val_VL_attention_linear_output_loss: 1.7543 - val_VH_attention_linear_output_loss: 1.7499 - val_VL_attention_linear_output_acc: 0.4970 - val_VH_attention_linear_output_acc: 0.4901\n",
      "Epoch 3580/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3701 - VL_attention_linear_output_loss: 1.6882 - VH_attention_linear_output_loss: 1.6819 - VL_attention_linear_output_acc: 0.5034 - VH_attention_linear_output_acc: 0.5048 - val_loss: 3.5010 - val_VL_attention_linear_output_loss: 1.7572 - val_VH_attention_linear_output_loss: 1.7438 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.4930\n",
      "Epoch 3581/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3936 - VL_attention_linear_output_loss: 1.7022 - VH_attention_linear_output_loss: 1.6913 - VL_attention_linear_output_acc: 0.4971 - VH_attention_linear_output_acc: 0.5010 - val_loss: 3.5171 - val_VL_attention_linear_output_loss: 1.7679 - val_VH_attention_linear_output_loss: 1.7492 - val_VL_attention_linear_output_acc: 0.4884 - val_VH_attention_linear_output_acc: 0.4900\n",
      "Epoch 3582/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3684 - VL_attention_linear_output_loss: 1.6851 - VH_attention_linear_output_loss: 1.6833 - VL_attention_linear_output_acc: 0.5060 - VH_attention_linear_output_acc: 0.5048 - val_loss: 3.5124 - val_VL_attention_linear_output_loss: 1.7612 - val_VH_attention_linear_output_loss: 1.7512 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.4917\n",
      "Epoch 3583/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3764 - VL_attention_linear_output_loss: 1.6844 - VH_attention_linear_output_loss: 1.6920 - VL_attention_linear_output_acc: 0.5061 - VH_attention_linear_output_acc: 0.5007 - val_loss: 3.5019 - val_VL_attention_linear_output_loss: 1.7530 - val_VH_attention_linear_output_loss: 1.7489 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.4870\n",
      "Epoch 3584/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3725 - VL_attention_linear_output_loss: 1.6871 - VH_attention_linear_output_loss: 1.6855 - VL_attention_linear_output_acc: 0.5038 - VH_attention_linear_output_acc: 0.5036 - val_loss: 3.5067 - val_VL_attention_linear_output_loss: 1.7602 - val_VH_attention_linear_output_loss: 1.7465 - val_VL_attention_linear_output_acc: 0.4911 - val_VH_attention_linear_output_acc: 0.4883\n",
      "Epoch 3585/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3769 - VL_attention_linear_output_loss: 1.6925 - VH_attention_linear_output_loss: 1.6843 - VL_attention_linear_output_acc: 0.5015 - VH_attention_linear_output_acc: 0.5041 - val_loss: 3.4983 - val_VL_attention_linear_output_loss: 1.7536 - val_VH_attention_linear_output_loss: 1.7447 - val_VL_attention_linear_output_acc: 0.4949 - val_VH_attention_linear_output_acc: 0.4910\n",
      "Epoch 3586/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3693 - VL_attention_linear_output_loss: 1.6866 - VH_attention_linear_output_loss: 1.6827 - VL_attention_linear_output_acc: 0.5043 - VH_attention_linear_output_acc: 0.5044 - val_loss: 3.5093 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7465 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4882\n",
      "Epoch 3587/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3884 - VL_attention_linear_output_loss: 1.6999 - VH_attention_linear_output_loss: 1.6885 - VL_attention_linear_output_acc: 0.4990 - VH_attention_linear_output_acc: 0.5024 - val_loss: 3.5066 - val_VL_attention_linear_output_loss: 1.7536 - val_VH_attention_linear_output_loss: 1.7530 - val_VL_attention_linear_output_acc: 0.4947 - val_VH_attention_linear_output_acc: 0.4889\n",
      "Epoch 3588/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3765 - VL_attention_linear_output_loss: 1.6842 - VH_attention_linear_output_loss: 1.6922 - VL_attention_linear_output_acc: 0.5065 - VH_attention_linear_output_acc: 0.5009 - val_loss: 3.5304 - val_VL_attention_linear_output_loss: 1.7637 - val_VH_attention_linear_output_loss: 1.7667 - val_VL_attention_linear_output_acc: 0.4918 - val_VH_attention_linear_output_acc: 0.4845\n",
      "Epoch 3589/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3806 - VL_attention_linear_output_loss: 1.6872 - VH_attention_linear_output_loss: 1.6934 - VL_attention_linear_output_acc: 0.5048 - VH_attention_linear_output_acc: 0.5012 - val_loss: 3.4977 - val_VL_attention_linear_output_loss: 1.7518 - val_VH_attention_linear_output_loss: 1.7459 - val_VL_attention_linear_output_acc: 0.4968 - val_VH_attention_linear_output_acc: 0.4904\n",
      "Epoch 3590/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3708 - VL_attention_linear_output_loss: 1.6865 - VH_attention_linear_output_loss: 1.6843 - VL_attention_linear_output_acc: 0.5036 - VH_attention_linear_output_acc: 0.5039 - val_loss: 3.5073 - val_VL_attention_linear_output_loss: 1.7548 - val_VH_attention_linear_output_loss: 1.7525 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.4866\n",
      "Epoch 3591/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3662 - VL_attention_linear_output_loss: 1.6860 - VH_attention_linear_output_loss: 1.6801 - VL_attention_linear_output_acc: 0.5049 - VH_attention_linear_output_acc: 0.5053 - val_loss: 3.4960 - val_VL_attention_linear_output_loss: 1.7519 - val_VH_attention_linear_output_loss: 1.7441 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.4893\n",
      "Epoch 3592/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3692 - VL_attention_linear_output_loss: 1.6830 - VH_attention_linear_output_loss: 1.6862 - VL_attention_linear_output_acc: 0.5060 - VH_attention_linear_output_acc: 0.5031 - val_loss: 3.5011 - val_VL_attention_linear_output_loss: 1.7595 - val_VH_attention_linear_output_loss: 1.7416 - val_VL_attention_linear_output_acc: 0.4957 - val_VH_attention_linear_output_acc: 0.4906\n",
      "Epoch 3593/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3711 - VL_attention_linear_output_loss: 1.6916 - VH_attention_linear_output_loss: 1.6795 - VL_attention_linear_output_acc: 0.5001 - VH_attention_linear_output_acc: 0.5061 - val_loss: 3.5382 - val_VL_attention_linear_output_loss: 1.7822 - val_VH_attention_linear_output_loss: 1.7560 - val_VL_attention_linear_output_acc: 0.4735 - val_VH_attention_linear_output_acc: 0.4881\n",
      "Epoch 3594/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3851 - VL_attention_linear_output_loss: 1.6978 - VH_attention_linear_output_loss: 1.6873 - VL_attention_linear_output_acc: 0.4987 - VH_attention_linear_output_acc: 0.5029 - val_loss: 3.5067 - val_VL_attention_linear_output_loss: 1.7633 - val_VH_attention_linear_output_loss: 1.7434 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.4919\n",
      "Epoch 3595/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3745 - VL_attention_linear_output_loss: 1.6849 - VH_attention_linear_output_loss: 1.6896 - VL_attention_linear_output_acc: 0.5055 - VH_attention_linear_output_acc: 0.5022 - val_loss: 3.5178 - val_VL_attention_linear_output_loss: 1.7558 - val_VH_attention_linear_output_loss: 1.7621 - val_VL_attention_linear_output_acc: 0.4946 - val_VH_attention_linear_output_acc: 0.4825\n",
      "Epoch 3596/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3899 - VL_attention_linear_output_loss: 1.6946 - VH_attention_linear_output_loss: 1.6953 - VL_attention_linear_output_acc: 0.5005 - VH_attention_linear_output_acc: 0.4995 - val_loss: 3.5115 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7487 - val_VL_attention_linear_output_acc: 0.4892 - val_VH_attention_linear_output_acc: 0.4854\n",
      "Epoch 3597/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3766 - VL_attention_linear_output_loss: 1.6817 - VH_attention_linear_output_loss: 1.6949 - VL_attention_linear_output_acc: 0.5070 - VH_attention_linear_output_acc: 0.4995 - val_loss: 3.5118 - val_VL_attention_linear_output_loss: 1.7684 - val_VH_attention_linear_output_loss: 1.7434 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4887\n",
      "Epoch 3598/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3722 - VL_attention_linear_output_loss: 1.6856 - VH_attention_linear_output_loss: 1.6866 - VL_attention_linear_output_acc: 0.5040 - VH_attention_linear_output_acc: 0.5029 - val_loss: 3.5118 - val_VL_attention_linear_output_loss: 1.7692 - val_VH_attention_linear_output_loss: 1.7425 - val_VL_attention_linear_output_acc: 0.4889 - val_VH_attention_linear_output_acc: 0.4923\n",
      "Epoch 3599/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3804 - VL_attention_linear_output_loss: 1.6873 - VH_attention_linear_output_loss: 1.6931 - VL_attention_linear_output_acc: 0.5039 - VH_attention_linear_output_acc: 0.5013 - val_loss: 3.5027 - val_VL_attention_linear_output_loss: 1.7603 - val_VH_attention_linear_output_loss: 1.7424 - val_VL_attention_linear_output_acc: 0.4927 - val_VH_attention_linear_output_acc: 0.4896\n",
      "Epoch 3600/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3685 - VL_attention_linear_output_loss: 1.6865 - VH_attention_linear_output_loss: 1.6819 - VL_attention_linear_output_acc: 0.5038 - VH_attention_linear_output_acc: 0.5052 - val_loss: 3.4957 - val_VL_attention_linear_output_loss: 1.7484 - val_VH_attention_linear_output_loss: 1.7473 - val_VL_attention_linear_output_acc: 0.4979 - val_VH_attention_linear_output_acc: 0.4895\n",
      "Epoch 3601/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3811 - VL_attention_linear_output_loss: 1.6929 - VH_attention_linear_output_loss: 1.6882 - VL_attention_linear_output_acc: 0.5013 - VH_attention_linear_output_acc: 0.5017 - val_loss: 3.5393 - val_VL_attention_linear_output_loss: 1.7751 - val_VH_attention_linear_output_loss: 1.7642 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4858\n",
      "Epoch 3602/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3830 - VL_attention_linear_output_loss: 1.7001 - VH_attention_linear_output_loss: 1.6828 - VL_attention_linear_output_acc: 0.4980 - VH_attention_linear_output_acc: 0.5049 - val_loss: 3.4915 - val_VL_attention_linear_output_loss: 1.7499 - val_VH_attention_linear_output_loss: 1.7417 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.4920\n",
      "Epoch 3603/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3779 - VL_attention_linear_output_loss: 1.6923 - VH_attention_linear_output_loss: 1.6856 - VL_attention_linear_output_acc: 0.5007 - VH_attention_linear_output_acc: 0.5036 - val_loss: 3.5058 - val_VL_attention_linear_output_loss: 1.7556 - val_VH_attention_linear_output_loss: 1.7502 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.4912\n",
      "Epoch 3604/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3817 - VL_attention_linear_output_loss: 1.6935 - VH_attention_linear_output_loss: 1.6883 - VL_attention_linear_output_acc: 0.5011 - VH_attention_linear_output_acc: 0.5029 - val_loss: 3.5008 - val_VL_attention_linear_output_loss: 1.7585 - val_VH_attention_linear_output_loss: 1.7423 - val_VL_attention_linear_output_acc: 0.4917 - val_VH_attention_linear_output_acc: 0.4900\n",
      "Epoch 3605/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3848 - VL_attention_linear_output_loss: 1.6956 - VH_attention_linear_output_loss: 1.6892 - VL_attention_linear_output_acc: 0.4997 - VH_attention_linear_output_acc: 0.5023 - val_loss: 3.5598 - val_VL_attention_linear_output_loss: 1.8162 - val_VH_attention_linear_output_loss: 1.7437 - val_VL_attention_linear_output_acc: 0.4686 - val_VH_attention_linear_output_acc: 0.4921\n",
      "Epoch 3606/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3806 - VL_attention_linear_output_loss: 1.6968 - VH_attention_linear_output_loss: 1.6838 - VL_attention_linear_output_acc: 0.4990 - VH_attention_linear_output_acc: 0.5050 - val_loss: 3.4931 - val_VL_attention_linear_output_loss: 1.7526 - val_VH_attention_linear_output_loss: 1.7406 - val_VL_attention_linear_output_acc: 0.4904 - val_VH_attention_linear_output_acc: 0.4897\n",
      "Epoch 3607/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3876 - VL_attention_linear_output_loss: 1.6992 - VH_attention_linear_output_loss: 1.6884 - VL_attention_linear_output_acc: 0.4993 - VH_attention_linear_output_acc: 0.5029 - val_loss: 3.4971 - val_VL_attention_linear_output_loss: 1.7579 - val_VH_attention_linear_output_loss: 1.7392 - val_VL_attention_linear_output_acc: 0.4928 - val_VH_attention_linear_output_acc: 0.4911\n",
      "Epoch 3608/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3999 - VL_attention_linear_output_loss: 1.6917 - VH_attention_linear_output_loss: 1.7082 - VL_attention_linear_output_acc: 0.5019 - VH_attention_linear_output_acc: 0.4953 - val_loss: 3.5265 - val_VL_attention_linear_output_loss: 1.7704 - val_VH_attention_linear_output_loss: 1.7562 - val_VL_attention_linear_output_acc: 0.4885 - val_VH_attention_linear_output_acc: 0.4877\n",
      "Epoch 3609/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3625 - VL_attention_linear_output_loss: 1.6825 - VH_attention_linear_output_loss: 1.6800 - VL_attention_linear_output_acc: 0.5061 - VH_attention_linear_output_acc: 0.5062 - val_loss: 3.5080 - val_VL_attention_linear_output_loss: 1.7618 - val_VH_attention_linear_output_loss: 1.7462 - val_VL_attention_linear_output_acc: 0.4899 - val_VH_attention_linear_output_acc: 0.4918\n",
      "Epoch 3610/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3734 - VL_attention_linear_output_loss: 1.6978 - VH_attention_linear_output_loss: 1.6756 - VL_attention_linear_output_acc: 0.4980 - VH_attention_linear_output_acc: 0.5085 - val_loss: 3.5192 - val_VL_attention_linear_output_loss: 1.7783 - val_VH_attention_linear_output_loss: 1.7410 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4947\n",
      "Epoch 3611/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3717 - VL_attention_linear_output_loss: 1.6881 - VH_attention_linear_output_loss: 1.6835 - VL_attention_linear_output_acc: 0.5042 - VH_attention_linear_output_acc: 0.5047 - val_loss: 3.4846 - val_VL_attention_linear_output_loss: 1.7473 - val_VH_attention_linear_output_loss: 1.7373 - val_VL_attention_linear_output_acc: 0.4988 - val_VH_attention_linear_output_acc: 0.4905\n",
      "Epoch 3612/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3701 - VL_attention_linear_output_loss: 1.6876 - VH_attention_linear_output_loss: 1.6825 - VL_attention_linear_output_acc: 0.5025 - VH_attention_linear_output_acc: 0.5048 - val_loss: 3.5064 - val_VL_attention_linear_output_loss: 1.7582 - val_VH_attention_linear_output_loss: 1.7483 - val_VL_attention_linear_output_acc: 0.4961 - val_VH_attention_linear_output_acc: 0.4891\n",
      "Epoch 3613/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3797 - VL_attention_linear_output_loss: 1.6932 - VH_attention_linear_output_loss: 1.6866 - VL_attention_linear_output_acc: 0.5001 - VH_attention_linear_output_acc: 0.5033 - val_loss: 3.5129 - val_VL_attention_linear_output_loss: 1.7751 - val_VH_attention_linear_output_loss: 1.7377 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4941\n",
      "Epoch 3614/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3776 - VL_attention_linear_output_loss: 1.6910 - VH_attention_linear_output_loss: 1.6867 - VL_attention_linear_output_acc: 0.5012 - VH_attention_linear_output_acc: 0.5037 - val_loss: 3.4996 - val_VL_attention_linear_output_loss: 1.7570 - val_VH_attention_linear_output_loss: 1.7426 - val_VL_attention_linear_output_acc: 0.4893 - val_VH_attention_linear_output_acc: 0.4928\n",
      "Epoch 3615/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3805 - VL_attention_linear_output_loss: 1.6935 - VH_attention_linear_output_loss: 1.6870 - VL_attention_linear_output_acc: 0.5007 - VH_attention_linear_output_acc: 0.5036 - val_loss: 3.5023 - val_VL_attention_linear_output_loss: 1.7561 - val_VH_attention_linear_output_loss: 1.7461 - val_VL_attention_linear_output_acc: 0.4970 - val_VH_attention_linear_output_acc: 0.4913\n",
      "Epoch 3616/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3758 - VL_attention_linear_output_loss: 1.6921 - VH_attention_linear_output_loss: 1.6836 - VL_attention_linear_output_acc: 0.5023 - VH_attention_linear_output_acc: 0.5041 - val_loss: 3.4890 - val_VL_attention_linear_output_loss: 1.7526 - val_VH_attention_linear_output_loss: 1.7363 - val_VL_attention_linear_output_acc: 0.4919 - val_VH_attention_linear_output_acc: 0.4908\n",
      "Epoch 3617/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3759 - VL_attention_linear_output_loss: 1.6883 - VH_attention_linear_output_loss: 1.6876 - VL_attention_linear_output_acc: 0.5025 - VH_attention_linear_output_acc: 0.5031 - val_loss: 3.4982 - val_VL_attention_linear_output_loss: 1.7500 - val_VH_attention_linear_output_loss: 1.7483 - val_VL_attention_linear_output_acc: 0.4961 - val_VH_attention_linear_output_acc: 0.4874\n",
      "Epoch 3618/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3800 - VL_attention_linear_output_loss: 1.6944 - VH_attention_linear_output_loss: 1.6856 - VL_attention_linear_output_acc: 0.5008 - VH_attention_linear_output_acc: 0.5037 - val_loss: 3.5180 - val_VL_attention_linear_output_loss: 1.7755 - val_VH_attention_linear_output_loss: 1.7425 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.4877\n",
      "Epoch 3619/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3964 - VL_attention_linear_output_loss: 1.6981 - VH_attention_linear_output_loss: 1.6984 - VL_attention_linear_output_acc: 0.4987 - VH_attention_linear_output_acc: 0.4999 - val_loss: 3.4995 - val_VL_attention_linear_output_loss: 1.7516 - val_VH_attention_linear_output_loss: 1.7479 - val_VL_attention_linear_output_acc: 0.4974 - val_VH_attention_linear_output_acc: 0.4898\n",
      "Epoch 3620/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3869 - VL_attention_linear_output_loss: 1.6958 - VH_attention_linear_output_loss: 1.6911 - VL_attention_linear_output_acc: 0.4995 - VH_attention_linear_output_acc: 0.5023 - val_loss: 3.5211 - val_VL_attention_linear_output_loss: 1.7804 - val_VH_attention_linear_output_loss: 1.7408 - val_VL_attention_linear_output_acc: 0.4769 - val_VH_attention_linear_output_acc: 0.4932\n",
      "Epoch 3621/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3731 - VL_attention_linear_output_loss: 1.6827 - VH_attention_linear_output_loss: 1.6904 - VL_attention_linear_output_acc: 0.5057 - VH_attention_linear_output_acc: 0.5020 - val_loss: 3.5266 - val_VL_attention_linear_output_loss: 1.7686 - val_VH_attention_linear_output_loss: 1.7580 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4885\n",
      "Epoch 3622/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3833 - VL_attention_linear_output_loss: 1.6902 - VH_attention_linear_output_loss: 1.6931 - VL_attention_linear_output_acc: 0.5017 - VH_attention_linear_output_acc: 0.5013 - val_loss: 3.5220 - val_VL_attention_linear_output_loss: 1.7607 - val_VH_attention_linear_output_loss: 1.7613 - val_VL_attention_linear_output_acc: 0.4965 - val_VH_attention_linear_output_acc: 0.4873\n",
      "Epoch 3623/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3715 - VL_attention_linear_output_loss: 1.6823 - VH_attention_linear_output_loss: 1.6892 - VL_attention_linear_output_acc: 0.5060 - VH_attention_linear_output_acc: 0.5020 - val_loss: 3.5169 - val_VL_attention_linear_output_loss: 1.7659 - val_VH_attention_linear_output_loss: 1.7511 - val_VL_attention_linear_output_acc: 0.4921 - val_VH_attention_linear_output_acc: 0.4879\n",
      "Epoch 3624/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3737 - VL_attention_linear_output_loss: 1.6887 - VH_attention_linear_output_loss: 1.6849 - VL_attention_linear_output_acc: 0.5036 - VH_attention_linear_output_acc: 0.5041 - val_loss: 3.6181 - val_VL_attention_linear_output_loss: 1.8536 - val_VH_attention_linear_output_loss: 1.7646 - val_VL_attention_linear_output_acc: 0.4413 - val_VH_attention_linear_output_acc: 0.4839\n",
      "Epoch 3625/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3831 - VL_attention_linear_output_loss: 1.6889 - VH_attention_linear_output_loss: 1.6942 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5005 - val_loss: 3.4915 - val_VL_attention_linear_output_loss: 1.7540 - val_VH_attention_linear_output_loss: 1.7376 - val_VL_attention_linear_output_acc: 0.4958 - val_VH_attention_linear_output_acc: 0.4954\n",
      "Epoch 3626/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3561 - VL_attention_linear_output_loss: 1.6800 - VH_attention_linear_output_loss: 1.6761 - VL_attention_linear_output_acc: 0.5082 - VH_attention_linear_output_acc: 0.5080 - val_loss: 3.4993 - val_VL_attention_linear_output_loss: 1.7601 - val_VH_attention_linear_output_loss: 1.7393 - val_VL_attention_linear_output_acc: 0.4902 - val_VH_attention_linear_output_acc: 0.4895\n",
      "Epoch 3627/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3615 - VL_attention_linear_output_loss: 1.6829 - VH_attention_linear_output_loss: 1.6786 - VL_attention_linear_output_acc: 0.5061 - VH_attention_linear_output_acc: 0.5071 - val_loss: 3.4996 - val_VL_attention_linear_output_loss: 1.7519 - val_VH_attention_linear_output_loss: 1.7477 - val_VL_attention_linear_output_acc: 0.4916 - val_VH_attention_linear_output_acc: 0.4891\n",
      "Epoch 3628/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3692 - VL_attention_linear_output_loss: 1.6902 - VH_attention_linear_output_loss: 1.6789 - VL_attention_linear_output_acc: 0.5022 - VH_attention_linear_output_acc: 0.5067 - val_loss: 3.5057 - val_VL_attention_linear_output_loss: 1.7655 - val_VH_attention_linear_output_loss: 1.7402 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.4928\n",
      "Epoch 3629/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3881 - VL_attention_linear_output_loss: 1.6912 - VH_attention_linear_output_loss: 1.6969 - VL_attention_linear_output_acc: 0.5024 - VH_attention_linear_output_acc: 0.5006 - val_loss: 3.4920 - val_VL_attention_linear_output_loss: 1.7514 - val_VH_attention_linear_output_loss: 1.7406 - val_VL_attention_linear_output_acc: 0.4946 - val_VH_attention_linear_output_acc: 0.4949\n",
      "Epoch 3630/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3774 - VL_attention_linear_output_loss: 1.6897 - VH_attention_linear_output_loss: 1.6877 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5028 - val_loss: 3.6006 - val_VL_attention_linear_output_loss: 1.8151 - val_VH_attention_linear_output_loss: 1.7855 - val_VL_attention_linear_output_acc: 0.4599 - val_VH_attention_linear_output_acc: 0.4704\n",
      "Epoch 3631/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3610 - VL_attention_linear_output_loss: 1.6821 - VH_attention_linear_output_loss: 1.6789 - VL_attention_linear_output_acc: 0.5073 - VH_attention_linear_output_acc: 0.5065 - val_loss: 3.5074 - val_VL_attention_linear_output_loss: 1.7555 - val_VH_attention_linear_output_loss: 1.7519 - val_VL_attention_linear_output_acc: 0.4933 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3632/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3564 - VL_attention_linear_output_loss: 1.6787 - VH_attention_linear_output_loss: 1.6777 - VL_attention_linear_output_acc: 0.5079 - VH_attention_linear_output_acc: 0.5063 - val_loss: 3.4940 - val_VL_attention_linear_output_loss: 1.7497 - val_VH_attention_linear_output_loss: 1.7443 - val_VL_attention_linear_output_acc: 0.4965 - val_VH_attention_linear_output_acc: 0.4934\n",
      "Epoch 3633/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3611 - VL_attention_linear_output_loss: 1.6840 - VH_attention_linear_output_loss: 1.6770 - VL_attention_linear_output_acc: 0.5053 - VH_attention_linear_output_acc: 0.5073 - val_loss: 3.4936 - val_VL_attention_linear_output_loss: 1.7512 - val_VH_attention_linear_output_loss: 1.7424 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.4961\n",
      "Epoch 3634/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3699 - VL_attention_linear_output_loss: 1.6877 - VH_attention_linear_output_loss: 1.6822 - VL_attention_linear_output_acc: 0.5037 - VH_attention_linear_output_acc: 0.5052 - val_loss: 3.5118 - val_VL_attention_linear_output_loss: 1.7673 - val_VH_attention_linear_output_loss: 1.7444 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.4890\n",
      "Epoch 3635/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3782 - VL_attention_linear_output_loss: 1.6961 - VH_attention_linear_output_loss: 1.6821 - VL_attention_linear_output_acc: 0.4991 - VH_attention_linear_output_acc: 0.5047 - val_loss: 3.4911 - val_VL_attention_linear_output_loss: 1.7541 - val_VH_attention_linear_output_loss: 1.7370 - val_VL_attention_linear_output_acc: 0.4953 - val_VH_attention_linear_output_acc: 0.4951\n",
      "Epoch 3636/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3641 - VL_attention_linear_output_loss: 1.6871 - VH_attention_linear_output_loss: 1.6770 - VL_attention_linear_output_acc: 0.5047 - VH_attention_linear_output_acc: 0.5074 - val_loss: 3.4896 - val_VL_attention_linear_output_loss: 1.7538 - val_VH_attention_linear_output_loss: 1.7357 - val_VL_attention_linear_output_acc: 0.4947 - val_VH_attention_linear_output_acc: 0.4922\n",
      "Epoch 3637/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3774 - VL_attention_linear_output_loss: 1.6884 - VH_attention_linear_output_loss: 1.6890 - VL_attention_linear_output_acc: 0.5037 - VH_attention_linear_output_acc: 0.5018 - val_loss: 3.4914 - val_VL_attention_linear_output_loss: 1.7536 - val_VH_attention_linear_output_loss: 1.7379 - val_VL_attention_linear_output_acc: 0.4947 - val_VH_attention_linear_output_acc: 0.4957\n",
      "Epoch 3638/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3693 - VL_attention_linear_output_loss: 1.6918 - VH_attention_linear_output_loss: 1.6775 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5072 - val_loss: 3.4994 - val_VL_attention_linear_output_loss: 1.7527 - val_VH_attention_linear_output_loss: 1.7468 - val_VL_attention_linear_output_acc: 0.4925 - val_VH_attention_linear_output_acc: 0.4909\n",
      "Epoch 3639/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3647 - VL_attention_linear_output_loss: 1.6833 - VH_attention_linear_output_loss: 1.6813 - VL_attention_linear_output_acc: 0.5057 - VH_attention_linear_output_acc: 0.5054 - val_loss: 3.5192 - val_VL_attention_linear_output_loss: 1.7759 - val_VH_attention_linear_output_loss: 1.7434 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4924\n",
      "Epoch 3640/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3729 - VL_attention_linear_output_loss: 1.6898 - VH_attention_linear_output_loss: 1.6831 - VL_attention_linear_output_acc: 0.5026 - VH_attention_linear_output_acc: 0.5054 - val_loss: 3.4929 - val_VL_attention_linear_output_loss: 1.7537 - val_VH_attention_linear_output_loss: 1.7392 - val_VL_attention_linear_output_acc: 0.4955 - val_VH_attention_linear_output_acc: 0.4927\n",
      "Epoch 3641/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3713 - VL_attention_linear_output_loss: 1.6843 - VH_attention_linear_output_loss: 1.6870 - VL_attention_linear_output_acc: 0.5052 - VH_attention_linear_output_acc: 0.5027 - val_loss: 3.5112 - val_VL_attention_linear_output_loss: 1.7742 - val_VH_attention_linear_output_loss: 1.7370 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4941\n",
      "Epoch 3642/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3843 - VL_attention_linear_output_loss: 1.6960 - VH_attention_linear_output_loss: 1.6882 - VL_attention_linear_output_acc: 0.4985 - VH_attention_linear_output_acc: 0.5022 - val_loss: 3.5280 - val_VL_attention_linear_output_loss: 1.7611 - val_VH_attention_linear_output_loss: 1.7669 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3643/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3584 - VL_attention_linear_output_loss: 1.6832 - VH_attention_linear_output_loss: 1.6753 - VL_attention_linear_output_acc: 0.5056 - VH_attention_linear_output_acc: 0.5078 - val_loss: 3.4863 - val_VL_attention_linear_output_loss: 1.7491 - val_VH_attention_linear_output_loss: 1.7372 - val_VL_attention_linear_output_acc: 0.4975 - val_VH_attention_linear_output_acc: 0.4962\n",
      "Epoch 3644/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3700 - VL_attention_linear_output_loss: 1.6873 - VH_attention_linear_output_loss: 1.6827 - VL_attention_linear_output_acc: 0.5043 - VH_attention_linear_output_acc: 0.5040 - val_loss: 3.5028 - val_VL_attention_linear_output_loss: 1.7644 - val_VH_attention_linear_output_loss: 1.7384 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4959\n",
      "Epoch 3645/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3726 - VL_attention_linear_output_loss: 1.6989 - VH_attention_linear_output_loss: 1.6736 - VL_attention_linear_output_acc: 0.4978 - VH_attention_linear_output_acc: 0.5084 - val_loss: 3.5147 - val_VL_attention_linear_output_loss: 1.7648 - val_VH_attention_linear_output_loss: 1.7500 - val_VL_attention_linear_output_acc: 0.4842 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3646/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3605 - VL_attention_linear_output_loss: 1.6834 - VH_attention_linear_output_loss: 1.6771 - VL_attention_linear_output_acc: 0.5059 - VH_attention_linear_output_acc: 0.5078 - val_loss: 3.5220 - val_VL_attention_linear_output_loss: 1.7631 - val_VH_attention_linear_output_loss: 1.7589 - val_VL_attention_linear_output_acc: 0.4935 - val_VH_attention_linear_output_acc: 0.4857\n",
      "Epoch 3647/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3610 - VL_attention_linear_output_loss: 1.6828 - VH_attention_linear_output_loss: 1.6782 - VL_attention_linear_output_acc: 0.5043 - VH_attention_linear_output_acc: 0.5064 - val_loss: 3.5167 - val_VL_attention_linear_output_loss: 1.7760 - val_VH_attention_linear_output_loss: 1.7406 - val_VL_attention_linear_output_acc: 0.4865 - val_VH_attention_linear_output_acc: 0.4909\n",
      "Epoch 3648/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3693 - VL_attention_linear_output_loss: 1.6895 - VH_attention_linear_output_loss: 1.6798 - VL_attention_linear_output_acc: 0.5017 - VH_attention_linear_output_acc: 0.5060 - val_loss: 3.5054 - val_VL_attention_linear_output_loss: 1.7550 - val_VH_attention_linear_output_loss: 1.7504 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.4902\n",
      "Epoch 3649/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3783 - VL_attention_linear_output_loss: 1.6920 - VH_attention_linear_output_loss: 1.6863 - VL_attention_linear_output_acc: 0.5009 - VH_attention_linear_output_acc: 0.5030 - val_loss: 3.5248 - val_VL_attention_linear_output_loss: 1.7771 - val_VH_attention_linear_output_loss: 1.7477 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.4945\n",
      "Epoch 3650/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3720 - VL_attention_linear_output_loss: 1.6891 - VH_attention_linear_output_loss: 1.6828 - VL_attention_linear_output_acc: 0.5036 - VH_attention_linear_output_acc: 0.5045 - val_loss: 3.4886 - val_VL_attention_linear_output_loss: 1.7499 - val_VH_attention_linear_output_loss: 1.7388 - val_VL_attention_linear_output_acc: 0.4965 - val_VH_attention_linear_output_acc: 0.4934\n",
      "Epoch 3651/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3664 - VL_attention_linear_output_loss: 1.6887 - VH_attention_linear_output_loss: 1.6776 - VL_attention_linear_output_acc: 0.5023 - VH_attention_linear_output_acc: 0.5069 - val_loss: 3.5108 - val_VL_attention_linear_output_loss: 1.7717 - val_VH_attention_linear_output_loss: 1.7391 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4957\n",
      "Epoch 3652/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3779 - VL_attention_linear_output_loss: 1.6933 - VH_attention_linear_output_loss: 1.6846 - VL_attention_linear_output_acc: 0.5015 - VH_attention_linear_output_acc: 0.5042 - val_loss: 3.5034 - val_VL_attention_linear_output_loss: 1.7593 - val_VH_attention_linear_output_loss: 1.7442 - val_VL_attention_linear_output_acc: 0.4946 - val_VH_attention_linear_output_acc: 0.4918\n",
      "Epoch 3653/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3629 - VL_attention_linear_output_loss: 1.6875 - VH_attention_linear_output_loss: 1.6755 - VL_attention_linear_output_acc: 0.5028 - VH_attention_linear_output_acc: 0.5083 - val_loss: 3.4915 - val_VL_attention_linear_output_loss: 1.7490 - val_VH_attention_linear_output_loss: 1.7425 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.4927\n",
      "Epoch 3654/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3708 - VL_attention_linear_output_loss: 1.6800 - VH_attention_linear_output_loss: 1.6908 - VL_attention_linear_output_acc: 0.5060 - VH_attention_linear_output_acc: 0.5019 - val_loss: 3.4992 - val_VL_attention_linear_output_loss: 1.7497 - val_VH_attention_linear_output_loss: 1.7495 - val_VL_attention_linear_output_acc: 0.4963 - val_VH_attention_linear_output_acc: 0.4918\n",
      "Epoch 3655/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3671 - VL_attention_linear_output_loss: 1.6866 - VH_attention_linear_output_loss: 1.6805 - VL_attention_linear_output_acc: 0.5032 - VH_attention_linear_output_acc: 0.5058 - val_loss: 3.5411 - val_VL_attention_linear_output_loss: 1.7764 - val_VH_attention_linear_output_loss: 1.7647 - val_VL_attention_linear_output_acc: 0.4826 - val_VH_attention_linear_output_acc: 0.4865\n",
      "Epoch 3656/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3705 - VL_attention_linear_output_loss: 1.6834 - VH_attention_linear_output_loss: 1.6871 - VL_attention_linear_output_acc: 0.5048 - VH_attention_linear_output_acc: 0.5035 - val_loss: 3.5207 - val_VL_attention_linear_output_loss: 1.7748 - val_VH_attention_linear_output_loss: 1.7459 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.4883\n",
      "Epoch 3657/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3551 - VL_attention_linear_output_loss: 1.6812 - VH_attention_linear_output_loss: 1.6738 - VL_attention_linear_output_acc: 0.5067 - VH_attention_linear_output_acc: 0.5084 - val_loss: 3.5058 - val_VL_attention_linear_output_loss: 1.7690 - val_VH_attention_linear_output_loss: 1.7368 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.4952\n",
      "Epoch 3658/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3730 - VL_attention_linear_output_loss: 1.6957 - VH_attention_linear_output_loss: 1.6773 - VL_attention_linear_output_acc: 0.4986 - VH_attention_linear_output_acc: 0.5073 - val_loss: 3.4955 - val_VL_attention_linear_output_loss: 1.7459 - val_VH_attention_linear_output_loss: 1.7496 - val_VL_attention_linear_output_acc: 0.4999 - val_VH_attention_linear_output_acc: 0.4875\n",
      "Epoch 3659/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3688 - VL_attention_linear_output_loss: 1.6882 - VH_attention_linear_output_loss: 1.6806 - VL_attention_linear_output_acc: 0.5025 - VH_attention_linear_output_acc: 0.5060 - val_loss: 3.5080 - val_VL_attention_linear_output_loss: 1.7569 - val_VH_attention_linear_output_loss: 1.7511 - val_VL_attention_linear_output_acc: 0.4955 - val_VH_attention_linear_output_acc: 0.4864\n",
      "Epoch 3660/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3822 - VL_attention_linear_output_loss: 1.6902 - VH_attention_linear_output_loss: 1.6919 - VL_attention_linear_output_acc: 0.5024 - VH_attention_linear_output_acc: 0.5013 - val_loss: 3.5004 - val_VL_attention_linear_output_loss: 1.7520 - val_VH_attention_linear_output_loss: 1.7484 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.4901\n",
      "Epoch 3661/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3655 - VL_attention_linear_output_loss: 1.6834 - VH_attention_linear_output_loss: 1.6821 - VL_attention_linear_output_acc: 0.5055 - VH_attention_linear_output_acc: 0.5058 - val_loss: 3.4948 - val_VL_attention_linear_output_loss: 1.7522 - val_VH_attention_linear_output_loss: 1.7426 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.4923\n",
      "Epoch 3662/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3789 - VL_attention_linear_output_loss: 1.6946 - VH_attention_linear_output_loss: 1.6842 - VL_attention_linear_output_acc: 0.4992 - VH_attention_linear_output_acc: 0.5038 - val_loss: 3.5016 - val_VL_attention_linear_output_loss: 1.7485 - val_VH_attention_linear_output_loss: 1.7531 - val_VL_attention_linear_output_acc: 0.4979 - val_VH_attention_linear_output_acc: 0.4892\n",
      "Epoch 3663/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3675 - VL_attention_linear_output_loss: 1.6801 - VH_attention_linear_output_loss: 1.6874 - VL_attention_linear_output_acc: 0.5074 - VH_attention_linear_output_acc: 0.5032 - val_loss: 3.5083 - val_VL_attention_linear_output_loss: 1.7495 - val_VH_attention_linear_output_loss: 1.7588 - val_VL_attention_linear_output_acc: 0.4961 - val_VH_attention_linear_output_acc: 0.4864\n",
      "Epoch 3664/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3689 - VL_attention_linear_output_loss: 1.6827 - VH_attention_linear_output_loss: 1.6862 - VL_attention_linear_output_acc: 0.5068 - VH_attention_linear_output_acc: 0.5045 - val_loss: 3.4845 - val_VL_attention_linear_output_loss: 1.7485 - val_VH_attention_linear_output_loss: 1.7360 - val_VL_attention_linear_output_acc: 0.4966 - val_VH_attention_linear_output_acc: 0.4957\n",
      "Epoch 3665/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3672 - VL_attention_linear_output_loss: 1.6887 - VH_attention_linear_output_loss: 1.6785 - VL_attention_linear_output_acc: 0.5024 - VH_attention_linear_output_acc: 0.5060 - val_loss: 3.4904 - val_VL_attention_linear_output_loss: 1.7542 - val_VH_attention_linear_output_loss: 1.7361 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.4940\n",
      "Epoch 3666/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3720 - VL_attention_linear_output_loss: 1.6916 - VH_attention_linear_output_loss: 1.6804 - VL_attention_linear_output_acc: 0.5019 - VH_attention_linear_output_acc: 0.5057 - val_loss: 3.5647 - val_VL_attention_linear_output_loss: 1.7513 - val_VH_attention_linear_output_loss: 1.8134 - val_VL_attention_linear_output_acc: 0.4966 - val_VH_attention_linear_output_acc: 0.4714\n",
      "Epoch 3667/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3679 - VL_attention_linear_output_loss: 1.6889 - VH_attention_linear_output_loss: 1.6790 - VL_attention_linear_output_acc: 0.5032 - VH_attention_linear_output_acc: 0.5072 - val_loss: 3.4971 - val_VL_attention_linear_output_loss: 1.7607 - val_VH_attention_linear_output_loss: 1.7364 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.4917\n",
      "Epoch 3668/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3857 - VL_attention_linear_output_loss: 1.6963 - VH_attention_linear_output_loss: 1.6894 - VL_attention_linear_output_acc: 0.4992 - VH_attention_linear_output_acc: 0.5027 - val_loss: 3.4995 - val_VL_attention_linear_output_loss: 1.7495 - val_VH_attention_linear_output_loss: 1.7499 - val_VL_attention_linear_output_acc: 0.4996 - val_VH_attention_linear_output_acc: 0.4872\n",
      "Epoch 3669/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3744 - VL_attention_linear_output_loss: 1.6870 - VH_attention_linear_output_loss: 1.6874 - VL_attention_linear_output_acc: 0.5034 - VH_attention_linear_output_acc: 0.5032 - val_loss: 3.5130 - val_VL_attention_linear_output_loss: 1.7656 - val_VH_attention_linear_output_loss: 1.7474 - val_VL_attention_linear_output_acc: 0.4939 - val_VH_attention_linear_output_acc: 0.4861\n",
      "Epoch 3670/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3640 - VL_attention_linear_output_loss: 1.6839 - VH_attention_linear_output_loss: 1.6800 - VL_attention_linear_output_acc: 0.5050 - VH_attention_linear_output_acc: 0.5059 - val_loss: 3.4838 - val_VL_attention_linear_output_loss: 1.7483 - val_VH_attention_linear_output_loss: 1.7355 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.4975\n",
      "Epoch 3671/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3599 - VL_attention_linear_output_loss: 1.6825 - VH_attention_linear_output_loss: 1.6773 - VL_attention_linear_output_acc: 0.5043 - VH_attention_linear_output_acc: 0.5070 - val_loss: 3.4909 - val_VL_attention_linear_output_loss: 1.7566 - val_VH_attention_linear_output_loss: 1.7343 - val_VL_attention_linear_output_acc: 0.4943 - val_VH_attention_linear_output_acc: 0.4971\n",
      "Epoch 3672/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3736 - VL_attention_linear_output_loss: 1.6896 - VH_attention_linear_output_loss: 1.6840 - VL_attention_linear_output_acc: 0.5020 - VH_attention_linear_output_acc: 0.5049 - val_loss: 3.4898 - val_VL_attention_linear_output_loss: 1.7495 - val_VH_attention_linear_output_loss: 1.7403 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.4921\n",
      "Epoch 3673/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3712 - VL_attention_linear_output_loss: 1.6874 - VH_attention_linear_output_loss: 1.6838 - VL_attention_linear_output_acc: 0.5037 - VH_attention_linear_output_acc: 0.5052 - val_loss: 3.5253 - val_VL_attention_linear_output_loss: 1.7678 - val_VH_attention_linear_output_loss: 1.7575 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.4794\n",
      "Epoch 3674/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3764 - VL_attention_linear_output_loss: 1.6949 - VH_attention_linear_output_loss: 1.6815 - VL_attention_linear_output_acc: 0.5005 - VH_attention_linear_output_acc: 0.5058 - val_loss: 3.5073 - val_VL_attention_linear_output_loss: 1.7533 - val_VH_attention_linear_output_loss: 1.7540 - val_VL_attention_linear_output_acc: 0.4942 - val_VH_attention_linear_output_acc: 0.4851\n",
      "Epoch 3675/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3634 - VL_attention_linear_output_loss: 1.6827 - VH_attention_linear_output_loss: 1.6807 - VL_attention_linear_output_acc: 0.5048 - VH_attention_linear_output_acc: 0.5058 - val_loss: 3.5036 - val_VL_attention_linear_output_loss: 1.7534 - val_VH_attention_linear_output_loss: 1.7503 - val_VL_attention_linear_output_acc: 0.4952 - val_VH_attention_linear_output_acc: 0.4895\n",
      "Epoch 3676/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3691 - VL_attention_linear_output_loss: 1.6881 - VH_attention_linear_output_loss: 1.6810 - VL_attention_linear_output_acc: 0.5028 - VH_attention_linear_output_acc: 0.5058 - val_loss: 3.4922 - val_VL_attention_linear_output_loss: 1.7553 - val_VH_attention_linear_output_loss: 1.7370 - val_VL_attention_linear_output_acc: 0.4932 - val_VH_attention_linear_output_acc: 0.4962\n",
      "Epoch 3677/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3802 - VL_attention_linear_output_loss: 1.6900 - VH_attention_linear_output_loss: 1.6901 - VL_attention_linear_output_acc: 0.5027 - VH_attention_linear_output_acc: 0.5025 - val_loss: 3.5105 - val_VL_attention_linear_output_loss: 1.7587 - val_VH_attention_linear_output_loss: 1.7518 - val_VL_attention_linear_output_acc: 0.4921 - val_VH_attention_linear_output_acc: 0.4917\n",
      "Epoch 3678/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3657 - VL_attention_linear_output_loss: 1.6837 - VH_attention_linear_output_loss: 1.6820 - VL_attention_linear_output_acc: 0.5055 - VH_attention_linear_output_acc: 0.5055 - val_loss: 3.4887 - val_VL_attention_linear_output_loss: 1.7519 - val_VH_attention_linear_output_loss: 1.7368 - val_VL_attention_linear_output_acc: 0.4947 - val_VH_attention_linear_output_acc: 0.4979\n",
      "Epoch 3679/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3644 - VL_attention_linear_output_loss: 1.6871 - VH_attention_linear_output_loss: 1.6773 - VL_attention_linear_output_acc: 0.5030 - VH_attention_linear_output_acc: 0.5076 - val_loss: 3.5044 - val_VL_attention_linear_output_loss: 1.7543 - val_VH_attention_linear_output_loss: 1.7502 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.4931\n",
      "Epoch 3680/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3814 - VL_attention_linear_output_loss: 1.6894 - VH_attention_linear_output_loss: 1.6920 - VL_attention_linear_output_acc: 0.5024 - VH_attention_linear_output_acc: 0.5024 - val_loss: 3.5165 - val_VL_attention_linear_output_loss: 1.7527 - val_VH_attention_linear_output_loss: 1.7637 - val_VL_attention_linear_output_acc: 0.4952 - val_VH_attention_linear_output_acc: 0.4830\n",
      "Epoch 3681/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3548 - VL_attention_linear_output_loss: 1.6787 - VH_attention_linear_output_loss: 1.6761 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5071 - val_loss: 3.4966 - val_VL_attention_linear_output_loss: 1.7608 - val_VH_attention_linear_output_loss: 1.7358 - val_VL_attention_linear_output_acc: 0.4900 - val_VH_attention_linear_output_acc: 0.4951\n",
      "Epoch 3682/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3665 - VL_attention_linear_output_loss: 1.6813 - VH_attention_linear_output_loss: 1.6853 - VL_attention_linear_output_acc: 0.5063 - VH_attention_linear_output_acc: 0.5041 - val_loss: 3.5474 - val_VL_attention_linear_output_loss: 1.7495 - val_VH_attention_linear_output_loss: 1.7979 - val_VL_attention_linear_output_acc: 0.4933 - val_VH_attention_linear_output_acc: 0.4741\n",
      "Epoch 3683/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3707 - VL_attention_linear_output_loss: 1.6881 - VH_attention_linear_output_loss: 1.6826 - VL_attention_linear_output_acc: 0.5029 - VH_attention_linear_output_acc: 0.5057 - val_loss: 3.5005 - val_VL_attention_linear_output_loss: 1.7527 - val_VH_attention_linear_output_loss: 1.7478 - val_VL_attention_linear_output_acc: 0.4918 - val_VH_attention_linear_output_acc: 0.4926\n",
      "Epoch 3684/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3746 - VL_attention_linear_output_loss: 1.6875 - VH_attention_linear_output_loss: 1.6871 - VL_attention_linear_output_acc: 0.5027 - VH_attention_linear_output_acc: 0.5034 - val_loss: 3.5770 - val_VL_attention_linear_output_loss: 1.8145 - val_VH_attention_linear_output_loss: 1.7625 - val_VL_attention_linear_output_acc: 0.4506 - val_VH_attention_linear_output_acc: 0.4852\n",
      "Epoch 3685/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3620 - VL_attention_linear_output_loss: 1.6788 - VH_attention_linear_output_loss: 1.6833 - VL_attention_linear_output_acc: 0.5076 - VH_attention_linear_output_acc: 0.5057 - val_loss: 3.5046 - val_VL_attention_linear_output_loss: 1.7691 - val_VH_attention_linear_output_loss: 1.7354 - val_VL_attention_linear_output_acc: 0.4783 - val_VH_attention_linear_output_acc: 0.4938\n",
      "Epoch 3686/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3549 - VL_attention_linear_output_loss: 1.6829 - VH_attention_linear_output_loss: 1.6720 - VL_attention_linear_output_acc: 0.5044 - VH_attention_linear_output_acc: 0.5098 - val_loss: 3.5410 - val_VL_attention_linear_output_loss: 1.8056 - val_VH_attention_linear_output_loss: 1.7353 - val_VL_attention_linear_output_acc: 0.4646 - val_VH_attention_linear_output_acc: 0.4965\n",
      "Epoch 3687/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3696 - VL_attention_linear_output_loss: 1.6851 - VH_attention_linear_output_loss: 1.6845 - VL_attention_linear_output_acc: 0.5034 - VH_attention_linear_output_acc: 0.5052 - val_loss: 3.4790 - val_VL_attention_linear_output_loss: 1.7439 - val_VH_attention_linear_output_loss: 1.7351 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.4944\n",
      "Epoch 3688/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3753 - VL_attention_linear_output_loss: 1.6893 - VH_attention_linear_output_loss: 1.6859 - VL_attention_linear_output_acc: 0.5025 - VH_attention_linear_output_acc: 0.5039 - val_loss: 3.4920 - val_VL_attention_linear_output_loss: 1.7463 - val_VH_attention_linear_output_loss: 1.7457 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.4946\n",
      "Epoch 3689/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3683 - VL_attention_linear_output_loss: 1.6849 - VH_attention_linear_output_loss: 1.6834 - VL_attention_linear_output_acc: 0.5040 - VH_attention_linear_output_acc: 0.5045 - val_loss: 3.4847 - val_VL_attention_linear_output_loss: 1.7433 - val_VH_attention_linear_output_loss: 1.7414 - val_VL_attention_linear_output_acc: 0.4979 - val_VH_attention_linear_output_acc: 0.4899\n",
      "Epoch 3690/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3777 - VL_attention_linear_output_loss: 1.6895 - VH_attention_linear_output_loss: 1.6882 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5032 - val_loss: 3.4982 - val_VL_attention_linear_output_loss: 1.7565 - val_VH_attention_linear_output_loss: 1.7417 - val_VL_attention_linear_output_acc: 0.4910 - val_VH_attention_linear_output_acc: 0.4965\n",
      "Epoch 3691/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3897 - VL_attention_linear_output_loss: 1.6964 - VH_attention_linear_output_loss: 1.6932 - VL_attention_linear_output_acc: 0.4995 - VH_attention_linear_output_acc: 0.5017 - val_loss: 3.5221 - val_VL_attention_linear_output_loss: 1.7770 - val_VH_attention_linear_output_loss: 1.7451 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.4896\n",
      "Epoch 3692/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3706 - VL_attention_linear_output_loss: 1.6932 - VH_attention_linear_output_loss: 1.6774 - VL_attention_linear_output_acc: 0.5003 - VH_attention_linear_output_acc: 0.5075 - val_loss: 3.5832 - val_VL_attention_linear_output_loss: 1.8309 - val_VH_attention_linear_output_loss: 1.7523 - val_VL_attention_linear_output_acc: 0.4519 - val_VH_attention_linear_output_acc: 0.4891\n",
      "Epoch 3693/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3738 - VL_attention_linear_output_loss: 1.6923 - VH_attention_linear_output_loss: 1.6815 - VL_attention_linear_output_acc: 0.5012 - VH_attention_linear_output_acc: 0.5054 - val_loss: 3.5417 - val_VL_attention_linear_output_loss: 1.7956 - val_VH_attention_linear_output_loss: 1.7460 - val_VL_attention_linear_output_acc: 0.4731 - val_VH_attention_linear_output_acc: 0.4930\n",
      "Epoch 3694/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3776 - VL_attention_linear_output_loss: 1.6917 - VH_attention_linear_output_loss: 1.6858 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5047 - val_loss: 3.5244 - val_VL_attention_linear_output_loss: 1.7506 - val_VH_attention_linear_output_loss: 1.7738 - val_VL_attention_linear_output_acc: 0.4914 - val_VH_attention_linear_output_acc: 0.4822\n",
      "Epoch 3695/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3677 - VL_attention_linear_output_loss: 1.6816 - VH_attention_linear_output_loss: 1.6861 - VL_attention_linear_output_acc: 0.5056 - VH_attention_linear_output_acc: 0.5048 - val_loss: 3.5123 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7495 - val_VL_attention_linear_output_acc: 0.4895 - val_VH_attention_linear_output_acc: 0.4913\n",
      "Epoch 3696/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3677 - VL_attention_linear_output_loss: 1.6924 - VH_attention_linear_output_loss: 1.6753 - VL_attention_linear_output_acc: 0.5005 - VH_attention_linear_output_acc: 0.5092 - val_loss: 3.4889 - val_VL_attention_linear_output_loss: 1.7525 - val_VH_attention_linear_output_loss: 1.7364 - val_VL_attention_linear_output_acc: 0.4949 - val_VH_attention_linear_output_acc: 0.4953\n",
      "Epoch 3697/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3556 - VL_attention_linear_output_loss: 1.6801 - VH_attention_linear_output_loss: 1.6755 - VL_attention_linear_output_acc: 0.5066 - VH_attention_linear_output_acc: 0.5084 - val_loss: 3.4877 - val_VL_attention_linear_output_loss: 1.7448 - val_VH_attention_linear_output_loss: 1.7429 - val_VL_attention_linear_output_acc: 0.4995 - val_VH_attention_linear_output_acc: 0.4929\n",
      "Epoch 3698/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3693 - VL_attention_linear_output_loss: 1.6878 - VH_attention_linear_output_loss: 1.6815 - VL_attention_linear_output_acc: 0.5039 - VH_attention_linear_output_acc: 0.5064 - val_loss: 3.4888 - val_VL_attention_linear_output_loss: 1.7477 - val_VH_attention_linear_output_loss: 1.7411 - val_VL_attention_linear_output_acc: 0.4960 - val_VH_attention_linear_output_acc: 0.4929\n",
      "Epoch 3699/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3643 - VL_attention_linear_output_loss: 1.6859 - VH_attention_linear_output_loss: 1.6785 - VL_attention_linear_output_acc: 0.5038 - VH_attention_linear_output_acc: 0.5071 - val_loss: 3.5230 - val_VL_attention_linear_output_loss: 1.7529 - val_VH_attention_linear_output_loss: 1.7701 - val_VL_attention_linear_output_acc: 0.4923 - val_VH_attention_linear_output_acc: 0.4882\n",
      "Epoch 3700/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3695 - VL_attention_linear_output_loss: 1.6908 - VH_attention_linear_output_loss: 1.6787 - VL_attention_linear_output_acc: 0.5011 - VH_attention_linear_output_acc: 0.5077 - val_loss: 3.4786 - val_VL_attention_linear_output_loss: 1.7422 - val_VH_attention_linear_output_loss: 1.7364 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.4992\n",
      "Epoch 3701/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3588 - VL_attention_linear_output_loss: 1.6789 - VH_attention_linear_output_loss: 1.6798 - VL_attention_linear_output_acc: 0.5070 - VH_attention_linear_output_acc: 0.5070 - val_loss: 3.4848 - val_VL_attention_linear_output_loss: 1.7487 - val_VH_attention_linear_output_loss: 1.7361 - val_VL_attention_linear_output_acc: 0.4949 - val_VH_attention_linear_output_acc: 0.4971\n",
      "Epoch 3702/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3502 - VL_attention_linear_output_loss: 1.6756 - VH_attention_linear_output_loss: 1.6747 - VL_attention_linear_output_acc: 0.5079 - VH_attention_linear_output_acc: 0.5094 - val_loss: 3.4964 - val_VL_attention_linear_output_loss: 1.7472 - val_VH_attention_linear_output_loss: 1.7492 - val_VL_attention_linear_output_acc: 0.4991 - val_VH_attention_linear_output_acc: 0.4885\n",
      "Epoch 3703/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3666 - VL_attention_linear_output_loss: 1.6818 - VH_attention_linear_output_loss: 1.6847 - VL_attention_linear_output_acc: 0.5056 - VH_attention_linear_output_acc: 0.5048 - val_loss: 3.4885 - val_VL_attention_linear_output_loss: 1.7515 - val_VH_attention_linear_output_loss: 1.7369 - val_VL_attention_linear_output_acc: 0.4956 - val_VH_attention_linear_output_acc: 0.4950\n",
      "Epoch 3704/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3649 - VL_attention_linear_output_loss: 1.6822 - VH_attention_linear_output_loss: 1.6827 - VL_attention_linear_output_acc: 0.5055 - VH_attention_linear_output_acc: 0.5057 - val_loss: 3.5560 - val_VL_attention_linear_output_loss: 1.7478 - val_VH_attention_linear_output_loss: 1.8082 - val_VL_attention_linear_output_acc: 0.4960 - val_VH_attention_linear_output_acc: 0.4725\n",
      "Epoch 3705/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3680 - VL_attention_linear_output_loss: 1.6863 - VH_attention_linear_output_loss: 1.6817 - VL_attention_linear_output_acc: 0.5024 - VH_attention_linear_output_acc: 0.5067 - val_loss: 3.5129 - val_VL_attention_linear_output_loss: 1.7682 - val_VH_attention_linear_output_loss: 1.7447 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.4908\n",
      "Epoch 3706/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3531 - VL_attention_linear_output_loss: 1.6770 - VH_attention_linear_output_loss: 1.6762 - VL_attention_linear_output_acc: 0.5074 - VH_attention_linear_output_acc: 0.5091 - val_loss: 3.4839 - val_VL_attention_linear_output_loss: 1.7466 - val_VH_attention_linear_output_loss: 1.7373 - val_VL_attention_linear_output_acc: 0.4897 - val_VH_attention_linear_output_acc: 0.4919\n",
      "Epoch 3707/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3583 - VL_attention_linear_output_loss: 1.6810 - VH_attention_linear_output_loss: 1.6773 - VL_attention_linear_output_acc: 0.5046 - VH_attention_linear_output_acc: 0.5077 - val_loss: 3.4934 - val_VL_attention_linear_output_loss: 1.7527 - val_VH_attention_linear_output_loss: 1.7407 - val_VL_attention_linear_output_acc: 0.4956 - val_VH_attention_linear_output_acc: 0.4928\n",
      "Epoch 3708/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3729 - VL_attention_linear_output_loss: 1.6928 - VH_attention_linear_output_loss: 1.6801 - VL_attention_linear_output_acc: 0.5010 - VH_attention_linear_output_acc: 0.5065 - val_loss: 3.5493 - val_VL_attention_linear_output_loss: 1.8056 - val_VH_attention_linear_output_loss: 1.7438 - val_VL_attention_linear_output_acc: 0.4596 - val_VH_attention_linear_output_acc: 0.4919\n",
      "Epoch 3709/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3649 - VL_attention_linear_output_loss: 1.6816 - VH_attention_linear_output_loss: 1.6833 - VL_attention_linear_output_acc: 0.5052 - VH_attention_linear_output_acc: 0.5058 - val_loss: 3.4929 - val_VL_attention_linear_output_loss: 1.7465 - val_VH_attention_linear_output_loss: 1.7464 - val_VL_attention_linear_output_acc: 0.4924 - val_VH_attention_linear_output_acc: 0.4902\n",
      "Epoch 3710/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3640 - VL_attention_linear_output_loss: 1.6847 - VH_attention_linear_output_loss: 1.6793 - VL_attention_linear_output_acc: 0.5041 - VH_attention_linear_output_acc: 0.5078 - val_loss: 3.4794 - val_VL_attention_linear_output_loss: 1.7466 - val_VH_attention_linear_output_loss: 1.7329 - val_VL_attention_linear_output_acc: 0.4972 - val_VH_attention_linear_output_acc: 0.4952\n",
      "Epoch 3711/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3541 - VL_attention_linear_output_loss: 1.6818 - VH_attention_linear_output_loss: 1.6723 - VL_attention_linear_output_acc: 0.5053 - VH_attention_linear_output_acc: 0.5105 - val_loss: 3.4872 - val_VL_attention_linear_output_loss: 1.7470 - val_VH_attention_linear_output_loss: 1.7402 - val_VL_attention_linear_output_acc: 0.4943 - val_VH_attention_linear_output_acc: 0.4948\n",
      "Epoch 3712/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3737 - VL_attention_linear_output_loss: 1.6878 - VH_attention_linear_output_loss: 1.6860 - VL_attention_linear_output_acc: 0.5024 - VH_attention_linear_output_acc: 0.5044 - val_loss: 3.5226 - val_VL_attention_linear_output_loss: 1.7582 - val_VH_attention_linear_output_loss: 1.7644 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4860\n",
      "Epoch 3713/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3591 - VL_attention_linear_output_loss: 1.6805 - VH_attention_linear_output_loss: 1.6786 - VL_attention_linear_output_acc: 0.5058 - VH_attention_linear_output_acc: 0.5078 - val_loss: 3.4892 - val_VL_attention_linear_output_loss: 1.7500 - val_VH_attention_linear_output_loss: 1.7392 - val_VL_attention_linear_output_acc: 0.4946 - val_VH_attention_linear_output_acc: 0.4938\n",
      "Epoch 3714/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3782 - VL_attention_linear_output_loss: 1.6955 - VH_attention_linear_output_loss: 1.6827 - VL_attention_linear_output_acc: 0.4993 - VH_attention_linear_output_acc: 0.5069 - val_loss: 3.4853 - val_VL_attention_linear_output_loss: 1.7512 - val_VH_attention_linear_output_loss: 1.7341 - val_VL_attention_linear_output_acc: 0.4947 - val_VH_attention_linear_output_acc: 0.4980\n",
      "Epoch 3715/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3661 - VL_attention_linear_output_loss: 1.6828 - VH_attention_linear_output_loss: 1.6833 - VL_attention_linear_output_acc: 0.5044 - VH_attention_linear_output_acc: 0.5057 - val_loss: 3.5006 - val_VL_attention_linear_output_loss: 1.7532 - val_VH_attention_linear_output_loss: 1.7474 - val_VL_attention_linear_output_acc: 0.4913 - val_VH_attention_linear_output_acc: 0.4893\n",
      "Epoch 3716/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3698 - VL_attention_linear_output_loss: 1.6884 - VH_attention_linear_output_loss: 1.6815 - VL_attention_linear_output_acc: 0.5014 - VH_attention_linear_output_acc: 0.5072 - val_loss: 3.5273 - val_VL_attention_linear_output_loss: 1.7694 - val_VH_attention_linear_output_loss: 1.7579 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4820\n",
      "Epoch 3717/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3634 - VL_attention_linear_output_loss: 1.6813 - VH_attention_linear_output_loss: 1.6821 - VL_attention_linear_output_acc: 0.5055 - VH_attention_linear_output_acc: 0.5066 - val_loss: 3.4899 - val_VL_attention_linear_output_loss: 1.7511 - val_VH_attention_linear_output_loss: 1.7389 - val_VL_attention_linear_output_acc: 0.4935 - val_VH_attention_linear_output_acc: 0.4955\n",
      "Epoch 3718/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3653 - VL_attention_linear_output_loss: 1.6879 - VH_attention_linear_output_loss: 1.6774 - VL_attention_linear_output_acc: 0.5028 - VH_attention_linear_output_acc: 0.5081 - val_loss: 3.4935 - val_VL_attention_linear_output_loss: 1.7491 - val_VH_attention_linear_output_loss: 1.7444 - val_VL_attention_linear_output_acc: 0.4981 - val_VH_attention_linear_output_acc: 0.4949\n",
      "Epoch 3719/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3647 - VL_attention_linear_output_loss: 1.6917 - VH_attention_linear_output_loss: 1.6730 - VL_attention_linear_output_acc: 0.5012 - VH_attention_linear_output_acc: 0.5102 - val_loss: 3.4984 - val_VL_attention_linear_output_loss: 1.7640 - val_VH_attention_linear_output_loss: 1.7344 - val_VL_attention_linear_output_acc: 0.4892 - val_VH_attention_linear_output_acc: 0.4965\n",
      "Epoch 3720/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3592 - VL_attention_linear_output_loss: 1.6864 - VH_attention_linear_output_loss: 1.6729 - VL_attention_linear_output_acc: 0.5035 - VH_attention_linear_output_acc: 0.5099 - val_loss: 3.4978 - val_VL_attention_linear_output_loss: 1.7523 - val_VH_attention_linear_output_loss: 1.7454 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.4939\n",
      "Epoch 3721/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3717 - VL_attention_linear_output_loss: 1.6957 - VH_attention_linear_output_loss: 1.6759 - VL_attention_linear_output_acc: 0.4990 - VH_attention_linear_output_acc: 0.5086 - val_loss: 3.4928 - val_VL_attention_linear_output_loss: 1.7538 - val_VH_attention_linear_output_loss: 1.7390 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.4930\n",
      "Epoch 3722/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3617 - VL_attention_linear_output_loss: 1.6782 - VH_attention_linear_output_loss: 1.6835 - VL_attention_linear_output_acc: 0.5069 - VH_attention_linear_output_acc: 0.5069 - val_loss: 3.4913 - val_VL_attention_linear_output_loss: 1.7433 - val_VH_attention_linear_output_loss: 1.7481 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.4911\n",
      "Epoch 3723/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3680 - VL_attention_linear_output_loss: 1.6835 - VH_attention_linear_output_loss: 1.6846 - VL_attention_linear_output_acc: 0.5056 - VH_attention_linear_output_acc: 0.5050 - val_loss: 3.4934 - val_VL_attention_linear_output_loss: 1.7459 - val_VH_attention_linear_output_loss: 1.7474 - val_VL_attention_linear_output_acc: 0.4946 - val_VH_attention_linear_output_acc: 0.4941\n",
      "Epoch 3724/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3717 - VL_attention_linear_output_loss: 1.6889 - VH_attention_linear_output_loss: 1.6828 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5064 - val_loss: 3.4981 - val_VL_attention_linear_output_loss: 1.7566 - val_VH_attention_linear_output_loss: 1.7415 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4965\n",
      "Epoch 3725/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3490 - VL_attention_linear_output_loss: 1.6764 - VH_attention_linear_output_loss: 1.6726 - VL_attention_linear_output_acc: 0.5075 - VH_attention_linear_output_acc: 0.5100 - val_loss: 3.4978 - val_VL_attention_linear_output_loss: 1.7500 - val_VH_attention_linear_output_loss: 1.7478 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.4952\n",
      "Epoch 3726/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3627 - VL_attention_linear_output_loss: 1.6850 - VH_attention_linear_output_loss: 1.6777 - VL_attention_linear_output_acc: 0.5033 - VH_attention_linear_output_acc: 0.5083 - val_loss: 3.4934 - val_VL_attention_linear_output_loss: 1.7586 - val_VH_attention_linear_output_loss: 1.7349 - val_VL_attention_linear_output_acc: 0.4902 - val_VH_attention_linear_output_acc: 0.4977\n",
      "Epoch 3727/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3654 - VL_attention_linear_output_loss: 1.6892 - VH_attention_linear_output_loss: 1.6761 - VL_attention_linear_output_acc: 0.5022 - VH_attention_linear_output_acc: 0.5090 - val_loss: 3.4914 - val_VL_attention_linear_output_loss: 1.7441 - val_VH_attention_linear_output_loss: 1.7472 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.4913\n",
      "Epoch 3728/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3551 - VL_attention_linear_output_loss: 1.6786 - VH_attention_linear_output_loss: 1.6764 - VL_attention_linear_output_acc: 0.5061 - VH_attention_linear_output_acc: 0.5089 - val_loss: 3.5094 - val_VL_attention_linear_output_loss: 1.7412 - val_VH_attention_linear_output_loss: 1.7682 - val_VL_attention_linear_output_acc: 0.4955 - val_VH_attention_linear_output_acc: 0.4879\n",
      "Epoch 3729/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3727 - VL_attention_linear_output_loss: 1.6884 - VH_attention_linear_output_loss: 1.6843 - VL_attention_linear_output_acc: 0.5027 - VH_attention_linear_output_acc: 0.5062 - val_loss: 3.5284 - val_VL_attention_linear_output_loss: 1.7895 - val_VH_attention_linear_output_loss: 1.7389 - val_VL_attention_linear_output_acc: 0.4712 - val_VH_attention_linear_output_acc: 0.4965\n",
      "Epoch 3730/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3795 - VL_attention_linear_output_loss: 1.6953 - VH_attention_linear_output_loss: 1.6842 - VL_attention_linear_output_acc: 0.4996 - VH_attention_linear_output_acc: 0.5060 - val_loss: 3.4872 - val_VL_attention_linear_output_loss: 1.7547 - val_VH_attention_linear_output_loss: 1.7325 - val_VL_attention_linear_output_acc: 0.4891 - val_VH_attention_linear_output_acc: 0.4955\n",
      "Epoch 3731/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3624 - VL_attention_linear_output_loss: 1.6865 - VH_attention_linear_output_loss: 1.6758 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5081 - val_loss: 3.4889 - val_VL_attention_linear_output_loss: 1.7533 - val_VH_attention_linear_output_loss: 1.7356 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.4969\n",
      "Epoch 3732/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3729 - VL_attention_linear_output_loss: 1.6849 - VH_attention_linear_output_loss: 1.6879 - VL_attention_linear_output_acc: 0.5042 - VH_attention_linear_output_acc: 0.5049 - val_loss: 3.4901 - val_VL_attention_linear_output_loss: 1.7503 - val_VH_attention_linear_output_loss: 1.7398 - val_VL_attention_linear_output_acc: 0.4917 - val_VH_attention_linear_output_acc: 0.4955\n",
      "Epoch 3733/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3573 - VL_attention_linear_output_loss: 1.6810 - VH_attention_linear_output_loss: 1.6763 - VL_attention_linear_output_acc: 0.5048 - VH_attention_linear_output_acc: 0.5097 - val_loss: 3.5141 - val_VL_attention_linear_output_loss: 1.7794 - val_VH_attention_linear_output_loss: 1.7347 - val_VL_attention_linear_output_acc: 0.4798 - val_VH_attention_linear_output_acc: 0.4968\n",
      "Epoch 3734/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3730 - VL_attention_linear_output_loss: 1.6934 - VH_attention_linear_output_loss: 1.6796 - VL_attention_linear_output_acc: 0.4991 - VH_attention_linear_output_acc: 0.5078 - val_loss: 3.4902 - val_VL_attention_linear_output_loss: 1.7502 - val_VH_attention_linear_output_loss: 1.7400 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.4950\n",
      "Epoch 3735/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3641 - VL_attention_linear_output_loss: 1.6801 - VH_attention_linear_output_loss: 1.6840 - VL_attention_linear_output_acc: 0.5067 - VH_attention_linear_output_acc: 0.5059 - val_loss: 3.5022 - val_VL_attention_linear_output_loss: 1.7557 - val_VH_attention_linear_output_loss: 1.7465 - val_VL_attention_linear_output_acc: 0.4938 - val_VH_attention_linear_output_acc: 0.4913\n",
      "Epoch 3736/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3669 - VL_attention_linear_output_loss: 1.6808 - VH_attention_linear_output_loss: 1.6861 - VL_attention_linear_output_acc: 0.5066 - VH_attention_linear_output_acc: 0.5058 - val_loss: 3.4982 - val_VL_attention_linear_output_loss: 1.7643 - val_VH_attention_linear_output_loss: 1.7338 - val_VL_attention_linear_output_acc: 0.4829 - val_VH_attention_linear_output_acc: 0.4935\n",
      "Epoch 3737/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3561 - VL_attention_linear_output_loss: 1.6828 - VH_attention_linear_output_loss: 1.6733 - VL_attention_linear_output_acc: 0.5045 - VH_attention_linear_output_acc: 0.5099 - val_loss: 3.4993 - val_VL_attention_linear_output_loss: 1.7532 - val_VH_attention_linear_output_loss: 1.7461 - val_VL_attention_linear_output_acc: 0.4911 - val_VH_attention_linear_output_acc: 0.4926\n",
      "Epoch 3738/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3765 - VL_attention_linear_output_loss: 1.6889 - VH_attention_linear_output_loss: 1.6876 - VL_attention_linear_output_acc: 0.5015 - VH_attention_linear_output_acc: 0.5045 - val_loss: 3.5092 - val_VL_attention_linear_output_loss: 1.7533 - val_VH_attention_linear_output_loss: 1.7559 - val_VL_attention_linear_output_acc: 0.4900 - val_VH_attention_linear_output_acc: 0.4913\n",
      "Epoch 3739/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3595 - VL_attention_linear_output_loss: 1.6829 - VH_attention_linear_output_loss: 1.6766 - VL_attention_linear_output_acc: 0.5041 - VH_attention_linear_output_acc: 0.5081 - val_loss: 3.4893 - val_VL_attention_linear_output_loss: 1.7453 - val_VH_attention_linear_output_loss: 1.7440 - val_VL_attention_linear_output_acc: 0.4989 - val_VH_attention_linear_output_acc: 0.4981\n",
      "Epoch 3740/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3520 - VL_attention_linear_output_loss: 1.6780 - VH_attention_linear_output_loss: 1.6740 - VL_attention_linear_output_acc: 0.5072 - VH_attention_linear_output_acc: 0.5100 - val_loss: 3.4880 - val_VL_attention_linear_output_loss: 1.7493 - val_VH_attention_linear_output_loss: 1.7388 - val_VL_attention_linear_output_acc: 0.4956 - val_VH_attention_linear_output_acc: 0.4912\n",
      "Epoch 3741/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3637 - VL_attention_linear_output_loss: 1.6863 - VH_attention_linear_output_loss: 1.6774 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5085 - val_loss: 3.5295 - val_VL_attention_linear_output_loss: 1.7523 - val_VH_attention_linear_output_loss: 1.7771 - val_VL_attention_linear_output_acc: 0.4976 - val_VH_attention_linear_output_acc: 0.4818\n",
      "Epoch 3742/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3601 - VL_attention_linear_output_loss: 1.6824 - VH_attention_linear_output_loss: 1.6777 - VL_attention_linear_output_acc: 0.5049 - VH_attention_linear_output_acc: 0.5086 - val_loss: 3.5334 - val_VL_attention_linear_output_loss: 1.7506 - val_VH_attention_linear_output_loss: 1.7829 - val_VL_attention_linear_output_acc: 0.4964 - val_VH_attention_linear_output_acc: 0.4815\n",
      "Epoch 3743/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3621 - VL_attention_linear_output_loss: 1.6857 - VH_attention_linear_output_loss: 1.6763 - VL_attention_linear_output_acc: 0.5034 - VH_attention_linear_output_acc: 0.5093 - val_loss: 3.5704 - val_VL_attention_linear_output_loss: 1.8225 - val_VH_attention_linear_output_loss: 1.7479 - val_VL_attention_linear_output_acc: 0.4453 - val_VH_attention_linear_output_acc: 0.4928\n",
      "Epoch 3744/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3641 - VL_attention_linear_output_loss: 1.6834 - VH_attention_linear_output_loss: 1.6807 - VL_attention_linear_output_acc: 0.5036 - VH_attention_linear_output_acc: 0.5080 - val_loss: 3.4851 - val_VL_attention_linear_output_loss: 1.7517 - val_VH_attention_linear_output_loss: 1.7334 - val_VL_attention_linear_output_acc: 0.4880 - val_VH_attention_linear_output_acc: 0.4946\n",
      "Epoch 3745/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3692 - VL_attention_linear_output_loss: 1.6843 - VH_attention_linear_output_loss: 1.6849 - VL_attention_linear_output_acc: 0.5035 - VH_attention_linear_output_acc: 0.5056 - val_loss: 3.5118 - val_VL_attention_linear_output_loss: 1.7615 - val_VH_attention_linear_output_loss: 1.7502 - val_VL_attention_linear_output_acc: 0.4916 - val_VH_attention_linear_output_acc: 0.4960\n",
      "Epoch 3746/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3543 - VL_attention_linear_output_loss: 1.6785 - VH_attention_linear_output_loss: 1.6758 - VL_attention_linear_output_acc: 0.5073 - VH_attention_linear_output_acc: 0.5099 - val_loss: 3.5011 - val_VL_attention_linear_output_loss: 1.7478 - val_VH_attention_linear_output_loss: 1.7533 - val_VL_attention_linear_output_acc: 0.4931 - val_VH_attention_linear_output_acc: 0.4899\n",
      "Epoch 3747/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3630 - VL_attention_linear_output_loss: 1.6839 - VH_attention_linear_output_loss: 1.6791 - VL_attention_linear_output_acc: 0.5049 - VH_attention_linear_output_acc: 0.5088 - val_loss: 3.5171 - val_VL_attention_linear_output_loss: 1.7680 - val_VH_attention_linear_output_loss: 1.7491 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.4915\n",
      "Epoch 3748/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3633 - VL_attention_linear_output_loss: 1.6808 - VH_attention_linear_output_loss: 1.6826 - VL_attention_linear_output_acc: 0.5050 - VH_attention_linear_output_acc: 0.5071 - val_loss: 3.4839 - val_VL_attention_linear_output_loss: 1.7470 - val_VH_attention_linear_output_loss: 1.7370 - val_VL_attention_linear_output_acc: 0.4949 - val_VH_attention_linear_output_acc: 0.4963\n",
      "Epoch 3749/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3646 - VL_attention_linear_output_loss: 1.6903 - VH_attention_linear_output_loss: 1.6744 - VL_attention_linear_output_acc: 0.5012 - VH_attention_linear_output_acc: 0.5098 - val_loss: 3.5101 - val_VL_attention_linear_output_loss: 1.7662 - val_VH_attention_linear_output_loss: 1.7440 - val_VL_attention_linear_output_acc: 0.4849 - val_VH_attention_linear_output_acc: 0.4937\n",
      "Epoch 3750/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3555 - VL_attention_linear_output_loss: 1.6773 - VH_attention_linear_output_loss: 1.6782 - VL_attention_linear_output_acc: 0.5075 - VH_attention_linear_output_acc: 0.5090 - val_loss: 3.5006 - val_VL_attention_linear_output_loss: 1.7441 - val_VH_attention_linear_output_loss: 1.7565 - val_VL_attention_linear_output_acc: 0.4983 - val_VH_attention_linear_output_acc: 0.4871\n",
      "Epoch 3751/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3699 - VL_attention_linear_output_loss: 1.6891 - VH_attention_linear_output_loss: 1.6808 - VL_attention_linear_output_acc: 0.5019 - VH_attention_linear_output_acc: 0.5072 - val_loss: 3.5354 - val_VL_attention_linear_output_loss: 1.7583 - val_VH_attention_linear_output_loss: 1.7771 - val_VL_attention_linear_output_acc: 0.4940 - val_VH_attention_linear_output_acc: 0.4797\n",
      "Epoch 3752/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3595 - VL_attention_linear_output_loss: 1.6783 - VH_attention_linear_output_loss: 1.6811 - VL_attention_linear_output_acc: 0.5066 - VH_attention_linear_output_acc: 0.5082 - val_loss: 3.4987 - val_VL_attention_linear_output_loss: 1.7491 - val_VH_attention_linear_output_loss: 1.7495 - val_VL_attention_linear_output_acc: 0.4960 - val_VH_attention_linear_output_acc: 0.4912\n",
      "Epoch 3753/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3647 - VL_attention_linear_output_loss: 1.6765 - VH_attention_linear_output_loss: 1.6882 - VL_attention_linear_output_acc: 0.5087 - VH_attention_linear_output_acc: 0.5052 - val_loss: 3.4798 - val_VL_attention_linear_output_loss: 1.7436 - val_VH_attention_linear_output_loss: 1.7362 - val_VL_attention_linear_output_acc: 0.4956 - val_VH_attention_linear_output_acc: 0.4978\n",
      "Epoch 3754/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3723 - VL_attention_linear_output_loss: 1.6878 - VH_attention_linear_output_loss: 1.6845 - VL_attention_linear_output_acc: 0.5029 - VH_attention_linear_output_acc: 0.5077 - val_loss: 3.4886 - val_VL_attention_linear_output_loss: 1.7500 - val_VH_attention_linear_output_loss: 1.7387 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.4964\n",
      "Epoch 3755/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3603 - VL_attention_linear_output_loss: 1.6756 - VH_attention_linear_output_loss: 1.6847 - VL_attention_linear_output_acc: 0.5088 - VH_attention_linear_output_acc: 0.5066 - val_loss: 3.4727 - val_VL_attention_linear_output_loss: 1.7390 - val_VH_attention_linear_output_loss: 1.7338 - val_VL_attention_linear_output_acc: 0.5002 - val_VH_attention_linear_output_acc: 0.5002\n",
      "Epoch 3756/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3650 - VL_attention_linear_output_loss: 1.6840 - VH_attention_linear_output_loss: 1.6810 - VL_attention_linear_output_acc: 0.5038 - VH_attention_linear_output_acc: 0.5084 - val_loss: 3.5030 - val_VL_attention_linear_output_loss: 1.7695 - val_VH_attention_linear_output_loss: 1.7335 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.4994\n",
      "Epoch 3757/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3689 - VL_attention_linear_output_loss: 1.6854 - VH_attention_linear_output_loss: 1.6835 - VL_attention_linear_output_acc: 0.5035 - VH_attention_linear_output_acc: 0.5071 - val_loss: 3.5226 - val_VL_attention_linear_output_loss: 1.7525 - val_VH_attention_linear_output_loss: 1.7701 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.4841\n",
      "Epoch 3758/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3666 - VL_attention_linear_output_loss: 1.6766 - VH_attention_linear_output_loss: 1.6900 - VL_attention_linear_output_acc: 0.5078 - VH_attention_linear_output_acc: 0.5038 - val_loss: 3.4835 - val_VL_attention_linear_output_loss: 1.7483 - val_VH_attention_linear_output_loss: 1.7352 - val_VL_attention_linear_output_acc: 0.4940 - val_VH_attention_linear_output_acc: 0.4973\n",
      "Epoch 3759/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3518 - VL_attention_linear_output_loss: 1.6820 - VH_attention_linear_output_loss: 1.6698 - VL_attention_linear_output_acc: 0.5050 - VH_attention_linear_output_acc: 0.5119 - val_loss: 3.4911 - val_VL_attention_linear_output_loss: 1.7429 - val_VH_attention_linear_output_loss: 1.7482 - val_VL_attention_linear_output_acc: 0.4991 - val_VH_attention_linear_output_acc: 0.4904\n",
      "Epoch 3760/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3688 - VL_attention_linear_output_loss: 1.6909 - VH_attention_linear_output_loss: 1.6779 - VL_attention_linear_output_acc: 0.5011 - VH_attention_linear_output_acc: 0.5089 - val_loss: 3.4830 - val_VL_attention_linear_output_loss: 1.7498 - val_VH_attention_linear_output_loss: 1.7332 - val_VL_attention_linear_output_acc: 0.4971 - val_VH_attention_linear_output_acc: 0.4976\n",
      "Epoch 3761/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3539 - VL_attention_linear_output_loss: 1.6750 - VH_attention_linear_output_loss: 1.6789 - VL_attention_linear_output_acc: 0.5079 - VH_attention_linear_output_acc: 0.5086 - val_loss: 3.5286 - val_VL_attention_linear_output_loss: 1.7438 - val_VH_attention_linear_output_loss: 1.7848 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.4735\n",
      "Epoch 3762/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3683 - VL_attention_linear_output_loss: 1.6842 - VH_attention_linear_output_loss: 1.6842 - VL_attention_linear_output_acc: 0.5047 - VH_attention_linear_output_acc: 0.5071 - val_loss: 3.4934 - val_VL_attention_linear_output_loss: 1.7468 - val_VH_attention_linear_output_loss: 1.7467 - val_VL_attention_linear_output_acc: 0.4999 - val_VH_attention_linear_output_acc: 0.4965\n",
      "Epoch 3763/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3554 - VL_attention_linear_output_loss: 1.6782 - VH_attention_linear_output_loss: 1.6772 - VL_attention_linear_output_acc: 0.5073 - VH_attention_linear_output_acc: 0.5093 - val_loss: 3.4878 - val_VL_attention_linear_output_loss: 1.7504 - val_VH_attention_linear_output_loss: 1.7374 - val_VL_attention_linear_output_acc: 0.4945 - val_VH_attention_linear_output_acc: 0.4972\n",
      "Epoch 3764/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3538 - VL_attention_linear_output_loss: 1.6769 - VH_attention_linear_output_loss: 1.6769 - VL_attention_linear_output_acc: 0.5076 - VH_attention_linear_output_acc: 0.5101 - val_loss: 3.5195 - val_VL_attention_linear_output_loss: 1.7603 - val_VH_attention_linear_output_loss: 1.7592 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4886\n",
      "Epoch 3765/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3611 - VL_attention_linear_output_loss: 1.6837 - VH_attention_linear_output_loss: 1.6774 - VL_attention_linear_output_acc: 0.5034 - VH_attention_linear_output_acc: 0.5096 - val_loss: 3.4906 - val_VL_attention_linear_output_loss: 1.7539 - val_VH_attention_linear_output_loss: 1.7367 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.4961\n",
      "Epoch 3766/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3544 - VL_attention_linear_output_loss: 1.6815 - VH_attention_linear_output_loss: 1.6729 - VL_attention_linear_output_acc: 0.5053 - VH_attention_linear_output_acc: 0.5116 - val_loss: 3.4781 - val_VL_attention_linear_output_loss: 1.7463 - val_VH_attention_linear_output_loss: 1.7318 - val_VL_attention_linear_output_acc: 0.4933 - val_VH_attention_linear_output_acc: 0.4971\n",
      "Epoch 3767/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3502 - VL_attention_linear_output_loss: 1.6745 - VH_attention_linear_output_loss: 1.6757 - VL_attention_linear_output_acc: 0.5081 - VH_attention_linear_output_acc: 0.5099 - val_loss: 3.4920 - val_VL_attention_linear_output_loss: 1.7495 - val_VH_attention_linear_output_loss: 1.7425 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.4958\n",
      "Epoch 3768/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3573 - VL_attention_linear_output_loss: 1.6821 - VH_attention_linear_output_loss: 1.6751 - VL_attention_linear_output_acc: 0.5043 - VH_attention_linear_output_acc: 0.5097 - val_loss: 3.4994 - val_VL_attention_linear_output_loss: 1.7585 - val_VH_attention_linear_output_loss: 1.7409 - val_VL_attention_linear_output_acc: 0.4867 - val_VH_attention_linear_output_acc: 0.4969\n",
      "Epoch 3769/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3626 - VL_attention_linear_output_loss: 1.6815 - VH_attention_linear_output_loss: 1.6811 - VL_attention_linear_output_acc: 0.5040 - VH_attention_linear_output_acc: 0.5088 - val_loss: 3.5058 - val_VL_attention_linear_output_loss: 1.7480 - val_VH_attention_linear_output_loss: 1.7578 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.4893\n",
      "Epoch 3770/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3618 - VL_attention_linear_output_loss: 1.6902 - VH_attention_linear_output_loss: 1.6716 - VL_attention_linear_output_acc: 0.5009 - VH_attention_linear_output_acc: 0.5115 - val_loss: 3.5183 - val_VL_attention_linear_output_loss: 1.7697 - val_VH_attention_linear_output_loss: 1.7485 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.4918\n",
      "Epoch 3771/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3651 - VL_attention_linear_output_loss: 1.6815 - VH_attention_linear_output_loss: 1.6836 - VL_attention_linear_output_acc: 0.5057 - VH_attention_linear_output_acc: 0.5073 - val_loss: 3.4902 - val_VL_attention_linear_output_loss: 1.7544 - val_VH_attention_linear_output_loss: 1.7358 - val_VL_attention_linear_output_acc: 0.4945 - val_VH_attention_linear_output_acc: 0.4988\n",
      "Epoch 3772/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3562 - VL_attention_linear_output_loss: 1.6862 - VH_attention_linear_output_loss: 1.6700 - VL_attention_linear_output_acc: 0.5033 - VH_attention_linear_output_acc: 0.5129 - val_loss: 3.4917 - val_VL_attention_linear_output_loss: 1.7478 - val_VH_attention_linear_output_loss: 1.7439 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.4967\n",
      "Epoch 3773/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3475 - VL_attention_linear_output_loss: 1.6732 - VH_attention_linear_output_loss: 1.6742 - VL_attention_linear_output_acc: 0.5088 - VH_attention_linear_output_acc: 0.5116 - val_loss: 3.5789 - val_VL_attention_linear_output_loss: 1.7701 - val_VH_attention_linear_output_loss: 1.8088 - val_VL_attention_linear_output_acc: 0.4874 - val_VH_attention_linear_output_acc: 0.4617\n",
      "Epoch 3774/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3508 - VL_attention_linear_output_loss: 1.6789 - VH_attention_linear_output_loss: 1.6718 - VL_attention_linear_output_acc: 0.5057 - VH_attention_linear_output_acc: 0.5119 - val_loss: 3.4767 - val_VL_attention_linear_output_loss: 1.7431 - val_VH_attention_linear_output_loss: 1.7336 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5003\n",
      "Epoch 3775/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3486 - VL_attention_linear_output_loss: 1.6812 - VH_attention_linear_output_loss: 1.6674 - VL_attention_linear_output_acc: 0.5019 - VH_attention_linear_output_acc: 0.5138 - val_loss: 3.4920 - val_VL_attention_linear_output_loss: 1.7572 - val_VH_attention_linear_output_loss: 1.7347 - val_VL_attention_linear_output_acc: 0.4895 - val_VH_attention_linear_output_acc: 0.4996\n",
      "Epoch 3776/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3599 - VL_attention_linear_output_loss: 1.6781 - VH_attention_linear_output_loss: 1.6818 - VL_attention_linear_output_acc: 0.5069 - VH_attention_linear_output_acc: 0.5077 - val_loss: 3.5613 - val_VL_attention_linear_output_loss: 1.7459 - val_VH_attention_linear_output_loss: 1.8155 - val_VL_attention_linear_output_acc: 0.4945 - val_VH_attention_linear_output_acc: 0.4674\n",
      "Epoch 3777/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3706 - VL_attention_linear_output_loss: 1.6947 - VH_attention_linear_output_loss: 1.6759 - VL_attention_linear_output_acc: 0.4979 - VH_attention_linear_output_acc: 0.5109 - val_loss: 3.4850 - val_VL_attention_linear_output_loss: 1.7529 - val_VH_attention_linear_output_loss: 1.7321 - val_VL_attention_linear_output_acc: 0.4931 - val_VH_attention_linear_output_acc: 0.5003\n",
      "Epoch 3778/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3544 - VL_attention_linear_output_loss: 1.6754 - VH_attention_linear_output_loss: 1.6790 - VL_attention_linear_output_acc: 0.5087 - VH_attention_linear_output_acc: 0.5093 - val_loss: 3.4786 - val_VL_attention_linear_output_loss: 1.7419 - val_VH_attention_linear_output_loss: 1.7367 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.4983\n",
      "Epoch 3779/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3418 - VL_attention_linear_output_loss: 1.6737 - VH_attention_linear_output_loss: 1.6681 - VL_attention_linear_output_acc: 0.5078 - VH_attention_linear_output_acc: 0.5137 - val_loss: 3.4845 - val_VL_attention_linear_output_loss: 1.7469 - val_VH_attention_linear_output_loss: 1.7375 - val_VL_attention_linear_output_acc: 0.4948 - val_VH_attention_linear_output_acc: 0.4942\n",
      "Epoch 3780/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3532 - VL_attention_linear_output_loss: 1.6805 - VH_attention_linear_output_loss: 1.6726 - VL_attention_linear_output_acc: 0.5038 - VH_attention_linear_output_acc: 0.5119 - val_loss: 3.5337 - val_VL_attention_linear_output_loss: 1.7960 - val_VH_attention_linear_output_loss: 1.7377 - val_VL_attention_linear_output_acc: 0.4748 - val_VH_attention_linear_output_acc: 0.4972\n",
      "Epoch 3781/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3595 - VL_attention_linear_output_loss: 1.6858 - VH_attention_linear_output_loss: 1.6737 - VL_attention_linear_output_acc: 0.5028 - VH_attention_linear_output_acc: 0.5115 - val_loss: 3.5046 - val_VL_attention_linear_output_loss: 1.7543 - val_VH_attention_linear_output_loss: 1.7503 - val_VL_attention_linear_output_acc: 0.4896 - val_VH_attention_linear_output_acc: 0.4932\n",
      "Epoch 3782/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3567 - VL_attention_linear_output_loss: 1.6815 - VH_attention_linear_output_loss: 1.6752 - VL_attention_linear_output_acc: 0.5046 - VH_attention_linear_output_acc: 0.5102 - val_loss: 3.4841 - val_VL_attention_linear_output_loss: 1.7488 - val_VH_attention_linear_output_loss: 1.7353 - val_VL_attention_linear_output_acc: 0.4991 - val_VH_attention_linear_output_acc: 0.4987\n",
      "Epoch 3783/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3569 - VL_attention_linear_output_loss: 1.6754 - VH_attention_linear_output_loss: 1.6815 - VL_attention_linear_output_acc: 0.5071 - VH_attention_linear_output_acc: 0.5082 - val_loss: 3.4869 - val_VL_attention_linear_output_loss: 1.7554 - val_VH_attention_linear_output_loss: 1.7315 - val_VL_attention_linear_output_acc: 0.4866 - val_VH_attention_linear_output_acc: 0.4997\n",
      "Epoch 3784/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3597 - VL_attention_linear_output_loss: 1.6813 - VH_attention_linear_output_loss: 1.6784 - VL_attention_linear_output_acc: 0.5050 - VH_attention_linear_output_acc: 0.5094 - val_loss: 3.5048 - val_VL_attention_linear_output_loss: 1.7489 - val_VH_attention_linear_output_loss: 1.7559 - val_VL_attention_linear_output_acc: 0.4907 - val_VH_attention_linear_output_acc: 0.4904\n",
      "Epoch 3785/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3615 - VL_attention_linear_output_loss: 1.6779 - VH_attention_linear_output_loss: 1.6836 - VL_attention_linear_output_acc: 0.5066 - VH_attention_linear_output_acc: 0.5077 - val_loss: 3.5408 - val_VL_attention_linear_output_loss: 1.8047 - val_VH_attention_linear_output_loss: 1.7361 - val_VL_attention_linear_output_acc: 0.4706 - val_VH_attention_linear_output_acc: 0.4962\n",
      "Epoch 3786/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3657 - VL_attention_linear_output_loss: 1.6893 - VH_attention_linear_output_loss: 1.6763 - VL_attention_linear_output_acc: 0.5009 - VH_attention_linear_output_acc: 0.5100 - val_loss: 3.5142 - val_VL_attention_linear_output_loss: 1.7669 - val_VH_attention_linear_output_loss: 1.7473 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.4938\n",
      "Epoch 3787/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3551 - VL_attention_linear_output_loss: 1.6817 - VH_attention_linear_output_loss: 1.6733 - VL_attention_linear_output_acc: 0.5049 - VH_attention_linear_output_acc: 0.5117 - val_loss: 3.4990 - val_VL_attention_linear_output_loss: 1.7536 - val_VH_attention_linear_output_loss: 1.7453 - val_VL_attention_linear_output_acc: 0.4908 - val_VH_attention_linear_output_acc: 0.4921\n",
      "Epoch 3788/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3737 - VL_attention_linear_output_loss: 1.6798 - VH_attention_linear_output_loss: 1.6939 - VL_attention_linear_output_acc: 0.5068 - VH_attention_linear_output_acc: 0.5041 - val_loss: 3.4994 - val_VL_attention_linear_output_loss: 1.7498 - val_VH_attention_linear_output_loss: 1.7497 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.4915\n",
      "Epoch 3789/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3663 - VL_attention_linear_output_loss: 1.6873 - VH_attention_linear_output_loss: 1.6791 - VL_attention_linear_output_acc: 0.5025 - VH_attention_linear_output_acc: 0.5090 - val_loss: 3.5061 - val_VL_attention_linear_output_loss: 1.7564 - val_VH_attention_linear_output_loss: 1.7497 - val_VL_attention_linear_output_acc: 0.4910 - val_VH_attention_linear_output_acc: 0.4929\n",
      "Epoch 3790/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3597 - VL_attention_linear_output_loss: 1.6799 - VH_attention_linear_output_loss: 1.6798 - VL_attention_linear_output_acc: 0.5054 - VH_attention_linear_output_acc: 0.5094 - val_loss: 3.5131 - val_VL_attention_linear_output_loss: 1.7573 - val_VH_attention_linear_output_loss: 1.7557 - val_VL_attention_linear_output_acc: 0.4891 - val_VH_attention_linear_output_acc: 0.4928\n",
      "Epoch 3791/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3550 - VL_attention_linear_output_loss: 1.6775 - VH_attention_linear_output_loss: 1.6776 - VL_attention_linear_output_acc: 0.5073 - VH_attention_linear_output_acc: 0.5101 - val_loss: 3.5204 - val_VL_attention_linear_output_loss: 1.7704 - val_VH_attention_linear_output_loss: 1.7500 - val_VL_attention_linear_output_acc: 0.4827 - val_VH_attention_linear_output_acc: 0.4921\n",
      "Epoch 3792/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3676 - VL_attention_linear_output_loss: 1.6857 - VH_attention_linear_output_loss: 1.6818 - VL_attention_linear_output_acc: 0.5021 - VH_attention_linear_output_acc: 0.5082 - val_loss: 3.5066 - val_VL_attention_linear_output_loss: 1.7434 - val_VH_attention_linear_output_loss: 1.7633 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.4863\n",
      "Epoch 3793/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3476 - VL_attention_linear_output_loss: 1.6752 - VH_attention_linear_output_loss: 1.6725 - VL_attention_linear_output_acc: 0.5080 - VH_attention_linear_output_acc: 0.5117 - val_loss: 3.5093 - val_VL_attention_linear_output_loss: 1.7518 - val_VH_attention_linear_output_loss: 1.7574 - val_VL_attention_linear_output_acc: 0.4926 - val_VH_attention_linear_output_acc: 0.4906\n",
      "Epoch 3794/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3608 - VL_attention_linear_output_loss: 1.6787 - VH_attention_linear_output_loss: 1.6821 - VL_attention_linear_output_acc: 0.5053 - VH_attention_linear_output_acc: 0.5080 - val_loss: 3.4995 - val_VL_attention_linear_output_loss: 1.7447 - val_VH_attention_linear_output_loss: 1.7548 - val_VL_attention_linear_output_acc: 0.4983 - val_VH_attention_linear_output_acc: 0.4897\n",
      "Epoch 3795/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3508 - VL_attention_linear_output_loss: 1.6799 - VH_attention_linear_output_loss: 1.6710 - VL_attention_linear_output_acc: 0.5049 - VH_attention_linear_output_acc: 0.5124 - val_loss: 3.4950 - val_VL_attention_linear_output_loss: 1.7608 - val_VH_attention_linear_output_loss: 1.7341 - val_VL_attention_linear_output_acc: 0.4870 - val_VH_attention_linear_output_acc: 0.5010\n",
      "Epoch 3796/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3640 - VL_attention_linear_output_loss: 1.6787 - VH_attention_linear_output_loss: 1.6852 - VL_attention_linear_output_acc: 0.5058 - VH_attention_linear_output_acc: 0.5076 - val_loss: 3.4833 - val_VL_attention_linear_output_loss: 1.7464 - val_VH_attention_linear_output_loss: 1.7368 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.4975\n",
      "Epoch 3797/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3611 - VL_attention_linear_output_loss: 1.6846 - VH_attention_linear_output_loss: 1.6764 - VL_attention_linear_output_acc: 0.5026 - VH_attention_linear_output_acc: 0.5110 - val_loss: 3.5509 - val_VL_attention_linear_output_loss: 1.7747 - val_VH_attention_linear_output_loss: 1.7762 - val_VL_attention_linear_output_acc: 0.4803 - val_VH_attention_linear_output_acc: 0.4878\n",
      "Epoch 3798/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3534 - VL_attention_linear_output_loss: 1.6798 - VH_attention_linear_output_loss: 1.6736 - VL_attention_linear_output_acc: 0.5060 - VH_attention_linear_output_acc: 0.5120 - val_loss: 3.5046 - val_VL_attention_linear_output_loss: 1.7628 - val_VH_attention_linear_output_loss: 1.7418 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4980\n",
      "Epoch 3799/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3544 - VL_attention_linear_output_loss: 1.6813 - VH_attention_linear_output_loss: 1.6730 - VL_attention_linear_output_acc: 0.5052 - VH_attention_linear_output_acc: 0.5117 - val_loss: 3.4823 - val_VL_attention_linear_output_loss: 1.7487 - val_VH_attention_linear_output_loss: 1.7337 - val_VL_attention_linear_output_acc: 0.4932 - val_VH_attention_linear_output_acc: 0.4986\n",
      "Epoch 3800/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3740 - VL_attention_linear_output_loss: 1.6827 - VH_attention_linear_output_loss: 1.6914 - VL_attention_linear_output_acc: 0.5043 - VH_attention_linear_output_acc: 0.5052 - val_loss: 3.4905 - val_VL_attention_linear_output_loss: 1.7577 - val_VH_attention_linear_output_loss: 1.7328 - val_VL_attention_linear_output_acc: 0.4884 - val_VH_attention_linear_output_acc: 0.5007\n",
      "Epoch 3801/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3488 - VL_attention_linear_output_loss: 1.6822 - VH_attention_linear_output_loss: 1.6667 - VL_attention_linear_output_acc: 0.5048 - VH_attention_linear_output_acc: 0.5141 - val_loss: 3.4770 - val_VL_attention_linear_output_loss: 1.7465 - val_VH_attention_linear_output_loss: 1.7305 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.5002\n",
      "Epoch 3802/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3519 - VL_attention_linear_output_loss: 1.6750 - VH_attention_linear_output_loss: 1.6769 - VL_attention_linear_output_acc: 0.5084 - VH_attention_linear_output_acc: 0.5102 - val_loss: 3.5019 - val_VL_attention_linear_output_loss: 1.7463 - val_VH_attention_linear_output_loss: 1.7556 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.4871\n",
      "Epoch 3803/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3515 - VL_attention_linear_output_loss: 1.6806 - VH_attention_linear_output_loss: 1.6709 - VL_attention_linear_output_acc: 0.5052 - VH_attention_linear_output_acc: 0.5126 - val_loss: 3.5148 - val_VL_attention_linear_output_loss: 1.7590 - val_VH_attention_linear_output_loss: 1.7558 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.4917\n",
      "Epoch 3804/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3704 - VL_attention_linear_output_loss: 1.6888 - VH_attention_linear_output_loss: 1.6816 - VL_attention_linear_output_acc: 0.5008 - VH_attention_linear_output_acc: 0.5085 - val_loss: 3.4980 - val_VL_attention_linear_output_loss: 1.7533 - val_VH_attention_linear_output_loss: 1.7446 - val_VL_attention_linear_output_acc: 0.4947 - val_VH_attention_linear_output_acc: 0.4969\n",
      "Epoch 3805/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3576 - VL_attention_linear_output_loss: 1.6818 - VH_attention_linear_output_loss: 1.6758 - VL_attention_linear_output_acc: 0.5046 - VH_attention_linear_output_acc: 0.5108 - val_loss: 3.4851 - val_VL_attention_linear_output_loss: 1.7515 - val_VH_attention_linear_output_loss: 1.7336 - val_VL_attention_linear_output_acc: 0.4924 - val_VH_attention_linear_output_acc: 0.4966\n",
      "Epoch 3806/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3532 - VL_attention_linear_output_loss: 1.6774 - VH_attention_linear_output_loss: 1.6758 - VL_attention_linear_output_acc: 0.5067 - VH_attention_linear_output_acc: 0.5105 - val_loss: 3.5099 - val_VL_attention_linear_output_loss: 1.7567 - val_VH_attention_linear_output_loss: 1.7532 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.4950\n",
      "Epoch 3807/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3641 - VL_attention_linear_output_loss: 1.6823 - VH_attention_linear_output_loss: 1.6817 - VL_attention_linear_output_acc: 0.5047 - VH_attention_linear_output_acc: 0.5087 - val_loss: 3.4929 - val_VL_attention_linear_output_loss: 1.7547 - val_VH_attention_linear_output_loss: 1.7382 - val_VL_attention_linear_output_acc: 0.4900 - val_VH_attention_linear_output_acc: 0.4984\n",
      "Epoch 3808/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3425 - VL_attention_linear_output_loss: 1.6760 - VH_attention_linear_output_loss: 1.6664 - VL_attention_linear_output_acc: 0.5060 - VH_attention_linear_output_acc: 0.5152 - val_loss: 3.4808 - val_VL_attention_linear_output_loss: 1.7461 - val_VH_attention_linear_output_loss: 1.7347 - val_VL_attention_linear_output_acc: 0.4933 - val_VH_attention_linear_output_acc: 0.4997\n",
      "Epoch 3809/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3606 - VL_attention_linear_output_loss: 1.6797 - VH_attention_linear_output_loss: 1.6809 - VL_attention_linear_output_acc: 0.5050 - VH_attention_linear_output_acc: 0.5090 - val_loss: 3.4919 - val_VL_attention_linear_output_loss: 1.7432 - val_VH_attention_linear_output_loss: 1.7487 - val_VL_attention_linear_output_acc: 0.4989 - val_VH_attention_linear_output_acc: 0.4969\n",
      "Epoch 3810/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3580 - VL_attention_linear_output_loss: 1.6770 - VH_attention_linear_output_loss: 1.6810 - VL_attention_linear_output_acc: 0.5070 - VH_attention_linear_output_acc: 0.5097 - val_loss: 3.4855 - val_VL_attention_linear_output_loss: 1.7549 - val_VH_attention_linear_output_loss: 1.7305 - val_VL_attention_linear_output_acc: 0.4920 - val_VH_attention_linear_output_acc: 0.5000\n",
      "Epoch 3811/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3528 - VL_attention_linear_output_loss: 1.6779 - VH_attention_linear_output_loss: 1.6749 - VL_attention_linear_output_acc: 0.5063 - VH_attention_linear_output_acc: 0.5113 - val_loss: 3.5323 - val_VL_attention_linear_output_loss: 1.7756 - val_VH_attention_linear_output_loss: 1.7567 - val_VL_attention_linear_output_acc: 0.4732 - val_VH_attention_linear_output_acc: 0.4900\n",
      "Epoch 3812/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3600 - VL_attention_linear_output_loss: 1.6852 - VH_attention_linear_output_loss: 1.6748 - VL_attention_linear_output_acc: 0.5025 - VH_attention_linear_output_acc: 0.5111 - val_loss: 3.5089 - val_VL_attention_linear_output_loss: 1.7583 - val_VH_attention_linear_output_loss: 1.7505 - val_VL_attention_linear_output_acc: 0.4846 - val_VH_attention_linear_output_acc: 0.4962\n",
      "Epoch 3813/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3677 - VL_attention_linear_output_loss: 1.6838 - VH_attention_linear_output_loss: 1.6839 - VL_attention_linear_output_acc: 0.5025 - VH_attention_linear_output_acc: 0.5084 - val_loss: 3.5237 - val_VL_attention_linear_output_loss: 1.7754 - val_VH_attention_linear_output_loss: 1.7483 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.4924\n",
      "Epoch 3814/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3560 - VL_attention_linear_output_loss: 1.6792 - VH_attention_linear_output_loss: 1.6768 - VL_attention_linear_output_acc: 0.5042 - VH_attention_linear_output_acc: 0.5107 - val_loss: 3.5325 - val_VL_attention_linear_output_loss: 1.7889 - val_VH_attention_linear_output_loss: 1.7435 - val_VL_attention_linear_output_acc: 0.4749 - val_VH_attention_linear_output_acc: 0.4987\n",
      "Epoch 3815/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3780 - VL_attention_linear_output_loss: 1.6893 - VH_attention_linear_output_loss: 1.6887 - VL_attention_linear_output_acc: 0.5024 - VH_attention_linear_output_acc: 0.5058 - val_loss: 3.5033 - val_VL_attention_linear_output_loss: 1.7493 - val_VH_attention_linear_output_loss: 1.7540 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.4916\n",
      "Epoch 3816/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3711 - VL_attention_linear_output_loss: 1.6835 - VH_attention_linear_output_loss: 1.6877 - VL_attention_linear_output_acc: 0.5041 - VH_attention_linear_output_acc: 0.5070 - val_loss: 3.4870 - val_VL_attention_linear_output_loss: 1.7464 - val_VH_attention_linear_output_loss: 1.7406 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.5000\n",
      "Epoch 3817/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3501 - VL_attention_linear_output_loss: 1.6776 - VH_attention_linear_output_loss: 1.6724 - VL_attention_linear_output_acc: 0.5059 - VH_attention_linear_output_acc: 0.5125 - val_loss: 3.4844 - val_VL_attention_linear_output_loss: 1.7548 - val_VH_attention_linear_output_loss: 1.7296 - val_VL_attention_linear_output_acc: 0.4941 - val_VH_attention_linear_output_acc: 0.4989\n",
      "Epoch 3818/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3600 - VL_attention_linear_output_loss: 1.6807 - VH_attention_linear_output_loss: 1.6794 - VL_attention_linear_output_acc: 0.5046 - VH_attention_linear_output_acc: 0.5096 - val_loss: 3.5068 - val_VL_attention_linear_output_loss: 1.7698 - val_VH_attention_linear_output_loss: 1.7370 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.5008\n",
      "Epoch 3819/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3547 - VL_attention_linear_output_loss: 1.6746 - VH_attention_linear_output_loss: 1.6801 - VL_attention_linear_output_acc: 0.5070 - VH_attention_linear_output_acc: 0.5086 - val_loss: 3.4967 - val_VL_attention_linear_output_loss: 1.7464 - val_VH_attention_linear_output_loss: 1.7503 - val_VL_attention_linear_output_acc: 0.5011 - val_VH_attention_linear_output_acc: 0.4909\n",
      "Epoch 3820/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3470 - VL_attention_linear_output_loss: 1.6748 - VH_attention_linear_output_loss: 1.6722 - VL_attention_linear_output_acc: 0.5079 - VH_attention_linear_output_acc: 0.5124 - val_loss: 3.4827 - val_VL_attention_linear_output_loss: 1.7399 - val_VH_attention_linear_output_loss: 1.7428 - val_VL_attention_linear_output_acc: 0.5015 - val_VH_attention_linear_output_acc: 0.4969\n",
      "Epoch 3821/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3654 - VL_attention_linear_output_loss: 1.6827 - VH_attention_linear_output_loss: 1.6827 - VL_attention_linear_output_acc: 0.5036 - VH_attention_linear_output_acc: 0.5086 - val_loss: 3.4886 - val_VL_attention_linear_output_loss: 1.7472 - val_VH_attention_linear_output_loss: 1.7414 - val_VL_attention_linear_output_acc: 0.4937 - val_VH_attention_linear_output_acc: 0.4948\n",
      "Epoch 3822/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3589 - VL_attention_linear_output_loss: 1.6840 - VH_attention_linear_output_loss: 1.6749 - VL_attention_linear_output_acc: 0.5029 - VH_attention_linear_output_acc: 0.5120 - val_loss: 3.6787 - val_VL_attention_linear_output_loss: 1.8103 - val_VH_attention_linear_output_loss: 1.8684 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.4544\n",
      "Epoch 3823/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3784 - VL_attention_linear_output_loss: 1.6913 - VH_attention_linear_output_loss: 1.6871 - VL_attention_linear_output_acc: 0.4995 - VH_attention_linear_output_acc: 0.5068 - val_loss: 3.5056 - val_VL_attention_linear_output_loss: 1.7611 - val_VH_attention_linear_output_loss: 1.7444 - val_VL_attention_linear_output_acc: 0.4909 - val_VH_attention_linear_output_acc: 0.4980\n",
      "Epoch 3824/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3606 - VL_attention_linear_output_loss: 1.6881 - VH_attention_linear_output_loss: 1.6725 - VL_attention_linear_output_acc: 0.5026 - VH_attention_linear_output_acc: 0.5127 - val_loss: 3.5038 - val_VL_attention_linear_output_loss: 1.7479 - val_VH_attention_linear_output_loss: 1.7559 - val_VL_attention_linear_output_acc: 0.4918 - val_VH_attention_linear_output_acc: 0.4932\n",
      "Epoch 3825/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3623 - VL_attention_linear_output_loss: 1.6859 - VH_attention_linear_output_loss: 1.6764 - VL_attention_linear_output_acc: 0.5024 - VH_attention_linear_output_acc: 0.5110 - val_loss: 3.4833 - val_VL_attention_linear_output_loss: 1.7477 - val_VH_attention_linear_output_loss: 1.7356 - val_VL_attention_linear_output_acc: 0.4920 - val_VH_attention_linear_output_acc: 0.4960\n",
      "Epoch 3826/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3357 - VL_attention_linear_output_loss: 1.6685 - VH_attention_linear_output_loss: 1.6671 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5147 - val_loss: 3.4903 - val_VL_attention_linear_output_loss: 1.7471 - val_VH_attention_linear_output_loss: 1.7432 - val_VL_attention_linear_output_acc: 0.4937 - val_VH_attention_linear_output_acc: 0.4962\n",
      "Epoch 3827/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3452 - VL_attention_linear_output_loss: 1.6732 - VH_attention_linear_output_loss: 1.6720 - VL_attention_linear_output_acc: 0.5076 - VH_attention_linear_output_acc: 0.5133 - val_loss: 3.5610 - val_VL_attention_linear_output_loss: 1.7460 - val_VH_attention_linear_output_loss: 1.8149 - val_VL_attention_linear_output_acc: 0.4957 - val_VH_attention_linear_output_acc: 0.4719\n",
      "Epoch 3828/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3628 - VL_attention_linear_output_loss: 1.6866 - VH_attention_linear_output_loss: 1.6762 - VL_attention_linear_output_acc: 0.5013 - VH_attention_linear_output_acc: 0.5117 - val_loss: 3.5040 - val_VL_attention_linear_output_loss: 1.7431 - val_VH_attention_linear_output_loss: 1.7609 - val_VL_attention_linear_output_acc: 0.5015 - val_VH_attention_linear_output_acc: 0.4920\n",
      "Epoch 3829/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3663 - VL_attention_linear_output_loss: 1.6723 - VH_attention_linear_output_loss: 1.6940 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5038 - val_loss: 3.4804 - val_VL_attention_linear_output_loss: 1.7452 - val_VH_attention_linear_output_loss: 1.7351 - val_VL_attention_linear_output_acc: 0.4956 - val_VH_attention_linear_output_acc: 0.4995\n",
      "Epoch 3830/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3527 - VL_attention_linear_output_loss: 1.6805 - VH_attention_linear_output_loss: 1.6722 - VL_attention_linear_output_acc: 0.5040 - VH_attention_linear_output_acc: 0.5125 - val_loss: 3.4752 - val_VL_attention_linear_output_loss: 1.7461 - val_VH_attention_linear_output_loss: 1.7291 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.5013\n",
      "Epoch 3831/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3480 - VL_attention_linear_output_loss: 1.6799 - VH_attention_linear_output_loss: 1.6681 - VL_attention_linear_output_acc: 0.5049 - VH_attention_linear_output_acc: 0.5140 - val_loss: 3.4902 - val_VL_attention_linear_output_loss: 1.7534 - val_VH_attention_linear_output_loss: 1.7368 - val_VL_attention_linear_output_acc: 0.4924 - val_VH_attention_linear_output_acc: 0.4986\n",
      "Epoch 3832/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3580 - VL_attention_linear_output_loss: 1.6832 - VH_attention_linear_output_loss: 1.6749 - VL_attention_linear_output_acc: 0.5027 - VH_attention_linear_output_acc: 0.5117 - val_loss: 3.4849 - val_VL_attention_linear_output_loss: 1.7430 - val_VH_attention_linear_output_loss: 1.7419 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.4988\n",
      "Epoch 3833/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3442 - VL_attention_linear_output_loss: 1.6748 - VH_attention_linear_output_loss: 1.6694 - VL_attention_linear_output_acc: 0.5068 - VH_attention_linear_output_acc: 0.5139 - val_loss: 3.4879 - val_VL_attention_linear_output_loss: 1.7508 - val_VH_attention_linear_output_loss: 1.7372 - val_VL_attention_linear_output_acc: 0.4892 - val_VH_attention_linear_output_acc: 0.5000\n",
      "Epoch 3834/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3531 - VL_attention_linear_output_loss: 1.6817 - VH_attention_linear_output_loss: 1.6714 - VL_attention_linear_output_acc: 0.5044 - VH_attention_linear_output_acc: 0.5136 - val_loss: 3.5245 - val_VL_attention_linear_output_loss: 1.7653 - val_VH_attention_linear_output_loss: 1.7592 - val_VL_attention_linear_output_acc: 0.4890 - val_VH_attention_linear_output_acc: 0.4946\n",
      "Epoch 3835/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3618 - VL_attention_linear_output_loss: 1.6808 - VH_attention_linear_output_loss: 1.6810 - VL_attention_linear_output_acc: 0.5044 - VH_attention_linear_output_acc: 0.5097 - val_loss: 3.4842 - val_VL_attention_linear_output_loss: 1.7544 - val_VH_attention_linear_output_loss: 1.7298 - val_VL_attention_linear_output_acc: 0.4943 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 3836/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3502 - VL_attention_linear_output_loss: 1.6768 - VH_attention_linear_output_loss: 1.6734 - VL_attention_linear_output_acc: 0.5069 - VH_attention_linear_output_acc: 0.5125 - val_loss: 3.5761 - val_VL_attention_linear_output_loss: 1.7775 - val_VH_attention_linear_output_loss: 1.7986 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.4719\n",
      "Epoch 3837/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3702 - VL_attention_linear_output_loss: 1.6809 - VH_attention_linear_output_loss: 1.6893 - VL_attention_linear_output_acc: 0.5045 - VH_attention_linear_output_acc: 0.5069 - val_loss: 3.5002 - val_VL_attention_linear_output_loss: 1.7447 - val_VH_attention_linear_output_loss: 1.7555 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.4948\n",
      "Epoch 3838/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3677 - VL_attention_linear_output_loss: 1.6774 - VH_attention_linear_output_loss: 1.6903 - VL_attention_linear_output_acc: 0.5065 - VH_attention_linear_output_acc: 0.5061 - val_loss: 3.5144 - val_VL_attention_linear_output_loss: 1.7539 - val_VH_attention_linear_output_loss: 1.7604 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.4910\n",
      "Epoch 3839/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3545 - VL_attention_linear_output_loss: 1.6836 - VH_attention_linear_output_loss: 1.6709 - VL_attention_linear_output_acc: 0.5025 - VH_attention_linear_output_acc: 0.5136 - val_loss: 3.4743 - val_VL_attention_linear_output_loss: 1.7444 - val_VH_attention_linear_output_loss: 1.7299 - val_VL_attention_linear_output_acc: 0.4992 - val_VH_attention_linear_output_acc: 0.5009\n",
      "Epoch 3840/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3577 - VL_attention_linear_output_loss: 1.6800 - VH_attention_linear_output_loss: 1.6777 - VL_attention_linear_output_acc: 0.5050 - VH_attention_linear_output_acc: 0.5109 - val_loss: 3.4918 - val_VL_attention_linear_output_loss: 1.7496 - val_VH_attention_linear_output_loss: 1.7422 - val_VL_attention_linear_output_acc: 0.4976 - val_VH_attention_linear_output_acc: 0.4990\n",
      "Epoch 3841/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3456 - VL_attention_linear_output_loss: 1.6755 - VH_attention_linear_output_loss: 1.6701 - VL_attention_linear_output_acc: 0.5069 - VH_attention_linear_output_acc: 0.5137 - val_loss: 3.4779 - val_VL_attention_linear_output_loss: 1.7454 - val_VH_attention_linear_output_loss: 1.7325 - val_VL_attention_linear_output_acc: 0.4937 - val_VH_attention_linear_output_acc: 0.5029\n",
      "Epoch 3842/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3473 - VL_attention_linear_output_loss: 1.6767 - VH_attention_linear_output_loss: 1.6706 - VL_attention_linear_output_acc: 0.5057 - VH_attention_linear_output_acc: 0.5139 - val_loss: 3.4747 - val_VL_attention_linear_output_loss: 1.7390 - val_VH_attention_linear_output_loss: 1.7357 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5020\n",
      "Epoch 3843/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3542 - VL_attention_linear_output_loss: 1.6712 - VH_attention_linear_output_loss: 1.6830 - VL_attention_linear_output_acc: 0.5081 - VH_attention_linear_output_acc: 0.5094 - val_loss: 3.4786 - val_VL_attention_linear_output_loss: 1.7431 - val_VH_attention_linear_output_loss: 1.7356 - val_VL_attention_linear_output_acc: 0.4966 - val_VH_attention_linear_output_acc: 0.5009\n",
      "Epoch 3844/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3449 - VL_attention_linear_output_loss: 1.6767 - VH_attention_linear_output_loss: 1.6681 - VL_attention_linear_output_acc: 0.5072 - VH_attention_linear_output_acc: 0.5151 - val_loss: 3.5094 - val_VL_attention_linear_output_loss: 1.7780 - val_VH_attention_linear_output_loss: 1.7314 - val_VL_attention_linear_output_acc: 0.4743 - val_VH_attention_linear_output_acc: 0.5012\n",
      "Epoch 3845/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3812 - VL_attention_linear_output_loss: 1.6916 - VH_attention_linear_output_loss: 1.6896 - VL_attention_linear_output_acc: 0.4997 - VH_attention_linear_output_acc: 0.5073 - val_loss: 3.5042 - val_VL_attention_linear_output_loss: 1.7737 - val_VH_attention_linear_output_loss: 1.7304 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.4997\n",
      "Epoch 3846/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3677 - VL_attention_linear_output_loss: 1.6964 - VH_attention_linear_output_loss: 1.6712 - VL_attention_linear_output_acc: 0.4984 - VH_attention_linear_output_acc: 0.5131 - val_loss: 3.4815 - val_VL_attention_linear_output_loss: 1.7437 - val_VH_attention_linear_output_loss: 1.7378 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.4974\n",
      "Epoch 3847/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3389 - VL_attention_linear_output_loss: 1.6696 - VH_attention_linear_output_loss: 1.6693 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5151 - val_loss: 3.4857 - val_VL_attention_linear_output_loss: 1.7467 - val_VH_attention_linear_output_loss: 1.7389 - val_VL_attention_linear_output_acc: 0.4939 - val_VH_attention_linear_output_acc: 0.4966\n",
      "Epoch 3848/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3433 - VL_attention_linear_output_loss: 1.6671 - VH_attention_linear_output_loss: 1.6762 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5116 - val_loss: 3.4793 - val_VL_attention_linear_output_loss: 1.7429 - val_VH_attention_linear_output_loss: 1.7364 - val_VL_attention_linear_output_acc: 0.4953 - val_VH_attention_linear_output_acc: 0.4989\n",
      "Epoch 3849/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3587 - VL_attention_linear_output_loss: 1.6775 - VH_attention_linear_output_loss: 1.6812 - VL_attention_linear_output_acc: 0.5061 - VH_attention_linear_output_acc: 0.5101 - val_loss: 3.4836 - val_VL_attention_linear_output_loss: 1.7461 - val_VH_attention_linear_output_loss: 1.7375 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.5015\n",
      "Epoch 3850/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3457 - VL_attention_linear_output_loss: 1.6753 - VH_attention_linear_output_loss: 1.6703 - VL_attention_linear_output_acc: 0.5072 - VH_attention_linear_output_acc: 0.5148 - val_loss: 3.4850 - val_VL_attention_linear_output_loss: 1.7529 - val_VH_attention_linear_output_loss: 1.7321 - val_VL_attention_linear_output_acc: 0.4943 - val_VH_attention_linear_output_acc: 0.4997\n",
      "Epoch 3851/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3401 - VL_attention_linear_output_loss: 1.6712 - VH_attention_linear_output_loss: 1.6690 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5146 - val_loss: 3.4765 - val_VL_attention_linear_output_loss: 1.7460 - val_VH_attention_linear_output_loss: 1.7304 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 3852/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3716 - VL_attention_linear_output_loss: 1.6754 - VH_attention_linear_output_loss: 1.6962 - VL_attention_linear_output_acc: 0.5058 - VH_attention_linear_output_acc: 0.5046 - val_loss: 3.4906 - val_VL_attention_linear_output_loss: 1.7546 - val_VH_attention_linear_output_loss: 1.7361 - val_VL_attention_linear_output_acc: 0.4941 - val_VH_attention_linear_output_acc: 0.4977\n",
      "Epoch 3853/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3526 - VL_attention_linear_output_loss: 1.6800 - VH_attention_linear_output_loss: 1.6726 - VL_attention_linear_output_acc: 0.5051 - VH_attention_linear_output_acc: 0.5133 - val_loss: 3.4742 - val_VL_attention_linear_output_loss: 1.7404 - val_VH_attention_linear_output_loss: 1.7337 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.5021\n",
      "Epoch 3854/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3470 - VL_attention_linear_output_loss: 1.6772 - VH_attention_linear_output_loss: 1.6698 - VL_attention_linear_output_acc: 0.5060 - VH_attention_linear_output_acc: 0.5141 - val_loss: 3.4912 - val_VL_attention_linear_output_loss: 1.7468 - val_VH_attention_linear_output_loss: 1.7445 - val_VL_attention_linear_output_acc: 0.4934 - val_VH_attention_linear_output_acc: 0.4978\n",
      "Epoch 3855/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3605 - VL_attention_linear_output_loss: 1.6790 - VH_attention_linear_output_loss: 1.6815 - VL_attention_linear_output_acc: 0.5043 - VH_attention_linear_output_acc: 0.5104 - val_loss: 3.5051 - val_VL_attention_linear_output_loss: 1.7509 - val_VH_attention_linear_output_loss: 1.7542 - val_VL_attention_linear_output_acc: 0.4922 - val_VH_attention_linear_output_acc: 0.4920\n",
      "Epoch 3856/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3585 - VL_attention_linear_output_loss: 1.6805 - VH_attention_linear_output_loss: 1.6780 - VL_attention_linear_output_acc: 0.5062 - VH_attention_linear_output_acc: 0.5113 - val_loss: 3.5182 - val_VL_attention_linear_output_loss: 1.7880 - val_VH_attention_linear_output_loss: 1.7302 - val_VL_attention_linear_output_acc: 0.4797 - val_VH_attention_linear_output_acc: 0.5000\n",
      "Epoch 3857/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3571 - VL_attention_linear_output_loss: 1.6828 - VH_attention_linear_output_loss: 1.6743 - VL_attention_linear_output_acc: 0.5031 - VH_attention_linear_output_acc: 0.5122 - val_loss: 3.4963 - val_VL_attention_linear_output_loss: 1.7548 - val_VH_attention_linear_output_loss: 1.7414 - val_VL_attention_linear_output_acc: 0.4925 - val_VH_attention_linear_output_acc: 0.4974\n",
      "Epoch 3858/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3506 - VL_attention_linear_output_loss: 1.6755 - VH_attention_linear_output_loss: 1.6751 - VL_attention_linear_output_acc: 0.5064 - VH_attention_linear_output_acc: 0.5128 - val_loss: 3.4890 - val_VL_attention_linear_output_loss: 1.7426 - val_VH_attention_linear_output_loss: 1.7464 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.4978\n",
      "Epoch 3859/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3623 - VL_attention_linear_output_loss: 1.6845 - VH_attention_linear_output_loss: 1.6778 - VL_attention_linear_output_acc: 0.5019 - VH_attention_linear_output_acc: 0.5111 - val_loss: 3.5347 - val_VL_attention_linear_output_loss: 1.7718 - val_VH_attention_linear_output_loss: 1.7629 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.4942\n",
      "Epoch 3860/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3588 - VL_attention_linear_output_loss: 1.6757 - VH_attention_linear_output_loss: 1.6832 - VL_attention_linear_output_acc: 0.5069 - VH_attention_linear_output_acc: 0.5095 - val_loss: 3.5071 - val_VL_attention_linear_output_loss: 1.7596 - val_VH_attention_linear_output_loss: 1.7476 - val_VL_attention_linear_output_acc: 0.4895 - val_VH_attention_linear_output_acc: 0.4958\n",
      "Epoch 3861/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3662 - VL_attention_linear_output_loss: 1.6834 - VH_attention_linear_output_loss: 1.6828 - VL_attention_linear_output_acc: 0.5025 - VH_attention_linear_output_acc: 0.5093 - val_loss: 3.4884 - val_VL_attention_linear_output_loss: 1.7602 - val_VH_attention_linear_output_loss: 1.7282 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.5019\n",
      "Epoch 3862/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3565 - VL_attention_linear_output_loss: 1.6810 - VH_attention_linear_output_loss: 1.6755 - VL_attention_linear_output_acc: 0.5044 - VH_attention_linear_output_acc: 0.5122 - val_loss: 3.4978 - val_VL_attention_linear_output_loss: 1.7634 - val_VH_attention_linear_output_loss: 1.7344 - val_VL_attention_linear_output_acc: 0.4809 - val_VH_attention_linear_output_acc: 0.5014\n",
      "Epoch 3863/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3407 - VL_attention_linear_output_loss: 1.6758 - VH_attention_linear_output_loss: 1.6649 - VL_attention_linear_output_acc: 0.5068 - VH_attention_linear_output_acc: 0.5163 - val_loss: 3.5096 - val_VL_attention_linear_output_loss: 1.7599 - val_VH_attention_linear_output_loss: 1.7497 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4919\n",
      "Epoch 3864/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3628 - VL_attention_linear_output_loss: 1.6863 - VH_attention_linear_output_loss: 1.6766 - VL_attention_linear_output_acc: 0.5019 - VH_attention_linear_output_acc: 0.5118 - val_loss: 3.4739 - val_VL_attention_linear_output_loss: 1.7439 - val_VH_attention_linear_output_loss: 1.7299 - val_VL_attention_linear_output_acc: 0.4997 - val_VH_attention_linear_output_acc: 0.5009\n",
      "Epoch 3865/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3360 - VL_attention_linear_output_loss: 1.6678 - VH_attention_linear_output_loss: 1.6682 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5145 - val_loss: 3.4765 - val_VL_attention_linear_output_loss: 1.7391 - val_VH_attention_linear_output_loss: 1.7374 - val_VL_attention_linear_output_acc: 0.4997 - val_VH_attention_linear_output_acc: 0.4997\n",
      "Epoch 3866/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3413 - VL_attention_linear_output_loss: 1.6681 - VH_attention_linear_output_loss: 1.6732 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5122 - val_loss: 3.4891 - val_VL_attention_linear_output_loss: 1.7432 - val_VH_attention_linear_output_loss: 1.7458 - val_VL_attention_linear_output_acc: 0.4998 - val_VH_attention_linear_output_acc: 0.4930\n",
      "Epoch 3867/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3617 - VL_attention_linear_output_loss: 1.6725 - VH_attention_linear_output_loss: 1.6892 - VL_attention_linear_output_acc: 0.5093 - VH_attention_linear_output_acc: 0.5070 - val_loss: 3.4896 - val_VL_attention_linear_output_loss: 1.7490 - val_VH_attention_linear_output_loss: 1.7406 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.4989\n",
      "Epoch 3868/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3532 - VL_attention_linear_output_loss: 1.6786 - VH_attention_linear_output_loss: 1.6746 - VL_attention_linear_output_acc: 0.5057 - VH_attention_linear_output_acc: 0.5128 - val_loss: 3.4818 - val_VL_attention_linear_output_loss: 1.7456 - val_VH_attention_linear_output_loss: 1.7363 - val_VL_attention_linear_output_acc: 0.4921 - val_VH_attention_linear_output_acc: 0.4967\n",
      "Epoch 3869/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3561 - VL_attention_linear_output_loss: 1.6808 - VH_attention_linear_output_loss: 1.6753 - VL_attention_linear_output_acc: 0.5050 - VH_attention_linear_output_acc: 0.5119 - val_loss: 3.4828 - val_VL_attention_linear_output_loss: 1.7468 - val_VH_attention_linear_output_loss: 1.7359 - val_VL_attention_linear_output_acc: 0.4925 - val_VH_attention_linear_output_acc: 0.4993\n",
      "Epoch 3870/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3461 - VL_attention_linear_output_loss: 1.6735 - VH_attention_linear_output_loss: 1.6726 - VL_attention_linear_output_acc: 0.5085 - VH_attention_linear_output_acc: 0.5129 - val_loss: 3.4833 - val_VL_attention_linear_output_loss: 1.7502 - val_VH_attention_linear_output_loss: 1.7331 - val_VL_attention_linear_output_acc: 0.4906 - val_VH_attention_linear_output_acc: 0.4982\n",
      "Epoch 3871/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3585 - VL_attention_linear_output_loss: 1.6804 - VH_attention_linear_output_loss: 1.6781 - VL_attention_linear_output_acc: 0.5048 - VH_attention_linear_output_acc: 0.5115 - val_loss: 3.5264 - val_VL_attention_linear_output_loss: 1.7518 - val_VH_attention_linear_output_loss: 1.7746 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.4863\n",
      "Epoch 3872/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3607 - VL_attention_linear_output_loss: 1.6858 - VH_attention_linear_output_loss: 1.6750 - VL_attention_linear_output_acc: 0.5038 - VH_attention_linear_output_acc: 0.5125 - val_loss: 3.4842 - val_VL_attention_linear_output_loss: 1.7455 - val_VH_attention_linear_output_loss: 1.7387 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.4928\n",
      "Epoch 3873/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3645 - VL_attention_linear_output_loss: 1.6839 - VH_attention_linear_output_loss: 1.6806 - VL_attention_linear_output_acc: 0.5037 - VH_attention_linear_output_acc: 0.5104 - val_loss: 3.4863 - val_VL_attention_linear_output_loss: 1.7415 - val_VH_attention_linear_output_loss: 1.7448 - val_VL_attention_linear_output_acc: 0.4985 - val_VH_attention_linear_output_acc: 0.4983\n",
      "Epoch 3874/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3573 - VL_attention_linear_output_loss: 1.6758 - VH_attention_linear_output_loss: 1.6815 - VL_attention_linear_output_acc: 0.5066 - VH_attention_linear_output_acc: 0.5091 - val_loss: 3.4721 - val_VL_attention_linear_output_loss: 1.7372 - val_VH_attention_linear_output_loss: 1.7348 - val_VL_attention_linear_output_acc: 0.5004 - val_VH_attention_linear_output_acc: 0.4999\n",
      "Epoch 3875/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3561 - VL_attention_linear_output_loss: 1.6853 - VH_attention_linear_output_loss: 1.6709 - VL_attention_linear_output_acc: 0.5027 - VH_attention_linear_output_acc: 0.5141 - val_loss: 3.4773 - val_VL_attention_linear_output_loss: 1.7466 - val_VH_attention_linear_output_loss: 1.7307 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.5029\n",
      "Epoch 3876/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3647 - VL_attention_linear_output_loss: 1.6897 - VH_attention_linear_output_loss: 1.6750 - VL_attention_linear_output_acc: 0.5007 - VH_attention_linear_output_acc: 0.5125 - val_loss: 3.4930 - val_VL_attention_linear_output_loss: 1.7486 - val_VH_attention_linear_output_loss: 1.7444 - val_VL_attention_linear_output_acc: 0.4924 - val_VH_attention_linear_output_acc: 0.4967\n",
      "Epoch 3877/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3546 - VL_attention_linear_output_loss: 1.6847 - VH_attention_linear_output_loss: 1.6699 - VL_attention_linear_output_acc: 0.5033 - VH_attention_linear_output_acc: 0.5143 - val_loss: 3.4883 - val_VL_attention_linear_output_loss: 1.7413 - val_VH_attention_linear_output_loss: 1.7470 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.4948\n",
      "Epoch 3878/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3442 - VL_attention_linear_output_loss: 1.6682 - VH_attention_linear_output_loss: 1.6760 - VL_attention_linear_output_acc: 0.5118 - VH_attention_linear_output_acc: 0.5121 - val_loss: 3.4806 - val_VL_attention_linear_output_loss: 1.7445 - val_VH_attention_linear_output_loss: 1.7361 - val_VL_attention_linear_output_acc: 0.4984 - val_VH_attention_linear_output_acc: 0.4979\n",
      "Epoch 3879/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3523 - VL_attention_linear_output_loss: 1.6725 - VH_attention_linear_output_loss: 1.6798 - VL_attention_linear_output_acc: 0.5075 - VH_attention_linear_output_acc: 0.5116 - val_loss: 3.4871 - val_VL_attention_linear_output_loss: 1.7499 - val_VH_attention_linear_output_loss: 1.7372 - val_VL_attention_linear_output_acc: 0.4905 - val_VH_attention_linear_output_acc: 0.5030\n",
      "Epoch 3880/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3474 - VL_attention_linear_output_loss: 1.6741 - VH_attention_linear_output_loss: 1.6733 - VL_attention_linear_output_acc: 0.5086 - VH_attention_linear_output_acc: 0.5128 - val_loss: 3.4770 - val_VL_attention_linear_output_loss: 1.7413 - val_VH_attention_linear_output_loss: 1.7357 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.5034\n",
      "Epoch 3881/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3589 - VL_attention_linear_output_loss: 1.6841 - VH_attention_linear_output_loss: 1.6748 - VL_attention_linear_output_acc: 0.5030 - VH_attention_linear_output_acc: 0.5128 - val_loss: 3.4949 - val_VL_attention_linear_output_loss: 1.7548 - val_VH_attention_linear_output_loss: 1.7401 - val_VL_attention_linear_output_acc: 0.4905 - val_VH_attention_linear_output_acc: 0.4975\n",
      "Epoch 3882/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3654 - VL_attention_linear_output_loss: 1.6816 - VH_attention_linear_output_loss: 1.6838 - VL_attention_linear_output_acc: 0.5042 - VH_attention_linear_output_acc: 0.5084 - val_loss: 3.5568 - val_VL_attention_linear_output_loss: 1.7442 - val_VH_attention_linear_output_loss: 1.8126 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.4668\n",
      "Epoch 3883/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3499 - VL_attention_linear_output_loss: 1.6719 - VH_attention_linear_output_loss: 1.6780 - VL_attention_linear_output_acc: 0.5087 - VH_attention_linear_output_acc: 0.5117 - val_loss: 3.5011 - val_VL_attention_linear_output_loss: 1.7539 - val_VH_attention_linear_output_loss: 1.7472 - val_VL_attention_linear_output_acc: 0.4917 - val_VH_attention_linear_output_acc: 0.4985\n",
      "Epoch 3884/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3589 - VL_attention_linear_output_loss: 1.6909 - VH_attention_linear_output_loss: 1.6680 - VL_attention_linear_output_acc: 0.5000 - VH_attention_linear_output_acc: 0.5150 - val_loss: 3.4915 - val_VL_attention_linear_output_loss: 1.7578 - val_VH_attention_linear_output_loss: 1.7337 - val_VL_attention_linear_output_acc: 0.4893 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 3885/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3369 - VL_attention_linear_output_loss: 1.6702 - VH_attention_linear_output_loss: 1.6668 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5163 - val_loss: 3.4771 - val_VL_attention_linear_output_loss: 1.7424 - val_VH_attention_linear_output_loss: 1.7347 - val_VL_attention_linear_output_acc: 0.4995 - val_VH_attention_linear_output_acc: 0.5021\n",
      "Epoch 3886/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3497 - VL_attention_linear_output_loss: 1.6824 - VH_attention_linear_output_loss: 1.6672 - VL_attention_linear_output_acc: 0.5040 - VH_attention_linear_output_acc: 0.5152 - val_loss: 3.4805 - val_VL_attention_linear_output_loss: 1.7443 - val_VH_attention_linear_output_loss: 1.7362 - val_VL_attention_linear_output_acc: 0.5012 - val_VH_attention_linear_output_acc: 0.5000\n",
      "Epoch 3887/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3522 - VL_attention_linear_output_loss: 1.6783 - VH_attention_linear_output_loss: 1.6739 - VL_attention_linear_output_acc: 0.5058 - VH_attention_linear_output_acc: 0.5131 - val_loss: 3.4863 - val_VL_attention_linear_output_loss: 1.7485 - val_VH_attention_linear_output_loss: 1.7378 - val_VL_attention_linear_output_acc: 0.4900 - val_VH_attention_linear_output_acc: 0.4966\n",
      "Epoch 3888/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3429 - VL_attention_linear_output_loss: 1.6701 - VH_attention_linear_output_loss: 1.6728 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5133 - val_loss: 3.4869 - val_VL_attention_linear_output_loss: 1.7440 - val_VH_attention_linear_output_loss: 1.7429 - val_VL_attention_linear_output_acc: 0.4979 - val_VH_attention_linear_output_acc: 0.4936\n",
      "Epoch 3889/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3608 - VL_attention_linear_output_loss: 1.6845 - VH_attention_linear_output_loss: 1.6762 - VL_attention_linear_output_acc: 0.5038 - VH_attention_linear_output_acc: 0.5119 - val_loss: 3.4895 - val_VL_attention_linear_output_loss: 1.7390 - val_VH_attention_linear_output_loss: 1.7505 - val_VL_attention_linear_output_acc: 0.4975 - val_VH_attention_linear_output_acc: 0.4977\n",
      "Epoch 3890/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3427 - VL_attention_linear_output_loss: 1.6724 - VH_attention_linear_output_loss: 1.6703 - VL_attention_linear_output_acc: 0.5093 - VH_attention_linear_output_acc: 0.5139 - val_loss: 3.4774 - val_VL_attention_linear_output_loss: 1.7355 - val_VH_attention_linear_output_loss: 1.7419 - val_VL_attention_linear_output_acc: 0.5000 - val_VH_attention_linear_output_acc: 0.4993\n",
      "Epoch 3891/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3347 - VL_attention_linear_output_loss: 1.6670 - VH_attention_linear_output_loss: 1.6677 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5148 - val_loss: 3.4860 - val_VL_attention_linear_output_loss: 1.7438 - val_VH_attention_linear_output_loss: 1.7422 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.4975\n",
      "Epoch 3892/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3414 - VL_attention_linear_output_loss: 1.6725 - VH_attention_linear_output_loss: 1.6689 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5147 - val_loss: 3.4732 - val_VL_attention_linear_output_loss: 1.7424 - val_VH_attention_linear_output_loss: 1.7308 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.5003\n",
      "Epoch 3893/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3465 - VL_attention_linear_output_loss: 1.6726 - VH_attention_linear_output_loss: 1.6738 - VL_attention_linear_output_acc: 0.5077 - VH_attention_linear_output_acc: 0.5126 - val_loss: 3.4752 - val_VL_attention_linear_output_loss: 1.7404 - val_VH_attention_linear_output_loss: 1.7348 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.5001\n",
      "Epoch 3894/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3555 - VL_attention_linear_output_loss: 1.6812 - VH_attention_linear_output_loss: 1.6743 - VL_attention_linear_output_acc: 0.5047 - VH_attention_linear_output_acc: 0.5125 - val_loss: 3.5321 - val_VL_attention_linear_output_loss: 1.7960 - val_VH_attention_linear_output_loss: 1.7362 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.5032\n",
      "Epoch 3895/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3365 - VL_attention_linear_output_loss: 1.6678 - VH_attention_linear_output_loss: 1.6686 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5148 - val_loss: 3.4700 - val_VL_attention_linear_output_loss: 1.7354 - val_VH_attention_linear_output_loss: 1.7346 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5014\n",
      "Epoch 3896/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3518 - VL_attention_linear_output_loss: 1.6796 - VH_attention_linear_output_loss: 1.6723 - VL_attention_linear_output_acc: 0.5046 - VH_attention_linear_output_acc: 0.5129 - val_loss: 3.5066 - val_VL_attention_linear_output_loss: 1.7739 - val_VH_attention_linear_output_loss: 1.7326 - val_VL_attention_linear_output_acc: 0.4800 - val_VH_attention_linear_output_acc: 0.5001\n",
      "Epoch 3897/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3664 - VL_attention_linear_output_loss: 1.6841 - VH_attention_linear_output_loss: 1.6824 - VL_attention_linear_output_acc: 0.5034 - VH_attention_linear_output_acc: 0.5097 - val_loss: 3.4707 - val_VL_attention_linear_output_loss: 1.7406 - val_VH_attention_linear_output_loss: 1.7302 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.5024\n",
      "Epoch 3898/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3368 - VL_attention_linear_output_loss: 1.6692 - VH_attention_linear_output_loss: 1.6676 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5151 - val_loss: 3.4667 - val_VL_attention_linear_output_loss: 1.7371 - val_VH_attention_linear_output_loss: 1.7296 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 3899/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3450 - VL_attention_linear_output_loss: 1.6757 - VH_attention_linear_output_loss: 1.6694 - VL_attention_linear_output_acc: 0.5063 - VH_attention_linear_output_acc: 0.5141 - val_loss: 3.4951 - val_VL_attention_linear_output_loss: 1.7383 - val_VH_attention_linear_output_loss: 1.7568 - val_VL_attention_linear_output_acc: 0.4981 - val_VH_attention_linear_output_acc: 0.4946\n",
      "Epoch 3900/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3509 - VL_attention_linear_output_loss: 1.6740 - VH_attention_linear_output_loss: 1.6769 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5117 - val_loss: 3.4882 - val_VL_attention_linear_output_loss: 1.7498 - val_VH_attention_linear_output_loss: 1.7385 - val_VL_attention_linear_output_acc: 0.4935 - val_VH_attention_linear_output_acc: 0.5028\n",
      "Epoch 3901/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3496 - VL_attention_linear_output_loss: 1.6814 - VH_attention_linear_output_loss: 1.6683 - VL_attention_linear_output_acc: 0.5041 - VH_attention_linear_output_acc: 0.5152 - val_loss: 3.4953 - val_VL_attention_linear_output_loss: 1.7592 - val_VH_attention_linear_output_loss: 1.7361 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.5011\n",
      "Epoch 3902/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3542 - VL_attention_linear_output_loss: 1.6763 - VH_attention_linear_output_loss: 1.6778 - VL_attention_linear_output_acc: 0.5071 - VH_attention_linear_output_acc: 0.5110 - val_loss: 3.4762 - val_VL_attention_linear_output_loss: 1.7391 - val_VH_attention_linear_output_loss: 1.7371 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.5003\n",
      "Epoch 3903/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3443 - VL_attention_linear_output_loss: 1.6700 - VH_attention_linear_output_loss: 1.6743 - VL_attention_linear_output_acc: 0.5093 - VH_attention_linear_output_acc: 0.5127 - val_loss: 3.4665 - val_VL_attention_linear_output_loss: 1.7383 - val_VH_attention_linear_output_loss: 1.7281 - val_VL_attention_linear_output_acc: 0.4939 - val_VH_attention_linear_output_acc: 0.5039\n",
      "Epoch 3904/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3465 - VL_attention_linear_output_loss: 1.6745 - VH_attention_linear_output_loss: 1.6720 - VL_attention_linear_output_acc: 0.5087 - VH_attention_linear_output_acc: 0.5129 - val_loss: 3.4808 - val_VL_attention_linear_output_loss: 1.7443 - val_VH_attention_linear_output_loss: 1.7365 - val_VL_attention_linear_output_acc: 0.4952 - val_VH_attention_linear_output_acc: 0.5011\n",
      "Epoch 3905/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3814 - VL_attention_linear_output_loss: 1.6935 - VH_attention_linear_output_loss: 1.6879 - VL_attention_linear_output_acc: 0.5018 - VH_attention_linear_output_acc: 0.5083 - val_loss: 3.4926 - val_VL_attention_linear_output_loss: 1.7611 - val_VH_attention_linear_output_loss: 1.7316 - val_VL_attention_linear_output_acc: 0.4911 - val_VH_attention_linear_output_acc: 0.5039\n",
      "Epoch 3906/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3378 - VL_attention_linear_output_loss: 1.6744 - VH_attention_linear_output_loss: 1.6634 - VL_attention_linear_output_acc: 0.5075 - VH_attention_linear_output_acc: 0.5173 - val_loss: 3.4841 - val_VL_attention_linear_output_loss: 1.7382 - val_VH_attention_linear_output_loss: 1.7459 - val_VL_attention_linear_output_acc: 0.5030 - val_VH_attention_linear_output_acc: 0.4948\n",
      "Epoch 3907/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3626 - VL_attention_linear_output_loss: 1.6836 - VH_attention_linear_output_loss: 1.6790 - VL_attention_linear_output_acc: 0.5047 - VH_attention_linear_output_acc: 0.5106 - val_loss: 3.4720 - val_VL_attention_linear_output_loss: 1.7389 - val_VH_attention_linear_output_loss: 1.7332 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 3908/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3326 - VL_attention_linear_output_loss: 1.6676 - VH_attention_linear_output_loss: 1.6650 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5173 - val_loss: 3.5106 - val_VL_attention_linear_output_loss: 1.7667 - val_VH_attention_linear_output_loss: 1.7439 - val_VL_attention_linear_output_acc: 0.4883 - val_VH_attention_linear_output_acc: 0.4993\n",
      "Epoch 3909/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3440 - VL_attention_linear_output_loss: 1.6749 - VH_attention_linear_output_loss: 1.6691 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5149 - val_loss: 3.4856 - val_VL_attention_linear_output_loss: 1.7496 - val_VH_attention_linear_output_loss: 1.7360 - val_VL_attention_linear_output_acc: 0.4906 - val_VH_attention_linear_output_acc: 0.5039\n",
      "Epoch 3910/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3408 - VL_attention_linear_output_loss: 1.6756 - VH_attention_linear_output_loss: 1.6652 - VL_attention_linear_output_acc: 0.5074 - VH_attention_linear_output_acc: 0.5163 - val_loss: 3.4700 - val_VL_attention_linear_output_loss: 1.7397 - val_VH_attention_linear_output_loss: 1.7303 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.5029\n",
      "Epoch 3911/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3380 - VL_attention_linear_output_loss: 1.6715 - VH_attention_linear_output_loss: 1.6664 - VL_attention_linear_output_acc: 0.5085 - VH_attention_linear_output_acc: 0.5166 - val_loss: 3.4730 - val_VL_attention_linear_output_loss: 1.7419 - val_VH_attention_linear_output_loss: 1.7311 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 3912/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3454 - VL_attention_linear_output_loss: 1.6777 - VH_attention_linear_output_loss: 1.6677 - VL_attention_linear_output_acc: 0.5060 - VH_attention_linear_output_acc: 0.5156 - val_loss: 3.4773 - val_VL_attention_linear_output_loss: 1.7400 - val_VH_attention_linear_output_loss: 1.7373 - val_VL_attention_linear_output_acc: 0.4966 - val_VH_attention_linear_output_acc: 0.5015\n",
      "Epoch 3913/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3554 - VL_attention_linear_output_loss: 1.6814 - VH_attention_linear_output_loss: 1.6741 - VL_attention_linear_output_acc: 0.5053 - VH_attention_linear_output_acc: 0.5124 - val_loss: 3.5201 - val_VL_attention_linear_output_loss: 1.7576 - val_VH_attention_linear_output_loss: 1.7626 - val_VL_attention_linear_output_acc: 0.4830 - val_VH_attention_linear_output_acc: 0.4852\n",
      "Epoch 3914/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3553 - VL_attention_linear_output_loss: 1.6800 - VH_attention_linear_output_loss: 1.6752 - VL_attention_linear_output_acc: 0.5051 - VH_attention_linear_output_acc: 0.5129 - val_loss: 3.4794 - val_VL_attention_linear_output_loss: 1.7455 - val_VH_attention_linear_output_loss: 1.7339 - val_VL_attention_linear_output_acc: 0.4964 - val_VH_attention_linear_output_acc: 0.5010\n",
      "Epoch 3915/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3498 - VL_attention_linear_output_loss: 1.6820 - VH_attention_linear_output_loss: 1.6678 - VL_attention_linear_output_acc: 0.5038 - VH_attention_linear_output_acc: 0.5154 - val_loss: 3.4702 - val_VL_attention_linear_output_loss: 1.7395 - val_VH_attention_linear_output_loss: 1.7308 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5014\n",
      "Epoch 3916/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3455 - VL_attention_linear_output_loss: 1.6778 - VH_attention_linear_output_loss: 1.6677 - VL_attention_linear_output_acc: 0.5058 - VH_attention_linear_output_acc: 0.5155 - val_loss: 3.4874 - val_VL_attention_linear_output_loss: 1.7585 - val_VH_attention_linear_output_loss: 1.7289 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.5024\n",
      "Epoch 3917/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3490 - VL_attention_linear_output_loss: 1.6759 - VH_attention_linear_output_loss: 1.6731 - VL_attention_linear_output_acc: 0.5078 - VH_attention_linear_output_acc: 0.5135 - val_loss: 3.5228 - val_VL_attention_linear_output_loss: 1.7657 - val_VH_attention_linear_output_loss: 1.7571 - val_VL_attention_linear_output_acc: 0.4885 - val_VH_attention_linear_output_acc: 0.4884\n",
      "Epoch 3918/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3547 - VL_attention_linear_output_loss: 1.6749 - VH_attention_linear_output_loss: 1.6799 - VL_attention_linear_output_acc: 0.5076 - VH_attention_linear_output_acc: 0.5107 - val_loss: 3.4675 - val_VL_attention_linear_output_loss: 1.7396 - val_VH_attention_linear_output_loss: 1.7279 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.5017\n",
      "Epoch 3919/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3420 - VL_attention_linear_output_loss: 1.6765 - VH_attention_linear_output_loss: 1.6654 - VL_attention_linear_output_acc: 0.5070 - VH_attention_linear_output_acc: 0.5165 - val_loss: 3.4838 - val_VL_attention_linear_output_loss: 1.7556 - val_VH_attention_linear_output_loss: 1.7282 - val_VL_attention_linear_output_acc: 0.4856 - val_VH_attention_linear_output_acc: 0.5021\n",
      "Epoch 3920/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3335 - VL_attention_linear_output_loss: 1.6711 - VH_attention_linear_output_loss: 1.6625 - VL_attention_linear_output_acc: 0.5094 - VH_attention_linear_output_acc: 0.5174 - val_loss: 3.5180 - val_VL_attention_linear_output_loss: 1.7840 - val_VH_attention_linear_output_loss: 1.7341 - val_VL_attention_linear_output_acc: 0.4668 - val_VH_attention_linear_output_acc: 0.4989\n",
      "Epoch 3921/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3599 - VL_attention_linear_output_loss: 1.6870 - VH_attention_linear_output_loss: 1.6729 - VL_attention_linear_output_acc: 0.5015 - VH_attention_linear_output_acc: 0.5131 - val_loss: 3.4760 - val_VL_attention_linear_output_loss: 1.7442 - val_VH_attention_linear_output_loss: 1.7318 - val_VL_attention_linear_output_acc: 0.4976 - val_VH_attention_linear_output_acc: 0.5009\n",
      "Epoch 3922/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3568 - VL_attention_linear_output_loss: 1.6737 - VH_attention_linear_output_loss: 1.6831 - VL_attention_linear_output_acc: 0.5089 - VH_attention_linear_output_acc: 0.5099 - val_loss: 3.4807 - val_VL_attention_linear_output_loss: 1.7424 - val_VH_attention_linear_output_loss: 1.7383 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.4952\n",
      "Epoch 3923/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3477 - VL_attention_linear_output_loss: 1.6734 - VH_attention_linear_output_loss: 1.6743 - VL_attention_linear_output_acc: 0.5078 - VH_attention_linear_output_acc: 0.5128 - val_loss: 3.4999 - val_VL_attention_linear_output_loss: 1.7489 - val_VH_attention_linear_output_loss: 1.7511 - val_VL_attention_linear_output_acc: 0.4916 - val_VH_attention_linear_output_acc: 0.4918\n",
      "Epoch 3924/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3411 - VL_attention_linear_output_loss: 1.6723 - VH_attention_linear_output_loss: 1.6687 - VL_attention_linear_output_acc: 0.5078 - VH_attention_linear_output_acc: 0.5156 - val_loss: 3.4958 - val_VL_attention_linear_output_loss: 1.7500 - val_VH_attention_linear_output_loss: 1.7458 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.4964\n",
      "Epoch 3925/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3432 - VL_attention_linear_output_loss: 1.6757 - VH_attention_linear_output_loss: 1.6675 - VL_attention_linear_output_acc: 0.5072 - VH_attention_linear_output_acc: 0.5160 - val_loss: 3.4778 - val_VL_attention_linear_output_loss: 1.7456 - val_VH_attention_linear_output_loss: 1.7322 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 3926/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3366 - VL_attention_linear_output_loss: 1.6695 - VH_attention_linear_output_loss: 1.6671 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5158 - val_loss: 3.5415 - val_VL_attention_linear_output_loss: 1.7456 - val_VH_attention_linear_output_loss: 1.7959 - val_VL_attention_linear_output_acc: 0.4926 - val_VH_attention_linear_output_acc: 0.4706\n",
      "Epoch 3927/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3410 - VL_attention_linear_output_loss: 1.6759 - VH_attention_linear_output_loss: 1.6650 - VL_attention_linear_output_acc: 0.5065 - VH_attention_linear_output_acc: 0.5166 - val_loss: 3.5191 - val_VL_attention_linear_output_loss: 1.7559 - val_VH_attention_linear_output_loss: 1.7632 - val_VL_attention_linear_output_acc: 0.4932 - val_VH_attention_linear_output_acc: 0.4873\n",
      "Epoch 3928/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3517 - VL_attention_linear_output_loss: 1.6798 - VH_attention_linear_output_loss: 1.6718 - VL_attention_linear_output_acc: 0.5050 - VH_attention_linear_output_acc: 0.5138 - val_loss: 3.4754 - val_VL_attention_linear_output_loss: 1.7478 - val_VH_attention_linear_output_loss: 1.7276 - val_VL_attention_linear_output_acc: 0.4929 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 3929/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3451 - VL_attention_linear_output_loss: 1.6805 - VH_attention_linear_output_loss: 1.6646 - VL_attention_linear_output_acc: 0.5054 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4950 - val_VL_attention_linear_output_loss: 1.7647 - val_VH_attention_linear_output_loss: 1.7303 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.5014\n",
      "Epoch 3930/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3472 - VL_attention_linear_output_loss: 1.6760 - VH_attention_linear_output_loss: 1.6713 - VL_attention_linear_output_acc: 0.5074 - VH_attention_linear_output_acc: 0.5147 - val_loss: 3.4795 - val_VL_attention_linear_output_loss: 1.7438 - val_VH_attention_linear_output_loss: 1.7357 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.4970\n",
      "Epoch 3931/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3525 - VL_attention_linear_output_loss: 1.6774 - VH_attention_linear_output_loss: 1.6751 - VL_attention_linear_output_acc: 0.5059 - VH_attention_linear_output_acc: 0.5125 - val_loss: 3.5018 - val_VL_attention_linear_output_loss: 1.7577 - val_VH_attention_linear_output_loss: 1.7441 - val_VL_attention_linear_output_acc: 0.4920 - val_VH_attention_linear_output_acc: 0.4976\n",
      "Epoch 3932/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3408 - VL_attention_linear_output_loss: 1.6742 - VH_attention_linear_output_loss: 1.6665 - VL_attention_linear_output_acc: 0.5068 - VH_attention_linear_output_acc: 0.5160 - val_loss: 3.4833 - val_VL_attention_linear_output_loss: 1.7451 - val_VH_attention_linear_output_loss: 1.7382 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.4993\n",
      "Epoch 3933/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3512 - VL_attention_linear_output_loss: 1.6703 - VH_attention_linear_output_loss: 1.6809 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5101 - val_loss: 3.5216 - val_VL_attention_linear_output_loss: 1.7658 - val_VH_attention_linear_output_loss: 1.7558 - val_VL_attention_linear_output_acc: 0.4834 - val_VH_attention_linear_output_acc: 0.4929\n",
      "Epoch 3934/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3450 - VL_attention_linear_output_loss: 1.6777 - VH_attention_linear_output_loss: 1.6673 - VL_attention_linear_output_acc: 0.5067 - VH_attention_linear_output_acc: 0.5161 - val_loss: 3.4927 - val_VL_attention_linear_output_loss: 1.7377 - val_VH_attention_linear_output_loss: 1.7550 - val_VL_attention_linear_output_acc: 0.5028 - val_VH_attention_linear_output_acc: 0.4909\n",
      "Epoch 3935/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3397 - VL_attention_linear_output_loss: 1.6739 - VH_attention_linear_output_loss: 1.6658 - VL_attention_linear_output_acc: 0.5087 - VH_attention_linear_output_acc: 0.5166 - val_loss: 3.4691 - val_VL_attention_linear_output_loss: 1.7396 - val_VH_attention_linear_output_loss: 1.7295 - val_VL_attention_linear_output_acc: 0.5004 - val_VH_attention_linear_output_acc: 0.4999\n",
      "Epoch 3936/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3539 - VL_attention_linear_output_loss: 1.6840 - VH_attention_linear_output_loss: 1.6699 - VL_attention_linear_output_acc: 0.5048 - VH_attention_linear_output_acc: 0.5138 - val_loss: 3.4639 - val_VL_attention_linear_output_loss: 1.7355 - val_VH_attention_linear_output_loss: 1.7284 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 3937/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3488 - VL_attention_linear_output_loss: 1.6711 - VH_attention_linear_output_loss: 1.6777 - VL_attention_linear_output_acc: 0.5090 - VH_attention_linear_output_acc: 0.5124 - val_loss: 3.4813 - val_VL_attention_linear_output_loss: 1.7473 - val_VH_attention_linear_output_loss: 1.7340 - val_VL_attention_linear_output_acc: 0.4942 - val_VH_attention_linear_output_acc: 0.5027\n",
      "Epoch 3938/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3375 - VL_attention_linear_output_loss: 1.6751 - VH_attention_linear_output_loss: 1.6623 - VL_attention_linear_output_acc: 0.5077 - VH_attention_linear_output_acc: 0.5174 - val_loss: 3.4902 - val_VL_attention_linear_output_loss: 1.7568 - val_VH_attention_linear_output_loss: 1.7334 - val_VL_attention_linear_output_acc: 0.4883 - val_VH_attention_linear_output_acc: 0.4982\n",
      "Epoch 3939/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3617 - VL_attention_linear_output_loss: 1.6895 - VH_attention_linear_output_loss: 1.6722 - VL_attention_linear_output_acc: 0.5005 - VH_attention_linear_output_acc: 0.5137 - val_loss: 3.4772 - val_VL_attention_linear_output_loss: 1.7482 - val_VH_attention_linear_output_loss: 1.7289 - val_VL_attention_linear_output_acc: 0.4970 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 3940/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3280 - VL_attention_linear_output_loss: 1.6654 - VH_attention_linear_output_loss: 1.6626 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5173 - val_loss: 3.4820 - val_VL_attention_linear_output_loss: 1.7461 - val_VH_attention_linear_output_loss: 1.7359 - val_VL_attention_linear_output_acc: 0.5002 - val_VH_attention_linear_output_acc: 0.5019\n",
      "Epoch 3941/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3473 - VL_attention_linear_output_loss: 1.6715 - VH_attention_linear_output_loss: 1.6758 - VL_attention_linear_output_acc: 0.5095 - VH_attention_linear_output_acc: 0.5129 - val_loss: 3.5124 - val_VL_attention_linear_output_loss: 1.7488 - val_VH_attention_linear_output_loss: 1.7635 - val_VL_attention_linear_output_acc: 0.4924 - val_VH_attention_linear_output_acc: 0.4963\n",
      "Epoch 3942/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3386 - VL_attention_linear_output_loss: 1.6690 - VH_attention_linear_output_loss: 1.6696 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5147 - val_loss: 3.4763 - val_VL_attention_linear_output_loss: 1.7367 - val_VH_attention_linear_output_loss: 1.7396 - val_VL_attention_linear_output_acc: 0.5007 - val_VH_attention_linear_output_acc: 0.4977\n",
      "Epoch 3943/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3602 - VL_attention_linear_output_loss: 1.6897 - VH_attention_linear_output_loss: 1.6705 - VL_attention_linear_output_acc: 0.5019 - VH_attention_linear_output_acc: 0.5147 - val_loss: 3.5082 - val_VL_attention_linear_output_loss: 1.7426 - val_VH_attention_linear_output_loss: 1.7656 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.4886\n",
      "Epoch 3944/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3385 - VL_attention_linear_output_loss: 1.6717 - VH_attention_linear_output_loss: 1.6668 - VL_attention_linear_output_acc: 0.5091 - VH_attention_linear_output_acc: 0.5165 - val_loss: 3.4723 - val_VL_attention_linear_output_loss: 1.7418 - val_VH_attention_linear_output_loss: 1.7305 - val_VL_attention_linear_output_acc: 0.5027 - val_VH_attention_linear_output_acc: 0.5043\n",
      "Epoch 3945/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3505 - VL_attention_linear_output_loss: 1.6766 - VH_attention_linear_output_loss: 1.6739 - VL_attention_linear_output_acc: 0.5071 - VH_attention_linear_output_acc: 0.5131 - val_loss: 3.5048 - val_VL_attention_linear_output_loss: 1.7530 - val_VH_attention_linear_output_loss: 1.7518 - val_VL_attention_linear_output_acc: 0.4984 - val_VH_attention_linear_output_acc: 0.4924\n",
      "Epoch 3946/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3523 - VL_attention_linear_output_loss: 1.6726 - VH_attention_linear_output_loss: 1.6797 - VL_attention_linear_output_acc: 0.5092 - VH_attention_linear_output_acc: 0.5115 - val_loss: 3.4901 - val_VL_attention_linear_output_loss: 1.7501 - val_VH_attention_linear_output_loss: 1.7400 - val_VL_attention_linear_output_acc: 0.4917 - val_VH_attention_linear_output_acc: 0.4975\n",
      "Epoch 3947/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3438 - VL_attention_linear_output_loss: 1.6734 - VH_attention_linear_output_loss: 1.6704 - VL_attention_linear_output_acc: 0.5086 - VH_attention_linear_output_acc: 0.5148 - val_loss: 3.4972 - val_VL_attention_linear_output_loss: 1.7457 - val_VH_attention_linear_output_loss: 1.7514 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.4903\n",
      "Epoch 3948/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3460 - VL_attention_linear_output_loss: 1.6752 - VH_attention_linear_output_loss: 1.6709 - VL_attention_linear_output_acc: 0.5081 - VH_attention_linear_output_acc: 0.5140 - val_loss: 3.4815 - val_VL_attention_linear_output_loss: 1.7430 - val_VH_attention_linear_output_loss: 1.7385 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.5012\n",
      "Epoch 3949/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3403 - VL_attention_linear_output_loss: 1.6682 - VH_attention_linear_output_loss: 1.6721 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5137 - val_loss: 3.4857 - val_VL_attention_linear_output_loss: 1.7565 - val_VH_attention_linear_output_loss: 1.7292 - val_VL_attention_linear_output_acc: 0.4922 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 3950/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3424 - VL_attention_linear_output_loss: 1.6696 - VH_attention_linear_output_loss: 1.6728 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5136 - val_loss: 3.4662 - val_VL_attention_linear_output_loss: 1.7386 - val_VH_attention_linear_output_loss: 1.7276 - val_VL_attention_linear_output_acc: 0.5042 - val_VH_attention_linear_output_acc: 0.5006\n",
      "Epoch 3951/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3401 - VL_attention_linear_output_loss: 1.6670 - VH_attention_linear_output_loss: 1.6731 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5140 - val_loss: 3.5040 - val_VL_attention_linear_output_loss: 1.7494 - val_VH_attention_linear_output_loss: 1.7546 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.4907\n",
      "Epoch 3952/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3470 - VL_attention_linear_output_loss: 1.6790 - VH_attention_linear_output_loss: 1.6680 - VL_attention_linear_output_acc: 0.5059 - VH_attention_linear_output_acc: 0.5159 - val_loss: 3.4767 - val_VL_attention_linear_output_loss: 1.7469 - val_VH_attention_linear_output_loss: 1.7298 - val_VL_attention_linear_output_acc: 0.4984 - val_VH_attention_linear_output_acc: 0.5025\n",
      "Epoch 3953/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3461 - VL_attention_linear_output_loss: 1.6841 - VH_attention_linear_output_loss: 1.6621 - VL_attention_linear_output_acc: 0.5032 - VH_attention_linear_output_acc: 0.5178 - val_loss: 3.4829 - val_VL_attention_linear_output_loss: 1.7502 - val_VH_attention_linear_output_loss: 1.7327 - val_VL_attention_linear_output_acc: 0.4949 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 3954/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3356 - VL_attention_linear_output_loss: 1.6688 - VH_attention_linear_output_loss: 1.6668 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5161 - val_loss: 3.4900 - val_VL_attention_linear_output_loss: 1.7490 - val_VH_attention_linear_output_loss: 1.7411 - val_VL_attention_linear_output_acc: 0.4904 - val_VH_attention_linear_output_acc: 0.4992\n",
      "Epoch 3955/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3434 - VL_attention_linear_output_loss: 1.6752 - VH_attention_linear_output_loss: 1.6682 - VL_attention_linear_output_acc: 0.5062 - VH_attention_linear_output_acc: 0.5147 - val_loss: 3.4752 - val_VL_attention_linear_output_loss: 1.7444 - val_VH_attention_linear_output_loss: 1.7309 - val_VL_attention_linear_output_acc: 0.4952 - val_VH_attention_linear_output_acc: 0.5059\n",
      "Epoch 3956/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3415 - VL_attention_linear_output_loss: 1.6770 - VH_attention_linear_output_loss: 1.6645 - VL_attention_linear_output_acc: 0.5067 - VH_attention_linear_output_acc: 0.5172 - val_loss: 3.4731 - val_VL_attention_linear_output_loss: 1.7383 - val_VH_attention_linear_output_loss: 1.7348 - val_VL_attention_linear_output_acc: 0.4995 - val_VH_attention_linear_output_acc: 0.5008\n",
      "Epoch 3957/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3364 - VL_attention_linear_output_loss: 1.6677 - VH_attention_linear_output_loss: 1.6687 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5154 - val_loss: 3.4674 - val_VL_attention_linear_output_loss: 1.7339 - val_VH_attention_linear_output_loss: 1.7336 - val_VL_attention_linear_output_acc: 0.5062 - val_VH_attention_linear_output_acc: 0.4984\n",
      "Epoch 3958/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3443 - VL_attention_linear_output_loss: 1.6787 - VH_attention_linear_output_loss: 1.6655 - VL_attention_linear_output_acc: 0.5047 - VH_attention_linear_output_acc: 0.5164 - val_loss: 3.4701 - val_VL_attention_linear_output_loss: 1.7371 - val_VH_attention_linear_output_loss: 1.7330 - val_VL_attention_linear_output_acc: 0.4949 - val_VH_attention_linear_output_acc: 0.5026\n",
      "Epoch 3959/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3495 - VL_attention_linear_output_loss: 1.6729 - VH_attention_linear_output_loss: 1.6765 - VL_attention_linear_output_acc: 0.5090 - VH_attention_linear_output_acc: 0.5136 - val_loss: 3.4702 - val_VL_attention_linear_output_loss: 1.7377 - val_VH_attention_linear_output_loss: 1.7325 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.5001\n",
      "Epoch 3960/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3459 - VL_attention_linear_output_loss: 1.6710 - VH_attention_linear_output_loss: 1.6749 - VL_attention_linear_output_acc: 0.5096 - VH_attention_linear_output_acc: 0.5130 - val_loss: 3.4727 - val_VL_attention_linear_output_loss: 1.7388 - val_VH_attention_linear_output_loss: 1.7339 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.4981\n",
      "Epoch 3961/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3499 - VL_attention_linear_output_loss: 1.6749 - VH_attention_linear_output_loss: 1.6751 - VL_attention_linear_output_acc: 0.5082 - VH_attention_linear_output_acc: 0.5133 - val_loss: 3.4616 - val_VL_attention_linear_output_loss: 1.7369 - val_VH_attention_linear_output_loss: 1.7247 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.5059\n",
      "Epoch 3962/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3260 - VL_attention_linear_output_loss: 1.6628 - VH_attention_linear_output_loss: 1.6632 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5178 - val_loss: 3.4652 - val_VL_attention_linear_output_loss: 1.7350 - val_VH_attention_linear_output_loss: 1.7302 - val_VL_attention_linear_output_acc: 0.5022 - val_VH_attention_linear_output_acc: 0.5020\n",
      "Epoch 3963/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3344 - VL_attention_linear_output_loss: 1.6631 - VH_attention_linear_output_loss: 1.6713 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5139 - val_loss: 3.4858 - val_VL_attention_linear_output_loss: 1.7430 - val_VH_attention_linear_output_loss: 1.7428 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.4944\n",
      "Epoch 3964/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3383 - VL_attention_linear_output_loss: 1.6686 - VH_attention_linear_output_loss: 1.6697 - VL_attention_linear_output_acc: 0.5120 - VH_attention_linear_output_acc: 0.5153 - val_loss: 3.4801 - val_VL_attention_linear_output_loss: 1.7451 - val_VH_attention_linear_output_loss: 1.7350 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 3965/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3338 - VL_attention_linear_output_loss: 1.6702 - VH_attention_linear_output_loss: 1.6636 - VL_attention_linear_output_acc: 0.5098 - VH_attention_linear_output_acc: 0.5173 - val_loss: 3.4816 - val_VL_attention_linear_output_loss: 1.7506 - val_VH_attention_linear_output_loss: 1.7310 - val_VL_attention_linear_output_acc: 0.4938 - val_VH_attention_linear_output_acc: 0.5004\n",
      "Epoch 3966/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3446 - VL_attention_linear_output_loss: 1.6714 - VH_attention_linear_output_loss: 1.6732 - VL_attention_linear_output_acc: 0.5095 - VH_attention_linear_output_acc: 0.5134 - val_loss: 3.4874 - val_VL_attention_linear_output_loss: 1.7397 - val_VH_attention_linear_output_loss: 1.7477 - val_VL_attention_linear_output_acc: 0.4997 - val_VH_attention_linear_output_acc: 0.4954\n",
      "Epoch 3967/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3473 - VL_attention_linear_output_loss: 1.6760 - VH_attention_linear_output_loss: 1.6712 - VL_attention_linear_output_acc: 0.5064 - VH_attention_linear_output_acc: 0.5144 - val_loss: 3.4909 - val_VL_attention_linear_output_loss: 1.7445 - val_VH_attention_linear_output_loss: 1.7464 - val_VL_attention_linear_output_acc: 0.4933 - val_VH_attention_linear_output_acc: 0.4978\n",
      "Epoch 3968/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3502 - VL_attention_linear_output_loss: 1.6761 - VH_attention_linear_output_loss: 1.6741 - VL_attention_linear_output_acc: 0.5082 - VH_attention_linear_output_acc: 0.5133 - val_loss: 3.4879 - val_VL_attention_linear_output_loss: 1.7399 - val_VH_attention_linear_output_loss: 1.7481 - val_VL_attention_linear_output_acc: 0.4949 - val_VH_attention_linear_output_acc: 0.4982\n",
      "Epoch 3969/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3404 - VL_attention_linear_output_loss: 1.6663 - VH_attention_linear_output_loss: 1.6741 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5127 - val_loss: 3.4848 - val_VL_attention_linear_output_loss: 1.7524 - val_VH_attention_linear_output_loss: 1.7323 - val_VL_attention_linear_output_acc: 0.4952 - val_VH_attention_linear_output_acc: 0.5030\n",
      "Epoch 3970/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3548 - VL_attention_linear_output_loss: 1.6771 - VH_attention_linear_output_loss: 1.6778 - VL_attention_linear_output_acc: 0.5075 - VH_attention_linear_output_acc: 0.5123 - val_loss: 3.4745 - val_VL_attention_linear_output_loss: 1.7391 - val_VH_attention_linear_output_loss: 1.7353 - val_VL_attention_linear_output_acc: 0.5058 - val_VH_attention_linear_output_acc: 0.5028\n",
      "Epoch 3971/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3388 - VL_attention_linear_output_loss: 1.6764 - VH_attention_linear_output_loss: 1.6624 - VL_attention_linear_output_acc: 0.5066 - VH_attention_linear_output_acc: 0.5175 - val_loss: 3.4854 - val_VL_attention_linear_output_loss: 1.7447 - val_VH_attention_linear_output_loss: 1.7406 - val_VL_attention_linear_output_acc: 0.4976 - val_VH_attention_linear_output_acc: 0.5023\n",
      "Epoch 3972/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3339 - VL_attention_linear_output_loss: 1.6663 - VH_attention_linear_output_loss: 1.6676 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5154 - val_loss: 3.4734 - val_VL_attention_linear_output_loss: 1.7466 - val_VH_attention_linear_output_loss: 1.7269 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.5033\n",
      "Epoch 3973/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3380 - VL_attention_linear_output_loss: 1.6713 - VH_attention_linear_output_loss: 1.6667 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5160 - val_loss: 3.4995 - val_VL_attention_linear_output_loss: 1.7638 - val_VH_attention_linear_output_loss: 1.7358 - val_VL_attention_linear_output_acc: 0.4808 - val_VH_attention_linear_output_acc: 0.5017\n",
      "Epoch 3974/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3564 - VL_attention_linear_output_loss: 1.6797 - VH_attention_linear_output_loss: 1.6768 - VL_attention_linear_output_acc: 0.5063 - VH_attention_linear_output_acc: 0.5124 - val_loss: 3.4904 - val_VL_attention_linear_output_loss: 1.7485 - val_VH_attention_linear_output_loss: 1.7419 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.4941\n",
      "Epoch 3975/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3434 - VL_attention_linear_output_loss: 1.6762 - VH_attention_linear_output_loss: 1.6672 - VL_attention_linear_output_acc: 0.5073 - VH_attention_linear_output_acc: 0.5165 - val_loss: 3.4672 - val_VL_attention_linear_output_loss: 1.7402 - val_VH_attention_linear_output_loss: 1.7271 - val_VL_attention_linear_output_acc: 0.5011 - val_VH_attention_linear_output_acc: 0.5048\n",
      "Epoch 3976/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3448 - VL_attention_linear_output_loss: 1.6794 - VH_attention_linear_output_loss: 1.6654 - VL_attention_linear_output_acc: 0.5067 - VH_attention_linear_output_acc: 0.5167 - val_loss: 3.5002 - val_VL_attention_linear_output_loss: 1.7427 - val_VH_attention_linear_output_loss: 1.7575 - val_VL_attention_linear_output_acc: 0.4941 - val_VH_attention_linear_output_acc: 0.4884\n",
      "Epoch 3977/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3356 - VL_attention_linear_output_loss: 1.6670 - VH_attention_linear_output_loss: 1.6686 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5150 - val_loss: 3.4649 - val_VL_attention_linear_output_loss: 1.7419 - val_VH_attention_linear_output_loss: 1.7230 - val_VL_attention_linear_output_acc: 0.5034 - val_VH_attention_linear_output_acc: 0.5062\n",
      "Epoch 3978/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3350 - VL_attention_linear_output_loss: 1.6761 - VH_attention_linear_output_loss: 1.6589 - VL_attention_linear_output_acc: 0.5078 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.5490 - val_VL_attention_linear_output_loss: 1.7574 - val_VH_attention_linear_output_loss: 1.7916 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.4833\n",
      "Epoch 3979/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3508 - VL_attention_linear_output_loss: 1.6772 - VH_attention_linear_output_loss: 1.6737 - VL_attention_linear_output_acc: 0.5066 - VH_attention_linear_output_acc: 0.5136 - val_loss: 3.4893 - val_VL_attention_linear_output_loss: 1.7400 - val_VH_attention_linear_output_loss: 1.7492 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.4971\n",
      "Epoch 3980/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3235 - VL_attention_linear_output_loss: 1.6627 - VH_attention_linear_output_loss: 1.6609 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5175 - val_loss: 3.4793 - val_VL_attention_linear_output_loss: 1.7449 - val_VH_attention_linear_output_loss: 1.7344 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.5037\n",
      "Epoch 3981/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3415 - VL_attention_linear_output_loss: 1.6671 - VH_attention_linear_output_loss: 1.6744 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5124 - val_loss: 3.4882 - val_VL_attention_linear_output_loss: 1.7425 - val_VH_attention_linear_output_loss: 1.7457 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.4925\n",
      "Epoch 3982/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3505 - VL_attention_linear_output_loss: 1.6733 - VH_attention_linear_output_loss: 1.6772 - VL_attention_linear_output_acc: 0.5088 - VH_attention_linear_output_acc: 0.5130 - val_loss: 3.4715 - val_VL_attention_linear_output_loss: 1.7455 - val_VH_attention_linear_output_loss: 1.7260 - val_VL_attention_linear_output_acc: 0.4964 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 3983/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3453 - VL_attention_linear_output_loss: 1.6747 - VH_attention_linear_output_loss: 1.6706 - VL_attention_linear_output_acc: 0.5087 - VH_attention_linear_output_acc: 0.5149 - val_loss: 3.5142 - val_VL_attention_linear_output_loss: 1.7617 - val_VH_attention_linear_output_loss: 1.7525 - val_VL_attention_linear_output_acc: 0.4918 - val_VH_attention_linear_output_acc: 0.4986\n",
      "Epoch 3984/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3344 - VL_attention_linear_output_loss: 1.6658 - VH_attention_linear_output_loss: 1.6686 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5157 - val_loss: 3.4800 - val_VL_attention_linear_output_loss: 1.7408 - val_VH_attention_linear_output_loss: 1.7392 - val_VL_attention_linear_output_acc: 0.5007 - val_VH_attention_linear_output_acc: 0.4977\n",
      "Epoch 3985/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3350 - VL_attention_linear_output_loss: 1.6650 - VH_attention_linear_output_loss: 1.6700 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5155 - val_loss: 3.5216 - val_VL_attention_linear_output_loss: 1.7716 - val_VH_attention_linear_output_loss: 1.7500 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4920\n",
      "Epoch 3986/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3478 - VL_attention_linear_output_loss: 1.6728 - VH_attention_linear_output_loss: 1.6750 - VL_attention_linear_output_acc: 0.5088 - VH_attention_linear_output_acc: 0.5127 - val_loss: 3.4848 - val_VL_attention_linear_output_loss: 1.7437 - val_VH_attention_linear_output_loss: 1.7410 - val_VL_attention_linear_output_acc: 0.4983 - val_VH_attention_linear_output_acc: 0.5000\n",
      "Epoch 3987/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3348 - VL_attention_linear_output_loss: 1.6736 - VH_attention_linear_output_loss: 1.6612 - VL_attention_linear_output_acc: 0.5085 - VH_attention_linear_output_acc: 0.5177 - val_loss: 3.4735 - val_VL_attention_linear_output_loss: 1.7397 - val_VH_attention_linear_output_loss: 1.7337 - val_VL_attention_linear_output_acc: 0.5041 - val_VH_attention_linear_output_acc: 0.5020\n",
      "Epoch 3988/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3468 - VL_attention_linear_output_loss: 1.6775 - VH_attention_linear_output_loss: 1.6694 - VL_attention_linear_output_acc: 0.5079 - VH_attention_linear_output_acc: 0.5147 - val_loss: 3.4706 - val_VL_attention_linear_output_loss: 1.7399 - val_VH_attention_linear_output_loss: 1.7307 - val_VL_attention_linear_output_acc: 0.5031 - val_VH_attention_linear_output_acc: 0.5024\n",
      "Epoch 3989/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3327 - VL_attention_linear_output_loss: 1.6683 - VH_attention_linear_output_loss: 1.6644 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4744 - val_VL_attention_linear_output_loss: 1.7461 - val_VH_attention_linear_output_loss: 1.7283 - val_VL_attention_linear_output_acc: 0.4923 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 3990/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3513 - VL_attention_linear_output_loss: 1.6793 - VH_attention_linear_output_loss: 1.6720 - VL_attention_linear_output_acc: 0.5059 - VH_attention_linear_output_acc: 0.5139 - val_loss: 3.5218 - val_VL_attention_linear_output_loss: 1.7849 - val_VH_attention_linear_output_loss: 1.7369 - val_VL_attention_linear_output_acc: 0.4766 - val_VH_attention_linear_output_acc: 0.5017\n",
      "Epoch 3991/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3334 - VL_attention_linear_output_loss: 1.6673 - VH_attention_linear_output_loss: 1.6662 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5163 - val_loss: 3.4717 - val_VL_attention_linear_output_loss: 1.7394 - val_VH_attention_linear_output_loss: 1.7323 - val_VL_attention_linear_output_acc: 0.4963 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 3992/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3343 - VL_attention_linear_output_loss: 1.6706 - VH_attention_linear_output_loss: 1.6637 - VL_attention_linear_output_acc: 0.5093 - VH_attention_linear_output_acc: 0.5170 - val_loss: 3.4787 - val_VL_attention_linear_output_loss: 1.7478 - val_VH_attention_linear_output_loss: 1.7310 - val_VL_attention_linear_output_acc: 0.4964 - val_VH_attention_linear_output_acc: 0.5042\n",
      "Epoch 3993/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3302 - VL_attention_linear_output_loss: 1.6634 - VH_attention_linear_output_loss: 1.6668 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5161 - val_loss: 3.4808 - val_VL_attention_linear_output_loss: 1.7393 - val_VH_attention_linear_output_loss: 1.7415 - val_VL_attention_linear_output_acc: 0.4997 - val_VH_attention_linear_output_acc: 0.5011\n",
      "Epoch 3994/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3427 - VL_attention_linear_output_loss: 1.6676 - VH_attention_linear_output_loss: 1.6751 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5130 - val_loss: 3.4783 - val_VL_attention_linear_output_loss: 1.7465 - val_VH_attention_linear_output_loss: 1.7318 - val_VL_attention_linear_output_acc: 0.4961 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 3995/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3364 - VL_attention_linear_output_loss: 1.6648 - VH_attention_linear_output_loss: 1.6716 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5138 - val_loss: 3.4695 - val_VL_attention_linear_output_loss: 1.7373 - val_VH_attention_linear_output_loss: 1.7322 - val_VL_attention_linear_output_acc: 0.5038 - val_VH_attention_linear_output_acc: 0.5025\n",
      "Epoch 3996/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3344 - VL_attention_linear_output_loss: 1.6634 - VH_attention_linear_output_loss: 1.6709 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5146 - val_loss: 3.4696 - val_VL_attention_linear_output_loss: 1.7368 - val_VH_attention_linear_output_loss: 1.7329 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.5003\n",
      "Epoch 3997/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3408 - VL_attention_linear_output_loss: 1.6738 - VH_attention_linear_output_loss: 1.6670 - VL_attention_linear_output_acc: 0.5082 - VH_attention_linear_output_acc: 0.5162 - val_loss: 3.4795 - val_VL_attention_linear_output_loss: 1.7417 - val_VH_attention_linear_output_loss: 1.7377 - val_VL_attention_linear_output_acc: 0.5020 - val_VH_attention_linear_output_acc: 0.4985\n",
      "Epoch 3998/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3544 - VL_attention_linear_output_loss: 1.6762 - VH_attention_linear_output_loss: 1.6782 - VL_attention_linear_output_acc: 0.5073 - VH_attention_linear_output_acc: 0.5119 - val_loss: 3.5106 - val_VL_attention_linear_output_loss: 1.7810 - val_VH_attention_linear_output_loss: 1.7296 - val_VL_attention_linear_output_acc: 0.4837 - val_VH_attention_linear_output_acc: 0.5026\n",
      "Epoch 3999/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3359 - VL_attention_linear_output_loss: 1.6738 - VH_attention_linear_output_loss: 1.6621 - VL_attention_linear_output_acc: 0.5088 - VH_attention_linear_output_acc: 0.5180 - val_loss: 3.4914 - val_VL_attention_linear_output_loss: 1.7582 - val_VH_attention_linear_output_loss: 1.7332 - val_VL_attention_linear_output_acc: 0.4886 - val_VH_attention_linear_output_acc: 0.5036\n",
      "Epoch 4000/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3337 - VL_attention_linear_output_loss: 1.6696 - VH_attention_linear_output_loss: 1.6641 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5170 - val_loss: 3.5193 - val_VL_attention_linear_output_loss: 1.7754 - val_VH_attention_linear_output_loss: 1.7439 - val_VL_attention_linear_output_acc: 0.4727 - val_VH_attention_linear_output_acc: 0.5015\n",
      "Epoch 4001/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3429 - VL_attention_linear_output_loss: 1.6754 - VH_attention_linear_output_loss: 1.6676 - VL_attention_linear_output_acc: 0.5088 - VH_attention_linear_output_acc: 0.5161 - val_loss: 3.4655 - val_VL_attention_linear_output_loss: 1.7375 - val_VH_attention_linear_output_loss: 1.7279 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 4002/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3348 - VL_attention_linear_output_loss: 1.6718 - VH_attention_linear_output_loss: 1.6629 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5166 - val_loss: 3.4773 - val_VL_attention_linear_output_loss: 1.7409 - val_VH_attention_linear_output_loss: 1.7364 - val_VL_attention_linear_output_acc: 0.5039 - val_VH_attention_linear_output_acc: 0.4994\n",
      "Epoch 4003/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3352 - VL_attention_linear_output_loss: 1.6620 - VH_attention_linear_output_loss: 1.6732 - VL_attention_linear_output_acc: 0.5148 - VH_attention_linear_output_acc: 0.5143 - val_loss: 3.4695 - val_VL_attention_linear_output_loss: 1.7390 - val_VH_attention_linear_output_loss: 1.7305 - val_VL_attention_linear_output_acc: 0.5019 - val_VH_attention_linear_output_acc: 0.5043\n",
      "Epoch 4004/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3372 - VL_attention_linear_output_loss: 1.6660 - VH_attention_linear_output_loss: 1.6713 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5151 - val_loss: 3.5365 - val_VL_attention_linear_output_loss: 1.8050 - val_VH_attention_linear_output_loss: 1.7315 - val_VL_attention_linear_output_acc: 0.4653 - val_VH_attention_linear_output_acc: 0.5032\n",
      "Epoch 4005/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3392 - VL_attention_linear_output_loss: 1.6716 - VH_attention_linear_output_loss: 1.6675 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5155 - val_loss: 3.4928 - val_VL_attention_linear_output_loss: 1.7576 - val_VH_attention_linear_output_loss: 1.7352 - val_VL_attention_linear_output_acc: 0.4845 - val_VH_attention_linear_output_acc: 0.5021\n",
      "Epoch 4006/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3457 - VL_attention_linear_output_loss: 1.6655 - VH_attention_linear_output_loss: 1.6802 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5112 - val_loss: 3.4706 - val_VL_attention_linear_output_loss: 1.7421 - val_VH_attention_linear_output_loss: 1.7286 - val_VL_attention_linear_output_acc: 0.5001 - val_VH_attention_linear_output_acc: 0.5062\n",
      "Epoch 4007/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3336 - VL_attention_linear_output_loss: 1.6734 - VH_attention_linear_output_loss: 1.6602 - VL_attention_linear_output_acc: 0.5085 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4696 - val_VL_attention_linear_output_loss: 1.7431 - val_VH_attention_linear_output_loss: 1.7265 - val_VL_attention_linear_output_acc: 0.5036 - val_VH_attention_linear_output_acc: 0.5033\n",
      "Epoch 4008/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3414 - VL_attention_linear_output_loss: 1.6715 - VH_attention_linear_output_loss: 1.6699 - VL_attention_linear_output_acc: 0.5096 - VH_attention_linear_output_acc: 0.5146 - val_loss: 3.5123 - val_VL_attention_linear_output_loss: 1.7501 - val_VH_attention_linear_output_loss: 1.7622 - val_VL_attention_linear_output_acc: 0.4988 - val_VH_attention_linear_output_acc: 0.4898\n",
      "Epoch 4009/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3382 - VL_attention_linear_output_loss: 1.6647 - VH_attention_linear_output_loss: 1.6735 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5131 - val_loss: 3.4666 - val_VL_attention_linear_output_loss: 1.7410 - val_VH_attention_linear_output_loss: 1.7256 - val_VL_attention_linear_output_acc: 0.5063 - val_VH_attention_linear_output_acc: 0.5069\n",
      "Epoch 4010/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3267 - VL_attention_linear_output_loss: 1.6682 - VH_attention_linear_output_loss: 1.6586 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5192 - val_loss: 3.4701 - val_VL_attention_linear_output_loss: 1.7355 - val_VH_attention_linear_output_loss: 1.7346 - val_VL_attention_linear_output_acc: 0.5030 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 4011/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3305 - VL_attention_linear_output_loss: 1.6674 - VH_attention_linear_output_loss: 1.6631 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5176 - val_loss: 3.4974 - val_VL_attention_linear_output_loss: 1.7492 - val_VH_attention_linear_output_loss: 1.7483 - val_VL_attention_linear_output_acc: 0.4931 - val_VH_attention_linear_output_acc: 0.4993\n",
      "Epoch 4012/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3422 - VL_attention_linear_output_loss: 1.6709 - VH_attention_linear_output_loss: 1.6713 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5145 - val_loss: 3.4942 - val_VL_attention_linear_output_loss: 1.7590 - val_VH_attention_linear_output_loss: 1.7352 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.5055\n",
      "Epoch 4013/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3492 - VL_attention_linear_output_loss: 1.6734 - VH_attention_linear_output_loss: 1.6758 - VL_attention_linear_output_acc: 0.5093 - VH_attention_linear_output_acc: 0.5129 - val_loss: 3.5030 - val_VL_attention_linear_output_loss: 1.7554 - val_VH_attention_linear_output_loss: 1.7476 - val_VL_attention_linear_output_acc: 0.4885 - val_VH_attention_linear_output_acc: 0.4968\n",
      "Epoch 4014/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3403 - VL_attention_linear_output_loss: 1.6752 - VH_attention_linear_output_loss: 1.6651 - VL_attention_linear_output_acc: 0.5087 - VH_attention_linear_output_acc: 0.5170 - val_loss: 3.4948 - val_VL_attention_linear_output_loss: 1.7636 - val_VH_attention_linear_output_loss: 1.7312 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.5039\n",
      "Epoch 4015/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3442 - VL_attention_linear_output_loss: 1.6746 - VH_attention_linear_output_loss: 1.6697 - VL_attention_linear_output_acc: 0.5080 - VH_attention_linear_output_acc: 0.5152 - val_loss: 3.5120 - val_VL_attention_linear_output_loss: 1.7600 - val_VH_attention_linear_output_loss: 1.7520 - val_VL_attention_linear_output_acc: 0.4934 - val_VH_attention_linear_output_acc: 0.4982\n",
      "Epoch 4016/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3528 - VL_attention_linear_output_loss: 1.6765 - VH_attention_linear_output_loss: 1.6763 - VL_attention_linear_output_acc: 0.5076 - VH_attention_linear_output_acc: 0.5130 - val_loss: 3.4844 - val_VL_attention_linear_output_loss: 1.7380 - val_VH_attention_linear_output_loss: 1.7463 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.4984\n",
      "Epoch 4017/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3367 - VL_attention_linear_output_loss: 1.6691 - VH_attention_linear_output_loss: 1.6676 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5162 - val_loss: 3.4681 - val_VL_attention_linear_output_loss: 1.7397 - val_VH_attention_linear_output_loss: 1.7284 - val_VL_attention_linear_output_acc: 0.5005 - val_VH_attention_linear_output_acc: 0.5034\n",
      "Epoch 4018/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3337 - VL_attention_linear_output_loss: 1.6685 - VH_attention_linear_output_loss: 1.6652 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5169 - val_loss: 3.4615 - val_VL_attention_linear_output_loss: 1.7359 - val_VH_attention_linear_output_loss: 1.7257 - val_VL_attention_linear_output_acc: 0.5057 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4019/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3330 - VL_attention_linear_output_loss: 1.6667 - VH_attention_linear_output_loss: 1.6663 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5166 - val_loss: 3.4782 - val_VL_attention_linear_output_loss: 1.7440 - val_VH_attention_linear_output_loss: 1.7342 - val_VL_attention_linear_output_acc: 0.4897 - val_VH_attention_linear_output_acc: 0.5020\n",
      "Epoch 4020/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3342 - VL_attention_linear_output_loss: 1.6673 - VH_attention_linear_output_loss: 1.6668 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5158 - val_loss: 3.5054 - val_VL_attention_linear_output_loss: 1.7479 - val_VH_attention_linear_output_loss: 1.7574 - val_VL_attention_linear_output_acc: 0.4936 - val_VH_attention_linear_output_acc: 0.4876\n",
      "Epoch 4021/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3361 - VL_attention_linear_output_loss: 1.6696 - VH_attention_linear_output_loss: 1.6665 - VL_attention_linear_output_acc: 0.5102 - VH_attention_linear_output_acc: 0.5158 - val_loss: 3.4678 - val_VL_attention_linear_output_loss: 1.7384 - val_VH_attention_linear_output_loss: 1.7293 - val_VL_attention_linear_output_acc: 0.5055 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 4022/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3325 - VL_attention_linear_output_loss: 1.6661 - VH_attention_linear_output_loss: 1.6664 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5169 - val_loss: 3.4973 - val_VL_attention_linear_output_loss: 1.7626 - val_VH_attention_linear_output_loss: 1.7346 - val_VL_attention_linear_output_acc: 0.4899 - val_VH_attention_linear_output_acc: 0.5014\n",
      "Epoch 4023/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3633 - VL_attention_linear_output_loss: 1.6882 - VH_attention_linear_output_loss: 1.6751 - VL_attention_linear_output_acc: 0.5026 - VH_attention_linear_output_acc: 0.5125 - val_loss: 3.4912 - val_VL_attention_linear_output_loss: 1.7382 - val_VH_attention_linear_output_loss: 1.7530 - val_VL_attention_linear_output_acc: 0.5065 - val_VH_attention_linear_output_acc: 0.4913\n",
      "Epoch 4024/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3195 - VL_attention_linear_output_loss: 1.6584 - VH_attention_linear_output_loss: 1.6611 - VL_attention_linear_output_acc: 0.5157 - VH_attention_linear_output_acc: 0.5184 - val_loss: 3.4714 - val_VL_attention_linear_output_loss: 1.7386 - val_VH_attention_linear_output_loss: 1.7328 - val_VL_attention_linear_output_acc: 0.5028 - val_VH_attention_linear_output_acc: 0.5048\n",
      "Epoch 4025/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3199 - VL_attention_linear_output_loss: 1.6602 - VH_attention_linear_output_loss: 1.6596 - VL_attention_linear_output_acc: 0.5152 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4708 - val_VL_attention_linear_output_loss: 1.7423 - val_VH_attention_linear_output_loss: 1.7285 - val_VL_attention_linear_output_acc: 0.5020 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4026/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3376 - VL_attention_linear_output_loss: 1.6755 - VH_attention_linear_output_loss: 1.6620 - VL_attention_linear_output_acc: 0.5078 - VH_attention_linear_output_acc: 0.5179 - val_loss: 3.4686 - val_VL_attention_linear_output_loss: 1.7336 - val_VH_attention_linear_output_loss: 1.7349 - val_VL_attention_linear_output_acc: 0.5054 - val_VH_attention_linear_output_acc: 0.5023\n",
      "Epoch 4027/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3244 - VL_attention_linear_output_loss: 1.6604 - VH_attention_linear_output_loss: 1.6639 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4628 - val_VL_attention_linear_output_loss: 1.7407 - val_VH_attention_linear_output_loss: 1.7221 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4028/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3215 - VL_attention_linear_output_loss: 1.6597 - VH_attention_linear_output_loss: 1.6618 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5173 - val_loss: 3.4917 - val_VL_attention_linear_output_loss: 1.7362 - val_VH_attention_linear_output_loss: 1.7555 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.4922\n",
      "Epoch 4029/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3235 - VL_attention_linear_output_loss: 1.6626 - VH_attention_linear_output_loss: 1.6609 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5184 - val_loss: 3.4885 - val_VL_attention_linear_output_loss: 1.7457 - val_VH_attention_linear_output_loss: 1.7428 - val_VL_attention_linear_output_acc: 0.4971 - val_VH_attention_linear_output_acc: 0.4989\n",
      "Epoch 4030/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3351 - VL_attention_linear_output_loss: 1.6711 - VH_attention_linear_output_loss: 1.6640 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5169 - val_loss: 3.4848 - val_VL_attention_linear_output_loss: 1.7514 - val_VH_attention_linear_output_loss: 1.7334 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.5003\n",
      "Epoch 4031/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3398 - VL_attention_linear_output_loss: 1.6700 - VH_attention_linear_output_loss: 1.6698 - VL_attention_linear_output_acc: 0.5099 - VH_attention_linear_output_acc: 0.5152 - val_loss: 3.4669 - val_VL_attention_linear_output_loss: 1.7375 - val_VH_attention_linear_output_loss: 1.7294 - val_VL_attention_linear_output_acc: 0.5054 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4032/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3330 - VL_attention_linear_output_loss: 1.6735 - VH_attention_linear_output_loss: 1.6595 - VL_attention_linear_output_acc: 0.5085 - VH_attention_linear_output_acc: 0.5184 - val_loss: 3.4805 - val_VL_attention_linear_output_loss: 1.7391 - val_VH_attention_linear_output_loss: 1.7414 - val_VL_attention_linear_output_acc: 0.5044 - val_VH_attention_linear_output_acc: 0.5011\n",
      "Epoch 4033/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3298 - VL_attention_linear_output_loss: 1.6724 - VH_attention_linear_output_loss: 1.6574 - VL_attention_linear_output_acc: 0.5085 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.5119 - val_VL_attention_linear_output_loss: 1.7862 - val_VH_attention_linear_output_loss: 1.7258 - val_VL_attention_linear_output_acc: 0.4696 - val_VH_attention_linear_output_acc: 0.5039\n",
      "Epoch 4034/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3325 - VL_attention_linear_output_loss: 1.6736 - VH_attention_linear_output_loss: 1.6589 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5190 - val_loss: 3.4958 - val_VL_attention_linear_output_loss: 1.7709 - val_VH_attention_linear_output_loss: 1.7250 - val_VL_attention_linear_output_acc: 0.4753 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4035/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3297 - VL_attention_linear_output_loss: 1.6697 - VH_attention_linear_output_loss: 1.6599 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4783 - val_VL_attention_linear_output_loss: 1.7551 - val_VH_attention_linear_output_loss: 1.7232 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.5048\n",
      "Epoch 4036/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3318 - VL_attention_linear_output_loss: 1.6651 - VH_attention_linear_output_loss: 1.6667 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5155 - val_loss: 3.4804 - val_VL_attention_linear_output_loss: 1.7390 - val_VH_attention_linear_output_loss: 1.7414 - val_VL_attention_linear_output_acc: 0.5031 - val_VH_attention_linear_output_acc: 0.4997\n",
      "Epoch 4037/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3425 - VL_attention_linear_output_loss: 1.6708 - VH_attention_linear_output_loss: 1.6717 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5134 - val_loss: 3.4797 - val_VL_attention_linear_output_loss: 1.7417 - val_VH_attention_linear_output_loss: 1.7380 - val_VL_attention_linear_output_acc: 0.5016 - val_VH_attention_linear_output_acc: 0.4996\n",
      "Epoch 4038/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3414 - VL_attention_linear_output_loss: 1.6739 - VH_attention_linear_output_loss: 1.6675 - VL_attention_linear_output_acc: 0.5075 - VH_attention_linear_output_acc: 0.5153 - val_loss: 3.4671 - val_VL_attention_linear_output_loss: 1.7387 - val_VH_attention_linear_output_loss: 1.7284 - val_VL_attention_linear_output_acc: 0.4975 - val_VH_attention_linear_output_acc: 0.5008\n",
      "Epoch 4039/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3334 - VL_attention_linear_output_loss: 1.6616 - VH_attention_linear_output_loss: 1.6718 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5138 - val_loss: 3.4739 - val_VL_attention_linear_output_loss: 1.7375 - val_VH_attention_linear_output_loss: 1.7365 - val_VL_attention_linear_output_acc: 0.4909 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4040/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3275 - VL_attention_linear_output_loss: 1.6697 - VH_attention_linear_output_loss: 1.6579 - VL_attention_linear_output_acc: 0.5095 - VH_attention_linear_output_acc: 0.5192 - val_loss: 3.5060 - val_VL_attention_linear_output_loss: 1.7809 - val_VH_attention_linear_output_loss: 1.7251 - val_VL_attention_linear_output_acc: 0.4744 - val_VH_attention_linear_output_acc: 0.5018\n",
      "Epoch 4041/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3329 - VL_attention_linear_output_loss: 1.6722 - VH_attention_linear_output_loss: 1.6607 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5179 - val_loss: 3.4771 - val_VL_attention_linear_output_loss: 1.7525 - val_VH_attention_linear_output_loss: 1.7247 - val_VL_attention_linear_output_acc: 0.5027 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 4042/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3440 - VL_attention_linear_output_loss: 1.6745 - VH_attention_linear_output_loss: 1.6695 - VL_attention_linear_output_acc: 0.5090 - VH_attention_linear_output_acc: 0.5151 - val_loss: 3.5276 - val_VL_attention_linear_output_loss: 1.7368 - val_VH_attention_linear_output_loss: 1.7908 - val_VL_attention_linear_output_acc: 0.5040 - val_VH_attention_linear_output_acc: 0.4846\n",
      "Epoch 4043/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3466 - VL_attention_linear_output_loss: 1.6810 - VH_attention_linear_output_loss: 1.6656 - VL_attention_linear_output_acc: 0.5047 - VH_attention_linear_output_acc: 0.5164 - val_loss: 3.4706 - val_VL_attention_linear_output_loss: 1.7420 - val_VH_attention_linear_output_loss: 1.7286 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5047\n",
      "Epoch 4044/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3283 - VL_attention_linear_output_loss: 1.6631 - VH_attention_linear_output_loss: 1.6652 - VL_attention_linear_output_acc: 0.5136 - VH_attention_linear_output_acc: 0.5174 - val_loss: 3.4582 - val_VL_attention_linear_output_loss: 1.7323 - val_VH_attention_linear_output_loss: 1.7259 - val_VL_attention_linear_output_acc: 0.5047 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4045/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3322 - VL_attention_linear_output_loss: 1.6635 - VH_attention_linear_output_loss: 1.6688 - VL_attention_linear_output_acc: 0.5132 - VH_attention_linear_output_acc: 0.5160 - val_loss: 3.4895 - val_VL_attention_linear_output_loss: 1.7561 - val_VH_attention_linear_output_loss: 1.7334 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.5022\n",
      "Epoch 4046/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3237 - VL_attention_linear_output_loss: 1.6624 - VH_attention_linear_output_loss: 1.6613 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5182 - val_loss: 3.4729 - val_VL_attention_linear_output_loss: 1.7422 - val_VH_attention_linear_output_loss: 1.7307 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5018\n",
      "Epoch 4047/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3347 - VL_attention_linear_output_loss: 1.6711 - VH_attention_linear_output_loss: 1.6636 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5173 - val_loss: 3.4734 - val_VL_attention_linear_output_loss: 1.7382 - val_VH_attention_linear_output_loss: 1.7352 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.4972\n",
      "Epoch 4048/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3275 - VL_attention_linear_output_loss: 1.6639 - VH_attention_linear_output_loss: 1.6636 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5170 - val_loss: 3.4580 - val_VL_attention_linear_output_loss: 1.7321 - val_VH_attention_linear_output_loss: 1.7259 - val_VL_attention_linear_output_acc: 0.5070 - val_VH_attention_linear_output_acc: 0.5030\n",
      "Epoch 4049/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3378 - VL_attention_linear_output_loss: 1.6651 - VH_attention_linear_output_loss: 1.6728 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5135 - val_loss: 3.4700 - val_VL_attention_linear_output_loss: 1.7382 - val_VH_attention_linear_output_loss: 1.7318 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.5006\n",
      "Epoch 4050/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3294 - VL_attention_linear_output_loss: 1.6653 - VH_attention_linear_output_loss: 1.6641 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5173 - val_loss: 3.4774 - val_VL_attention_linear_output_loss: 1.7432 - val_VH_attention_linear_output_loss: 1.7341 - val_VL_attention_linear_output_acc: 0.4966 - val_VH_attention_linear_output_acc: 0.5026\n",
      "Epoch 4051/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3430 - VL_attention_linear_output_loss: 1.6747 - VH_attention_linear_output_loss: 1.6683 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5158 - val_loss: 3.4621 - val_VL_attention_linear_output_loss: 1.7362 - val_VH_attention_linear_output_loss: 1.7259 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5048\n",
      "Epoch 4052/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3243 - VL_attention_linear_output_loss: 1.6612 - VH_attention_linear_output_loss: 1.6630 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.5009 - val_VL_attention_linear_output_loss: 1.7376 - val_VH_attention_linear_output_loss: 1.7633 - val_VL_attention_linear_output_acc: 0.5056 - val_VH_attention_linear_output_acc: 0.4931\n",
      "Epoch 4053/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3358 - VL_attention_linear_output_loss: 1.6708 - VH_attention_linear_output_loss: 1.6650 - VL_attention_linear_output_acc: 0.5090 - VH_attention_linear_output_acc: 0.5163 - val_loss: 3.4881 - val_VL_attention_linear_output_loss: 1.7541 - val_VH_attention_linear_output_loss: 1.7340 - val_VL_attention_linear_output_acc: 0.4979 - val_VH_attention_linear_output_acc: 0.5003\n",
      "Epoch 4054/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3256 - VL_attention_linear_output_loss: 1.6648 - VH_attention_linear_output_loss: 1.6609 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5179 - val_loss: 3.4859 - val_VL_attention_linear_output_loss: 1.7545 - val_VH_attention_linear_output_loss: 1.7314 - val_VL_attention_linear_output_acc: 0.4921 - val_VH_attention_linear_output_acc: 0.5002\n",
      "Epoch 4055/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3476 - VL_attention_linear_output_loss: 1.6773 - VH_attention_linear_output_loss: 1.6703 - VL_attention_linear_output_acc: 0.5078 - VH_attention_linear_output_acc: 0.5139 - val_loss: 3.4764 - val_VL_attention_linear_output_loss: 1.7415 - val_VH_attention_linear_output_loss: 1.7349 - val_VL_attention_linear_output_acc: 0.5006 - val_VH_attention_linear_output_acc: 0.4988\n",
      "Epoch 4056/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3317 - VL_attention_linear_output_loss: 1.6654 - VH_attention_linear_output_loss: 1.6663 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5163 - val_loss: 3.4630 - val_VL_attention_linear_output_loss: 1.7351 - val_VH_attention_linear_output_loss: 1.7280 - val_VL_attention_linear_output_acc: 0.5062 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4057/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3311 - VL_attention_linear_output_loss: 1.6678 - VH_attention_linear_output_loss: 1.6632 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5174 - val_loss: 3.4812 - val_VL_attention_linear_output_loss: 1.7369 - val_VH_attention_linear_output_loss: 1.7443 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.4964\n",
      "Epoch 4058/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3514 - VL_attention_linear_output_loss: 1.6745 - VH_attention_linear_output_loss: 1.6770 - VL_attention_linear_output_acc: 0.5089 - VH_attention_linear_output_acc: 0.5122 - val_loss: 3.4692 - val_VL_attention_linear_output_loss: 1.7424 - val_VH_attention_linear_output_loss: 1.7268 - val_VL_attention_linear_output_acc: 0.5015 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 4059/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3195 - VL_attention_linear_output_loss: 1.6600 - VH_attention_linear_output_loss: 1.6595 - VL_attention_linear_output_acc: 0.5147 - VH_attention_linear_output_acc: 0.5189 - val_loss: 3.4648 - val_VL_attention_linear_output_loss: 1.7341 - val_VH_attention_linear_output_loss: 1.7307 - val_VL_attention_linear_output_acc: 0.5030 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4060/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3421 - VL_attention_linear_output_loss: 1.6706 - VH_attention_linear_output_loss: 1.6715 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5136 - val_loss: 3.4693 - val_VL_attention_linear_output_loss: 1.7382 - val_VH_attention_linear_output_loss: 1.7311 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5005\n",
      "Epoch 4061/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3243 - VL_attention_linear_output_loss: 1.6654 - VH_attention_linear_output_loss: 1.6588 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5182 - val_loss: 3.4795 - val_VL_attention_linear_output_loss: 1.7427 - val_VH_attention_linear_output_loss: 1.7368 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.4977\n",
      "Epoch 4062/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3375 - VL_attention_linear_output_loss: 1.6654 - VH_attention_linear_output_loss: 1.6721 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5140 - val_loss: 3.4710 - val_VL_attention_linear_output_loss: 1.7456 - val_VH_attention_linear_output_loss: 1.7254 - val_VL_attention_linear_output_acc: 0.4996 - val_VH_attention_linear_output_acc: 0.5028\n",
      "Epoch 4063/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3437 - VL_attention_linear_output_loss: 1.6751 - VH_attention_linear_output_loss: 1.6687 - VL_attention_linear_output_acc: 0.5071 - VH_attention_linear_output_acc: 0.5149 - val_loss: 3.4836 - val_VL_attention_linear_output_loss: 1.7536 - val_VH_attention_linear_output_loss: 1.7300 - val_VL_attention_linear_output_acc: 0.4897 - val_VH_attention_linear_output_acc: 0.5026\n",
      "Epoch 4064/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3293 - VL_attention_linear_output_loss: 1.6686 - VH_attention_linear_output_loss: 1.6607 - VL_attention_linear_output_acc: 0.5096 - VH_attention_linear_output_acc: 0.5183 - val_loss: 3.4811 - val_VL_attention_linear_output_loss: 1.7428 - val_VH_attention_linear_output_loss: 1.7383 - val_VL_attention_linear_output_acc: 0.5065 - val_VH_attention_linear_output_acc: 0.4986\n",
      "Epoch 4065/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3373 - VL_attention_linear_output_loss: 1.6666 - VH_attention_linear_output_loss: 1.6707 - VL_attention_linear_output_acc: 0.5120 - VH_attention_linear_output_acc: 0.5147 - val_loss: 3.4957 - val_VL_attention_linear_output_loss: 1.7357 - val_VH_attention_linear_output_loss: 1.7600 - val_VL_attention_linear_output_acc: 0.5046 - val_VH_attention_linear_output_acc: 0.4882\n",
      "Epoch 4066/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3359 - VL_attention_linear_output_loss: 1.6696 - VH_attention_linear_output_loss: 1.6663 - VL_attention_linear_output_acc: 0.5096 - VH_attention_linear_output_acc: 0.5155 - val_loss: 3.5444 - val_VL_attention_linear_output_loss: 1.8022 - val_VH_attention_linear_output_loss: 1.7421 - val_VL_attention_linear_output_acc: 0.4755 - val_VH_attention_linear_output_acc: 0.4978\n",
      "Epoch 4067/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3332 - VL_attention_linear_output_loss: 1.6667 - VH_attention_linear_output_loss: 1.6665 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5156 - val_loss: 3.4680 - val_VL_attention_linear_output_loss: 1.7420 - val_VH_attention_linear_output_loss: 1.7259 - val_VL_attention_linear_output_acc: 0.4975 - val_VH_attention_linear_output_acc: 0.5072\n",
      "Epoch 4068/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3247 - VL_attention_linear_output_loss: 1.6604 - VH_attention_linear_output_loss: 1.6643 - VL_attention_linear_output_acc: 0.5150 - VH_attention_linear_output_acc: 0.5178 - val_loss: 3.4604 - val_VL_attention_linear_output_loss: 1.7371 - val_VH_attention_linear_output_loss: 1.7233 - val_VL_attention_linear_output_acc: 0.5030 - val_VH_attention_linear_output_acc: 0.5027\n",
      "Epoch 4069/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3339 - VL_attention_linear_output_loss: 1.6712 - VH_attention_linear_output_loss: 1.6627 - VL_attention_linear_output_acc: 0.5087 - VH_attention_linear_output_acc: 0.5180 - val_loss: 3.4934 - val_VL_attention_linear_output_loss: 1.7379 - val_VH_attention_linear_output_loss: 1.7554 - val_VL_attention_linear_output_acc: 0.5019 - val_VH_attention_linear_output_acc: 0.4939\n",
      "Epoch 4070/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3412 - VL_attention_linear_output_loss: 1.6631 - VH_attention_linear_output_loss: 1.6780 - VL_attention_linear_output_acc: 0.5144 - VH_attention_linear_output_acc: 0.5118 - val_loss: 3.4968 - val_VL_attention_linear_output_loss: 1.7514 - val_VH_attention_linear_output_loss: 1.7454 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.4946\n",
      "Epoch 4071/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3335 - VL_attention_linear_output_loss: 1.6709 - VH_attention_linear_output_loss: 1.6626 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5177 - val_loss: 3.4845 - val_VL_attention_linear_output_loss: 1.7513 - val_VH_attention_linear_output_loss: 1.7333 - val_VL_attention_linear_output_acc: 0.4885 - val_VH_attention_linear_output_acc: 0.5001\n",
      "Epoch 4072/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3421 - VL_attention_linear_output_loss: 1.6777 - VH_attention_linear_output_loss: 1.6644 - VL_attention_linear_output_acc: 0.5061 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.5252 - val_VL_attention_linear_output_loss: 1.7476 - val_VH_attention_linear_output_loss: 1.7776 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.4889\n",
      "Epoch 4073/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3339 - VL_attention_linear_output_loss: 1.6675 - VH_attention_linear_output_loss: 1.6664 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5160 - val_loss: 3.4674 - val_VL_attention_linear_output_loss: 1.7364 - val_VH_attention_linear_output_loss: 1.7310 - val_VL_attention_linear_output_acc: 0.5038 - val_VH_attention_linear_output_acc: 0.5020\n",
      "Epoch 4074/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3390 - VL_attention_linear_output_loss: 1.6716 - VH_attention_linear_output_loss: 1.6674 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5156 - val_loss: 3.5444 - val_VL_attention_linear_output_loss: 1.7969 - val_VH_attention_linear_output_loss: 1.7476 - val_VL_attention_linear_output_acc: 0.4825 - val_VH_attention_linear_output_acc: 0.4966\n",
      "Epoch 4075/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3364 - VL_attention_linear_output_loss: 1.6680 - VH_attention_linear_output_loss: 1.6684 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5151 - val_loss: 3.4670 - val_VL_attention_linear_output_loss: 1.7327 - val_VH_attention_linear_output_loss: 1.7344 - val_VL_attention_linear_output_acc: 0.5037 - val_VH_attention_linear_output_acc: 0.4987\n",
      "Epoch 4076/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3310 - VL_attention_linear_output_loss: 1.6645 - VH_attention_linear_output_loss: 1.6665 - VL_attention_linear_output_acc: 0.5109 - VH_attention_linear_output_acc: 0.5163 - val_loss: 3.4712 - val_VL_attention_linear_output_loss: 1.7485 - val_VH_attention_linear_output_loss: 1.7226 - val_VL_attention_linear_output_acc: 0.5029 - val_VH_attention_linear_output_acc: 0.5044\n",
      "Epoch 4077/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3390 - VL_attention_linear_output_loss: 1.6745 - VH_attention_linear_output_loss: 1.6645 - VL_attention_linear_output_acc: 0.5092 - VH_attention_linear_output_acc: 0.5167 - val_loss: 3.4700 - val_VL_attention_linear_output_loss: 1.7429 - val_VH_attention_linear_output_loss: 1.7271 - val_VL_attention_linear_output_acc: 0.5001 - val_VH_attention_linear_output_acc: 0.5011\n",
      "Epoch 4078/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3278 - VL_attention_linear_output_loss: 1.6636 - VH_attention_linear_output_loss: 1.6642 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5164 - val_loss: 3.4705 - val_VL_attention_linear_output_loss: 1.7475 - val_VH_attention_linear_output_loss: 1.7231 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.5062\n",
      "Epoch 4079/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3277 - VL_attention_linear_output_loss: 1.6659 - VH_attention_linear_output_loss: 1.6618 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5181 - val_loss: 3.4768 - val_VL_attention_linear_output_loss: 1.7415 - val_VH_attention_linear_output_loss: 1.7353 - val_VL_attention_linear_output_acc: 0.4996 - val_VH_attention_linear_output_acc: 0.5019\n",
      "Epoch 4080/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3312 - VL_attention_linear_output_loss: 1.6659 - VH_attention_linear_output_loss: 1.6653 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5169 - val_loss: 3.4670 - val_VL_attention_linear_output_loss: 1.7407 - val_VH_attention_linear_output_loss: 1.7263 - val_VL_attention_linear_output_acc: 0.5052 - val_VH_attention_linear_output_acc: 0.5021\n",
      "Epoch 4081/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3349 - VL_attention_linear_output_loss: 1.6657 - VH_attention_linear_output_loss: 1.6692 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5147 - val_loss: 3.4837 - val_VL_attention_linear_output_loss: 1.7462 - val_VH_attention_linear_output_loss: 1.7375 - val_VL_attention_linear_output_acc: 0.4905 - val_VH_attention_linear_output_acc: 0.5014\n",
      "Epoch 4082/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3337 - VL_attention_linear_output_loss: 1.6647 - VH_attention_linear_output_loss: 1.6690 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5148 - val_loss: 3.4790 - val_VL_attention_linear_output_loss: 1.7482 - val_VH_attention_linear_output_loss: 1.7308 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4083/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3423 - VL_attention_linear_output_loss: 1.6692 - VH_attention_linear_output_loss: 1.6730 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5135 - val_loss: 3.4601 - val_VL_attention_linear_output_loss: 1.7381 - val_VH_attention_linear_output_loss: 1.7220 - val_VL_attention_linear_output_acc: 0.5054 - val_VH_attention_linear_output_acc: 0.5067s: 3.3484 - VL_attention_linear_output_loss: 1.6744 - VH_attention_linear_output_loss: 1.6740 - VL_attention_linear_outp\n",
      "Epoch 4084/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3215 - VL_attention_linear_output_loss: 1.6574 - VH_attention_linear_output_loss: 1.6641 - VL_attention_linear_output_acc: 0.5160 - VH_attention_linear_output_acc: 0.5163 - val_loss: 3.4656 - val_VL_attention_linear_output_loss: 1.7361 - val_VH_attention_linear_output_loss: 1.7294 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.5013\n",
      "Epoch 4085/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3367 - VL_attention_linear_output_loss: 1.6620 - VH_attention_linear_output_loss: 1.6747 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5135 - val_loss: 3.4779 - val_VL_attention_linear_output_loss: 1.7457 - val_VH_attention_linear_output_loss: 1.7322 - val_VL_attention_linear_output_acc: 0.4974 - val_VH_attention_linear_output_acc: 0.5013\n",
      "Epoch 4086/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3308 - VL_attention_linear_output_loss: 1.6669 - VH_attention_linear_output_loss: 1.6638 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5171 - val_loss: 3.4677 - val_VL_attention_linear_output_loss: 1.7403 - val_VH_attention_linear_output_loss: 1.7273 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.5040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4087/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3433 - VL_attention_linear_output_loss: 1.6742 - VH_attention_linear_output_loss: 1.6691 - VL_attention_linear_output_acc: 0.5094 - VH_attention_linear_output_acc: 0.5148 - val_loss: 3.4719 - val_VL_attention_linear_output_loss: 1.7405 - val_VH_attention_linear_output_loss: 1.7314 - val_VL_attention_linear_output_acc: 0.5034 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 4088/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3474 - VL_attention_linear_output_loss: 1.6824 - VH_attention_linear_output_loss: 1.6650 - VL_attention_linear_output_acc: 0.5062 - VH_attention_linear_output_acc: 0.5165 - val_loss: 3.4856 - val_VL_attention_linear_output_loss: 1.7504 - val_VH_attention_linear_output_loss: 1.7351 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.5007\n",
      "Epoch 4089/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3454 - VL_attention_linear_output_loss: 1.6683 - VH_attention_linear_output_loss: 1.6771 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5122 - val_loss: 3.4936 - val_VL_attention_linear_output_loss: 1.7570 - val_VH_attention_linear_output_loss: 1.7366 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.4998\n",
      "Epoch 4090/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3372 - VL_attention_linear_output_loss: 1.6709 - VH_attention_linear_output_loss: 1.6664 - VL_attention_linear_output_acc: 0.5093 - VH_attention_linear_output_acc: 0.5158 - val_loss: 3.4841 - val_VL_attention_linear_output_loss: 1.7504 - val_VH_attention_linear_output_loss: 1.7337 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.5005\n",
      "Epoch 4091/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3333 - VL_attention_linear_output_loss: 1.6644 - VH_attention_linear_output_loss: 1.6690 - VL_attention_linear_output_acc: 0.5119 - VH_attention_linear_output_acc: 0.5156 - val_loss: 3.4721 - val_VL_attention_linear_output_loss: 1.7496 - val_VH_attention_linear_output_loss: 1.7225 - val_VL_attention_linear_output_acc: 0.4963 - val_VH_attention_linear_output_acc: 0.5033\n",
      "Epoch 4092/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3465 - VL_attention_linear_output_loss: 1.6677 - VH_attention_linear_output_loss: 1.6788 - VL_attention_linear_output_acc: 0.5119 - VH_attention_linear_output_acc: 0.5110 - val_loss: 3.4917 - val_VL_attention_linear_output_loss: 1.7584 - val_VH_attention_linear_output_loss: 1.7333 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.4991\n",
      "Epoch 4093/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3359 - VL_attention_linear_output_loss: 1.6755 - VH_attention_linear_output_loss: 1.6604 - VL_attention_linear_output_acc: 0.5073 - VH_attention_linear_output_acc: 0.5183 - val_loss: 3.4722 - val_VL_attention_linear_output_loss: 1.7478 - val_VH_attention_linear_output_loss: 1.7245 - val_VL_attention_linear_output_acc: 0.4988 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 4094/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3284 - VL_attention_linear_output_loss: 1.6639 - VH_attention_linear_output_loss: 1.6645 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4733 - val_VL_attention_linear_output_loss: 1.7382 - val_VH_attention_linear_output_loss: 1.7351 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.5022\n",
      "Epoch 4095/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3375 - VL_attention_linear_output_loss: 1.6709 - VH_attention_linear_output_loss: 1.6666 - VL_attention_linear_output_acc: 0.5094 - VH_attention_linear_output_acc: 0.5148 - val_loss: 3.5105 - val_VL_attention_linear_output_loss: 1.7361 - val_VH_attention_linear_output_loss: 1.7744 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.4904\n",
      "Epoch 4096/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3415 - VL_attention_linear_output_loss: 1.6728 - VH_attention_linear_output_loss: 1.6687 - VL_attention_linear_output_acc: 0.5088 - VH_attention_linear_output_acc: 0.5154 - val_loss: 3.4707 - val_VL_attention_linear_output_loss: 1.7365 - val_VH_attention_linear_output_loss: 1.7342 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.4976\n",
      "Epoch 4097/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3207 - VL_attention_linear_output_loss: 1.6579 - VH_attention_linear_output_loss: 1.6627 - VL_attention_linear_output_acc: 0.5163 - VH_attention_linear_output_acc: 0.5166 - val_loss: 3.5363 - val_VL_attention_linear_output_loss: 1.7604 - val_VH_attention_linear_output_loss: 1.7759 - val_VL_attention_linear_output_acc: 0.4843 - val_VH_attention_linear_output_acc: 0.4915\n",
      "Epoch 4098/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3285 - VL_attention_linear_output_loss: 1.6643 - VH_attention_linear_output_loss: 1.6642 - VL_attention_linear_output_acc: 0.5120 - VH_attention_linear_output_acc: 0.5169 - val_loss: 3.4817 - val_VL_attention_linear_output_loss: 1.7505 - val_VH_attention_linear_output_loss: 1.7312 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.5025\n",
      "Epoch 4099/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3321 - VL_attention_linear_output_loss: 1.6687 - VH_attention_linear_output_loss: 1.6634 - VL_attention_linear_output_acc: 0.5102 - VH_attention_linear_output_acc: 0.5169 - val_loss: 3.4607 - val_VL_attention_linear_output_loss: 1.7339 - val_VH_attention_linear_output_loss: 1.7268 - val_VL_attention_linear_output_acc: 0.4998 - val_VH_attention_linear_output_acc: 0.5061\n",
      "Epoch 4100/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3323 - VL_attention_linear_output_loss: 1.6682 - VH_attention_linear_output_loss: 1.6641 - VL_attention_linear_output_acc: 0.5094 - VH_attention_linear_output_acc: 0.5161 - val_loss: 3.4654 - val_VL_attention_linear_output_loss: 1.7352 - val_VH_attention_linear_output_loss: 1.7302 - val_VL_attention_linear_output_acc: 0.5048 - val_VH_attention_linear_output_acc: 0.5009\n",
      "Epoch 4101/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3447 - VL_attention_linear_output_loss: 1.6776 - VH_attention_linear_output_loss: 1.6671 - VL_attention_linear_output_acc: 0.5068 - VH_attention_linear_output_acc: 0.5159 - val_loss: 3.4623 - val_VL_attention_linear_output_loss: 1.7417 - val_VH_attention_linear_output_loss: 1.7206 - val_VL_attention_linear_output_acc: 0.4970 - val_VH_attention_linear_output_acc: 0.5062\n",
      "Epoch 4102/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3289 - VL_attention_linear_output_loss: 1.6634 - VH_attention_linear_output_loss: 1.6655 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5165 - val_loss: 3.4746 - val_VL_attention_linear_output_loss: 1.7382 - val_VH_attention_linear_output_loss: 1.7364 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.5015\n",
      "Epoch 4103/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3363 - VL_attention_linear_output_loss: 1.6681 - VH_attention_linear_output_loss: 1.6683 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5153 - val_loss: 3.4697 - val_VL_attention_linear_output_loss: 1.7358 - val_VH_attention_linear_output_loss: 1.7339 - val_VL_attention_linear_output_acc: 0.5027 - val_VH_attention_linear_output_acc: 0.5044\n",
      "Epoch 4104/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3268 - VL_attention_linear_output_loss: 1.6652 - VH_attention_linear_output_loss: 1.6616 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5179 - val_loss: 3.4610 - val_VL_attention_linear_output_loss: 1.7342 - val_VH_attention_linear_output_loss: 1.7268 - val_VL_attention_linear_output_acc: 0.5028 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4105/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3401 - VL_attention_linear_output_loss: 1.6710 - VH_attention_linear_output_loss: 1.6691 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5147 - val_loss: 3.4988 - val_VL_attention_linear_output_loss: 1.7367 - val_VH_attention_linear_output_loss: 1.7621 - val_VL_attention_linear_output_acc: 0.5042 - val_VH_attention_linear_output_acc: 0.4940\n",
      "Epoch 4106/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3325 - VL_attention_linear_output_loss: 1.6651 - VH_attention_linear_output_loss: 1.6674 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5158 - val_loss: 3.4646 - val_VL_attention_linear_output_loss: 1.7350 - val_VH_attention_linear_output_loss: 1.7296 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5019\n",
      "Epoch 4107/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3327 - VL_attention_linear_output_loss: 1.6624 - VH_attention_linear_output_loss: 1.6703 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5145 - val_loss: 3.4780 - val_VL_attention_linear_output_loss: 1.7393 - val_VH_attention_linear_output_loss: 1.7386 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.4981\n",
      "Epoch 4108/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3371 - VL_attention_linear_output_loss: 1.6649 - VH_attention_linear_output_loss: 1.6722 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5139 - val_loss: 3.4854 - val_VL_attention_linear_output_loss: 1.7442 - val_VH_attention_linear_output_loss: 1.7412 - val_VL_attention_linear_output_acc: 0.4905 - val_VH_attention_linear_output_acc: 0.4985\n",
      "Epoch 4109/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3299 - VL_attention_linear_output_loss: 1.6644 - VH_attention_linear_output_loss: 1.6655 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5155 - val_loss: 3.4796 - val_VL_attention_linear_output_loss: 1.7413 - val_VH_attention_linear_output_loss: 1.7383 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.4980\n",
      "Epoch 4110/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3365 - VL_attention_linear_output_loss: 1.6666 - VH_attention_linear_output_loss: 1.6699 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5143 - val_loss: 3.4603 - val_VL_attention_linear_output_loss: 1.7388 - val_VH_attention_linear_output_loss: 1.7214 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.5047\n",
      "Epoch 4111/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3250 - VL_attention_linear_output_loss: 1.6662 - VH_attention_linear_output_loss: 1.6588 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.4531 - val_VL_attention_linear_output_loss: 1.7302 - val_VH_attention_linear_output_loss: 1.7230 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 4112/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3350 - VL_attention_linear_output_loss: 1.6633 - VH_attention_linear_output_loss: 1.6717 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5138 - val_loss: 3.4693 - val_VL_attention_linear_output_loss: 1.7429 - val_VH_attention_linear_output_loss: 1.7264 - val_VL_attention_linear_output_acc: 0.5006 - val_VH_attention_linear_output_acc: 0.5020\n",
      "Epoch 4113/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3220 - VL_attention_linear_output_loss: 1.6633 - VH_attention_linear_output_loss: 1.6587 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5187 - val_loss: 3.4818 - val_VL_attention_linear_output_loss: 1.7602 - val_VH_attention_linear_output_loss: 1.7215 - val_VL_attention_linear_output_acc: 0.4784 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4114/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3370 - VL_attention_linear_output_loss: 1.6700 - VH_attention_linear_output_loss: 1.6669 - VL_attention_linear_output_acc: 0.5093 - VH_attention_linear_output_acc: 0.5162 - val_loss: 3.4664 - val_VL_attention_linear_output_loss: 1.7363 - val_VH_attention_linear_output_loss: 1.7301 - val_VL_attention_linear_output_acc: 0.5035 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4115/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3289 - VL_attention_linear_output_loss: 1.6605 - VH_attention_linear_output_loss: 1.6684 - VL_attention_linear_output_acc: 0.5154 - VH_attention_linear_output_acc: 0.5144 - val_loss: 3.4614 - val_VL_attention_linear_output_loss: 1.7343 - val_VH_attention_linear_output_loss: 1.7270 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.5059\n",
      "Epoch 4116/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3229 - VL_attention_linear_output_loss: 1.6615 - VH_attention_linear_output_loss: 1.6614 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5172 - val_loss: 3.4780 - val_VL_attention_linear_output_loss: 1.7399 - val_VH_attention_linear_output_loss: 1.7380 - val_VL_attention_linear_output_acc: 0.5001 - val_VH_attention_linear_output_acc: 0.4987\n",
      "Epoch 4117/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3388 - VL_attention_linear_output_loss: 1.6642 - VH_attention_linear_output_loss: 1.6746 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5123 - val_loss: 3.5006 - val_VL_attention_linear_output_loss: 1.7455 - val_VH_attention_linear_output_loss: 1.7552 - val_VL_attention_linear_output_acc: 0.4920 - val_VH_attention_linear_output_acc: 0.4958\n",
      "Epoch 4118/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3284 - VL_attention_linear_output_loss: 1.6659 - VH_attention_linear_output_loss: 1.6626 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5174 - val_loss: 3.4755 - val_VL_attention_linear_output_loss: 1.7481 - val_VH_attention_linear_output_loss: 1.7274 - val_VL_attention_linear_output_acc: 0.4949 - val_VH_attention_linear_output_acc: 0.5020\n",
      "Epoch 4119/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3341 - VL_attention_linear_output_loss: 1.6743 - VH_attention_linear_output_loss: 1.6598 - VL_attention_linear_output_acc: 0.5076 - VH_attention_linear_output_acc: 0.5181 - val_loss: 3.4544 - val_VL_attention_linear_output_loss: 1.7325 - val_VH_attention_linear_output_loss: 1.7220 - val_VL_attention_linear_output_acc: 0.5007 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4120/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3294 - VL_attention_linear_output_loss: 1.6672 - VH_attention_linear_output_loss: 1.6622 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5175 - val_loss: 3.4594 - val_VL_attention_linear_output_loss: 1.7360 - val_VH_attention_linear_output_loss: 1.7234 - val_VL_attention_linear_output_acc: 0.5035 - val_VH_attention_linear_output_acc: 0.5037\n",
      "Epoch 4121/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3349 - VL_attention_linear_output_loss: 1.6640 - VH_attention_linear_output_loss: 1.6709 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5145 - val_loss: 3.4643 - val_VL_attention_linear_output_loss: 1.7411 - val_VH_attention_linear_output_loss: 1.7232 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4122/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3400 - VL_attention_linear_output_loss: 1.6706 - VH_attention_linear_output_loss: 1.6694 - VL_attention_linear_output_acc: 0.5087 - VH_attention_linear_output_acc: 0.5151 - val_loss: 3.4862 - val_VL_attention_linear_output_loss: 1.7519 - val_VH_attention_linear_output_loss: 1.7343 - val_VL_attention_linear_output_acc: 0.4917 - val_VH_attention_linear_output_acc: 0.4982\n",
      "Epoch 4123/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3328 - VL_attention_linear_output_loss: 1.6735 - VH_attention_linear_output_loss: 1.6594 - VL_attention_linear_output_acc: 0.5074 - VH_attention_linear_output_acc: 0.5185 - val_loss: 3.4977 - val_VL_attention_linear_output_loss: 1.7775 - val_VH_attention_linear_output_loss: 1.7202 - val_VL_attention_linear_output_acc: 0.4947 - val_VH_attention_linear_output_acc: 0.5058\n",
      "Epoch 4124/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3314 - VL_attention_linear_output_loss: 1.6661 - VH_attention_linear_output_loss: 1.6653 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5158 - val_loss: 3.5055 - val_VL_attention_linear_output_loss: 1.7758 - val_VH_attention_linear_output_loss: 1.7297 - val_VL_attention_linear_output_acc: 0.4765 - val_VH_attention_linear_output_acc: 0.5023\n",
      "Epoch 4125/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3435 - VL_attention_linear_output_loss: 1.6663 - VH_attention_linear_output_loss: 1.6772 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5116 - val_loss: 3.4534 - val_VL_attention_linear_output_loss: 1.7333 - val_VH_attention_linear_output_loss: 1.7201 - val_VL_attention_linear_output_acc: 0.5033 - val_VH_attention_linear_output_acc: 0.5073\n",
      "Epoch 4126/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3282 - VL_attention_linear_output_loss: 1.6695 - VH_attention_linear_output_loss: 1.6588 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5185 - val_loss: 3.4632 - val_VL_attention_linear_output_loss: 1.7376 - val_VH_attention_linear_output_loss: 1.7256 - val_VL_attention_linear_output_acc: 0.4995 - val_VH_attention_linear_output_acc: 0.5067\n",
      "Epoch 4127/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3287 - VL_attention_linear_output_loss: 1.6569 - VH_attention_linear_output_loss: 1.6718 - VL_attention_linear_output_acc: 0.5152 - VH_attention_linear_output_acc: 0.5139 - val_loss: 3.4655 - val_VL_attention_linear_output_loss: 1.7354 - val_VH_attention_linear_output_loss: 1.7302 - val_VL_attention_linear_output_acc: 0.5037 - val_VH_attention_linear_output_acc: 0.5061\n",
      "Epoch 4128/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3291 - VL_attention_linear_output_loss: 1.6665 - VH_attention_linear_output_loss: 1.6625 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5172 - val_loss: 3.4561 - val_VL_attention_linear_output_loss: 1.7322 - val_VH_attention_linear_output_loss: 1.7239 - val_VL_attention_linear_output_acc: 0.5063 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 4129/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3345 - VL_attention_linear_output_loss: 1.6658 - VH_attention_linear_output_loss: 1.6688 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5146 - val_loss: 3.4886 - val_VL_attention_linear_output_loss: 1.7466 - val_VH_attention_linear_output_loss: 1.7420 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.4944\n",
      "Epoch 4130/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3227 - VL_attention_linear_output_loss: 1.6607 - VH_attention_linear_output_loss: 1.6620 - VL_attention_linear_output_acc: 0.5140 - VH_attention_linear_output_acc: 0.5172 - val_loss: 3.4736 - val_VL_attention_linear_output_loss: 1.7394 - val_VH_attention_linear_output_loss: 1.7342 - val_VL_attention_linear_output_acc: 0.4955 - val_VH_attention_linear_output_acc: 0.5046\n",
      "Epoch 4131/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3255 - VL_attention_linear_output_loss: 1.6619 - VH_attention_linear_output_loss: 1.6636 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5166 - val_loss: 3.4692 - val_VL_attention_linear_output_loss: 1.7389 - val_VH_attention_linear_output_loss: 1.7303 - val_VL_attention_linear_output_acc: 0.4943 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4132/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3458 - VL_attention_linear_output_loss: 1.6721 - VH_attention_linear_output_loss: 1.6737 - VL_attention_linear_output_acc: 0.5079 - VH_attention_linear_output_acc: 0.5134 - val_loss: 3.4784 - val_VL_attention_linear_output_loss: 1.7413 - val_VH_attention_linear_output_loss: 1.7371 - val_VL_attention_linear_output_acc: 0.4896 - val_VH_attention_linear_output_acc: 0.4993\n",
      "Epoch 4133/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3175 - VL_attention_linear_output_loss: 1.6580 - VH_attention_linear_output_loss: 1.6596 - VL_attention_linear_output_acc: 0.5147 - VH_attention_linear_output_acc: 0.5184 - val_loss: 3.4597 - val_VL_attention_linear_output_loss: 1.7361 - val_VH_attention_linear_output_loss: 1.7236 - val_VL_attention_linear_output_acc: 0.4981 - val_VH_attention_linear_output_acc: 0.5082\n",
      "Epoch 4134/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3218 - VL_attention_linear_output_loss: 1.6644 - VH_attention_linear_output_loss: 1.6574 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.4733 - val_VL_attention_linear_output_loss: 1.7344 - val_VH_attention_linear_output_loss: 1.7389 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.4989\n",
      "Epoch 4135/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3261 - VL_attention_linear_output_loss: 1.6584 - VH_attention_linear_output_loss: 1.6676 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5150 - val_loss: 3.4543 - val_VL_attention_linear_output_loss: 1.7327 - val_VH_attention_linear_output_loss: 1.7216 - val_VL_attention_linear_output_acc: 0.5027 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4136/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3280 - VL_attention_linear_output_loss: 1.6673 - VH_attention_linear_output_loss: 1.6607 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5173 - val_loss: 3.4835 - val_VL_attention_linear_output_loss: 1.7406 - val_VH_attention_linear_output_loss: 1.7429 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.5003\n",
      "Epoch 4137/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3480 - VL_attention_linear_output_loss: 1.6780 - VH_attention_linear_output_loss: 1.6699 - VL_attention_linear_output_acc: 0.5059 - VH_attention_linear_output_acc: 0.5154 - val_loss: 3.5093 - val_VL_attention_linear_output_loss: 1.7343 - val_VH_attention_linear_output_loss: 1.7750 - val_VL_attention_linear_output_acc: 0.4984 - val_VH_attention_linear_output_acc: 0.4820\n",
      "Epoch 4138/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3248 - VL_attention_linear_output_loss: 1.6592 - VH_attention_linear_output_loss: 1.6655 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5159 - val_loss: 3.4734 - val_VL_attention_linear_output_loss: 1.7371 - val_VH_attention_linear_output_loss: 1.7363 - val_VL_attention_linear_output_acc: 0.5064 - val_VH_attention_linear_output_acc: 0.4991\n",
      "Epoch 4139/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3229 - VL_attention_linear_output_loss: 1.6589 - VH_attention_linear_output_loss: 1.6640 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5166 - val_loss: 3.4829 - val_VL_attention_linear_output_loss: 1.7456 - val_VH_attention_linear_output_loss: 1.7373 - val_VL_attention_linear_output_acc: 0.4939 - val_VH_attention_linear_output_acc: 0.5012\n",
      "Epoch 4140/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3268 - VL_attention_linear_output_loss: 1.6683 - VH_attention_linear_output_loss: 1.6585 - VL_attention_linear_output_acc: 0.5091 - VH_attention_linear_output_acc: 0.5190 - val_loss: 3.4669 - val_VL_attention_linear_output_loss: 1.7375 - val_VH_attention_linear_output_loss: 1.7294 - val_VL_attention_linear_output_acc: 0.5031 - val_VH_attention_linear_output_acc: 0.5024\n",
      "Epoch 4141/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3222 - VL_attention_linear_output_loss: 1.6635 - VH_attention_linear_output_loss: 1.6587 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5188 - val_loss: 3.4580 - val_VL_attention_linear_output_loss: 1.7318 - val_VH_attention_linear_output_loss: 1.7262 - val_VL_attention_linear_output_acc: 0.5005 - val_VH_attention_linear_output_acc: 0.5034\n",
      "Epoch 4142/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3325 - VL_attention_linear_output_loss: 1.6610 - VH_attention_linear_output_loss: 1.6714 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5135 - val_loss: 3.4678 - val_VL_attention_linear_output_loss: 1.7407 - val_VH_attention_linear_output_loss: 1.7272 - val_VL_attention_linear_output_acc: 0.5011 - val_VH_attention_linear_output_acc: 0.5059\n",
      "Epoch 4143/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3170 - VL_attention_linear_output_loss: 1.6594 - VH_attention_linear_output_loss: 1.6576 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4828 - val_VL_attention_linear_output_loss: 1.7583 - val_VH_attention_linear_output_loss: 1.7245 - val_VL_attention_linear_output_acc: 0.4858 - val_VH_attention_linear_output_acc: 0.5061\n",
      "Epoch 4144/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3284 - VL_attention_linear_output_loss: 1.6710 - VH_attention_linear_output_loss: 1.6573 - VL_attention_linear_output_acc: 0.5088 - VH_attention_linear_output_acc: 0.5195 - val_loss: 3.4732 - val_VL_attention_linear_output_loss: 1.7382 - val_VH_attention_linear_output_loss: 1.7350 - val_VL_attention_linear_output_acc: 0.4996 - val_VH_attention_linear_output_acc: 0.5025\n",
      "Epoch 4145/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3257 - VL_attention_linear_output_loss: 1.6606 - VH_attention_linear_output_loss: 1.6651 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5166 - val_loss: 3.5107 - val_VL_attention_linear_output_loss: 1.7645 - val_VH_attention_linear_output_loss: 1.7461 - val_VL_attention_linear_output_acc: 0.4957 - val_VH_attention_linear_output_acc: 0.4970\n",
      "Epoch 4146/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3438 - VL_attention_linear_output_loss: 1.6815 - VH_attention_linear_output_loss: 1.6623 - VL_attention_linear_output_acc: 0.5053 - VH_attention_linear_output_acc: 0.5174 - val_loss: 3.4658 - val_VL_attention_linear_output_loss: 1.7384 - val_VH_attention_linear_output_loss: 1.7274 - val_VL_attention_linear_output_acc: 0.5035 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4147/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3366 - VL_attention_linear_output_loss: 1.6732 - VH_attention_linear_output_loss: 1.6634 - VL_attention_linear_output_acc: 0.5094 - VH_attention_linear_output_acc: 0.5178 - val_loss: 3.4694 - val_VL_attention_linear_output_loss: 1.7458 - val_VH_attention_linear_output_loss: 1.7236 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.5051\n",
      "Epoch 4148/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3316 - VL_attention_linear_output_loss: 1.6616 - VH_attention_linear_output_loss: 1.6699 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5140 - val_loss: 3.4938 - val_VL_attention_linear_output_loss: 1.7679 - val_VH_attention_linear_output_loss: 1.7259 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 4149/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3437 - VL_attention_linear_output_loss: 1.6644 - VH_attention_linear_output_loss: 1.6793 - VL_attention_linear_output_acc: 0.5119 - VH_attention_linear_output_acc: 0.5109 - val_loss: 3.4672 - val_VL_attention_linear_output_loss: 1.7424 - val_VH_attention_linear_output_loss: 1.7248 - val_VL_attention_linear_output_acc: 0.4992 - val_VH_attention_linear_output_acc: 0.5046\n",
      "Epoch 4150/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3200 - VL_attention_linear_output_loss: 1.6612 - VH_attention_linear_output_loss: 1.6588 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5189 - val_loss: 3.4530 - val_VL_attention_linear_output_loss: 1.7329 - val_VH_attention_linear_output_loss: 1.7202 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.5091\n",
      "Epoch 4151/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3284 - VL_attention_linear_output_loss: 1.6618 - VH_attention_linear_output_loss: 1.6666 - VL_attention_linear_output_acc: 0.5118 - VH_attention_linear_output_acc: 0.5158 - val_loss: 3.4597 - val_VL_attention_linear_output_loss: 1.7389 - val_VH_attention_linear_output_loss: 1.7208 - val_VL_attention_linear_output_acc: 0.4974 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4152/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3240 - VL_attention_linear_output_loss: 1.6692 - VH_attention_linear_output_loss: 1.6548 - VL_attention_linear_output_acc: 0.5099 - VH_attention_linear_output_acc: 0.5204 - val_loss: 3.4661 - val_VL_attention_linear_output_loss: 1.7338 - val_VH_attention_linear_output_loss: 1.7323 - val_VL_attention_linear_output_acc: 0.5016 - val_VH_attention_linear_output_acc: 0.5006\n",
      "Epoch 4153/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3203 - VL_attention_linear_output_loss: 1.6546 - VH_attention_linear_output_loss: 1.6657 - VL_attention_linear_output_acc: 0.5148 - VH_attention_linear_output_acc: 0.5158 - val_loss: 3.4482 - val_VL_attention_linear_output_loss: 1.7310 - val_VH_attention_linear_output_loss: 1.7172 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.5055\n",
      "Epoch 4154/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3138 - VL_attention_linear_output_loss: 1.6569 - VH_attention_linear_output_loss: 1.6569 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5190 - val_loss: 3.4651 - val_VL_attention_linear_output_loss: 1.7353 - val_VH_attention_linear_output_loss: 1.7298 - val_VL_attention_linear_output_acc: 0.5055 - val_VH_attention_linear_output_acc: 0.5064\n",
      "Epoch 4155/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3101 - VL_attention_linear_output_loss: 1.6537 - VH_attention_linear_output_loss: 1.6564 - VL_attention_linear_output_acc: 0.5160 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.4701 - val_VL_attention_linear_output_loss: 1.7400 - val_VH_attention_linear_output_loss: 1.7301 - val_VL_attention_linear_output_acc: 0.5017 - val_VH_attention_linear_output_acc: 0.5018\n",
      "Epoch 4156/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3141 - VL_attention_linear_output_loss: 1.6553 - VH_attention_linear_output_loss: 1.6587 - VL_attention_linear_output_acc: 0.5148 - VH_attention_linear_output_acc: 0.5189 - val_loss: 3.4756 - val_VL_attention_linear_output_loss: 1.7391 - val_VH_attention_linear_output_loss: 1.7365 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.4977\n",
      "Epoch 4157/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3591 - VL_attention_linear_output_loss: 1.6812 - VH_attention_linear_output_loss: 1.6778 - VL_attention_linear_output_acc: 0.5044 - VH_attention_linear_output_acc: 0.5113 - val_loss: 3.5036 - val_VL_attention_linear_output_loss: 1.7653 - val_VH_attention_linear_output_loss: 1.7383 - val_VL_attention_linear_output_acc: 0.4999 - val_VH_attention_linear_output_acc: 0.5037\n",
      "Epoch 4158/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3255 - VL_attention_linear_output_loss: 1.6626 - VH_attention_linear_output_loss: 1.6628 - VL_attention_linear_output_acc: 0.5109 - VH_attention_linear_output_acc: 0.5177 - val_loss: 3.4812 - val_VL_attention_linear_output_loss: 1.7533 - val_VH_attention_linear_output_loss: 1.7279 - val_VL_attention_linear_output_acc: 0.4840 - val_VH_attention_linear_output_acc: 0.5023\n",
      "Epoch 4159/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3240 - VL_attention_linear_output_loss: 1.6602 - VH_attention_linear_output_loss: 1.6638 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5164 - val_loss: 3.4651 - val_VL_attention_linear_output_loss: 1.7379 - val_VH_attention_linear_output_loss: 1.7272 - val_VL_attention_linear_output_acc: 0.5070 - val_VH_attention_linear_output_acc: 0.5053\n",
      "Epoch 4160/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3348 - VL_attention_linear_output_loss: 1.6757 - VH_attention_linear_output_loss: 1.6591 - VL_attention_linear_output_acc: 0.5067 - VH_attention_linear_output_acc: 0.5183 - val_loss: 3.4596 - val_VL_attention_linear_output_loss: 1.7368 - val_VH_attention_linear_output_loss: 1.7228 - val_VL_attention_linear_output_acc: 0.5052 - val_VH_attention_linear_output_acc: 0.5024\n",
      "Epoch 4161/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3187 - VL_attention_linear_output_loss: 1.6604 - VH_attention_linear_output_loss: 1.6583 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5189 - val_loss: 3.5100 - val_VL_attention_linear_output_loss: 1.7535 - val_VH_attention_linear_output_loss: 1.7565 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.4884\n",
      "Epoch 4162/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3295 - VL_attention_linear_output_loss: 1.6599 - VH_attention_linear_output_loss: 1.6696 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5145 - val_loss: 3.4640 - val_VL_attention_linear_output_loss: 1.7357 - val_VH_attention_linear_output_loss: 1.7283 - val_VL_attention_linear_output_acc: 0.5049 - val_VH_attention_linear_output_acc: 0.5026\n",
      "Epoch 4163/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3222 - VL_attention_linear_output_loss: 1.6606 - VH_attention_linear_output_loss: 1.6616 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5181 - val_loss: 3.4602 - val_VL_attention_linear_output_loss: 1.7317 - val_VH_attention_linear_output_loss: 1.7285 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4164/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3404 - VL_attention_linear_output_loss: 1.6657 - VH_attention_linear_output_loss: 1.6746 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5126 - val_loss: 3.4829 - val_VL_attention_linear_output_loss: 1.7587 - val_VH_attention_linear_output_loss: 1.7242 - val_VL_attention_linear_output_acc: 0.4914 - val_VH_attention_linear_output_acc: 0.5086\n",
      "Epoch 4165/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3400 - VL_attention_linear_output_loss: 1.6734 - VH_attention_linear_output_loss: 1.6666 - VL_attention_linear_output_acc: 0.5068 - VH_attention_linear_output_acc: 0.5160 - val_loss: 3.4665 - val_VL_attention_linear_output_loss: 1.7373 - val_VH_attention_linear_output_loss: 1.7292 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5033\n",
      "Epoch 4166/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3167 - VL_attention_linear_output_loss: 1.6611 - VH_attention_linear_output_loss: 1.6556 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5202 - val_loss: 3.4683 - val_VL_attention_linear_output_loss: 1.7388 - val_VH_attention_linear_output_loss: 1.7295 - val_VL_attention_linear_output_acc: 0.5024 - val_VH_attention_linear_output_acc: 0.5010\n",
      "Epoch 4167/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3268 - VL_attention_linear_output_loss: 1.6665 - VH_attention_linear_output_loss: 1.6603 - VL_attention_linear_output_acc: 0.5098 - VH_attention_linear_output_acc: 0.5182 - val_loss: 3.4878 - val_VL_attention_linear_output_loss: 1.7340 - val_VH_attention_linear_output_loss: 1.7538 - val_VL_attention_linear_output_acc: 0.5072 - val_VH_attention_linear_output_acc: 0.4965\n",
      "Epoch 4168/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3438 - VL_attention_linear_output_loss: 1.6754 - VH_attention_linear_output_loss: 1.6684 - VL_attention_linear_output_acc: 0.5075 - VH_attention_linear_output_acc: 0.5150 - val_loss: 3.4531 - val_VL_attention_linear_output_loss: 1.7247 - val_VH_attention_linear_output_loss: 1.7284 - val_VL_attention_linear_output_acc: 0.5046 - val_VH_attention_linear_output_acc: 0.5013\n",
      "Epoch 4169/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3428 - VL_attention_linear_output_loss: 1.6649 - VH_attention_linear_output_loss: 1.6778 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5121 - val_loss: 3.4876 - val_VL_attention_linear_output_loss: 1.7317 - val_VH_attention_linear_output_loss: 1.7560 - val_VL_attention_linear_output_acc: 0.5002 - val_VH_attention_linear_output_acc: 0.4888\n",
      "Epoch 4170/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3274 - VL_attention_linear_output_loss: 1.6676 - VH_attention_linear_output_loss: 1.6598 - VL_attention_linear_output_acc: 0.5093 - VH_attention_linear_output_acc: 0.5180 - val_loss: 3.4800 - val_VL_attention_linear_output_loss: 1.7506 - val_VH_attention_linear_output_loss: 1.7293 - val_VL_attention_linear_output_acc: 0.4932 - val_VH_attention_linear_output_acc: 0.5023\n",
      "Epoch 4171/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3289 - VL_attention_linear_output_loss: 1.6642 - VH_attention_linear_output_loss: 1.6647 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5169 - val_loss: 3.4736 - val_VL_attention_linear_output_loss: 1.7482 - val_VH_attention_linear_output_loss: 1.7254 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.5038\n",
      "Epoch 4172/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3229 - VL_attention_linear_output_loss: 1.6621 - VH_attention_linear_output_loss: 1.6608 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5186 - val_loss: 3.4677 - val_VL_attention_linear_output_loss: 1.7317 - val_VH_attention_linear_output_loss: 1.7360 - val_VL_attention_linear_output_acc: 0.4958 - val_VH_attention_linear_output_acc: 0.5002\n",
      "Epoch 4173/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3280 - VL_attention_linear_output_loss: 1.6591 - VH_attention_linear_output_loss: 1.6688 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5151 - val_loss: 3.5039 - val_VL_attention_linear_output_loss: 1.7383 - val_VH_attention_linear_output_loss: 1.7655 - val_VL_attention_linear_output_acc: 0.4961 - val_VH_attention_linear_output_acc: 0.4841\n",
      "Epoch 4174/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3202 - VL_attention_linear_output_loss: 1.6616 - VH_attention_linear_output_loss: 1.6586 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5187 - val_loss: 3.4984 - val_VL_attention_linear_output_loss: 1.7615 - val_VH_attention_linear_output_loss: 1.7369 - val_VL_attention_linear_output_acc: 0.4881 - val_VH_attention_linear_output_acc: 0.5007\n",
      "Epoch 4175/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3227 - VL_attention_linear_output_loss: 1.6636 - VH_attention_linear_output_loss: 1.6591 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5180 - val_loss: 3.4573 - val_VL_attention_linear_output_loss: 1.7378 - val_VH_attention_linear_output_loss: 1.7195 - val_VL_attention_linear_output_acc: 0.5012 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4176/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3292 - VL_attention_linear_output_loss: 1.6665 - VH_attention_linear_output_loss: 1.6627 - VL_attention_linear_output_acc: 0.5092 - VH_attention_linear_output_acc: 0.5171 - val_loss: 3.4526 - val_VL_attention_linear_output_loss: 1.7332 - val_VH_attention_linear_output_loss: 1.7194 - val_VL_attention_linear_output_acc: 0.5050 - val_VH_attention_linear_output_acc: 0.5104\n",
      "Epoch 4177/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3257 - VL_attention_linear_output_loss: 1.6649 - VH_attention_linear_output_loss: 1.6608 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5180 - val_loss: 3.4728 - val_VL_attention_linear_output_loss: 1.7504 - val_VH_attention_linear_output_loss: 1.7224 - val_VL_attention_linear_output_acc: 0.4868 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4178/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3402 - VL_attention_linear_output_loss: 1.6789 - VH_attention_linear_output_loss: 1.6613 - VL_attention_linear_output_acc: 0.5040 - VH_attention_linear_output_acc: 0.5181 - val_loss: 3.4563 - val_VL_attention_linear_output_loss: 1.7342 - val_VH_attention_linear_output_loss: 1.7220 - val_VL_attention_linear_output_acc: 0.5017 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4179/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3196 - VL_attention_linear_output_loss: 1.6591 - VH_attention_linear_output_loss: 1.6605 - VL_attention_linear_output_acc: 0.5120 - VH_attention_linear_output_acc: 0.5185 - val_loss: 3.4661 - val_VL_attention_linear_output_loss: 1.7358 - val_VH_attention_linear_output_loss: 1.7303 - val_VL_attention_linear_output_acc: 0.5004 - val_VH_attention_linear_output_acc: 0.4981\n",
      "Epoch 4180/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3247 - VL_attention_linear_output_loss: 1.6606 - VH_attention_linear_output_loss: 1.6641 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5164 - val_loss: 3.4940 - val_VL_attention_linear_output_loss: 1.7530 - val_VH_attention_linear_output_loss: 1.7409 - val_VL_attention_linear_output_acc: 0.4872 - val_VH_attention_linear_output_acc: 0.4943\n",
      "Epoch 4181/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3290 - VL_attention_linear_output_loss: 1.6584 - VH_attention_linear_output_loss: 1.6706 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5140 - val_loss: 3.4689 - val_VL_attention_linear_output_loss: 1.7447 - val_VH_attention_linear_output_loss: 1.7242 - val_VL_attention_linear_output_acc: 0.4989 - val_VH_attention_linear_output_acc: 0.5055\n",
      "Epoch 4182/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3390 - VL_attention_linear_output_loss: 1.6760 - VH_attention_linear_output_loss: 1.6630 - VL_attention_linear_output_acc: 0.5054 - VH_attention_linear_output_acc: 0.5171 - val_loss: 3.4470 - val_VL_attention_linear_output_loss: 1.7273 - val_VH_attention_linear_output_loss: 1.7196 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5063\n",
      "Epoch 4183/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3049 - VL_attention_linear_output_loss: 1.6526 - VH_attention_linear_output_loss: 1.6523 - VL_attention_linear_output_acc: 0.5159 - VH_attention_linear_output_acc: 0.5212 - val_loss: 3.4644 - val_VL_attention_linear_output_loss: 1.7276 - val_VH_attention_linear_output_loss: 1.7368 - val_VL_attention_linear_output_acc: 0.4972 - val_VH_attention_linear_output_acc: 0.5016\n",
      "Epoch 4184/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3273 - VL_attention_linear_output_loss: 1.6633 - VH_attention_linear_output_loss: 1.6640 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4739 - val_VL_attention_linear_output_loss: 1.7498 - val_VH_attention_linear_output_loss: 1.7241 - val_VL_attention_linear_output_acc: 0.5015 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4185/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3244 - VL_attention_linear_output_loss: 1.6612 - VH_attention_linear_output_loss: 1.6632 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5169 - val_loss: 3.4666 - val_VL_attention_linear_output_loss: 1.7319 - val_VH_attention_linear_output_loss: 1.7347 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.5039\n",
      "Epoch 4186/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3317 - VL_attention_linear_output_loss: 1.6609 - VH_attention_linear_output_loss: 1.6708 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5134 - val_loss: 3.4507 - val_VL_attention_linear_output_loss: 1.7312 - val_VH_attention_linear_output_loss: 1.7196 - val_VL_attention_linear_output_acc: 0.5064 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4187/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3173 - VL_attention_linear_output_loss: 1.6658 - VH_attention_linear_output_loss: 1.6515 - VL_attention_linear_output_acc: 0.5095 - VH_attention_linear_output_acc: 0.5212 - val_loss: 3.4759 - val_VL_attention_linear_output_loss: 1.7531 - val_VH_attention_linear_output_loss: 1.7228 - val_VL_attention_linear_output_acc: 0.4833 - val_VH_attention_linear_output_acc: 0.5046\n",
      "Epoch 4188/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3147 - VL_attention_linear_output_loss: 1.6553 - VH_attention_linear_output_loss: 1.6594 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5177 - val_loss: 3.4649 - val_VL_attention_linear_output_loss: 1.7349 - val_VH_attention_linear_output_loss: 1.7300 - val_VL_attention_linear_output_acc: 0.5037 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 4189/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3172 - VL_attention_linear_output_loss: 1.6584 - VH_attention_linear_output_loss: 1.6588 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5186 - val_loss: 3.4511 - val_VL_attention_linear_output_loss: 1.7278 - val_VH_attention_linear_output_loss: 1.7232 - val_VL_attention_linear_output_acc: 0.4996 - val_VH_attention_linear_output_acc: 0.5063\n",
      "Epoch 4190/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3257 - VL_attention_linear_output_loss: 1.6630 - VH_attention_linear_output_loss: 1.6628 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5177 - val_loss: 3.4735 - val_VL_attention_linear_output_loss: 1.7384 - val_VH_attention_linear_output_loss: 1.7351 - val_VL_attention_linear_output_acc: 0.4984 - val_VH_attention_linear_output_acc: 0.5000\n",
      "Epoch 4191/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3316 - VL_attention_linear_output_loss: 1.6675 - VH_attention_linear_output_loss: 1.6641 - VL_attention_linear_output_acc: 0.5092 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4484 - val_VL_attention_linear_output_loss: 1.7280 - val_VH_attention_linear_output_loss: 1.7204 - val_VL_attention_linear_output_acc: 0.5052 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 4192/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3321 - VL_attention_linear_output_loss: 1.6632 - VH_attention_linear_output_loss: 1.6690 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5145 - val_loss: 3.5259 - val_VL_attention_linear_output_loss: 1.7644 - val_VH_attention_linear_output_loss: 1.7615 - val_VL_attention_linear_output_acc: 0.4992 - val_VH_attention_linear_output_acc: 0.4965\n",
      "Epoch 4193/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3202 - VL_attention_linear_output_loss: 1.6624 - VH_attention_linear_output_loss: 1.6578 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5190 - val_loss: 3.4633 - val_VL_attention_linear_output_loss: 1.7386 - val_VH_attention_linear_output_loss: 1.7247 - val_VL_attention_linear_output_acc: 0.5001 - val_VH_attention_linear_output_acc: 0.5051\n",
      "Epoch 4194/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3322 - VL_attention_linear_output_loss: 1.6635 - VH_attention_linear_output_loss: 1.6687 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5150 - val_loss: 3.4907 - val_VL_attention_linear_output_loss: 1.7443 - val_VH_attention_linear_output_loss: 1.7465 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.4972\n",
      "Epoch 4195/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3244 - VL_attention_linear_output_loss: 1.6656 - VH_attention_linear_output_loss: 1.6588 - VL_attention_linear_output_acc: 0.5094 - VH_attention_linear_output_acc: 0.5181 - val_loss: 3.5061 - val_VL_attention_linear_output_loss: 1.7859 - val_VH_attention_linear_output_loss: 1.7202 - val_VL_attention_linear_output_acc: 0.4722 - val_VH_attention_linear_output_acc: 0.5063\n",
      "Epoch 4196/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3120 - VL_attention_linear_output_loss: 1.6619 - VH_attention_linear_output_loss: 1.6502 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4535 - val_VL_attention_linear_output_loss: 1.7294 - val_VH_attention_linear_output_loss: 1.7241 - val_VL_attention_linear_output_acc: 0.5029 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4197/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3071 - VL_attention_linear_output_loss: 1.6516 - VH_attention_linear_output_loss: 1.6555 - VL_attention_linear_output_acc: 0.5149 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.5337 - val_VL_attention_linear_output_loss: 1.7241 - val_VH_attention_linear_output_loss: 1.8096 - val_VL_attention_linear_output_acc: 0.5030 - val_VH_attention_linear_output_acc: 0.4778\n",
      "Epoch 4198/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3136 - VL_attention_linear_output_loss: 1.6580 - VH_attention_linear_output_loss: 1.6555 - VL_attention_linear_output_acc: 0.5140 - VH_attention_linear_output_acc: 0.5211 - val_loss: 3.4443 - val_VL_attention_linear_output_loss: 1.7260 - val_VH_attention_linear_output_loss: 1.7184 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 4199/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3198 - VL_attention_linear_output_loss: 1.6600 - VH_attention_linear_output_loss: 1.6598 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5184 - val_loss: 3.5070 - val_VL_attention_linear_output_loss: 1.7714 - val_VH_attention_linear_output_loss: 1.7356 - val_VL_attention_linear_output_acc: 0.4737 - val_VH_attention_linear_output_acc: 0.4981\n",
      "Epoch 4200/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3342 - VL_attention_linear_output_loss: 1.6659 - VH_attention_linear_output_loss: 1.6683 - VL_attention_linear_output_acc: 0.5084 - VH_attention_linear_output_acc: 0.5159 - val_loss: 3.4915 - val_VL_attention_linear_output_loss: 1.7669 - val_VH_attention_linear_output_loss: 1.7246 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.5063\n",
      "Epoch 4201/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3306 - VL_attention_linear_output_loss: 1.6712 - VH_attention_linear_output_loss: 1.6594 - VL_attention_linear_output_acc: 0.5086 - VH_attention_linear_output_acc: 0.5180 - val_loss: 3.4606 - val_VL_attention_linear_output_loss: 1.7330 - val_VH_attention_linear_output_loss: 1.7276 - val_VL_attention_linear_output_acc: 0.5029 - val_VH_attention_linear_output_acc: 0.5064\n",
      "Epoch 4202/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3077 - VL_attention_linear_output_loss: 1.6512 - VH_attention_linear_output_loss: 1.6565 - VL_attention_linear_output_acc: 0.5153 - VH_attention_linear_output_acc: 0.5189 - val_loss: 3.4410 - val_VL_attention_linear_output_loss: 1.7267 - val_VH_attention_linear_output_loss: 1.7143 - val_VL_attention_linear_output_acc: 0.5058 - val_VH_attention_linear_output_acc: 0.5086\n",
      "Epoch 4203/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3004 - VL_attention_linear_output_loss: 1.6487 - VH_attention_linear_output_loss: 1.6517 - VL_attention_linear_output_acc: 0.5170 - VH_attention_linear_output_acc: 0.5210 - val_loss: 3.4385 - val_VL_attention_linear_output_loss: 1.7247 - val_VH_attention_linear_output_loss: 1.7137 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4204/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3071 - VL_attention_linear_output_loss: 1.6492 - VH_attention_linear_output_loss: 1.6579 - VL_attention_linear_output_acc: 0.5163 - VH_attention_linear_output_acc: 0.5185 - val_loss: 3.4490 - val_VL_attention_linear_output_loss: 1.7284 - val_VH_attention_linear_output_loss: 1.7206 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.5065\n",
      "Epoch 4205/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3078 - VL_attention_linear_output_loss: 1.6520 - VH_attention_linear_output_loss: 1.6558 - VL_attention_linear_output_acc: 0.5149 - VH_attention_linear_output_acc: 0.5196 - val_loss: 3.4942 - val_VL_attention_linear_output_loss: 1.7767 - val_VH_attention_linear_output_loss: 1.7174 - val_VL_attention_linear_output_acc: 0.4898 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 4206/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3181 - VL_attention_linear_output_loss: 1.6579 - VH_attention_linear_output_loss: 1.6603 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5177 - val_loss: 3.4601 - val_VL_attention_linear_output_loss: 1.7386 - val_VH_attention_linear_output_loss: 1.7215 - val_VL_attention_linear_output_acc: 0.4901 - val_VH_attention_linear_output_acc: 0.5058\n",
      "Epoch 4207/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3072 - VL_attention_linear_output_loss: 1.6531 - VH_attention_linear_output_loss: 1.6542 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5199 - val_loss: 3.4619 - val_VL_attention_linear_output_loss: 1.7301 - val_VH_attention_linear_output_loss: 1.7317 - val_VL_attention_linear_output_acc: 0.5057 - val_VH_attention_linear_output_acc: 0.4996\n",
      "Epoch 4208/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3109 - VL_attention_linear_output_loss: 1.6581 - VH_attention_linear_output_loss: 1.6528 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5207 - val_loss: 3.4587 - val_VL_attention_linear_output_loss: 1.7348 - val_VH_attention_linear_output_loss: 1.7239 - val_VL_attention_linear_output_acc: 0.5056 - val_VH_attention_linear_output_acc: 0.5029\n",
      "Epoch 4209/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3213 - VL_attention_linear_output_loss: 1.6568 - VH_attention_linear_output_loss: 1.6645 - VL_attention_linear_output_acc: 0.5118 - VH_attention_linear_output_acc: 0.5160 - val_loss: 3.4483 - val_VL_attention_linear_output_loss: 1.7277 - val_VH_attention_linear_output_loss: 1.7207 - val_VL_attention_linear_output_acc: 0.5018 - val_VH_attention_linear_output_acc: 0.5047\n",
      "Epoch 4210/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3053 - VL_attention_linear_output_loss: 1.6553 - VH_attention_linear_output_loss: 1.6500 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4431 - val_VL_attention_linear_output_loss: 1.7268 - val_VH_attention_linear_output_loss: 1.7163 - val_VL_attention_linear_output_acc: 0.5020 - val_VH_attention_linear_output_acc: 0.5098\n",
      "Epoch 4211/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3158 - VL_attention_linear_output_loss: 1.6618 - VH_attention_linear_output_loss: 1.6540 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5198 - val_loss: 3.4594 - val_VL_attention_linear_output_loss: 1.7385 - val_VH_attention_linear_output_loss: 1.7209 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.5047\n",
      "Epoch 4212/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3100 - VL_attention_linear_output_loss: 1.6511 - VH_attention_linear_output_loss: 1.6589 - VL_attention_linear_output_acc: 0.5152 - VH_attention_linear_output_acc: 0.5182 - val_loss: 3.4473 - val_VL_attention_linear_output_loss: 1.7243 - val_VH_attention_linear_output_loss: 1.7230 - val_VL_attention_linear_output_acc: 0.5062 - val_VH_attention_linear_output_acc: 0.5032\n",
      "Epoch 4213/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3196 - VL_attention_linear_output_loss: 1.6561 - VH_attention_linear_output_loss: 1.6635 - VL_attention_linear_output_acc: 0.5147 - VH_attention_linear_output_acc: 0.5166 - val_loss: 3.4559 - val_VL_attention_linear_output_loss: 1.7344 - val_VH_attention_linear_output_loss: 1.7215 - val_VL_attention_linear_output_acc: 0.4935 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 4214/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3119 - VL_attention_linear_output_loss: 1.6536 - VH_attention_linear_output_loss: 1.6582 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5180 - val_loss: 3.4499 - val_VL_attention_linear_output_loss: 1.7271 - val_VH_attention_linear_output_loss: 1.7228 - val_VL_attention_linear_output_acc: 0.5063 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 4215/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3256 - VL_attention_linear_output_loss: 1.6681 - VH_attention_linear_output_loss: 1.6575 - VL_attention_linear_output_acc: 0.5085 - VH_attention_linear_output_acc: 0.5190 - val_loss: 3.4594 - val_VL_attention_linear_output_loss: 1.7328 - val_VH_attention_linear_output_loss: 1.7266 - val_VL_attention_linear_output_acc: 0.5080 - val_VH_attention_linear_output_acc: 0.5039\n",
      "Epoch 4216/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3106 - VL_attention_linear_output_loss: 1.6596 - VH_attention_linear_output_loss: 1.6510 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5216 - val_loss: 3.4709 - val_VL_attention_linear_output_loss: 1.7422 - val_VH_attention_linear_output_loss: 1.7287 - val_VL_attention_linear_output_acc: 0.4895 - val_VH_attention_linear_output_acc: 0.5060\n",
      "Epoch 4217/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3099 - VL_attention_linear_output_loss: 1.6570 - VH_attention_linear_output_loss: 1.6528 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5201 - val_loss: 3.4654 - val_VL_attention_linear_output_loss: 1.7440 - val_VH_attention_linear_output_loss: 1.7214 - val_VL_attention_linear_output_acc: 0.4916 - val_VH_attention_linear_output_acc: 0.5070\n",
      "Epoch 4218/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3254 - VL_attention_linear_output_loss: 1.6678 - VH_attention_linear_output_loss: 1.6576 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5189 - val_loss: 3.4569 - val_VL_attention_linear_output_loss: 1.7353 - val_VH_attention_linear_output_loss: 1.7216 - val_VL_attention_linear_output_acc: 0.5045 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4219/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3260 - VL_attention_linear_output_loss: 1.6602 - VH_attention_linear_output_loss: 1.6658 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5158 - val_loss: 3.4517 - val_VL_attention_linear_output_loss: 1.7317 - val_VH_attention_linear_output_loss: 1.7200 - val_VL_attention_linear_output_acc: 0.5004 - val_VH_attention_linear_output_acc: 0.5042\n",
      "Epoch 4220/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3124 - VL_attention_linear_output_loss: 1.6585 - VH_attention_linear_output_loss: 1.6538 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5200 - val_loss: 3.4724 - val_VL_attention_linear_output_loss: 1.7512 - val_VH_attention_linear_output_loss: 1.7212 - val_VL_attention_linear_output_acc: 0.4848 - val_VH_attention_linear_output_acc: 0.5053\n",
      "Epoch 4221/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3186 - VL_attention_linear_output_loss: 1.6610 - VH_attention_linear_output_loss: 1.6576 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5187 - val_loss: 3.5041 - val_VL_attention_linear_output_loss: 1.7289 - val_VH_attention_linear_output_loss: 1.7751 - val_VL_attention_linear_output_acc: 0.4952 - val_VH_attention_linear_output_acc: 0.4897\n",
      "Epoch 4222/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3080 - VL_attention_linear_output_loss: 1.6540 - VH_attention_linear_output_loss: 1.6540 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5205 - val_loss: 3.4631 - val_VL_attention_linear_output_loss: 1.7461 - val_VH_attention_linear_output_loss: 1.7170 - val_VL_attention_linear_output_acc: 0.4895 - val_VH_attention_linear_output_acc: 0.5061\n",
      "Epoch 4223/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3184 - VL_attention_linear_output_loss: 1.6615 - VH_attention_linear_output_loss: 1.6569 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5196 - val_loss: 3.4603 - val_VL_attention_linear_output_loss: 1.7330 - val_VH_attention_linear_output_loss: 1.7273 - val_VL_attention_linear_output_acc: 0.5035 - val_VH_attention_linear_output_acc: 0.5018\n",
      "Epoch 4224/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3128 - VL_attention_linear_output_loss: 1.6549 - VH_attention_linear_output_loss: 1.6578 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5185 - val_loss: 3.4466 - val_VL_attention_linear_output_loss: 1.7280 - val_VH_attention_linear_output_loss: 1.7186 - val_VL_attention_linear_output_acc: 0.5064 - val_VH_attention_linear_output_acc: 0.5039\n",
      "Epoch 4225/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3210 - VL_attention_linear_output_loss: 1.6631 - VH_attention_linear_output_loss: 1.6578 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.5103 - val_VL_attention_linear_output_loss: 1.7650 - val_VH_attention_linear_output_loss: 1.7453 - val_VL_attention_linear_output_acc: 0.4847 - val_VH_attention_linear_output_acc: 0.4935\n",
      "Epoch 4226/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3357 - VL_attention_linear_output_loss: 1.6683 - VH_attention_linear_output_loss: 1.6673 - VL_attention_linear_output_acc: 0.5084 - VH_attention_linear_output_acc: 0.5146 - val_loss: 3.4604 - val_VL_attention_linear_output_loss: 1.7276 - val_VH_attention_linear_output_loss: 1.7328 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.4976\n",
      "Epoch 4227/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3032 - VL_attention_linear_output_loss: 1.6535 - VH_attention_linear_output_loss: 1.6497 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4459 - val_VL_attention_linear_output_loss: 1.7266 - val_VH_attention_linear_output_loss: 1.7193 - val_VL_attention_linear_output_acc: 0.5033 - val_VH_attention_linear_output_acc: 0.5071\n",
      "Epoch 4228/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3078 - VL_attention_linear_output_loss: 1.6542 - VH_attention_linear_output_loss: 1.6536 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5199 - val_loss: 3.4774 - val_VL_attention_linear_output_loss: 1.7514 - val_VH_attention_linear_output_loss: 1.7260 - val_VL_attention_linear_output_acc: 0.4878 - val_VH_attention_linear_output_acc: 0.5015\n",
      "Epoch 4229/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3272 - VL_attention_linear_output_loss: 1.6640 - VH_attention_linear_output_loss: 1.6632 - VL_attention_linear_output_acc: 0.5093 - VH_attention_linear_output_acc: 0.5169 - val_loss: 3.5044 - val_VL_attention_linear_output_loss: 1.7416 - val_VH_attention_linear_output_loss: 1.7628 - val_VL_attention_linear_output_acc: 0.4957 - val_VH_attention_linear_output_acc: 0.4941\n",
      "Epoch 4230/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3251 - VL_attention_linear_output_loss: 1.6582 - VH_attention_linear_output_loss: 1.6669 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5153 - val_loss: 3.5540 - val_VL_attention_linear_output_loss: 1.8272 - val_VH_attention_linear_output_loss: 1.7268 - val_VL_attention_linear_output_acc: 0.4685 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4231/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3218 - VL_attention_linear_output_loss: 1.6605 - VH_attention_linear_output_loss: 1.6613 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5175 - val_loss: 3.4669 - val_VL_attention_linear_output_loss: 1.7372 - val_VH_attention_linear_output_loss: 1.7296 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.5019\n",
      "Epoch 4232/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3255 - VL_attention_linear_output_loss: 1.6600 - VH_attention_linear_output_loss: 1.6655 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5157 - val_loss: 3.4804 - val_VL_attention_linear_output_loss: 1.7542 - val_VH_attention_linear_output_loss: 1.7262 - val_VL_attention_linear_output_acc: 0.4853 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4233/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3349 - VL_attention_linear_output_loss: 1.6688 - VH_attention_linear_output_loss: 1.6661 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5154 - val_loss: 3.4662 - val_VL_attention_linear_output_loss: 1.7338 - val_VH_attention_linear_output_loss: 1.7324 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 4234/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3206 - VL_attention_linear_output_loss: 1.6583 - VH_attention_linear_output_loss: 1.6623 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4581 - val_VL_attention_linear_output_loss: 1.7291 - val_VH_attention_linear_output_loss: 1.7290 - val_VL_attention_linear_output_acc: 0.5049 - val_VH_attention_linear_output_acc: 0.5048\n",
      "Epoch 4235/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3435 - VL_attention_linear_output_loss: 1.6650 - VH_attention_linear_output_loss: 1.6784 - VL_attention_linear_output_acc: 0.5091 - VH_attention_linear_output_acc: 0.5115 - val_loss: 3.4659 - val_VL_attention_linear_output_loss: 1.7378 - val_VH_attention_linear_output_loss: 1.7282 - val_VL_attention_linear_output_acc: 0.5028 - val_VH_attention_linear_output_acc: 0.5022\n",
      "Epoch 4236/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3207 - VL_attention_linear_output_loss: 1.6549 - VH_attention_linear_output_loss: 1.6659 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5159 - val_loss: 3.4678 - val_VL_attention_linear_output_loss: 1.7322 - val_VH_attention_linear_output_loss: 1.7357 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.5033\n",
      "Epoch 4237/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3128 - VL_attention_linear_output_loss: 1.6502 - VH_attention_linear_output_loss: 1.6626 - VL_attention_linear_output_acc: 0.5155 - VH_attention_linear_output_acc: 0.5171 - val_loss: 3.4876 - val_VL_attention_linear_output_loss: 1.7275 - val_VH_attention_linear_output_loss: 1.7601 - val_VL_attention_linear_output_acc: 0.4999 - val_VH_attention_linear_output_acc: 0.4867\n",
      "Epoch 4238/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3264 - VL_attention_linear_output_loss: 1.6658 - VH_attention_linear_output_loss: 1.6605 - VL_attention_linear_output_acc: 0.5090 - VH_attention_linear_output_acc: 0.5175 - val_loss: 3.4445 - val_VL_attention_linear_output_loss: 1.7266 - val_VH_attention_linear_output_loss: 1.7179 - val_VL_attention_linear_output_acc: 0.5046 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4239/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3196 - VL_attention_linear_output_loss: 1.6637 - VH_attention_linear_output_loss: 1.6559 - VL_attention_linear_output_acc: 0.5098 - VH_attention_linear_output_acc: 0.5189 - val_loss: 3.4556 - val_VL_attention_linear_output_loss: 1.7339 - val_VH_attention_linear_output_loss: 1.7217 - val_VL_attention_linear_output_acc: 0.5038 - val_VH_attention_linear_output_acc: 0.5033\n",
      "Epoch 4240/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3290 - VL_attention_linear_output_loss: 1.6653 - VH_attention_linear_output_loss: 1.6637 - VL_attention_linear_output_acc: 0.5096 - VH_attention_linear_output_acc: 0.5167 - val_loss: 3.5028 - val_VL_attention_linear_output_loss: 1.7627 - val_VH_attention_linear_output_loss: 1.7401 - val_VL_attention_linear_output_acc: 0.4772 - val_VH_attention_linear_output_acc: 0.4978\n",
      "Epoch 4241/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3253 - VL_attention_linear_output_loss: 1.6668 - VH_attention_linear_output_loss: 1.6586 - VL_attention_linear_output_acc: 0.5078 - VH_attention_linear_output_acc: 0.5188 - val_loss: 3.4440 - val_VL_attention_linear_output_loss: 1.7286 - val_VH_attention_linear_output_loss: 1.7154 - val_VL_attention_linear_output_acc: 0.5036 - val_VH_attention_linear_output_acc: 0.5080\n",
      "Epoch 4242/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3146 - VL_attention_linear_output_loss: 1.6574 - VH_attention_linear_output_loss: 1.6572 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.5271 - val_VL_attention_linear_output_loss: 1.7528 - val_VH_attention_linear_output_loss: 1.7743 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.4805\n",
      "Epoch 4243/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3215 - VL_attention_linear_output_loss: 1.6648 - VH_attention_linear_output_loss: 1.6567 - VL_attention_linear_output_acc: 0.5091 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.4623 - val_VL_attention_linear_output_loss: 1.7416 - val_VH_attention_linear_output_loss: 1.7207 - val_VL_attention_linear_output_acc: 0.4925 - val_VH_attention_linear_output_acc: 0.5051\n",
      "Epoch 4244/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3126 - VL_attention_linear_output_loss: 1.6556 - VH_attention_linear_output_loss: 1.6570 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.4538 - val_VL_attention_linear_output_loss: 1.7268 - val_VH_attention_linear_output_loss: 1.7270 - val_VL_attention_linear_output_acc: 0.5024 - val_VH_attention_linear_output_acc: 0.5018\n",
      "Epoch 4245/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3288 - VL_attention_linear_output_loss: 1.6638 - VH_attention_linear_output_loss: 1.6651 - VL_attention_linear_output_acc: 0.5091 - VH_attention_linear_output_acc: 0.5165 - val_loss: 3.4747 - val_VL_attention_linear_output_loss: 1.7418 - val_VH_attention_linear_output_loss: 1.7329 - val_VL_attention_linear_output_acc: 0.5027 - val_VH_attention_linear_output_acc: 0.4991\n",
      "Epoch 4246/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3143 - VL_attention_linear_output_loss: 1.6568 - VH_attention_linear_output_loss: 1.6574 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5189 - val_loss: 3.4514 - val_VL_attention_linear_output_loss: 1.7311 - val_VH_attention_linear_output_loss: 1.7203 - val_VL_attention_linear_output_acc: 0.5020 - val_VH_attention_linear_output_acc: 0.5062\n",
      "Epoch 4247/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3085 - VL_attention_linear_output_loss: 1.6528 - VH_attention_linear_output_loss: 1.6556 - VL_attention_linear_output_acc: 0.5132 - VH_attention_linear_output_acc: 0.5195 - val_loss: 3.4685 - val_VL_attention_linear_output_loss: 1.7310 - val_VH_attention_linear_output_loss: 1.7375 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.4980\n",
      "Epoch 4248/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3203 - VL_attention_linear_output_loss: 1.6612 - VH_attention_linear_output_loss: 1.6591 - VL_attention_linear_output_acc: 0.5099 - VH_attention_linear_output_acc: 0.5181 - val_loss: 3.4677 - val_VL_attention_linear_output_loss: 1.7311 - val_VH_attention_linear_output_loss: 1.7366 - val_VL_attention_linear_output_acc: 0.5068 - val_VH_attention_linear_output_acc: 0.5029\n",
      "Epoch 4249/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3229 - VL_attention_linear_output_loss: 1.6615 - VH_attention_linear_output_loss: 1.6614 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5176 - val_loss: 3.4663 - val_VL_attention_linear_output_loss: 1.7332 - val_VH_attention_linear_output_loss: 1.7330 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.4988\n",
      "Epoch 4250/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3156 - VL_attention_linear_output_loss: 1.6596 - VH_attention_linear_output_loss: 1.6560 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.5343 - val_VL_attention_linear_output_loss: 1.7309 - val_VH_attention_linear_output_loss: 1.8035 - val_VL_attention_linear_output_acc: 0.5057 - val_VH_attention_linear_output_acc: 0.4690\n",
      "Epoch 4251/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3189 - VL_attention_linear_output_loss: 1.6570 - VH_attention_linear_output_loss: 1.6619 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5175 - val_loss: 3.4606 - val_VL_attention_linear_output_loss: 1.7311 - val_VH_attention_linear_output_loss: 1.7294 - val_VL_attention_linear_output_acc: 0.5024 - val_VH_attention_linear_output_acc: 0.5017\n",
      "Epoch 4252/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3219 - VL_attention_linear_output_loss: 1.6694 - VH_attention_linear_output_loss: 1.6526 - VL_attention_linear_output_acc: 0.5064 - VH_attention_linear_output_acc: 0.5205 - val_loss: 3.4781 - val_VL_attention_linear_output_loss: 1.7481 - val_VH_attention_linear_output_loss: 1.7300 - val_VL_attention_linear_output_acc: 0.5027 - val_VH_attention_linear_output_acc: 0.5012\n",
      "Epoch 4253/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3269 - VL_attention_linear_output_loss: 1.6661 - VH_attention_linear_output_loss: 1.6607 - VL_attention_linear_output_acc: 0.5093 - VH_attention_linear_output_acc: 0.5176 - val_loss: 3.4509 - val_VL_attention_linear_output_loss: 1.7289 - val_VH_attention_linear_output_loss: 1.7220 - val_VL_attention_linear_output_acc: 0.4953 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 4254/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3096 - VL_attention_linear_output_loss: 1.6493 - VH_attention_linear_output_loss: 1.6603 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5184 - val_loss: 3.4606 - val_VL_attention_linear_output_loss: 1.7239 - val_VH_attention_linear_output_loss: 1.7367 - val_VL_attention_linear_output_acc: 0.4985 - val_VH_attention_linear_output_acc: 0.5012\n",
      "Epoch 4255/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3006 - VL_attention_linear_output_loss: 1.6479 - VH_attention_linear_output_loss: 1.6526 - VL_attention_linear_output_acc: 0.5156 - VH_attention_linear_output_acc: 0.5205 - val_loss: 3.4704 - val_VL_attention_linear_output_loss: 1.7289 - val_VH_attention_linear_output_loss: 1.7415 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.4963\n",
      "Epoch 4256/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3081 - VL_attention_linear_output_loss: 1.6532 - VH_attention_linear_output_loss: 1.6549 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5196 - val_loss: 3.4390 - val_VL_attention_linear_output_loss: 1.7261 - val_VH_attention_linear_output_loss: 1.7129 - val_VL_attention_linear_output_acc: 0.5040 - val_VH_attention_linear_output_acc: 0.5065\n",
      "Epoch 4257/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3109 - VL_attention_linear_output_loss: 1.6546 - VH_attention_linear_output_loss: 1.6563 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.4547 - val_VL_attention_linear_output_loss: 1.7314 - val_VH_attention_linear_output_loss: 1.7234 - val_VL_attention_linear_output_acc: 0.5040 - val_VH_attention_linear_output_acc: 0.5039\n",
      "Epoch 4258/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3104 - VL_attention_linear_output_loss: 1.6563 - VH_attention_linear_output_loss: 1.6541 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5201 - val_loss: 3.4608 - val_VL_attention_linear_output_loss: 1.7331 - val_VH_attention_linear_output_loss: 1.7277 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.4995\n",
      "Epoch 4259/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3159 - VL_attention_linear_output_loss: 1.6600 - VH_attention_linear_output_loss: 1.6558 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.4560 - val_VL_attention_linear_output_loss: 1.7366 - val_VH_attention_linear_output_loss: 1.7194 - val_VL_attention_linear_output_acc: 0.5005 - val_VH_attention_linear_output_acc: 0.5102\n",
      "Epoch 4260/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3198 - VL_attention_linear_output_loss: 1.6622 - VH_attention_linear_output_loss: 1.6576 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5189 - val_loss: 3.4552 - val_VL_attention_linear_output_loss: 1.7358 - val_VH_attention_linear_output_loss: 1.7194 - val_VL_attention_linear_output_acc: 0.5049 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4261/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3243 - VL_attention_linear_output_loss: 1.6644 - VH_attention_linear_output_loss: 1.6599 - VL_attention_linear_output_acc: 0.5082 - VH_attention_linear_output_acc: 0.5184 - val_loss: 3.4456 - val_VL_attention_linear_output_loss: 1.7293 - val_VH_attention_linear_output_loss: 1.7163 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.5061\n",
      "Epoch 4262/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3080 - VL_attention_linear_output_loss: 1.6594 - VH_attention_linear_output_loss: 1.6486 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5223 - val_loss: 3.4615 - val_VL_attention_linear_output_loss: 1.7338 - val_VH_attention_linear_output_loss: 1.7277 - val_VL_attention_linear_output_acc: 0.4974 - val_VH_attention_linear_output_acc: 0.5030\n",
      "Epoch 4263/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3359 - VL_attention_linear_output_loss: 1.6633 - VH_attention_linear_output_loss: 1.6725 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5133 - val_loss: 3.5383 - val_VL_attention_linear_output_loss: 1.7261 - val_VH_attention_linear_output_loss: 1.8122 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.4653\n",
      "Epoch 4264/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3161 - VL_attention_linear_output_loss: 1.6609 - VH_attention_linear_output_loss: 1.6552 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5195 - val_loss: 3.5087 - val_VL_attention_linear_output_loss: 1.7916 - val_VH_attention_linear_output_loss: 1.7171 - val_VL_attention_linear_output_acc: 0.4619 - val_VH_attention_linear_output_acc: 0.5085\n",
      "Epoch 4265/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3035 - VL_attention_linear_output_loss: 1.6565 - VH_attention_linear_output_loss: 1.6470 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5231 - val_loss: 3.4447 - val_VL_attention_linear_output_loss: 1.7298 - val_VH_attention_linear_output_loss: 1.7150 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4266/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2984 - VL_attention_linear_output_loss: 1.6489 - VH_attention_linear_output_loss: 1.6496 - VL_attention_linear_output_acc: 0.5146 - VH_attention_linear_output_acc: 0.5218 - val_loss: 3.4663 - val_VL_attention_linear_output_loss: 1.7322 - val_VH_attention_linear_output_loss: 1.7341 - val_VL_attention_linear_output_acc: 0.5027 - val_VH_attention_linear_output_acc: 0.4996\n",
      "Epoch 4267/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3171 - VL_attention_linear_output_loss: 1.6622 - VH_attention_linear_output_loss: 1.6549 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.4602 - val_VL_attention_linear_output_loss: 1.7307 - val_VH_attention_linear_output_loss: 1.7295 - val_VL_attention_linear_output_acc: 0.4983 - val_VH_attention_linear_output_acc: 0.5009\n",
      "Epoch 4268/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3099 - VL_attention_linear_output_loss: 1.6540 - VH_attention_linear_output_loss: 1.6559 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4652 - val_VL_attention_linear_output_loss: 1.7411 - val_VH_attention_linear_output_loss: 1.7242 - val_VL_attention_linear_output_acc: 0.4901 - val_VH_attention_linear_output_acc: 0.5042\n",
      "Epoch 4269/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3166 - VL_attention_linear_output_loss: 1.6613 - VH_attention_linear_output_loss: 1.6553 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5199 - val_loss: 3.4585 - val_VL_attention_linear_output_loss: 1.7256 - val_VH_attention_linear_output_loss: 1.7329 - val_VL_attention_linear_output_acc: 0.4989 - val_VH_attention_linear_output_acc: 0.5013\n",
      "Epoch 4270/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3160 - VL_attention_linear_output_loss: 1.6527 - VH_attention_linear_output_loss: 1.6633 - VL_attention_linear_output_acc: 0.5144 - VH_attention_linear_output_acc: 0.5171 - val_loss: 3.4518 - val_VL_attention_linear_output_loss: 1.7281 - val_VH_attention_linear_output_loss: 1.7237 - val_VL_attention_linear_output_acc: 0.4981 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 4271/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3154 - VL_attention_linear_output_loss: 1.6516 - VH_attention_linear_output_loss: 1.6638 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4963 - val_VL_attention_linear_output_loss: 1.7547 - val_VH_attention_linear_output_loss: 1.7416 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5002\n",
      "Epoch 4272/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3258 - VL_attention_linear_output_loss: 1.6635 - VH_attention_linear_output_loss: 1.6623 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5173 - val_loss: 3.4879 - val_VL_attention_linear_output_loss: 1.7599 - val_VH_attention_linear_output_loss: 1.7280 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.5048\n",
      "Epoch 4273/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3290 - VL_attention_linear_output_loss: 1.6625 - VH_attention_linear_output_loss: 1.6665 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5155 - val_loss: 3.4682 - val_VL_attention_linear_output_loss: 1.7285 - val_VH_attention_linear_output_loss: 1.7397 - val_VL_attention_linear_output_acc: 0.5049 - val_VH_attention_linear_output_acc: 0.4955\n",
      "Epoch 4274/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3390 - VL_attention_linear_output_loss: 1.6694 - VH_attention_linear_output_loss: 1.6696 - VL_attention_linear_output_acc: 0.5076 - VH_attention_linear_output_acc: 0.5142 - val_loss: 3.4657 - val_VL_attention_linear_output_loss: 1.7343 - val_VH_attention_linear_output_loss: 1.7314 - val_VL_attention_linear_output_acc: 0.4996 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 4275/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3064 - VL_attention_linear_output_loss: 1.6536 - VH_attention_linear_output_loss: 1.6528 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5212 - val_loss: 3.4448 - val_VL_attention_linear_output_loss: 1.7224 - val_VH_attention_linear_output_loss: 1.7224 - val_VL_attention_linear_output_acc: 0.4957 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 4276/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3083 - VL_attention_linear_output_loss: 1.6516 - VH_attention_linear_output_loss: 1.6567 - VL_attention_linear_output_acc: 0.5146 - VH_attention_linear_output_acc: 0.5189 - val_loss: 3.4432 - val_VL_attention_linear_output_loss: 1.7217 - val_VH_attention_linear_output_loss: 1.7215 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.5043\n",
      "Epoch 4277/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3106 - VL_attention_linear_output_loss: 1.6556 - VH_attention_linear_output_loss: 1.6549 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5199 - val_loss: 3.4490 - val_VL_attention_linear_output_loss: 1.7302 - val_VH_attention_linear_output_loss: 1.7188 - val_VL_attention_linear_output_acc: 0.4985 - val_VH_attention_linear_output_acc: 0.5058\n",
      "Epoch 4278/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3060 - VL_attention_linear_output_loss: 1.6544 - VH_attention_linear_output_loss: 1.6515 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5207 - val_loss: 3.4500 - val_VL_attention_linear_output_loss: 1.7259 - val_VH_attention_linear_output_loss: 1.7241 - val_VL_attention_linear_output_acc: 0.5051 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 4279/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3193 - VL_attention_linear_output_loss: 1.6575 - VH_attention_linear_output_loss: 1.6617 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5177 - val_loss: 3.4672 - val_VL_attention_linear_output_loss: 1.7284 - val_VH_attention_linear_output_loss: 1.7388 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.5024\n",
      "Epoch 4280/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3041 - VL_attention_linear_output_loss: 1.6498 - VH_attention_linear_output_loss: 1.6543 - VL_attention_linear_output_acc: 0.5152 - VH_attention_linear_output_acc: 0.5196 - val_loss: 3.4843 - val_VL_attention_linear_output_loss: 1.7255 - val_VH_attention_linear_output_loss: 1.7587 - val_VL_attention_linear_output_acc: 0.5064 - val_VH_attention_linear_output_acc: 0.4944\n",
      "Epoch 4281/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3120 - VL_attention_linear_output_loss: 1.6534 - VH_attention_linear_output_loss: 1.6586 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5183 - val_loss: 3.4577 - val_VL_attention_linear_output_loss: 1.7380 - val_VH_attention_linear_output_loss: 1.7197 - val_VL_attention_linear_output_acc: 0.5036 - val_VH_attention_linear_output_acc: 0.5068\n",
      "Epoch 4282/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3087 - VL_attention_linear_output_loss: 1.6599 - VH_attention_linear_output_loss: 1.6488 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5221 - val_loss: 3.4759 - val_VL_attention_linear_output_loss: 1.7314 - val_VH_attention_linear_output_loss: 1.7445 - val_VL_attention_linear_output_acc: 0.5052 - val_VH_attention_linear_output_acc: 0.4985\n",
      "Epoch 4283/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3151 - VL_attention_linear_output_loss: 1.6634 - VH_attention_linear_output_loss: 1.6517 - VL_attention_linear_output_acc: 0.5091 - VH_attention_linear_output_acc: 0.5205 - val_loss: 3.4859 - val_VL_attention_linear_output_loss: 1.7363 - val_VH_attention_linear_output_loss: 1.7497 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.4973\n",
      "Epoch 4284/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3255 - VL_attention_linear_output_loss: 1.6578 - VH_attention_linear_output_loss: 1.6677 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5152 - val_loss: 3.4636 - val_VL_attention_linear_output_loss: 1.7351 - val_VH_attention_linear_output_loss: 1.7286 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5053\n",
      "Epoch 4285/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3112 - VL_attention_linear_output_loss: 1.6547 - VH_attention_linear_output_loss: 1.6565 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5196 - val_loss: 3.4704 - val_VL_attention_linear_output_loss: 1.7475 - val_VH_attention_linear_output_loss: 1.7229 - val_VL_attention_linear_output_acc: 0.4918 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4286/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3185 - VL_attention_linear_output_loss: 1.6626 - VH_attention_linear_output_loss: 1.6559 - VL_attention_linear_output_acc: 0.5094 - VH_attention_linear_output_acc: 0.5190 - val_loss: 3.4737 - val_VL_attention_linear_output_loss: 1.7462 - val_VH_attention_linear_output_loss: 1.7275 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.5051\n",
      "Epoch 4287/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3266 - VL_attention_linear_output_loss: 1.6621 - VH_attention_linear_output_loss: 1.6645 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4526 - val_VL_attention_linear_output_loss: 1.7284 - val_VH_attention_linear_output_loss: 1.7242 - val_VL_attention_linear_output_acc: 0.5039 - val_VH_attention_linear_output_acc: 0.5055\n",
      "Epoch 4288/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3048 - VL_attention_linear_output_loss: 1.6520 - VH_attention_linear_output_loss: 1.6527 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5206 - val_loss: 3.4541 - val_VL_attention_linear_output_loss: 1.7275 - val_VH_attention_linear_output_loss: 1.7266 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.5034\n",
      "Epoch 4289/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3181 - VL_attention_linear_output_loss: 1.6641 - VH_attention_linear_output_loss: 1.6539 - VL_attention_linear_output_acc: 0.5095 - VH_attention_linear_output_acc: 0.5204 - val_loss: 3.4552 - val_VL_attention_linear_output_loss: 1.7312 - val_VH_attention_linear_output_loss: 1.7240 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5046\n",
      "Epoch 4290/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3059 - VL_attention_linear_output_loss: 1.6556 - VH_attention_linear_output_loss: 1.6503 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5211 - val_loss: 3.4964 - val_VL_attention_linear_output_loss: 1.7287 - val_VH_attention_linear_output_loss: 1.7678 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.4949\n",
      "Epoch 4291/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3218 - VL_attention_linear_output_loss: 1.6694 - VH_attention_linear_output_loss: 1.6524 - VL_attention_linear_output_acc: 0.5072 - VH_attention_linear_output_acc: 0.5210 - val_loss: 3.4806 - val_VL_attention_linear_output_loss: 1.7464 - val_VH_attention_linear_output_loss: 1.7342 - val_VL_attention_linear_output_acc: 0.4907 - val_VH_attention_linear_output_acc: 0.5042\n",
      "Epoch 4292/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3129 - VL_attention_linear_output_loss: 1.6526 - VH_attention_linear_output_loss: 1.6604 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5174 - val_loss: 3.4854 - val_VL_attention_linear_output_loss: 1.7537 - val_VH_attention_linear_output_loss: 1.7317 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.5028\n",
      "Epoch 4293/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3138 - VL_attention_linear_output_loss: 1.6606 - VH_attention_linear_output_loss: 1.6532 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5207 - val_loss: 3.4899 - val_VL_attention_linear_output_loss: 1.7467 - val_VH_attention_linear_output_loss: 1.7432 - val_VL_attention_linear_output_acc: 0.4835 - val_VH_attention_linear_output_acc: 0.4999\n",
      "Epoch 4294/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3115 - VL_attention_linear_output_loss: 1.6597 - VH_attention_linear_output_loss: 1.6519 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5212 - val_loss: 3.4507 - val_VL_attention_linear_output_loss: 1.7276 - val_VH_attention_linear_output_loss: 1.7231 - val_VL_attention_linear_output_acc: 0.5047 - val_VH_attention_linear_output_acc: 0.5070\n",
      "Epoch 4295/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3036 - VL_attention_linear_output_loss: 1.6573 - VH_attention_linear_output_loss: 1.6463 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.4463 - val_VL_attention_linear_output_loss: 1.7300 - val_VH_attention_linear_output_loss: 1.7163 - val_VL_attention_linear_output_acc: 0.4995 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 4296/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3152 - VL_attention_linear_output_loss: 1.6676 - VH_attention_linear_output_loss: 1.6477 - VL_attention_linear_output_acc: 0.5081 - VH_attention_linear_output_acc: 0.5223 - val_loss: 3.4672 - val_VL_attention_linear_output_loss: 1.7486 - val_VH_attention_linear_output_loss: 1.7187 - val_VL_attention_linear_output_acc: 0.4844 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4297/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3064 - VL_attention_linear_output_loss: 1.6511 - VH_attention_linear_output_loss: 1.6553 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5195 - val_loss: 3.4605 - val_VL_attention_linear_output_loss: 1.7276 - val_VH_attention_linear_output_loss: 1.7330 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.5014\n",
      "Epoch 4298/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3171 - VL_attention_linear_output_loss: 1.6531 - VH_attention_linear_output_loss: 1.6641 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5167 - val_loss: 3.4559 - val_VL_attention_linear_output_loss: 1.7354 - val_VH_attention_linear_output_loss: 1.7205 - val_VL_attention_linear_output_acc: 0.4946 - val_VH_attention_linear_output_acc: 0.5056\n",
      "Epoch 4299/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3198 - VL_attention_linear_output_loss: 1.6615 - VH_attention_linear_output_loss: 1.6582 - VL_attention_linear_output_acc: 0.5102 - VH_attention_linear_output_acc: 0.5179 - val_loss: 3.4576 - val_VL_attention_linear_output_loss: 1.7360 - val_VH_attention_linear_output_loss: 1.7216 - val_VL_attention_linear_output_acc: 0.4965 - val_VH_attention_linear_output_acc: 0.5048\n",
      "Epoch 4300/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3217 - VL_attention_linear_output_loss: 1.6658 - VH_attention_linear_output_loss: 1.6559 - VL_attention_linear_output_acc: 0.5086 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.4734 - val_VL_attention_linear_output_loss: 1.7286 - val_VH_attention_linear_output_loss: 1.7448 - val_VL_attention_linear_output_acc: 0.4972 - val_VH_attention_linear_output_acc: 0.5019\n",
      "Epoch 4301/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3046 - VL_attention_linear_output_loss: 1.6526 - VH_attention_linear_output_loss: 1.6521 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5209 - val_loss: 3.4640 - val_VL_attention_linear_output_loss: 1.7316 - val_VH_attention_linear_output_loss: 1.7324 - val_VL_attention_linear_output_acc: 0.5008 - val_VH_attention_linear_output_acc: 0.4989\n",
      "Epoch 4302/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3033 - VL_attention_linear_output_loss: 1.6515 - VH_attention_linear_output_loss: 1.6518 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5214 - val_loss: 3.4469 - val_VL_attention_linear_output_loss: 1.7305 - val_VH_attention_linear_output_loss: 1.7164 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.5085\n",
      "Epoch 4303/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3169 - VL_attention_linear_output_loss: 1.6574 - VH_attention_linear_output_loss: 1.6594 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5180 - val_loss: 3.4563 - val_VL_attention_linear_output_loss: 1.7350 - val_VH_attention_linear_output_loss: 1.7213 - val_VL_attention_linear_output_acc: 0.4939 - val_VH_attention_linear_output_acc: 0.5044\n",
      "Epoch 4304/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3131 - VL_attention_linear_output_loss: 1.6556 - VH_attention_linear_output_loss: 1.6575 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.4785 - val_VL_attention_linear_output_loss: 1.7262 - val_VH_attention_linear_output_loss: 1.7523 - val_VL_attention_linear_output_acc: 0.4983 - val_VH_attention_linear_output_acc: 0.4899\n",
      "Epoch 4305/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3079 - VL_attention_linear_output_loss: 1.6522 - VH_attention_linear_output_loss: 1.6556 - VL_attention_linear_output_acc: 0.5140 - VH_attention_linear_output_acc: 0.5195 - val_loss: 3.4477 - val_VL_attention_linear_output_loss: 1.7277 - val_VH_attention_linear_output_loss: 1.7200 - val_VL_attention_linear_output_acc: 0.5067 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4306/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3096 - VL_attention_linear_output_loss: 1.6614 - VH_attention_linear_output_loss: 1.6482 - VL_attention_linear_output_acc: 0.5092 - VH_attention_linear_output_acc: 0.5218 - val_loss: 3.4791 - val_VL_attention_linear_output_loss: 1.7539 - val_VH_attention_linear_output_loss: 1.7251 - val_VL_attention_linear_output_acc: 0.4876 - val_VH_attention_linear_output_acc: 0.5043\n",
      "Epoch 4307/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3200 - VL_attention_linear_output_loss: 1.6616 - VH_attention_linear_output_loss: 1.6584 - VL_attention_linear_output_acc: 0.5095 - VH_attention_linear_output_acc: 0.5188 - val_loss: 3.4700 - val_VL_attention_linear_output_loss: 1.7362 - val_VH_attention_linear_output_loss: 1.7338 - val_VL_attention_linear_output_acc: 0.4940 - val_VH_attention_linear_output_acc: 0.4997\n",
      "Epoch 4308/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2978 - VL_attention_linear_output_loss: 1.6501 - VH_attention_linear_output_loss: 1.6476 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5221 - val_loss: 3.4506 - val_VL_attention_linear_output_loss: 1.7289 - val_VH_attention_linear_output_loss: 1.7218 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4309/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3132 - VL_attention_linear_output_loss: 1.6517 - VH_attention_linear_output_loss: 1.6615 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5172 - val_loss: 3.4597 - val_VL_attention_linear_output_loss: 1.7319 - val_VH_attention_linear_output_loss: 1.7277 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5008\n",
      "Epoch 4310/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3137 - VL_attention_linear_output_loss: 1.6586 - VH_attention_linear_output_loss: 1.6552 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5198 - val_loss: 3.4511 - val_VL_attention_linear_output_loss: 1.7292 - val_VH_attention_linear_output_loss: 1.7219 - val_VL_attention_linear_output_acc: 0.5004 - val_VH_attention_linear_output_acc: 0.5038\n",
      "Epoch 4311/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3094 - VL_attention_linear_output_loss: 1.6583 - VH_attention_linear_output_loss: 1.6511 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5210 - val_loss: 3.4455 - val_VL_attention_linear_output_loss: 1.7225 - val_VH_attention_linear_output_loss: 1.7230 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.5012\n",
      "Epoch 4312/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3120 - VL_attention_linear_output_loss: 1.6558 - VH_attention_linear_output_loss: 1.6563 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5187 - val_loss: 3.4928 - val_VL_attention_linear_output_loss: 1.7301 - val_VH_attention_linear_output_loss: 1.7627 - val_VL_attention_linear_output_acc: 0.4997 - val_VH_attention_linear_output_acc: 0.4974\n",
      "Epoch 4313/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3221 - VL_attention_linear_output_loss: 1.6606 - VH_attention_linear_output_loss: 1.6615 - VL_attention_linear_output_acc: 0.5099 - VH_attention_linear_output_acc: 0.5172 - val_loss: 3.4550 - val_VL_attention_linear_output_loss: 1.7330 - val_VH_attention_linear_output_loss: 1.7221 - val_VL_attention_linear_output_acc: 0.5060 - val_VH_attention_linear_output_acc: 0.5043\n",
      "Epoch 4314/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3056 - VL_attention_linear_output_loss: 1.6518 - VH_attention_linear_output_loss: 1.6538 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5201 - val_loss: 3.5244 - val_VL_attention_linear_output_loss: 1.7579 - val_VH_attention_linear_output_loss: 1.7665 - val_VL_attention_linear_output_acc: 0.4836 - val_VH_attention_linear_output_acc: 0.4873\n",
      "Epoch 4315/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3173 - VL_attention_linear_output_loss: 1.6577 - VH_attention_linear_output_loss: 1.6596 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5181 - val_loss: 3.4479 - val_VL_attention_linear_output_loss: 1.7283 - val_VH_attention_linear_output_loss: 1.7196 - val_VL_attention_linear_output_acc: 0.5024 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4316/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2996 - VL_attention_linear_output_loss: 1.6519 - VH_attention_linear_output_loss: 1.6477 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5224 - val_loss: 3.4555 - val_VL_attention_linear_output_loss: 1.7294 - val_VH_attention_linear_output_loss: 1.7261 - val_VL_attention_linear_output_acc: 0.5024 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 4317/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3066 - VL_attention_linear_output_loss: 1.6499 - VH_attention_linear_output_loss: 1.6568 - VL_attention_linear_output_acc: 0.5151 - VH_attention_linear_output_acc: 0.5187 - val_loss: 3.4693 - val_VL_attention_linear_output_loss: 1.7384 - val_VH_attention_linear_output_loss: 1.7309 - val_VL_attention_linear_output_acc: 0.5047 - val_VH_attention_linear_output_acc: 0.5002\n",
      "Epoch 4318/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3144 - VL_attention_linear_output_loss: 1.6584 - VH_attention_linear_output_loss: 1.6560 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5195 - val_loss: 3.4639 - val_VL_attention_linear_output_loss: 1.7312 - val_VH_attention_linear_output_loss: 1.7327 - val_VL_attention_linear_output_acc: 0.4968 - val_VH_attention_linear_output_acc: 0.4975\n",
      "Epoch 4319/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3184 - VL_attention_linear_output_loss: 1.6586 - VH_attention_linear_output_loss: 1.6598 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5180 - val_loss: 3.4559 - val_VL_attention_linear_output_loss: 1.7319 - val_VH_attention_linear_output_loss: 1.7240 - val_VL_attention_linear_output_acc: 0.5001 - val_VH_attention_linear_output_acc: 0.5018\n",
      "Epoch 4320/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3255 - VL_attention_linear_output_loss: 1.6639 - VH_attention_linear_output_loss: 1.6616 - VL_attention_linear_output_acc: 0.5080 - VH_attention_linear_output_acc: 0.5170 - val_loss: 3.4814 - val_VL_attention_linear_output_loss: 1.7339 - val_VH_attention_linear_output_loss: 1.7476 - val_VL_attention_linear_output_acc: 0.5029 - val_VH_attention_linear_output_acc: 0.4956\n",
      "Epoch 4321/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3187 - VL_attention_linear_output_loss: 1.6601 - VH_attention_linear_output_loss: 1.6586 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5181 - val_loss: 3.4515 - val_VL_attention_linear_output_loss: 1.7285 - val_VH_attention_linear_output_loss: 1.7230 - val_VL_attention_linear_output_acc: 0.4972 - val_VH_attention_linear_output_acc: 0.5024\n",
      "Epoch 4322/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3161 - VL_attention_linear_output_loss: 1.6583 - VH_attention_linear_output_loss: 1.6578 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.4422 - val_VL_attention_linear_output_loss: 1.7264 - val_VH_attention_linear_output_loss: 1.7158 - val_VL_attention_linear_output_acc: 0.5022 - val_VH_attention_linear_output_acc: 0.5088\n",
      "Epoch 4323/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3145 - VL_attention_linear_output_loss: 1.6514 - VH_attention_linear_output_loss: 1.6631 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5169 - val_loss: 3.4843 - val_VL_attention_linear_output_loss: 1.7590 - val_VH_attention_linear_output_loss: 1.7253 - val_VL_attention_linear_output_acc: 0.4775 - val_VH_attention_linear_output_acc: 0.5067\n",
      "Epoch 4324/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3215 - VL_attention_linear_output_loss: 1.6617 - VH_attention_linear_output_loss: 1.6598 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5179 - val_loss: 3.4517 - val_VL_attention_linear_output_loss: 1.7297 - val_VH_attention_linear_output_loss: 1.7219 - val_VL_attention_linear_output_acc: 0.5058 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4325/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2992 - VL_attention_linear_output_loss: 1.6481 - VH_attention_linear_output_loss: 1.6511 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5205 - val_loss: 3.4561 - val_VL_attention_linear_output_loss: 1.7219 - val_VH_attention_linear_output_loss: 1.7343 - val_VL_attention_linear_output_acc: 0.4992 - val_VH_attention_linear_output_acc: 0.4970\n",
      "Epoch 4326/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3151 - VL_attention_linear_output_loss: 1.6598 - VH_attention_linear_output_loss: 1.6553 - VL_attention_linear_output_acc: 0.5099 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.4797 - val_VL_attention_linear_output_loss: 1.7476 - val_VH_attention_linear_output_loss: 1.7321 - val_VL_attention_linear_output_acc: 0.4998 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 4327/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3200 - VL_attention_linear_output_loss: 1.6583 - VH_attention_linear_output_loss: 1.6617 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5172 - val_loss: 3.4597 - val_VL_attention_linear_output_loss: 1.7277 - val_VH_attention_linear_output_loss: 1.7320 - val_VL_attention_linear_output_acc: 0.5039 - val_VH_attention_linear_output_acc: 0.5006\n",
      "Epoch 4328/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3094 - VL_attention_linear_output_loss: 1.6598 - VH_attention_linear_output_loss: 1.6496 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5218 - val_loss: 3.4392 - val_VL_attention_linear_output_loss: 1.7235 - val_VH_attention_linear_output_loss: 1.7157 - val_VL_attention_linear_output_acc: 0.5034 - val_VH_attention_linear_output_acc: 0.5088\n",
      "Epoch 4329/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3048 - VL_attention_linear_output_loss: 1.6520 - VH_attention_linear_output_loss: 1.6527 - VL_attention_linear_output_acc: 0.5132 - VH_attention_linear_output_acc: 0.5207 - val_loss: 3.4456 - val_VL_attention_linear_output_loss: 1.7216 - val_VH_attention_linear_output_loss: 1.7240 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.5056\n",
      "Epoch 4330/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3198 - VL_attention_linear_output_loss: 1.6613 - VH_attention_linear_output_loss: 1.6585 - VL_attention_linear_output_acc: 0.5086 - VH_attention_linear_output_acc: 0.5186 - val_loss: 3.4878 - val_VL_attention_linear_output_loss: 1.7278 - val_VH_attention_linear_output_loss: 1.7600 - val_VL_attention_linear_output_acc: 0.4996 - val_VH_attention_linear_output_acc: 0.4876\n",
      "Epoch 4331/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3063 - VL_attention_linear_output_loss: 1.6519 - VH_attention_linear_output_loss: 1.6544 - VL_attention_linear_output_acc: 0.5136 - VH_attention_linear_output_acc: 0.5200 - val_loss: 3.4451 - val_VL_attention_linear_output_loss: 1.7323 - val_VH_attention_linear_output_loss: 1.7129 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4332/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3072 - VL_attention_linear_output_loss: 1.6548 - VH_attention_linear_output_loss: 1.6524 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5204 - val_loss: 3.4767 - val_VL_attention_linear_output_loss: 1.7488 - val_VH_attention_linear_output_loss: 1.7279 - val_VL_attention_linear_output_acc: 0.5028 - val_VH_attention_linear_output_acc: 0.5043\n",
      "Epoch 4333/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3092 - VL_attention_linear_output_loss: 1.6575 - VH_attention_linear_output_loss: 1.6517 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5208 - val_loss: 3.4540 - val_VL_attention_linear_output_loss: 1.7335 - val_VH_attention_linear_output_loss: 1.7205 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.5055\n",
      "Epoch 4334/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3193 - VL_attention_linear_output_loss: 1.6529 - VH_attention_linear_output_loss: 1.6665 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5154 - val_loss: 3.4513 - val_VL_attention_linear_output_loss: 1.7233 - val_VH_attention_linear_output_loss: 1.7279 - val_VL_attention_linear_output_acc: 0.5058 - val_VH_attention_linear_output_acc: 0.5053\n",
      "Epoch 4335/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3102 - VL_attention_linear_output_loss: 1.6645 - VH_attention_linear_output_loss: 1.6457 - VL_attention_linear_output_acc: 0.5079 - VH_attention_linear_output_acc: 0.5235 - val_loss: 3.4701 - val_VL_attention_linear_output_loss: 1.7541 - val_VH_attention_linear_output_loss: 1.7161 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.5068\n",
      "Epoch 4336/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3123 - VL_attention_linear_output_loss: 1.6594 - VH_attention_linear_output_loss: 1.6529 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5205 - val_loss: 3.4488 - val_VL_attention_linear_output_loss: 1.7275 - val_VH_attention_linear_output_loss: 1.7213 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.5061\n",
      "Epoch 4337/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3157 - VL_attention_linear_output_loss: 1.6558 - VH_attention_linear_output_loss: 1.6600 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5181 - val_loss: 3.4776 - val_VL_attention_linear_output_loss: 1.7555 - val_VH_attention_linear_output_loss: 1.7221 - val_VL_attention_linear_output_acc: 0.4920 - val_VH_attention_linear_output_acc: 0.5069\n",
      "Epoch 4338/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3049 - VL_attention_linear_output_loss: 1.6547 - VH_attention_linear_output_loss: 1.6502 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5215 - val_loss: 3.4845 - val_VL_attention_linear_output_loss: 1.7405 - val_VH_attention_linear_output_loss: 1.7440 - val_VL_attention_linear_output_acc: 0.5067 - val_VH_attention_linear_output_acc: 0.4984\n",
      "Epoch 4339/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3191 - VL_attention_linear_output_loss: 1.6624 - VH_attention_linear_output_loss: 1.6567 - VL_attention_linear_output_acc: 0.5094 - VH_attention_linear_output_acc: 0.5192 - val_loss: 3.5059 - val_VL_attention_linear_output_loss: 1.7440 - val_VH_attention_linear_output_loss: 1.7619 - val_VL_attention_linear_output_acc: 0.4909 - val_VH_attention_linear_output_acc: 0.4857\n",
      "Epoch 4340/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3235 - VL_attention_linear_output_loss: 1.6606 - VH_attention_linear_output_loss: 1.6629 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5163 - val_loss: 3.4455 - val_VL_attention_linear_output_loss: 1.7230 - val_VH_attention_linear_output_loss: 1.7225 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.5053\n",
      "Epoch 4341/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3075 - VL_attention_linear_output_loss: 1.6606 - VH_attention_linear_output_loss: 1.6468 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4484 - val_VL_attention_linear_output_loss: 1.7264 - val_VH_attention_linear_output_loss: 1.7220 - val_VL_attention_linear_output_acc: 0.5041 - val_VH_attention_linear_output_acc: 0.5026\n",
      "Epoch 4342/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3149 - VL_attention_linear_output_loss: 1.6586 - VH_attention_linear_output_loss: 1.6563 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4616 - val_VL_attention_linear_output_loss: 1.7247 - val_VH_attention_linear_output_loss: 1.7369 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.5013\n",
      "Epoch 4343/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3033 - VL_attention_linear_output_loss: 1.6543 - VH_attention_linear_output_loss: 1.6490 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5217 - val_loss: 3.4790 - val_VL_attention_linear_output_loss: 1.7579 - val_VH_attention_linear_output_loss: 1.7211 - val_VL_attention_linear_output_acc: 0.4786 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4344/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3139 - VL_attention_linear_output_loss: 1.6641 - VH_attention_linear_output_loss: 1.6499 - VL_attention_linear_output_acc: 0.5075 - VH_attention_linear_output_acc: 0.5213 - val_loss: 3.4421 - val_VL_attention_linear_output_loss: 1.7255 - val_VH_attention_linear_output_loss: 1.7166 - val_VL_attention_linear_output_acc: 0.5000 - val_VH_attention_linear_output_acc: 0.5093\n",
      "Epoch 4345/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3129 - VL_attention_linear_output_loss: 1.6503 - VH_attention_linear_output_loss: 1.6626 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4739 - val_VL_attention_linear_output_loss: 1.7518 - val_VH_attention_linear_output_loss: 1.7221 - val_VL_attention_linear_output_acc: 0.5015 - val_VH_attention_linear_output_acc: 0.5017\n",
      "Epoch 4346/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3186 - VL_attention_linear_output_loss: 1.6575 - VH_attention_linear_output_loss: 1.6611 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5173 - val_loss: 3.4611 - val_VL_attention_linear_output_loss: 1.7458 - val_VH_attention_linear_output_loss: 1.7153 - val_VL_attention_linear_output_acc: 0.5025 - val_VH_attention_linear_output_acc: 0.5064\n",
      "Epoch 4347/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3102 - VL_attention_linear_output_loss: 1.6567 - VH_attention_linear_output_loss: 1.6536 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5203 - val_loss: 3.4840 - val_VL_attention_linear_output_loss: 1.7618 - val_VH_attention_linear_output_loss: 1.7222 - val_VL_attention_linear_output_acc: 0.5002 - val_VH_attention_linear_output_acc: 0.5060\n",
      "Epoch 4348/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3070 - VL_attention_linear_output_loss: 1.6571 - VH_attention_linear_output_loss: 1.6499 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5218 - val_loss: 3.4840 - val_VL_attention_linear_output_loss: 1.7352 - val_VH_attention_linear_output_loss: 1.7488 - val_VL_attention_linear_output_acc: 0.4974 - val_VH_attention_linear_output_acc: 0.4950\n",
      "Epoch 4349/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2992 - VL_attention_linear_output_loss: 1.6495 - VH_attention_linear_output_loss: 1.6498 - VL_attention_linear_output_acc: 0.5147 - VH_attention_linear_output_acc: 0.5215 - val_loss: 3.4928 - val_VL_attention_linear_output_loss: 1.7389 - val_VH_attention_linear_output_loss: 1.7539 - val_VL_attention_linear_output_acc: 0.4891 - val_VH_attention_linear_output_acc: 0.4908\n",
      "Epoch 4350/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3165 - VL_attention_linear_output_loss: 1.6536 - VH_attention_linear_output_loss: 1.6630 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4425 - val_VL_attention_linear_output_loss: 1.7227 - val_VH_attention_linear_output_loss: 1.7198 - val_VL_attention_linear_output_acc: 0.5066 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4351/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3008 - VL_attention_linear_output_loss: 1.6516 - VH_attention_linear_output_loss: 1.6491 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4646 - val_VL_attention_linear_output_loss: 1.7403 - val_VH_attention_linear_output_loss: 1.7243 - val_VL_attention_linear_output_acc: 0.4908 - val_VH_attention_linear_output_acc: 0.5047\n",
      "Epoch 4352/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3175 - VL_attention_linear_output_loss: 1.6667 - VH_attention_linear_output_loss: 1.6508 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5212 - val_loss: 3.4591 - val_VL_attention_linear_output_loss: 1.7388 - val_VH_attention_linear_output_loss: 1.7203 - val_VL_attention_linear_output_acc: 0.4899 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4353/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3103 - VL_attention_linear_output_loss: 1.6579 - VH_attention_linear_output_loss: 1.6524 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5203 - val_loss: 3.4628 - val_VL_attention_linear_output_loss: 1.7318 - val_VH_attention_linear_output_loss: 1.7310 - val_VL_attention_linear_output_acc: 0.4938 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 4354/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3060 - VL_attention_linear_output_loss: 1.6570 - VH_attention_linear_output_loss: 1.6490 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5217 - val_loss: 3.5033 - val_VL_attention_linear_output_loss: 1.7829 - val_VH_attention_linear_output_loss: 1.7203 - val_VL_attention_linear_output_acc: 0.4690 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4355/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3172 - VL_attention_linear_output_loss: 1.6602 - VH_attention_linear_output_loss: 1.6570 - VL_attention_linear_output_acc: 0.5094 - VH_attention_linear_output_acc: 0.5195 - val_loss: 3.4505 - val_VL_attention_linear_output_loss: 1.7263 - val_VH_attention_linear_output_loss: 1.7242 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.5047\n",
      "Epoch 4356/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3166 - VL_attention_linear_output_loss: 1.6618 - VH_attention_linear_output_loss: 1.6548 - VL_attention_linear_output_acc: 0.5090 - VH_attention_linear_output_acc: 0.5202 - val_loss: 3.4486 - val_VL_attention_linear_output_loss: 1.7313 - val_VH_attention_linear_output_loss: 1.7173 - val_VL_attention_linear_output_acc: 0.4974 - val_VH_attention_linear_output_acc: 0.5068\n",
      "Epoch 4357/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3184 - VL_attention_linear_output_loss: 1.6499 - VH_attention_linear_output_loss: 1.6685 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5150 - val_loss: 3.4625 - val_VL_attention_linear_output_loss: 1.7249 - val_VH_attention_linear_output_loss: 1.7376 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5026\n",
      "Epoch 4358/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3000 - VL_attention_linear_output_loss: 1.6510 - VH_attention_linear_output_loss: 1.6490 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4591 - val_VL_attention_linear_output_loss: 1.7374 - val_VH_attention_linear_output_loss: 1.7217 - val_VL_attention_linear_output_acc: 0.5011 - val_VH_attention_linear_output_acc: 0.5063\n",
      "Epoch 4359/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3015 - VL_attention_linear_output_loss: 1.6548 - VH_attention_linear_output_loss: 1.6468 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4491 - val_VL_attention_linear_output_loss: 1.7303 - val_VH_attention_linear_output_loss: 1.7187 - val_VL_attention_linear_output_acc: 0.5008 - val_VH_attention_linear_output_acc: 0.5053\n",
      "Epoch 4360/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3031 - VL_attention_linear_output_loss: 1.6502 - VH_attention_linear_output_loss: 1.6528 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5203 - val_loss: 3.4860 - val_VL_attention_linear_output_loss: 1.7627 - val_VH_attention_linear_output_loss: 1.7233 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.5039\n",
      "Epoch 4361/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3133 - VL_attention_linear_output_loss: 1.6566 - VH_attention_linear_output_loss: 1.6567 - VL_attention_linear_output_acc: 0.5119 - VH_attention_linear_output_acc: 0.5192 - val_loss: 3.4633 - val_VL_attention_linear_output_loss: 1.7257 - val_VH_attention_linear_output_loss: 1.7377 - val_VL_attention_linear_output_acc: 0.4999 - val_VH_attention_linear_output_acc: 0.4994\n",
      "Epoch 4362/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3140 - VL_attention_linear_output_loss: 1.6585 - VH_attention_linear_output_loss: 1.6555 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5194 - val_loss: 3.4472 - val_VL_attention_linear_output_loss: 1.7255 - val_VH_attention_linear_output_loss: 1.7217 - val_VL_attention_linear_output_acc: 0.5020 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4363/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2975 - VL_attention_linear_output_loss: 1.6497 - VH_attention_linear_output_loss: 1.6478 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5226 - val_loss: 3.4580 - val_VL_attention_linear_output_loss: 1.7368 - val_VH_attention_linear_output_loss: 1.7212 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.5065\n",
      "Epoch 4364/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3308 - VL_attention_linear_output_loss: 1.6691 - VH_attention_linear_output_loss: 1.6616 - VL_attention_linear_output_acc: 0.5066 - VH_attention_linear_output_acc: 0.5163 - val_loss: 3.4514 - val_VL_attention_linear_output_loss: 1.7321 - val_VH_attention_linear_output_loss: 1.7193 - val_VL_attention_linear_output_acc: 0.5056 - val_VH_attention_linear_output_acc: 0.5068\n",
      "Epoch 4365/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3093 - VL_attention_linear_output_loss: 1.6541 - VH_attention_linear_output_loss: 1.6552 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5189 - val_loss: 3.4517 - val_VL_attention_linear_output_loss: 1.7312 - val_VH_attention_linear_output_loss: 1.7205 - val_VL_attention_linear_output_acc: 0.5031 - val_VH_attention_linear_output_acc: 0.5078\n",
      "Epoch 4366/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2946 - VL_attention_linear_output_loss: 1.6449 - VH_attention_linear_output_loss: 1.6497 - VL_attention_linear_output_acc: 0.5158 - VH_attention_linear_output_acc: 0.5216 - val_loss: 3.4448 - val_VL_attention_linear_output_loss: 1.7301 - val_VH_attention_linear_output_loss: 1.7147 - val_VL_attention_linear_output_acc: 0.4965 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4367/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3121 - VL_attention_linear_output_loss: 1.6652 - VH_attention_linear_output_loss: 1.6468 - VL_attention_linear_output_acc: 0.5084 - VH_attention_linear_output_acc: 0.5224 - val_loss: 3.4794 - val_VL_attention_linear_output_loss: 1.7630 - val_VH_attention_linear_output_loss: 1.7163 - val_VL_attention_linear_output_acc: 0.4979 - val_VH_attention_linear_output_acc: 0.5065\n",
      "Epoch 4368/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3069 - VL_attention_linear_output_loss: 1.6518 - VH_attention_linear_output_loss: 1.6552 - VL_attention_linear_output_acc: 0.5132 - VH_attention_linear_output_acc: 0.5194 - val_loss: 3.4681 - val_VL_attention_linear_output_loss: 1.7181 - val_VH_attention_linear_output_loss: 1.7500 - val_VL_attention_linear_output_acc: 0.5055 - val_VH_attention_linear_output_acc: 0.5000\n",
      "Epoch 4369/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2881 - VL_attention_linear_output_loss: 1.6451 - VH_attention_linear_output_loss: 1.6430 - VL_attention_linear_output_acc: 0.5156 - VH_attention_linear_output_acc: 0.5238 - val_loss: 3.4391 - val_VL_attention_linear_output_loss: 1.7262 - val_VH_attention_linear_output_loss: 1.7129 - val_VL_attention_linear_output_acc: 0.5016 - val_VH_attention_linear_output_acc: 0.5060\n",
      "Epoch 4370/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2881 - VL_attention_linear_output_loss: 1.6462 - VH_attention_linear_output_loss: 1.6419 - VL_attention_linear_output_acc: 0.5147 - VH_attention_linear_output_acc: 0.5242 - val_loss: 3.4538 - val_VL_attention_linear_output_loss: 1.7276 - val_VH_attention_linear_output_loss: 1.7261 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4371/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2946 - VL_attention_linear_output_loss: 1.6520 - VH_attention_linear_output_loss: 1.6427 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4582 - val_VL_attention_linear_output_loss: 1.7387 - val_VH_attention_linear_output_loss: 1.7195 - val_VL_attention_linear_output_acc: 0.4940 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4372/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3203 - VL_attention_linear_output_loss: 1.6576 - VH_attention_linear_output_loss: 1.6627 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5169 - val_loss: 3.4636 - val_VL_attention_linear_output_loss: 1.7284 - val_VH_attention_linear_output_loss: 1.7353 - val_VL_attention_linear_output_acc: 0.5037 - val_VH_attention_linear_output_acc: 0.4983\n",
      "Epoch 4373/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3113 - VL_attention_linear_output_loss: 1.6548 - VH_attention_linear_output_loss: 1.6565 - VL_attention_linear_output_acc: 0.5120 - VH_attention_linear_output_acc: 0.5184 - val_loss: 3.4518 - val_VL_attention_linear_output_loss: 1.7382 - val_VH_attention_linear_output_loss: 1.7136 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.5098\n",
      "Epoch 4374/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3066 - VL_attention_linear_output_loss: 1.6560 - VH_attention_linear_output_loss: 1.6506 - VL_attention_linear_output_acc: 0.5109 - VH_attention_linear_output_acc: 0.5206 - val_loss: 3.4746 - val_VL_attention_linear_output_loss: 1.7343 - val_VH_attention_linear_output_loss: 1.7403 - val_VL_attention_linear_output_acc: 0.5017 - val_VH_attention_linear_output_acc: 0.5004\n",
      "Epoch 4375/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3201 - VL_attention_linear_output_loss: 1.6658 - VH_attention_linear_output_loss: 1.6543 - VL_attention_linear_output_acc: 0.5078 - VH_attention_linear_output_acc: 0.5196 - val_loss: 3.5422 - val_VL_attention_linear_output_loss: 1.8202 - val_VH_attention_linear_output_loss: 1.7220 - val_VL_attention_linear_output_acc: 0.4506 - val_VH_attention_linear_output_acc: 0.5032\n",
      "Epoch 4376/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3147 - VL_attention_linear_output_loss: 1.6600 - VH_attention_linear_output_loss: 1.6547 - VL_attention_linear_output_acc: 0.5095 - VH_attention_linear_output_acc: 0.5196 - val_loss: 3.6275 - val_VL_attention_linear_output_loss: 1.7367 - val_VH_attention_linear_output_loss: 1.8908 - val_VL_attention_linear_output_acc: 0.5039 - val_VH_attention_linear_output_acc: 0.4522\n",
      "Epoch 4377/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3150 - VL_attention_linear_output_loss: 1.6577 - VH_attention_linear_output_loss: 1.6573 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5180 - val_loss: 3.4781 - val_VL_attention_linear_output_loss: 1.7428 - val_VH_attention_linear_output_loss: 1.7353 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.5028\n",
      "Epoch 4378/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2962 - VL_attention_linear_output_loss: 1.6518 - VH_attention_linear_output_loss: 1.6444 - VL_attention_linear_output_acc: 0.5128 - VH_attention_linear_output_acc: 0.5232 - val_loss: 3.4490 - val_VL_attention_linear_output_loss: 1.7290 - val_VH_attention_linear_output_loss: 1.7201 - val_VL_attention_linear_output_acc: 0.5055 - val_VH_attention_linear_output_acc: 0.5068\n",
      "Epoch 4379/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3028 - VL_attention_linear_output_loss: 1.6569 - VH_attention_linear_output_loss: 1.6459 - VL_attention_linear_output_acc: 0.5118 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4537 - val_VL_attention_linear_output_loss: 1.7405 - val_VH_attention_linear_output_loss: 1.7132 - val_VL_attention_linear_output_acc: 0.4857 - val_VH_attention_linear_output_acc: 0.5085\n",
      "Epoch 4380/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3112 - VL_attention_linear_output_loss: 1.6586 - VH_attention_linear_output_loss: 1.6526 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5204 - val_loss: 3.4529 - val_VL_attention_linear_output_loss: 1.7314 - val_VH_attention_linear_output_loss: 1.7215 - val_VL_attention_linear_output_acc: 0.4945 - val_VH_attention_linear_output_acc: 0.5063\n",
      "Epoch 4381/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3023 - VL_attention_linear_output_loss: 1.6502 - VH_attention_linear_output_loss: 1.6521 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5208 - val_loss: 3.4865 - val_VL_attention_linear_output_loss: 1.7282 - val_VH_attention_linear_output_loss: 1.7583 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.4969\n",
      "Epoch 4382/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3013 - VL_attention_linear_output_loss: 1.6544 - VH_attention_linear_output_loss: 1.6469 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5228 - val_loss: 3.4542 - val_VL_attention_linear_output_loss: 1.7354 - val_VH_attention_linear_output_loss: 1.7188 - val_VL_attention_linear_output_acc: 0.4991 - val_VH_attention_linear_output_acc: 0.5055\n",
      "Epoch 4383/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2993 - VL_attention_linear_output_loss: 1.6530 - VH_attention_linear_output_loss: 1.6463 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4584 - val_VL_attention_linear_output_loss: 1.7422 - val_VH_attention_linear_output_loss: 1.7162 - val_VL_attention_linear_output_acc: 0.4938 - val_VH_attention_linear_output_acc: 0.5082\n",
      "Epoch 4384/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3088 - VL_attention_linear_output_loss: 1.6584 - VH_attention_linear_output_loss: 1.6503 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5221 - val_loss: 3.4964 - val_VL_attention_linear_output_loss: 1.7833 - val_VH_attention_linear_output_loss: 1.7131 - val_VL_attention_linear_output_acc: 0.4677 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4385/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3041 - VL_attention_linear_output_loss: 1.6566 - VH_attention_linear_output_loss: 1.6475 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5215 - val_loss: 3.4374 - val_VL_attention_linear_output_loss: 1.7246 - val_VH_attention_linear_output_loss: 1.7127 - val_VL_attention_linear_output_acc: 0.5044 - val_VH_attention_linear_output_acc: 0.5113\n",
      "Epoch 4386/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3171 - VL_attention_linear_output_loss: 1.6643 - VH_attention_linear_output_loss: 1.6528 - VL_attention_linear_output_acc: 0.5086 - VH_attention_linear_output_acc: 0.5201 - val_loss: 3.4622 - val_VL_attention_linear_output_loss: 1.7448 - val_VH_attention_linear_output_loss: 1.7174 - val_VL_attention_linear_output_acc: 0.4921 - val_VH_attention_linear_output_acc: 0.5067\n",
      "Epoch 4387/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3094 - VL_attention_linear_output_loss: 1.6612 - VH_attention_linear_output_loss: 1.6482 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5218 - val_loss: 3.4737 - val_VL_attention_linear_output_loss: 1.7440 - val_VH_attention_linear_output_loss: 1.7297 - val_VL_attention_linear_output_acc: 0.4949 - val_VH_attention_linear_output_acc: 0.5026\n",
      "Epoch 4388/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3149 - VL_attention_linear_output_loss: 1.6585 - VH_attention_linear_output_loss: 1.6563 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4454 - val_VL_attention_linear_output_loss: 1.7307 - val_VH_attention_linear_output_loss: 1.7147 - val_VL_attention_linear_output_acc: 0.4997 - val_VH_attention_linear_output_acc: 0.5087\n",
      "Epoch 4389/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3114 - VL_attention_linear_output_loss: 1.6558 - VH_attention_linear_output_loss: 1.6556 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.4443 - val_VL_attention_linear_output_loss: 1.7297 - val_VH_attention_linear_output_loss: 1.7146 - val_VL_attention_linear_output_acc: 0.5031 - val_VH_attention_linear_output_acc: 0.5046\n",
      "Epoch 4390/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3022 - VL_attention_linear_output_loss: 1.6553 - VH_attention_linear_output_loss: 1.6469 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5222 - val_loss: 3.4565 - val_VL_attention_linear_output_loss: 1.7367 - val_VH_attention_linear_output_loss: 1.7198 - val_VL_attention_linear_output_acc: 0.4947 - val_VH_attention_linear_output_acc: 0.5080\n",
      "Epoch 4391/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3027 - VL_attention_linear_output_loss: 1.6527 - VH_attention_linear_output_loss: 1.6501 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5214 - val_loss: 3.4563 - val_VL_attention_linear_output_loss: 1.7281 - val_VH_attention_linear_output_loss: 1.7281 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 4392/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3057 - VL_attention_linear_output_loss: 1.6574 - VH_attention_linear_output_loss: 1.6483 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5221 - val_loss: 3.4652 - val_VL_attention_linear_output_loss: 1.7429 - val_VH_attention_linear_output_loss: 1.7223 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5063\n",
      "Epoch 4393/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2998 - VL_attention_linear_output_loss: 1.6502 - VH_attention_linear_output_loss: 1.6496 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5217 - val_loss: 3.4522 - val_VL_attention_linear_output_loss: 1.7264 - val_VH_attention_linear_output_loss: 1.7258 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 4394/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3162 - VL_attention_linear_output_loss: 1.6579 - VH_attention_linear_output_loss: 1.6583 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5184 - val_loss: 3.4497 - val_VL_attention_linear_output_loss: 1.7315 - val_VH_attention_linear_output_loss: 1.7182 - val_VL_attention_linear_output_acc: 0.5045 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4395/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3108 - VL_attention_linear_output_loss: 1.6540 - VH_attention_linear_output_loss: 1.6568 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5190 - val_loss: 3.4465 - val_VL_attention_linear_output_loss: 1.7284 - val_VH_attention_linear_output_loss: 1.7182 - val_VL_attention_linear_output_acc: 0.5027 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4396/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3114 - VL_attention_linear_output_loss: 1.6607 - VH_attention_linear_output_loss: 1.6507 - VL_attention_linear_output_acc: 0.5099 - VH_attention_linear_output_acc: 0.5217 - val_loss: 3.4603 - val_VL_attention_linear_output_loss: 1.7263 - val_VH_attention_linear_output_loss: 1.7340 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.4979\n",
      "Epoch 4397/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3158 - VL_attention_linear_output_loss: 1.6658 - VH_attention_linear_output_loss: 1.6500 - VL_attention_linear_output_acc: 0.5072 - VH_attention_linear_output_acc: 0.5213 - val_loss: 3.5139 - val_VL_attention_linear_output_loss: 1.7892 - val_VH_attention_linear_output_loss: 1.7247 - val_VL_attention_linear_output_acc: 0.4869 - val_VH_attention_linear_output_acc: 0.5058\n",
      "Epoch 4398/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3082 - VL_attention_linear_output_loss: 1.6588 - VH_attention_linear_output_loss: 1.6494 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5212 - val_loss: 3.4680 - val_VL_attention_linear_output_loss: 1.7400 - val_VH_attention_linear_output_loss: 1.7280 - val_VL_attention_linear_output_acc: 0.4887 - val_VH_attention_linear_output_acc: 0.5053\n",
      "Epoch 4399/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3093 - VL_attention_linear_output_loss: 1.6572 - VH_attention_linear_output_loss: 1.6521 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5200 - val_loss: 3.4731 - val_VL_attention_linear_output_loss: 1.7317 - val_VH_attention_linear_output_loss: 1.7415 - val_VL_attention_linear_output_acc: 0.4963 - val_VH_attention_linear_output_acc: 0.4949\n",
      "Epoch 4400/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3113 - VL_attention_linear_output_loss: 1.6544 - VH_attention_linear_output_loss: 1.6569 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5187 - val_loss: 3.4738 - val_VL_attention_linear_output_loss: 1.7533 - val_VH_attention_linear_output_loss: 1.7205 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.5048\n",
      "Epoch 4401/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3142 - VL_attention_linear_output_loss: 1.6519 - VH_attention_linear_output_loss: 1.6622 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5173 - val_loss: 3.4808 - val_VL_attention_linear_output_loss: 1.7294 - val_VH_attention_linear_output_loss: 1.7514 - val_VL_attention_linear_output_acc: 0.5032 - val_VH_attention_linear_output_acc: 0.4989\n",
      "Epoch 4402/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3032 - VL_attention_linear_output_loss: 1.6511 - VH_attention_linear_output_loss: 1.6521 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5205 - val_loss: 3.4619 - val_VL_attention_linear_output_loss: 1.7430 - val_VH_attention_linear_output_loss: 1.7188 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.5018\n",
      "Epoch 4403/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3042 - VL_attention_linear_output_loss: 1.6587 - VH_attention_linear_output_loss: 1.6455 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4872 - val_VL_attention_linear_output_loss: 1.7610 - val_VH_attention_linear_output_loss: 1.7262 - val_VL_attention_linear_output_acc: 0.4970 - val_VH_attention_linear_output_acc: 0.5028\n",
      "Epoch 4404/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3082 - VL_attention_linear_output_loss: 1.6562 - VH_attention_linear_output_loss: 1.6521 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5209 - val_loss: 3.4540 - val_VL_attention_linear_output_loss: 1.7271 - val_VH_attention_linear_output_loss: 1.7270 - val_VL_attention_linear_output_acc: 0.5033 - val_VH_attention_linear_output_acc: 0.5014\n",
      "Epoch 4405/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2996 - VL_attention_linear_output_loss: 1.6483 - VH_attention_linear_output_loss: 1.6513 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5210 - val_loss: 3.4482 - val_VL_attention_linear_output_loss: 1.7332 - val_VH_attention_linear_output_loss: 1.7150 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.5089\n",
      "Epoch 4406/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3011 - VL_attention_linear_output_loss: 1.6539 - VH_attention_linear_output_loss: 1.6472 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5223 - val_loss: 3.4401 - val_VL_attention_linear_output_loss: 1.7266 - val_VH_attention_linear_output_loss: 1.7135 - val_VL_attention_linear_output_acc: 0.5041 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4407/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3089 - VL_attention_linear_output_loss: 1.6570 - VH_attention_linear_output_loss: 1.6519 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5203 - val_loss: 3.5019 - val_VL_attention_linear_output_loss: 1.7376 - val_VH_attention_linear_output_loss: 1.7643 - val_VL_attention_linear_output_acc: 0.4892 - val_VH_attention_linear_output_acc: 0.4863\n",
      "Epoch 4408/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3213 - VL_attention_linear_output_loss: 1.6528 - VH_attention_linear_output_loss: 1.6685 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5147 - val_loss: 3.4353 - val_VL_attention_linear_output_loss: 1.7242 - val_VH_attention_linear_output_loss: 1.7111 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5075\n",
      "Epoch 4409/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2919 - VL_attention_linear_output_loss: 1.6457 - VH_attention_linear_output_loss: 1.6461 - VL_attention_linear_output_acc: 0.5152 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4753 - val_VL_attention_linear_output_loss: 1.7551 - val_VH_attention_linear_output_loss: 1.7202 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.5028\n",
      "Epoch 4410/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2956 - VL_attention_linear_output_loss: 1.6502 - VH_attention_linear_output_loss: 1.6455 - VL_attention_linear_output_acc: 0.5136 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.4598 - val_VL_attention_linear_output_loss: 1.7396 - val_VH_attention_linear_output_loss: 1.7202 - val_VL_attention_linear_output_acc: 0.4928 - val_VH_attention_linear_output_acc: 0.5098\n",
      "Epoch 4411/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3049 - VL_attention_linear_output_loss: 1.6575 - VH_attention_linear_output_loss: 1.6475 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5223 - val_loss: 3.4994 - val_VL_attention_linear_output_loss: 1.7715 - val_VH_attention_linear_output_loss: 1.7279 - val_VL_attention_linear_output_acc: 0.4932 - val_VH_attention_linear_output_acc: 0.5051\n",
      "Epoch 4412/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3049 - VL_attention_linear_output_loss: 1.6526 - VH_attention_linear_output_loss: 1.6523 - VL_attention_linear_output_acc: 0.5128 - VH_attention_linear_output_acc: 0.5203 - val_loss: 3.4457 - val_VL_attention_linear_output_loss: 1.7293 - val_VH_attention_linear_output_loss: 1.7163 - val_VL_attention_linear_output_acc: 0.5005 - val_VH_attention_linear_output_acc: 0.5087\n",
      "Epoch 4413/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3133 - VL_attention_linear_output_loss: 1.6622 - VH_attention_linear_output_loss: 1.6511 - VL_attention_linear_output_acc: 0.5088 - VH_attention_linear_output_acc: 0.5207 - val_loss: 3.4632 - val_VL_attention_linear_output_loss: 1.7410 - val_VH_attention_linear_output_loss: 1.7222 - val_VL_attention_linear_output_acc: 0.4964 - val_VH_attention_linear_output_acc: 0.5078\n",
      "Epoch 4414/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3005 - VL_attention_linear_output_loss: 1.6497 - VH_attention_linear_output_loss: 1.6508 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5210 - val_loss: 3.4671 - val_VL_attention_linear_output_loss: 1.7371 - val_VH_attention_linear_output_loss: 1.7300 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.4991\n",
      "Epoch 4415/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3156 - VL_attention_linear_output_loss: 1.6582 - VH_attention_linear_output_loss: 1.6575 - VL_attention_linear_output_acc: 0.5098 - VH_attention_linear_output_acc: 0.5185 - val_loss: 3.4467 - val_VL_attention_linear_output_loss: 1.7242 - val_VH_attention_linear_output_loss: 1.7224 - val_VL_attention_linear_output_acc: 0.4981 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 4416/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3116 - VL_attention_linear_output_loss: 1.6557 - VH_attention_linear_output_loss: 1.6559 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4538 - val_VL_attention_linear_output_loss: 1.7345 - val_VH_attention_linear_output_loss: 1.7193 - val_VL_attention_linear_output_acc: 0.4895 - val_VH_attention_linear_output_acc: 0.5064\n",
      "Epoch 4417/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3061 - VL_attention_linear_output_loss: 1.6560 - VH_attention_linear_output_loss: 1.6501 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5204 - val_loss: 3.4793 - val_VL_attention_linear_output_loss: 1.7421 - val_VH_attention_linear_output_loss: 1.7372 - val_VL_attention_linear_output_acc: 0.5005 - val_VH_attention_linear_output_acc: 0.4998\n",
      "Epoch 4418/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3051 - VL_attention_linear_output_loss: 1.6533 - VH_attention_linear_output_loss: 1.6519 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5206 - val_loss: 3.4550 - val_VL_attention_linear_output_loss: 1.7275 - val_VH_attention_linear_output_loss: 1.7276 - val_VL_attention_linear_output_acc: 0.4976 - val_VH_attention_linear_output_acc: 0.5083\n",
      "Epoch 4419/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3015 - VL_attention_linear_output_loss: 1.6501 - VH_attention_linear_output_loss: 1.6513 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5215 - val_loss: 3.4369 - val_VL_attention_linear_output_loss: 1.7229 - val_VH_attention_linear_output_loss: 1.7140 - val_VL_attention_linear_output_acc: 0.5063 - val_VH_attention_linear_output_acc: 0.5073\n",
      "Epoch 4420/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3046 - VL_attention_linear_output_loss: 1.6593 - VH_attention_linear_output_loss: 1.6453 - VL_attention_linear_output_acc: 0.5096 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4655 - val_VL_attention_linear_output_loss: 1.7402 - val_VH_attention_linear_output_loss: 1.7253 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 4421/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3019 - VL_attention_linear_output_loss: 1.6486 - VH_attention_linear_output_loss: 1.6533 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.4533 - val_VL_attention_linear_output_loss: 1.7216 - val_VH_attention_linear_output_loss: 1.7317 - val_VL_attention_linear_output_acc: 0.5004 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 4422/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3057 - VL_attention_linear_output_loss: 1.6502 - VH_attention_linear_output_loss: 1.6556 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5195 - val_loss: 3.4883 - val_VL_attention_linear_output_loss: 1.7523 - val_VH_attention_linear_output_loss: 1.7360 - val_VL_attention_linear_output_acc: 0.4910 - val_VH_attention_linear_output_acc: 0.4990\n",
      "Epoch 4423/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3191 - VL_attention_linear_output_loss: 1.6644 - VH_attention_linear_output_loss: 1.6548 - VL_attention_linear_output_acc: 0.5073 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4480 - val_VL_attention_linear_output_loss: 1.7232 - val_VH_attention_linear_output_loss: 1.7248 - val_VL_attention_linear_output_acc: 0.5008 - val_VH_attention_linear_output_acc: 0.5074\n",
      "Epoch 4424/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2995 - VL_attention_linear_output_loss: 1.6518 - VH_attention_linear_output_loss: 1.6477 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4858 - val_VL_attention_linear_output_loss: 1.7330 - val_VH_attention_linear_output_loss: 1.7527 - val_VL_attention_linear_output_acc: 0.5033 - val_VH_attention_linear_output_acc: 0.4972\n",
      "Epoch 4425/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3031 - VL_attention_linear_output_loss: 1.6480 - VH_attention_linear_output_loss: 1.6551 - VL_attention_linear_output_acc: 0.5153 - VH_attention_linear_output_acc: 0.5192 - val_loss: 3.4812 - val_VL_attention_linear_output_loss: 1.7559 - val_VH_attention_linear_output_loss: 1.7253 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.5046\n",
      "Epoch 4426/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3229 - VL_attention_linear_output_loss: 1.6677 - VH_attention_linear_output_loss: 1.6552 - VL_attention_linear_output_acc: 0.5071 - VH_attention_linear_output_acc: 0.5190 - val_loss: 3.4429 - val_VL_attention_linear_output_loss: 1.7241 - val_VH_attention_linear_output_loss: 1.7187 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5083\n",
      "Epoch 4427/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3080 - VL_attention_linear_output_loss: 1.6477 - VH_attention_linear_output_loss: 1.6603 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5175 - val_loss: 3.4424 - val_VL_attention_linear_output_loss: 1.7194 - val_VH_attention_linear_output_loss: 1.7230 - val_VL_attention_linear_output_acc: 0.5086 - val_VH_attention_linear_output_acc: 0.5040\n",
      "Epoch 4428/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3022 - VL_attention_linear_output_loss: 1.6474 - VH_attention_linear_output_loss: 1.6549 - VL_attention_linear_output_acc: 0.5149 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4735 - val_VL_attention_linear_output_loss: 1.7546 - val_VH_attention_linear_output_loss: 1.7189 - val_VL_attention_linear_output_acc: 0.4909 - val_VH_attention_linear_output_acc: 0.5071\n",
      "Epoch 4429/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2921 - VL_attention_linear_output_loss: 1.6484 - VH_attention_linear_output_loss: 1.6436 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4601 - val_VL_attention_linear_output_loss: 1.7266 - val_VH_attention_linear_output_loss: 1.7335 - val_VL_attention_linear_output_acc: 0.5050 - val_VH_attention_linear_output_acc: 0.5019\n",
      "Epoch 4430/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3019 - VL_attention_linear_output_loss: 1.6569 - VH_attention_linear_output_loss: 1.6450 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4817 - val_VL_attention_linear_output_loss: 1.7555 - val_VH_attention_linear_output_loss: 1.7261 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4431/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3133 - VL_attention_linear_output_loss: 1.6499 - VH_attention_linear_output_loss: 1.6634 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5162 - val_loss: 3.4420 - val_VL_attention_linear_output_loss: 1.7226 - val_VH_attention_linear_output_loss: 1.7194 - val_VL_attention_linear_output_acc: 0.5037 - val_VH_attention_linear_output_acc: 0.5042\n",
      "Epoch 4432/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3012 - VL_attention_linear_output_loss: 1.6548 - VH_attention_linear_output_loss: 1.6464 - VL_attention_linear_output_acc: 0.5118 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4527 - val_VL_attention_linear_output_loss: 1.7348 - val_VH_attention_linear_output_loss: 1.7179 - val_VL_attention_linear_output_acc: 0.4942 - val_VH_attention_linear_output_acc: 0.5064\n",
      "Epoch 4433/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2945 - VL_attention_linear_output_loss: 1.6475 - VH_attention_linear_output_loss: 1.6469 - VL_attention_linear_output_acc: 0.5149 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4773 - val_VL_attention_linear_output_loss: 1.7276 - val_VH_attention_linear_output_loss: 1.7497 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.4926\n",
      "Epoch 4434/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3132 - VL_attention_linear_output_loss: 1.6485 - VH_attention_linear_output_loss: 1.6646 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5155 - val_loss: 3.4472 - val_VL_attention_linear_output_loss: 1.7278 - val_VH_attention_linear_output_loss: 1.7194 - val_VL_attention_linear_output_acc: 0.5017 - val_VH_attention_linear_output_acc: 0.5064\n",
      "Epoch 4435/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2980 - VL_attention_linear_output_loss: 1.6522 - VH_attention_linear_output_loss: 1.6458 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4476 - val_VL_attention_linear_output_loss: 1.7310 - val_VH_attention_linear_output_loss: 1.7166 - val_VL_attention_linear_output_acc: 0.4902 - val_VH_attention_linear_output_acc: 0.5037\n",
      "Epoch 4436/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3112 - VL_attention_linear_output_loss: 1.6608 - VH_attention_linear_output_loss: 1.6504 - VL_attention_linear_output_acc: 0.5095 - VH_attention_linear_output_acc: 0.5208 - val_loss: 3.4576 - val_VL_attention_linear_output_loss: 1.7426 - val_VH_attention_linear_output_loss: 1.7150 - val_VL_attention_linear_output_acc: 0.4883 - val_VH_attention_linear_output_acc: 0.5068\n",
      "Epoch 4437/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3210 - VL_attention_linear_output_loss: 1.6640 - VH_attention_linear_output_loss: 1.6570 - VL_attention_linear_output_acc: 0.5078 - VH_attention_linear_output_acc: 0.5186 - val_loss: 3.4474 - val_VL_attention_linear_output_loss: 1.7314 - val_VH_attention_linear_output_loss: 1.7160 - val_VL_attention_linear_output_acc: 0.5041 - val_VH_attention_linear_output_acc: 0.5088\n",
      "Epoch 4438/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2917 - VL_attention_linear_output_loss: 1.6442 - VH_attention_linear_output_loss: 1.6475 - VL_attention_linear_output_acc: 0.5156 - VH_attention_linear_output_acc: 0.5221 - val_loss: 3.4343 - val_VL_attention_linear_output_loss: 1.7237 - val_VH_attention_linear_output_loss: 1.7106 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.5115\n",
      "Epoch 4439/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3104 - VL_attention_linear_output_loss: 1.6628 - VH_attention_linear_output_loss: 1.6476 - VL_attention_linear_output_acc: 0.5082 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4578 - val_VL_attention_linear_output_loss: 1.7366 - val_VH_attention_linear_output_loss: 1.7212 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.5077\n",
      "Epoch 4440/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3168 - VL_attention_linear_output_loss: 1.6573 - VH_attention_linear_output_loss: 1.6595 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5175 - val_loss: 3.4449 - val_VL_attention_linear_output_loss: 1.7261 - val_VH_attention_linear_output_loss: 1.7188 - val_VL_attention_linear_output_acc: 0.5015 - val_VH_attention_linear_output_acc: 0.5098\n",
      "Epoch 4441/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3080 - VL_attention_linear_output_loss: 1.6471 - VH_attention_linear_output_loss: 1.6610 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5172 - val_loss: 3.4478 - val_VL_attention_linear_output_loss: 1.7305 - val_VH_attention_linear_output_loss: 1.7172 - val_VL_attention_linear_output_acc: 0.5034 - val_VH_attention_linear_output_acc: 0.5097\n",
      "Epoch 4442/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2925 - VL_attention_linear_output_loss: 1.6486 - VH_attention_linear_output_loss: 1.6439 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5235 - val_loss: 3.4643 - val_VL_attention_linear_output_loss: 1.7203 - val_VH_attention_linear_output_loss: 1.7440 - val_VL_attention_linear_output_acc: 0.4965 - val_VH_attention_linear_output_acc: 0.5023\n",
      "Epoch 4443/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3011 - VL_attention_linear_output_loss: 1.6453 - VH_attention_linear_output_loss: 1.6558 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5192 - val_loss: 3.4824 - val_VL_attention_linear_output_loss: 1.7262 - val_VH_attention_linear_output_loss: 1.7561 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.4931\n",
      "Epoch 4444/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3119 - VL_attention_linear_output_loss: 1.6501 - VH_attention_linear_output_loss: 1.6618 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5168 - val_loss: 3.4593 - val_VL_attention_linear_output_loss: 1.7247 - val_VH_attention_linear_output_loss: 1.7346 - val_VL_attention_linear_output_acc: 0.5030 - val_VH_attention_linear_output_acc: 0.5028\n",
      "Epoch 4445/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2990 - VL_attention_linear_output_loss: 1.6551 - VH_attention_linear_output_loss: 1.6439 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5237 - val_loss: 3.4469 - val_VL_attention_linear_output_loss: 1.7285 - val_VH_attention_linear_output_loss: 1.7184 - val_VL_attention_linear_output_acc: 0.4961 - val_VH_attention_linear_output_acc: 0.5072\n",
      "Epoch 4446/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2953 - VL_attention_linear_output_loss: 1.6507 - VH_attention_linear_output_loss: 1.6446 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5229 - val_loss: 3.4482 - val_VL_attention_linear_output_loss: 1.7263 - val_VH_attention_linear_output_loss: 1.7219 - val_VL_attention_linear_output_acc: 0.5025 - val_VH_attention_linear_output_acc: 0.5075\n",
      "Epoch 4447/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3200 - VL_attention_linear_output_loss: 1.6600 - VH_attention_linear_output_loss: 1.6600 - VL_attention_linear_output_acc: 0.5091 - VH_attention_linear_output_acc: 0.5174 - val_loss: 3.4697 - val_VL_attention_linear_output_loss: 1.7260 - val_VH_attention_linear_output_loss: 1.7437 - val_VL_attention_linear_output_acc: 0.5047 - val_VH_attention_linear_output_acc: 0.4943\n",
      "Epoch 4448/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3055 - VL_attention_linear_output_loss: 1.6522 - VH_attention_linear_output_loss: 1.6533 - VL_attention_linear_output_acc: 0.5119 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.4440 - val_VL_attention_linear_output_loss: 1.7271 - val_VH_attention_linear_output_loss: 1.7169 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.5097\n",
      "Epoch 4449/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3046 - VL_attention_linear_output_loss: 1.6518 - VH_attention_linear_output_loss: 1.6529 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5199 - val_loss: 3.4571 - val_VL_attention_linear_output_loss: 1.7360 - val_VH_attention_linear_output_loss: 1.7211 - val_VL_attention_linear_output_acc: 0.4960 - val_VH_attention_linear_output_acc: 0.5044\n",
      "Epoch 4450/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3166 - VL_attention_linear_output_loss: 1.6628 - VH_attention_linear_output_loss: 1.6538 - VL_attention_linear_output_acc: 0.5085 - VH_attention_linear_output_acc: 0.5195 - val_loss: 3.4699 - val_VL_attention_linear_output_loss: 1.7216 - val_VH_attention_linear_output_loss: 1.7482 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.4973\n",
      "Epoch 4451/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3146 - VL_attention_linear_output_loss: 1.6554 - VH_attention_linear_output_loss: 1.6592 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5177 - val_loss: 3.4755 - val_VL_attention_linear_output_loss: 1.7306 - val_VH_attention_linear_output_loss: 1.7449 - val_VL_attention_linear_output_acc: 0.5041 - val_VH_attention_linear_output_acc: 0.4991\n",
      "Epoch 4452/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3064 - VL_attention_linear_output_loss: 1.6519 - VH_attention_linear_output_loss: 1.6545 - VL_attention_linear_output_acc: 0.5120 - VH_attention_linear_output_acc: 0.5195 - val_loss: 3.4368 - val_VL_attention_linear_output_loss: 1.7204 - val_VH_attention_linear_output_loss: 1.7163 - val_VL_attention_linear_output_acc: 0.5056 - val_VH_attention_linear_output_acc: 0.5063\n",
      "Epoch 4453/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2866 - VL_attention_linear_output_loss: 1.6441 - VH_attention_linear_output_loss: 1.6425 - VL_attention_linear_output_acc: 0.5152 - VH_attention_linear_output_acc: 0.5238 - val_loss: 3.4465 - val_VL_attention_linear_output_loss: 1.7191 - val_VH_attention_linear_output_loss: 1.7274 - val_VL_attention_linear_output_acc: 0.5024 - val_VH_attention_linear_output_acc: 0.5064\n",
      "Epoch 4454/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2979 - VL_attention_linear_output_loss: 1.6472 - VH_attention_linear_output_loss: 1.6507 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5212 - val_loss: 3.4595 - val_VL_attention_linear_output_loss: 1.7271 - val_VH_attention_linear_output_loss: 1.7324 - val_VL_attention_linear_output_acc: 0.5001 - val_VH_attention_linear_output_acc: 0.5005\n",
      "Epoch 4455/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3072 - VL_attention_linear_output_loss: 1.6587 - VH_attention_linear_output_loss: 1.6486 - VL_attention_linear_output_acc: 0.5096 - VH_attention_linear_output_acc: 0.5216 - val_loss: 3.4378 - val_VL_attention_linear_output_loss: 1.7231 - val_VH_attention_linear_output_loss: 1.7148 - val_VL_attention_linear_output_acc: 0.5036 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4456/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2994 - VL_attention_linear_output_loss: 1.6490 - VH_attention_linear_output_loss: 1.6504 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5207 - val_loss: 3.4766 - val_VL_attention_linear_output_loss: 1.7204 - val_VH_attention_linear_output_loss: 1.7562 - val_VL_attention_linear_output_acc: 0.4995 - val_VH_attention_linear_output_acc: 0.4876\n",
      "Epoch 4457/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3071 - VL_attention_linear_output_loss: 1.6526 - VH_attention_linear_output_loss: 1.6544 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5200 - val_loss: 3.4406 - val_VL_attention_linear_output_loss: 1.7255 - val_VH_attention_linear_output_loss: 1.7150 - val_VL_attention_linear_output_acc: 0.4930 - val_VH_attention_linear_output_acc: 0.5031\n",
      "Epoch 4458/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3043 - VL_attention_linear_output_loss: 1.6502 - VH_attention_linear_output_loss: 1.6541 - VL_attention_linear_output_acc: 0.5119 - VH_attention_linear_output_acc: 0.5200 - val_loss: 3.4606 - val_VL_attention_linear_output_loss: 1.7236 - val_VH_attention_linear_output_loss: 1.7370 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5011\n",
      "Epoch 4459/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3119 - VL_attention_linear_output_loss: 1.6447 - VH_attention_linear_output_loss: 1.6673 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5143 - val_loss: 3.4795 - val_VL_attention_linear_output_loss: 1.7623 - val_VH_attention_linear_output_loss: 1.7173 - val_VL_attention_linear_output_acc: 0.4926 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4460/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2893 - VL_attention_linear_output_loss: 1.6506 - VH_attention_linear_output_loss: 1.6387 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5251 - val_loss: 3.4340 - val_VL_attention_linear_output_loss: 1.7208 - val_VH_attention_linear_output_loss: 1.7132 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.5069\n",
      "Epoch 4461/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3126 - VL_attention_linear_output_loss: 1.6580 - VH_attention_linear_output_loss: 1.6545 - VL_attention_linear_output_acc: 0.5091 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4472 - val_VL_attention_linear_output_loss: 1.7213 - val_VH_attention_linear_output_loss: 1.7259 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5085\n",
      "Epoch 4462/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3081 - VL_attention_linear_output_loss: 1.6514 - VH_attention_linear_output_loss: 1.6567 - VL_attention_linear_output_acc: 0.5118 - VH_attention_linear_output_acc: 0.5194 - val_loss: 3.4617 - val_VL_attention_linear_output_loss: 1.7416 - val_VH_attention_linear_output_loss: 1.7200 - val_VL_attention_linear_output_acc: 0.4949 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4463/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2952 - VL_attention_linear_output_loss: 1.6449 - VH_attention_linear_output_loss: 1.6503 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5212 - val_loss: 3.4468 - val_VL_attention_linear_output_loss: 1.7306 - val_VH_attention_linear_output_loss: 1.7162 - val_VL_attention_linear_output_acc: 0.4958 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4464/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2982 - VL_attention_linear_output_loss: 1.6534 - VH_attention_linear_output_loss: 1.6449 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5232 - val_loss: 3.4449 - val_VL_attention_linear_output_loss: 1.7237 - val_VH_attention_linear_output_loss: 1.7212 - val_VL_attention_linear_output_acc: 0.5019 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4465/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2955 - VL_attention_linear_output_loss: 1.6495 - VH_attention_linear_output_loss: 1.6460 - VL_attention_linear_output_acc: 0.5132 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4398 - val_VL_attention_linear_output_loss: 1.7236 - val_VH_attention_linear_output_loss: 1.7162 - val_VL_attention_linear_output_acc: 0.5036 - val_VH_attention_linear_output_acc: 0.5089\n",
      "Epoch 4466/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3243 - VL_attention_linear_output_loss: 1.6647 - VH_attention_linear_output_loss: 1.6596 - VL_attention_linear_output_acc: 0.5084 - VH_attention_linear_output_acc: 0.5175 - val_loss: 3.4358 - val_VL_attention_linear_output_loss: 1.7235 - val_VH_attention_linear_output_loss: 1.7123 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4467/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2953 - VL_attention_linear_output_loss: 1.6453 - VH_attention_linear_output_loss: 1.6500 - VL_attention_linear_output_acc: 0.5136 - VH_attention_linear_output_acc: 0.5203 - val_loss: 3.4397 - val_VL_attention_linear_output_loss: 1.7278 - val_VH_attention_linear_output_loss: 1.7119 - val_VL_attention_linear_output_acc: 0.5012 - val_VH_attention_linear_output_acc: 0.5077\n",
      "Epoch 4468/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3102 - VL_attention_linear_output_loss: 1.6530 - VH_attention_linear_output_loss: 1.6572 - VL_attention_linear_output_acc: 0.5120 - VH_attention_linear_output_acc: 0.5184 - val_loss: 3.4423 - val_VL_attention_linear_output_loss: 1.7349 - val_VH_attention_linear_output_loss: 1.7074 - val_VL_attention_linear_output_acc: 0.4953 - val_VH_attention_linear_output_acc: 0.5101\n",
      "Epoch 4469/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2866 - VL_attention_linear_output_loss: 1.6419 - VH_attention_linear_output_loss: 1.6448 - VL_attention_linear_output_acc: 0.5157 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4522 - val_VL_attention_linear_output_loss: 1.7321 - val_VH_attention_linear_output_loss: 1.7202 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.5056\n",
      "Epoch 4470/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3058 - VL_attention_linear_output_loss: 1.6580 - VH_attention_linear_output_loss: 1.6478 - VL_attention_linear_output_acc: 0.5092 - VH_attention_linear_output_acc: 0.5213 - val_loss: 3.4696 - val_VL_attention_linear_output_loss: 1.7252 - val_VH_attention_linear_output_loss: 1.7444 - val_VL_attention_linear_output_acc: 0.4965 - val_VH_attention_linear_output_acc: 0.4934\n",
      "Epoch 4471/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3035 - VL_attention_linear_output_loss: 1.6461 - VH_attention_linear_output_loss: 1.6574 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5188 - val_loss: 3.4578 - val_VL_attention_linear_output_loss: 1.7413 - val_VH_attention_linear_output_loss: 1.7165 - val_VL_attention_linear_output_acc: 0.4873 - val_VH_attention_linear_output_acc: 0.5056\n",
      "Epoch 4472/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2991 - VL_attention_linear_output_loss: 1.6469 - VH_attention_linear_output_loss: 1.6522 - VL_attention_linear_output_acc: 0.5136 - VH_attention_linear_output_acc: 0.5200 - val_loss: 3.4752 - val_VL_attention_linear_output_loss: 1.7340 - val_VH_attention_linear_output_loss: 1.7412 - val_VL_attention_linear_output_acc: 0.4922 - val_VH_attention_linear_output_acc: 0.4961\n",
      "Epoch 4473/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3098 - VL_attention_linear_output_loss: 1.6614 - VH_attention_linear_output_loss: 1.6485 - VL_attention_linear_output_acc: 0.5089 - VH_attention_linear_output_acc: 0.5217 - val_loss: 3.4743 - val_VL_attention_linear_output_loss: 1.7283 - val_VH_attention_linear_output_loss: 1.7459 - val_VL_attention_linear_output_acc: 0.4972 - val_VH_attention_linear_output_acc: 0.4985\n",
      "Epoch 4474/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3061 - VL_attention_linear_output_loss: 1.6497 - VH_attention_linear_output_loss: 1.6564 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5184 - val_loss: 3.4553 - val_VL_attention_linear_output_loss: 1.7381 - val_VH_attention_linear_output_loss: 1.7173 - val_VL_attention_linear_output_acc: 0.4964 - val_VH_attention_linear_output_acc: 0.5051\n",
      "Epoch 4475/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3031 - VL_attention_linear_output_loss: 1.6508 - VH_attention_linear_output_loss: 1.6522 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5203 - val_loss: 3.4406 - val_VL_attention_linear_output_loss: 1.7224 - val_VH_attention_linear_output_loss: 1.7182 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.5060\n",
      "Epoch 4476/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3013 - VL_attention_linear_output_loss: 1.6506 - VH_attention_linear_output_loss: 1.6507 - VL_attention_linear_output_acc: 0.5119 - VH_attention_linear_output_acc: 0.5210 - val_loss: 3.4889 - val_VL_attention_linear_output_loss: 1.7527 - val_VH_attention_linear_output_loss: 1.7362 - val_VL_attention_linear_output_acc: 0.4828 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4477/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3061 - VL_attention_linear_output_loss: 1.6475 - VH_attention_linear_output_loss: 1.6586 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5183 - val_loss: 3.4511 - val_VL_attention_linear_output_loss: 1.7213 - val_VH_attention_linear_output_loss: 1.7298 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.4999\n",
      "Epoch 4478/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3094 - VL_attention_linear_output_loss: 1.6500 - VH_attention_linear_output_loss: 1.6595 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5175 - val_loss: 3.4545 - val_VL_attention_linear_output_loss: 1.7356 - val_VH_attention_linear_output_loss: 1.7189 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.5086\n",
      "Epoch 4479/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2939 - VL_attention_linear_output_loss: 1.6472 - VH_attention_linear_output_loss: 1.6466 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5228 - val_loss: 3.4452 - val_VL_attention_linear_output_loss: 1.7221 - val_VH_attention_linear_output_loss: 1.7230 - val_VL_attention_linear_output_acc: 0.5025 - val_VH_attention_linear_output_acc: 0.5018\n",
      "Epoch 4480/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3064 - VL_attention_linear_output_loss: 1.6569 - VH_attention_linear_output_loss: 1.6495 - VL_attention_linear_output_acc: 0.5093 - VH_attention_linear_output_acc: 0.5213 - val_loss: 3.4464 - val_VL_attention_linear_output_loss: 1.7249 - val_VH_attention_linear_output_loss: 1.7215 - val_VL_attention_linear_output_acc: 0.5016 - val_VH_attention_linear_output_acc: 0.5046\n",
      "Epoch 4481/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3062 - VL_attention_linear_output_loss: 1.6497 - VH_attention_linear_output_loss: 1.6565 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5185 - val_loss: 3.4500 - val_VL_attention_linear_output_loss: 1.7234 - val_VH_attention_linear_output_loss: 1.7266 - val_VL_attention_linear_output_acc: 0.5029 - val_VH_attention_linear_output_acc: 0.5065\n",
      "Epoch 4482/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3071 - VL_attention_linear_output_loss: 1.6524 - VH_attention_linear_output_loss: 1.6546 - VL_attention_linear_output_acc: 0.5118 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.4337 - val_VL_attention_linear_output_loss: 1.7217 - val_VH_attention_linear_output_loss: 1.7120 - val_VL_attention_linear_output_acc: 0.5061 - val_VH_attention_linear_output_acc: 0.5091\n",
      "Epoch 4483/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2906 - VL_attention_linear_output_loss: 1.6434 - VH_attention_linear_output_loss: 1.6472 - VL_attention_linear_output_acc: 0.5150 - VH_attention_linear_output_acc: 0.5222 - val_loss: 3.4535 - val_VL_attention_linear_output_loss: 1.7323 - val_VH_attention_linear_output_loss: 1.7212 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4484/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2933 - VL_attention_linear_output_loss: 1.6452 - VH_attention_linear_output_loss: 1.6481 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4584 - val_VL_attention_linear_output_loss: 1.7358 - val_VH_attention_linear_output_loss: 1.7226 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4485/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3057 - VL_attention_linear_output_loss: 1.6571 - VH_attention_linear_output_loss: 1.6486 - VL_attention_linear_output_acc: 0.5086 - VH_attention_linear_output_acc: 0.5216 - val_loss: 3.4503 - val_VL_attention_linear_output_loss: 1.7278 - val_VH_attention_linear_output_loss: 1.7224 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.5061\n",
      "Epoch 4486/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3016 - VL_attention_linear_output_loss: 1.6472 - VH_attention_linear_output_loss: 1.6544 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5196 - val_loss: 3.4427 - val_VL_attention_linear_output_loss: 1.7262 - val_VH_attention_linear_output_loss: 1.7165 - val_VL_attention_linear_output_acc: 0.4945 - val_VH_attention_linear_output_acc: 0.5083\n",
      "Epoch 4487/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2871 - VL_attention_linear_output_loss: 1.6472 - VH_attention_linear_output_loss: 1.6398 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5244 - val_loss: 3.4474 - val_VL_attention_linear_output_loss: 1.7237 - val_VH_attention_linear_output_loss: 1.7237 - val_VL_attention_linear_output_acc: 0.5006 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4488/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2870 - VL_attention_linear_output_loss: 1.6429 - VH_attention_linear_output_loss: 1.6441 - VL_attention_linear_output_acc: 0.5150 - VH_attention_linear_output_acc: 0.5231 - val_loss: 3.4517 - val_VL_attention_linear_output_loss: 1.7246 - val_VH_attention_linear_output_loss: 1.7271 - val_VL_attention_linear_output_acc: 0.4996 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4489/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3032 - VL_attention_linear_output_loss: 1.6558 - VH_attention_linear_output_loss: 1.6474 - VL_attention_linear_output_acc: 0.5095 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4550 - val_VL_attention_linear_output_loss: 1.7297 - val_VH_attention_linear_output_loss: 1.7253 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.5077\n",
      "Epoch 4490/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2845 - VL_attention_linear_output_loss: 1.6418 - VH_attention_linear_output_loss: 1.6427 - VL_attention_linear_output_acc: 0.5156 - VH_attention_linear_output_acc: 0.5238 - val_loss: 3.4528 - val_VL_attention_linear_output_loss: 1.7169 - val_VH_attention_linear_output_loss: 1.7359 - val_VL_attention_linear_output_acc: 0.5026 - val_VH_attention_linear_output_acc: 0.5021\n",
      "Epoch 4491/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2946 - VL_attention_linear_output_loss: 1.6456 - VH_attention_linear_output_loss: 1.6491 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5216 - val_loss: 3.4812 - val_VL_attention_linear_output_loss: 1.7632 - val_VH_attention_linear_output_loss: 1.7180 - val_VL_attention_linear_output_acc: 0.4784 - val_VH_attention_linear_output_acc: 0.5044\n",
      "Epoch 4492/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3082 - VL_attention_linear_output_loss: 1.6502 - VH_attention_linear_output_loss: 1.6580 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5178 - val_loss: 3.4884 - val_VL_attention_linear_output_loss: 1.7231 - val_VH_attention_linear_output_loss: 1.7653 - val_VL_attention_linear_output_acc: 0.5016 - val_VH_attention_linear_output_acc: 0.4934\n",
      "Epoch 4493/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2948 - VL_attention_linear_output_loss: 1.6487 - VH_attention_linear_output_loss: 1.6461 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5231 - val_loss: 3.4462 - val_VL_attention_linear_output_loss: 1.7374 - val_VH_attention_linear_output_loss: 1.7087 - val_VL_attention_linear_output_acc: 0.5044 - val_VH_attention_linear_output_acc: 0.5097\n",
      "Epoch 4494/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2978 - VL_attention_linear_output_loss: 1.6525 - VH_attention_linear_output_loss: 1.6453 - VL_attention_linear_output_acc: 0.5109 - VH_attention_linear_output_acc: 0.5222 - val_loss: 3.4540 - val_VL_attention_linear_output_loss: 1.7348 - val_VH_attention_linear_output_loss: 1.7192 - val_VL_attention_linear_output_acc: 0.4928 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4495/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3131 - VL_attention_linear_output_loss: 1.6537 - VH_attention_linear_output_loss: 1.6595 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5178 - val_loss: 3.4537 - val_VL_attention_linear_output_loss: 1.7351 - val_VH_attention_linear_output_loss: 1.7186 - val_VL_attention_linear_output_acc: 0.4940 - val_VH_attention_linear_output_acc: 0.5053\n",
      "Epoch 4496/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3072 - VL_attention_linear_output_loss: 1.6587 - VH_attention_linear_output_loss: 1.6485 - VL_attention_linear_output_acc: 0.5086 - VH_attention_linear_output_acc: 0.5214 - val_loss: 3.4751 - val_VL_attention_linear_output_loss: 1.7295 - val_VH_attention_linear_output_loss: 1.7456 - val_VL_attention_linear_output_acc: 0.5040 - val_VH_attention_linear_output_acc: 0.4946\n",
      "Epoch 4497/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3023 - VL_attention_linear_output_loss: 1.6481 - VH_attention_linear_output_loss: 1.6542 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5199 - val_loss: 3.4436 - val_VL_attention_linear_output_loss: 1.7259 - val_VH_attention_linear_output_loss: 1.7177 - val_VL_attention_linear_output_acc: 0.5044 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4498/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3137 - VL_attention_linear_output_loss: 1.6597 - VH_attention_linear_output_loss: 1.6540 - VL_attention_linear_output_acc: 0.5085 - VH_attention_linear_output_acc: 0.5204 - val_loss: 3.4349 - val_VL_attention_linear_output_loss: 1.7243 - val_VH_attention_linear_output_loss: 1.7106 - val_VL_attention_linear_output_acc: 0.4992 - val_VH_attention_linear_output_acc: 0.5085\n",
      "Epoch 4499/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2912 - VL_attention_linear_output_loss: 1.6462 - VH_attention_linear_output_loss: 1.6450 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4633 - val_VL_attention_linear_output_loss: 1.7271 - val_VH_attention_linear_output_loss: 1.7362 - val_VL_attention_linear_output_acc: 0.5004 - val_VH_attention_linear_output_acc: 0.4979\n",
      "Epoch 4500/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3085 - VL_attention_linear_output_loss: 1.6551 - VH_attention_linear_output_loss: 1.6535 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5203 - val_loss: 3.4690 - val_VL_attention_linear_output_loss: 1.7496 - val_VH_attention_linear_output_loss: 1.7194 - val_VL_attention_linear_output_acc: 0.4882 - val_VH_attention_linear_output_acc: 0.5100\n",
      "Epoch 4501/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3079 - VL_attention_linear_output_loss: 1.6533 - VH_attention_linear_output_loss: 1.6545 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5188 - val_loss: 3.4670 - val_VL_attention_linear_output_loss: 1.7504 - val_VH_attention_linear_output_loss: 1.7166 - val_VL_attention_linear_output_acc: 0.4938 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4502/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2963 - VL_attention_linear_output_loss: 1.6472 - VH_attention_linear_output_loss: 1.6490 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5213 - val_loss: 3.5047 - val_VL_attention_linear_output_loss: 1.7599 - val_VH_attention_linear_output_loss: 1.7448 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.4957\n",
      "Epoch 4503/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3134 - VL_attention_linear_output_loss: 1.6573 - VH_attention_linear_output_loss: 1.6560 - VL_attention_linear_output_acc: 0.5096 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.4363 - val_VL_attention_linear_output_loss: 1.7212 - val_VH_attention_linear_output_loss: 1.7151 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4504/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2926 - VL_attention_linear_output_loss: 1.6460 - VH_attention_linear_output_loss: 1.6465 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4415 - val_VL_attention_linear_output_loss: 1.7262 - val_VH_attention_linear_output_loss: 1.7154 - val_VL_attention_linear_output_acc: 0.4988 - val_VH_attention_linear_output_acc: 0.5070\n",
      "Epoch 4505/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2957 - VL_attention_linear_output_loss: 1.6537 - VH_attention_linear_output_loss: 1.6420 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5244 - val_loss: 3.4419 - val_VL_attention_linear_output_loss: 1.7209 - val_VH_attention_linear_output_loss: 1.7210 - val_VL_attention_linear_output_acc: 0.5019 - val_VH_attention_linear_output_acc: 0.5055\n",
      "Epoch 4506/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2897 - VL_attention_linear_output_loss: 1.6413 - VH_attention_linear_output_loss: 1.6483 - VL_attention_linear_output_acc: 0.5155 - VH_attention_linear_output_acc: 0.5213 - val_loss: 3.4506 - val_VL_attention_linear_output_loss: 1.7251 - val_VH_attention_linear_output_loss: 1.7255 - val_VL_attention_linear_output_acc: 0.4983 - val_VH_attention_linear_output_acc: 0.5055\n",
      "Epoch 4507/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3051 - VL_attention_linear_output_loss: 1.6563 - VH_attention_linear_output_loss: 1.6488 - VL_attention_linear_output_acc: 0.5099 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4989 - val_VL_attention_linear_output_loss: 1.7409 - val_VH_attention_linear_output_loss: 1.7580 - val_VL_attention_linear_output_acc: 0.5031 - val_VH_attention_linear_output_acc: 0.4909\n",
      "Epoch 4508/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2954 - VL_attention_linear_output_loss: 1.6468 - VH_attention_linear_output_loss: 1.6486 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5209 - val_loss: 3.4526 - val_VL_attention_linear_output_loss: 1.7322 - val_VH_attention_linear_output_loss: 1.7204 - val_VL_attention_linear_output_acc: 0.5041 - val_VH_attention_linear_output_acc: 0.5064\n",
      "Epoch 4509/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2989 - VL_attention_linear_output_loss: 1.6483 - VH_attention_linear_output_loss: 1.6506 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5208 - val_loss: 3.4550 - val_VL_attention_linear_output_loss: 1.7326 - val_VH_attention_linear_output_loss: 1.7224 - val_VL_attention_linear_output_acc: 0.4968 - val_VH_attention_linear_output_acc: 0.5051\n",
      "Epoch 4510/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2977 - VL_attention_linear_output_loss: 1.6514 - VH_attention_linear_output_loss: 1.6463 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5222 - val_loss: 3.4431 - val_VL_attention_linear_output_loss: 1.7298 - val_VH_attention_linear_output_loss: 1.7133 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.5080\n",
      "Epoch 4511/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2787 - VL_attention_linear_output_loss: 1.6423 - VH_attention_linear_output_loss: 1.6365 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5259 - val_loss: 3.4446 - val_VL_attention_linear_output_loss: 1.7332 - val_VH_attention_linear_output_loss: 1.7114 - val_VL_attention_linear_output_acc: 0.4929 - val_VH_attention_linear_output_acc: 0.5097\n",
      "Epoch 4512/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2896 - VL_attention_linear_output_loss: 1.6516 - VH_attention_linear_output_loss: 1.6379 - VL_attention_linear_output_acc: 0.5119 - VH_attention_linear_output_acc: 0.5253 - val_loss: 3.4455 - val_VL_attention_linear_output_loss: 1.7244 - val_VH_attention_linear_output_loss: 1.7211 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5073\n",
      "Epoch 4513/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2948 - VL_attention_linear_output_loss: 1.6503 - VH_attention_linear_output_loss: 1.6445 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4672 - val_VL_attention_linear_output_loss: 1.7242 - val_VH_attention_linear_output_loss: 1.7430 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.4992\n",
      "Epoch 4514/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2938 - VL_attention_linear_output_loss: 1.6499 - VH_attention_linear_output_loss: 1.6439 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5231 - val_loss: 3.4640 - val_VL_attention_linear_output_loss: 1.7434 - val_VH_attention_linear_output_loss: 1.7205 - val_VL_attention_linear_output_acc: 0.4934 - val_VH_attention_linear_output_acc: 0.5078\n",
      "Epoch 4515/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2945 - VL_attention_linear_output_loss: 1.6542 - VH_attention_linear_output_loss: 1.6402 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4400 - val_VL_attention_linear_output_loss: 1.7277 - val_VH_attention_linear_output_loss: 1.7123 - val_VL_attention_linear_output_acc: 0.5012 - val_VH_attention_linear_output_acc: 0.5112\n",
      "Epoch 4516/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2932 - VL_attention_linear_output_loss: 1.6490 - VH_attention_linear_output_loss: 1.6442 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5236 - val_loss: 3.4438 - val_VL_attention_linear_output_loss: 1.7276 - val_VH_attention_linear_output_loss: 1.7162 - val_VL_attention_linear_output_acc: 0.4929 - val_VH_attention_linear_output_acc: 0.5080\n",
      "Epoch 4517/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2872 - VL_attention_linear_output_loss: 1.6417 - VH_attention_linear_output_loss: 1.6455 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5222 - val_loss: 3.4432 - val_VL_attention_linear_output_loss: 1.7313 - val_VH_attention_linear_output_loss: 1.7120 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.5109\n",
      "Epoch 4518/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3061 - VL_attention_linear_output_loss: 1.6544 - VH_attention_linear_output_loss: 1.6517 - VL_attention_linear_output_acc: 0.5098 - VH_attention_linear_output_acc: 0.5205 - val_loss: 3.4358 - val_VL_attention_linear_output_loss: 1.7204 - val_VH_attention_linear_output_loss: 1.7154 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5085\n",
      "Epoch 4519/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2864 - VL_attention_linear_output_loss: 1.6408 - VH_attention_linear_output_loss: 1.6455 - VL_attention_linear_output_acc: 0.5150 - VH_attention_linear_output_acc: 0.5221 - val_loss: 3.4406 - val_VL_attention_linear_output_loss: 1.7168 - val_VH_attention_linear_output_loss: 1.7238 - val_VL_attention_linear_output_acc: 0.5036 - val_VH_attention_linear_output_acc: 0.5015\n",
      "Epoch 4520/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2975 - VL_attention_linear_output_loss: 1.6564 - VH_attention_linear_output_loss: 1.6412 - VL_attention_linear_output_acc: 0.5087 - VH_attention_linear_output_acc: 0.5238 - val_loss: 3.4469 - val_VL_attention_linear_output_loss: 1.7220 - val_VH_attention_linear_output_loss: 1.7250 - val_VL_attention_linear_output_acc: 0.4988 - val_VH_attention_linear_output_acc: 0.5055\n",
      "Epoch 4521/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2894 - VL_attention_linear_output_loss: 1.6514 - VH_attention_linear_output_loss: 1.6380 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5252 - val_loss: 3.4335 - val_VL_attention_linear_output_loss: 1.7178 - val_VH_attention_linear_output_loss: 1.7157 - val_VL_attention_linear_output_acc: 0.5071 - val_VH_attention_linear_output_acc: 0.5070\n",
      "Epoch 4522/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3086 - VL_attention_linear_output_loss: 1.6570 - VH_attention_linear_output_loss: 1.6517 - VL_attention_linear_output_acc: 0.5095 - VH_attention_linear_output_acc: 0.5199 - val_loss: 3.4475 - val_VL_attention_linear_output_loss: 1.7318 - val_VH_attention_linear_output_loss: 1.7157 - val_VL_attention_linear_output_acc: 0.4910 - val_VH_attention_linear_output_acc: 0.5061\n",
      "Epoch 4523/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2892 - VL_attention_linear_output_loss: 1.6483 - VH_attention_linear_output_loss: 1.6409 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5241 - val_loss: 3.4370 - val_VL_attention_linear_output_loss: 1.7193 - val_VH_attention_linear_output_loss: 1.7177 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5072\n",
      "Epoch 4524/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2981 - VL_attention_linear_output_loss: 1.6506 - VH_attention_linear_output_loss: 1.6475 - VL_attention_linear_output_acc: 0.5109 - VH_attention_linear_output_acc: 0.5217 - val_loss: 3.5285 - val_VL_attention_linear_output_loss: 1.7904 - val_VH_attention_linear_output_loss: 1.7381 - val_VL_attention_linear_output_acc: 0.4594 - val_VH_attention_linear_output_acc: 0.5036\n",
      "Epoch 4525/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3133 - VL_attention_linear_output_loss: 1.6614 - VH_attention_linear_output_loss: 1.6519 - VL_attention_linear_output_acc: 0.5071 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.4395 - val_VL_attention_linear_output_loss: 1.7178 - val_VH_attention_linear_output_loss: 1.7217 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5062\n",
      "Epoch 4526/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2940 - VL_attention_linear_output_loss: 1.6459 - VH_attention_linear_output_loss: 1.6481 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5217 - val_loss: 3.4348 - val_VL_attention_linear_output_loss: 1.7220 - val_VH_attention_linear_output_loss: 1.7129 - val_VL_attention_linear_output_acc: 0.5035 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4527/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2914 - VL_attention_linear_output_loss: 1.6418 - VH_attention_linear_output_loss: 1.6496 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5212 - val_loss: 3.4601 - val_VL_attention_linear_output_loss: 1.7410 - val_VH_attention_linear_output_loss: 1.7192 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.5080\n",
      "Epoch 4528/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2964 - VL_attention_linear_output_loss: 1.6468 - VH_attention_linear_output_loss: 1.6496 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5205 - val_loss: 3.4456 - val_VL_attention_linear_output_loss: 1.7183 - val_VH_attention_linear_output_loss: 1.7272 - val_VL_attention_linear_output_acc: 0.4983 - val_VH_attention_linear_output_acc: 0.5061\n",
      "Epoch 4529/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2903 - VL_attention_linear_output_loss: 1.6447 - VH_attention_linear_output_loss: 1.6456 - VL_attention_linear_output_acc: 0.5128 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4397 - val_VL_attention_linear_output_loss: 1.7271 - val_VH_attention_linear_output_loss: 1.7126 - val_VL_attention_linear_output_acc: 0.4979 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4530/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3117 - VL_attention_linear_output_loss: 1.6457 - VH_attention_linear_output_loss: 1.6660 - VL_attention_linear_output_acc: 0.5136 - VH_attention_linear_output_acc: 0.5149 - val_loss: 3.4432 - val_VL_attention_linear_output_loss: 1.7265 - val_VH_attention_linear_output_loss: 1.7167 - val_VL_attention_linear_output_acc: 0.4948 - val_VH_attention_linear_output_acc: 0.5108\n",
      "Epoch 4531/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2885 - VL_attention_linear_output_loss: 1.6451 - VH_attention_linear_output_loss: 1.6434 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4343 - val_VL_attention_linear_output_loss: 1.7228 - val_VH_attention_linear_output_loss: 1.7115 - val_VL_attention_linear_output_acc: 0.5038 - val_VH_attention_linear_output_acc: 0.5086\n",
      "Epoch 4532/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2968 - VL_attention_linear_output_loss: 1.6563 - VH_attention_linear_output_loss: 1.6405 - VL_attention_linear_output_acc: 0.5092 - VH_attention_linear_output_acc: 0.5245 - val_loss: 3.5355 - val_VL_attention_linear_output_loss: 1.8226 - val_VH_attention_linear_output_loss: 1.7130 - val_VL_attention_linear_output_acc: 0.4791 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4533/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2928 - VL_attention_linear_output_loss: 1.6480 - VH_attention_linear_output_loss: 1.6448 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.5455 - val_VL_attention_linear_output_loss: 1.7199 - val_VH_attention_linear_output_loss: 1.8256 - val_VL_attention_linear_output_acc: 0.5025 - val_VH_attention_linear_output_acc: 0.4746\n",
      "Epoch 4534/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2816 - VL_attention_linear_output_loss: 1.6381 - VH_attention_linear_output_loss: 1.6435 - VL_attention_linear_output_acc: 0.5159 - VH_attention_linear_output_acc: 0.5236 - val_loss: 3.4386 - val_VL_attention_linear_output_loss: 1.7209 - val_VH_attention_linear_output_loss: 1.7177 - val_VL_attention_linear_output_acc: 0.4985 - val_VH_attention_linear_output_acc: 0.5046\n",
      "Epoch 4535/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2800 - VL_attention_linear_output_loss: 1.6393 - VH_attention_linear_output_loss: 1.6407 - VL_attention_linear_output_acc: 0.5153 - VH_attention_linear_output_acc: 0.5239 - val_loss: 3.4628 - val_VL_attention_linear_output_loss: 1.7349 - val_VH_attention_linear_output_loss: 1.7279 - val_VL_attention_linear_output_acc: 0.4970 - val_VH_attention_linear_output_acc: 0.5077\n",
      "Epoch 4536/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2829 - VL_attention_linear_output_loss: 1.6419 - VH_attention_linear_output_loss: 1.6410 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5243 - val_loss: 3.4447 - val_VL_attention_linear_output_loss: 1.7251 - val_VH_attention_linear_output_loss: 1.7196 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 4537/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2962 - VL_attention_linear_output_loss: 1.6464 - VH_attention_linear_output_loss: 1.6498 - VL_attention_linear_output_acc: 0.5128 - VH_attention_linear_output_acc: 0.5214 - val_loss: 3.4469 - val_VL_attention_linear_output_loss: 1.7202 - val_VH_attention_linear_output_loss: 1.7267 - val_VL_attention_linear_output_acc: 0.5057 - val_VH_attention_linear_output_acc: 0.5026\n",
      "Epoch 4538/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3021 - VL_attention_linear_output_loss: 1.6534 - VH_attention_linear_output_loss: 1.6488 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5210 - val_loss: 3.5478 - val_VL_attention_linear_output_loss: 1.8247 - val_VH_attention_linear_output_loss: 1.7232 - val_VL_attention_linear_output_acc: 0.4552 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4539/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2986 - VL_attention_linear_output_loss: 1.6471 - VH_attention_linear_output_loss: 1.6515 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5207 - val_loss: 3.4437 - val_VL_attention_linear_output_loss: 1.7303 - val_VH_attention_linear_output_loss: 1.7134 - val_VL_attention_linear_output_acc: 0.5020 - val_VH_attention_linear_output_acc: 0.5096\n",
      "Epoch 4540/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2965 - VL_attention_linear_output_loss: 1.6507 - VH_attention_linear_output_loss: 1.6458 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5224 - val_loss: 3.4521 - val_VL_attention_linear_output_loss: 1.7226 - val_VH_attention_linear_output_loss: 1.7295 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.4975\n",
      "Epoch 4541/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2950 - VL_attention_linear_output_loss: 1.6464 - VH_attention_linear_output_loss: 1.6486 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5207 - val_loss: 3.4512 - val_VL_attention_linear_output_loss: 1.7276 - val_VH_attention_linear_output_loss: 1.7235 - val_VL_attention_linear_output_acc: 0.5002 - val_VH_attention_linear_output_acc: 0.5068\n",
      "Epoch 4542/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3063 - VL_attention_linear_output_loss: 1.6577 - VH_attention_linear_output_loss: 1.6486 - VL_attention_linear_output_acc: 0.5085 - VH_attention_linear_output_acc: 0.5216 - val_loss: 3.4426 - val_VL_attention_linear_output_loss: 1.7346 - val_VH_attention_linear_output_loss: 1.7079 - val_VL_attention_linear_output_acc: 0.4871 - val_VH_attention_linear_output_acc: 0.5103\n",
      "Epoch 4543/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3002 - VL_attention_linear_output_loss: 1.6525 - VH_attention_linear_output_loss: 1.6477 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5217 - val_loss: 3.4705 - val_VL_attention_linear_output_loss: 1.7493 - val_VH_attention_linear_output_loss: 1.7212 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.5067\n",
      "Epoch 4544/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2987 - VL_attention_linear_output_loss: 1.6513 - VH_attention_linear_output_loss: 1.6475 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5215 - val_loss: 3.4343 - val_VL_attention_linear_output_loss: 1.7205 - val_VH_attention_linear_output_loss: 1.7138 - val_VL_attention_linear_output_acc: 0.5039 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4545/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2949 - VL_attention_linear_output_loss: 1.6480 - VH_attention_linear_output_loss: 1.6469 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5213 - val_loss: 3.4482 - val_VL_attention_linear_output_loss: 1.7320 - val_VH_attention_linear_output_loss: 1.7162 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.5068\n",
      "Epoch 4546/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2892 - VL_attention_linear_output_loss: 1.6428 - VH_attention_linear_output_loss: 1.6464 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5221 - val_loss: 3.4484 - val_VL_attention_linear_output_loss: 1.7166 - val_VH_attention_linear_output_loss: 1.7318 - val_VL_attention_linear_output_acc: 0.5026 - val_VH_attention_linear_output_acc: 0.4997\n",
      "Epoch 4547/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3075 - VL_attention_linear_output_loss: 1.6516 - VH_attention_linear_output_loss: 1.6559 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5193 - val_loss: 3.4530 - val_VL_attention_linear_output_loss: 1.7273 - val_VH_attention_linear_output_loss: 1.7256 - val_VL_attention_linear_output_acc: 0.5029 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4548/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2867 - VL_attention_linear_output_loss: 1.6412 - VH_attention_linear_output_loss: 1.6454 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4721 - val_VL_attention_linear_output_loss: 1.7311 - val_VH_attention_linear_output_loss: 1.7410 - val_VL_attention_linear_output_acc: 0.4943 - val_VH_attention_linear_output_acc: 0.5023\n",
      "Epoch 4549/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3058 - VL_attention_linear_output_loss: 1.6472 - VH_attention_linear_output_loss: 1.6586 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5180 - val_loss: 3.4647 - val_VL_attention_linear_output_loss: 1.7282 - val_VH_attention_linear_output_loss: 1.7365 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.4958\n",
      "Epoch 4550/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2837 - VL_attention_linear_output_loss: 1.6452 - VH_attention_linear_output_loss: 1.6385 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5253 - val_loss: 3.4408 - val_VL_attention_linear_output_loss: 1.7287 - val_VH_attention_linear_output_loss: 1.7122 - val_VL_attention_linear_output_acc: 0.5038 - val_VH_attention_linear_output_acc: 0.5068\n",
      "Epoch 4551/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2853 - VL_attention_linear_output_loss: 1.6449 - VH_attention_linear_output_loss: 1.6405 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4396 - val_VL_attention_linear_output_loss: 1.7328 - val_VH_attention_linear_output_loss: 1.7068 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4552/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2950 - VL_attention_linear_output_loss: 1.6449 - VH_attention_linear_output_loss: 1.6501 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5208 - val_loss: 3.4386 - val_VL_attention_linear_output_loss: 1.7202 - val_VH_attention_linear_output_loss: 1.7185 - val_VL_attention_linear_output_acc: 0.5017 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4553/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2940 - VL_attention_linear_output_loss: 1.6499 - VH_attention_linear_output_loss: 1.6441 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5232 - val_loss: 3.4464 - val_VL_attention_linear_output_loss: 1.7243 - val_VH_attention_linear_output_loss: 1.7221 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5042\n",
      "Epoch 4554/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2942 - VL_attention_linear_output_loss: 1.6435 - VH_attention_linear_output_loss: 1.6507 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5211 - val_loss: 3.4368 - val_VL_attention_linear_output_loss: 1.7216 - val_VH_attention_linear_output_loss: 1.7152 - val_VL_attention_linear_output_acc: 0.4989 - val_VH_attention_linear_output_acc: 0.5106\n",
      "Epoch 4555/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2986 - VL_attention_linear_output_loss: 1.6506 - VH_attention_linear_output_loss: 1.6480 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5213 - val_loss: 3.4415 - val_VL_attention_linear_output_loss: 1.7237 - val_VH_attention_linear_output_loss: 1.7179 - val_VL_attention_linear_output_acc: 0.4974 - val_VH_attention_linear_output_acc: 0.5102\n",
      "Epoch 4556/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2947 - VL_attention_linear_output_loss: 1.6440 - VH_attention_linear_output_loss: 1.6507 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5209 - val_loss: 3.4500 - val_VL_attention_linear_output_loss: 1.7285 - val_VH_attention_linear_output_loss: 1.7215 - val_VL_attention_linear_output_acc: 0.4995 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4557/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3064 - VL_attention_linear_output_loss: 1.6537 - VH_attention_linear_output_loss: 1.6528 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5209 - val_loss: 3.4400 - val_VL_attention_linear_output_loss: 1.7235 - val_VH_attention_linear_output_loss: 1.7165 - val_VL_attention_linear_output_acc: 0.5007 - val_VH_attention_linear_output_acc: 0.5072\n",
      "Epoch 4558/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2992 - VL_attention_linear_output_loss: 1.6504 - VH_attention_linear_output_loss: 1.6488 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5214 - val_loss: 3.4378 - val_VL_attention_linear_output_loss: 1.7225 - val_VH_attention_linear_output_loss: 1.7152 - val_VL_attention_linear_output_acc: 0.5007 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4559/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2924 - VL_attention_linear_output_loss: 1.6442 - VH_attention_linear_output_loss: 1.6482 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4478 - val_VL_attention_linear_output_loss: 1.7250 - val_VH_attention_linear_output_loss: 1.7228 - val_VL_attention_linear_output_acc: 0.4970 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4560/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2953 - VL_attention_linear_output_loss: 1.6489 - VH_attention_linear_output_loss: 1.6464 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5222 - val_loss: 3.4590 - val_VL_attention_linear_output_loss: 1.7447 - val_VH_attention_linear_output_loss: 1.7144 - val_VL_attention_linear_output_acc: 0.4955 - val_VH_attention_linear_output_acc: 0.5073\n",
      "Epoch 4561/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2859 - VL_attention_linear_output_loss: 1.6442 - VH_attention_linear_output_loss: 1.6416 - VL_attention_linear_output_acc: 0.5140 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4401 - val_VL_attention_linear_output_loss: 1.7201 - val_VH_attention_linear_output_loss: 1.7200 - val_VL_attention_linear_output_acc: 0.4991 - val_VH_attention_linear_output_acc: 0.5021\n",
      "Epoch 4562/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2922 - VL_attention_linear_output_loss: 1.6474 - VH_attention_linear_output_loss: 1.6447 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5229 - val_loss: 3.4303 - val_VL_attention_linear_output_loss: 1.7201 - val_VH_attention_linear_output_loss: 1.7103 - val_VL_attention_linear_output_acc: 0.5037 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4563/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2910 - VL_attention_linear_output_loss: 1.6416 - VH_attention_linear_output_loss: 1.6494 - VL_attention_linear_output_acc: 0.5144 - VH_attention_linear_output_acc: 0.5207 - val_loss: 3.4477 - val_VL_attention_linear_output_loss: 1.7244 - val_VH_attention_linear_output_loss: 1.7233 - val_VL_attention_linear_output_acc: 0.4955 - val_VH_attention_linear_output_acc: 0.5082\n",
      "Epoch 4564/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2896 - VL_attention_linear_output_loss: 1.6459 - VH_attention_linear_output_loss: 1.6436 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5229 - val_loss: 3.4699 - val_VL_attention_linear_output_loss: 1.7204 - val_VH_attention_linear_output_loss: 1.7495 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.4922\n",
      "Epoch 4565/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2845 - VL_attention_linear_output_loss: 1.6417 - VH_attention_linear_output_loss: 1.6428 - VL_attention_linear_output_acc: 0.5147 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4463 - val_VL_attention_linear_output_loss: 1.7318 - val_VH_attention_linear_output_loss: 1.7146 - val_VL_attention_linear_output_acc: 0.4850 - val_VH_attention_linear_output_acc: 0.5075\n",
      "Epoch 4566/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3022 - VL_attention_linear_output_loss: 1.6548 - VH_attention_linear_output_loss: 1.6474 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5215 - val_loss: 3.4299 - val_VL_attention_linear_output_loss: 1.7158 - val_VH_attention_linear_output_loss: 1.7141 - val_VL_attention_linear_output_acc: 0.5038 - val_VH_attention_linear_output_acc: 0.5101\n",
      "Epoch 4567/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2834 - VL_attention_linear_output_loss: 1.6374 - VH_attention_linear_output_loss: 1.6460 - VL_attention_linear_output_acc: 0.5154 - VH_attention_linear_output_acc: 0.5226 - val_loss: 3.4567 - val_VL_attention_linear_output_loss: 1.7174 - val_VH_attention_linear_output_loss: 1.7394 - val_VL_attention_linear_output_acc: 0.4998 - val_VH_attention_linear_output_acc: 0.4911\n",
      "Epoch 4568/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2942 - VL_attention_linear_output_loss: 1.6397 - VH_attention_linear_output_loss: 1.6545 - VL_attention_linear_output_acc: 0.5146 - VH_attention_linear_output_acc: 0.5191 - val_loss: 3.4437 - val_VL_attention_linear_output_loss: 1.7345 - val_VH_attention_linear_output_loss: 1.7091 - val_VL_attention_linear_output_acc: 0.4983 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4569/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2950 - VL_attention_linear_output_loss: 1.6555 - VH_attention_linear_output_loss: 1.6395 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5248 - val_loss: 3.4392 - val_VL_attention_linear_output_loss: 1.7258 - val_VH_attention_linear_output_loss: 1.7135 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.5070\n",
      "Epoch 4570/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2889 - VL_attention_linear_output_loss: 1.6458 - VH_attention_linear_output_loss: 1.6431 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5236 - val_loss: 3.4510 - val_VL_attention_linear_output_loss: 1.7254 - val_VH_attention_linear_output_loss: 1.7256 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5037\n",
      "Epoch 4571/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3001 - VL_attention_linear_output_loss: 1.6478 - VH_attention_linear_output_loss: 1.6522 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5204 - val_loss: 3.4512 - val_VL_attention_linear_output_loss: 1.7366 - val_VH_attention_linear_output_loss: 1.7146 - val_VL_attention_linear_output_acc: 0.5025 - val_VH_attention_linear_output_acc: 0.5071\n",
      "Epoch 4572/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2943 - VL_attention_linear_output_loss: 1.6441 - VH_attention_linear_output_loss: 1.6502 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5213 - val_loss: 3.4516 - val_VL_attention_linear_output_loss: 1.7376 - val_VH_attention_linear_output_loss: 1.7140 - val_VL_attention_linear_output_acc: 0.4851 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4573/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2895 - VL_attention_linear_output_loss: 1.6430 - VH_attention_linear_output_loss: 1.6465 - VL_attention_linear_output_acc: 0.5132 - VH_attention_linear_output_acc: 0.5223 - val_loss: 3.4257 - val_VL_attention_linear_output_loss: 1.7150 - val_VH_attention_linear_output_loss: 1.7106 - val_VL_attention_linear_output_acc: 0.5044 - val_VH_attention_linear_output_acc: 0.5109\n",
      "Epoch 4574/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2886 - VL_attention_linear_output_loss: 1.6413 - VH_attention_linear_output_loss: 1.6473 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5223 - val_loss: 3.4283 - val_VL_attention_linear_output_loss: 1.7202 - val_VH_attention_linear_output_loss: 1.7082 - val_VL_attention_linear_output_acc: 0.5031 - val_VH_attention_linear_output_acc: 0.5105\n",
      "Epoch 4575/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2839 - VL_attention_linear_output_loss: 1.6398 - VH_attention_linear_output_loss: 1.6441 - VL_attention_linear_output_acc: 0.5148 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4335 - val_VL_attention_linear_output_loss: 1.7189 - val_VH_attention_linear_output_loss: 1.7146 - val_VL_attention_linear_output_acc: 0.5050 - val_VH_attention_linear_output_acc: 0.5094\n",
      "Epoch 4576/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2877 - VL_attention_linear_output_loss: 1.6459 - VH_attention_linear_output_loss: 1.6418 - VL_attention_linear_output_acc: 0.5128 - VH_attention_linear_output_acc: 0.5243 - val_loss: 3.4624 - val_VL_attention_linear_output_loss: 1.7518 - val_VH_attention_linear_output_loss: 1.7106 - val_VL_attention_linear_output_acc: 0.4806 - val_VH_attention_linear_output_acc: 0.5070\n",
      "Epoch 4577/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3123 - VL_attention_linear_output_loss: 1.6526 - VH_attention_linear_output_loss: 1.6597 - VL_attention_linear_output_acc: 0.5091 - VH_attention_linear_output_acc: 0.5175 - val_loss: 3.4474 - val_VL_attention_linear_output_loss: 1.7330 - val_VH_attention_linear_output_loss: 1.7145 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.5073\n",
      "Epoch 4578/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3012 - VL_attention_linear_output_loss: 1.6553 - VH_attention_linear_output_loss: 1.6460 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4481 - val_VL_attention_linear_output_loss: 1.7194 - val_VH_attention_linear_output_loss: 1.7287 - val_VL_attention_linear_output_acc: 0.5007 - val_VH_attention_linear_output_acc: 0.5060\n",
      "Epoch 4579/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2952 - VL_attention_linear_output_loss: 1.6479 - VH_attention_linear_output_loss: 1.6473 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5221 - val_loss: 3.4436 - val_VL_attention_linear_output_loss: 1.7267 - val_VH_attention_linear_output_loss: 1.7169 - val_VL_attention_linear_output_acc: 0.4952 - val_VH_attention_linear_output_acc: 0.5065\n",
      "Epoch 4580/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2816 - VL_attention_linear_output_loss: 1.6421 - VH_attention_linear_output_loss: 1.6395 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5249 - val_loss: 3.4821 - val_VL_attention_linear_output_loss: 1.7151 - val_VH_attention_linear_output_loss: 1.7671 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.4906\n",
      "Epoch 4581/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2912 - VL_attention_linear_output_loss: 1.6372 - VH_attention_linear_output_loss: 1.6539 - VL_attention_linear_output_acc: 0.5151 - VH_attention_linear_output_acc: 0.5196 - val_loss: 3.4951 - val_VL_attention_linear_output_loss: 1.7164 - val_VH_attention_linear_output_loss: 1.7787 - val_VL_attention_linear_output_acc: 0.5020 - val_VH_attention_linear_output_acc: 0.4811\n",
      "Epoch 4582/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3117 - VL_attention_linear_output_loss: 1.6618 - VH_attention_linear_output_loss: 1.6499 - VL_attention_linear_output_acc: 0.5065 - VH_attention_linear_output_acc: 0.5208 - val_loss: 3.5135 - val_VL_attention_linear_output_loss: 1.7883 - val_VH_attention_linear_output_loss: 1.7252 - val_VL_attention_linear_output_acc: 0.4818 - val_VH_attention_linear_output_acc: 0.5055\n",
      "Epoch 4583/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2887 - VL_attention_linear_output_loss: 1.6440 - VH_attention_linear_output_loss: 1.6447 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5229 - val_loss: 3.4341 - val_VL_attention_linear_output_loss: 1.7250 - val_VH_attention_linear_output_loss: 1.7091 - val_VL_attention_linear_output_acc: 0.4981 - val_VH_attention_linear_output_acc: 0.5099\n",
      "Epoch 4584/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3123 - VL_attention_linear_output_loss: 1.6463 - VH_attention_linear_output_loss: 1.6660 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5158 - val_loss: 3.4576 - val_VL_attention_linear_output_loss: 1.7263 - val_VH_attention_linear_output_loss: 1.7313 - val_VL_attention_linear_output_acc: 0.4996 - val_VH_attention_linear_output_acc: 0.5024\n",
      "Epoch 4585/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2940 - VL_attention_linear_output_loss: 1.6474 - VH_attention_linear_output_loss: 1.6466 - VL_attention_linear_output_acc: 0.5120 - VH_attention_linear_output_acc: 0.5230 - val_loss: 3.5144 - val_VL_attention_linear_output_loss: 1.8028 - val_VH_attention_linear_output_loss: 1.7116 - val_VL_attention_linear_output_acc: 0.4691 - val_VH_attention_linear_output_acc: 0.5061\n",
      "Epoch 4586/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2867 - VL_attention_linear_output_loss: 1.6456 - VH_attention_linear_output_loss: 1.6410 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5245 - val_loss: 3.4344 - val_VL_attention_linear_output_loss: 1.7163 - val_VH_attention_linear_output_loss: 1.7181 - val_VL_attention_linear_output_acc: 0.5024 - val_VH_attention_linear_output_acc: 0.5062\n",
      "Epoch 4587/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3055 - VL_attention_linear_output_loss: 1.6583 - VH_attention_linear_output_loss: 1.6472 - VL_attention_linear_output_acc: 0.5080 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4317 - val_VL_attention_linear_output_loss: 1.7171 - val_VH_attention_linear_output_loss: 1.7146 - val_VL_attention_linear_output_acc: 0.5019 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4588/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2855 - VL_attention_linear_output_loss: 1.6378 - VH_attention_linear_output_loss: 1.6477 - VL_attention_linear_output_acc: 0.5156 - VH_attention_linear_output_acc: 0.5214 - val_loss: 3.4492 - val_VL_attention_linear_output_loss: 1.7181 - val_VH_attention_linear_output_loss: 1.7310 - val_VL_attention_linear_output_acc: 0.4934 - val_VH_attention_linear_output_acc: 0.5034\n",
      "Epoch 4589/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2959 - VL_attention_linear_output_loss: 1.6418 - VH_attention_linear_output_loss: 1.6540 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5201 - val_loss: 3.4469 - val_VL_attention_linear_output_loss: 1.7212 - val_VH_attention_linear_output_loss: 1.7257 - val_VL_attention_linear_output_acc: 0.5033 - val_VH_attention_linear_output_acc: 0.5043\n",
      "Epoch 4590/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3001 - VL_attention_linear_output_loss: 1.6432 - VH_attention_linear_output_loss: 1.6569 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5186 - val_loss: 3.4510 - val_VL_attention_linear_output_loss: 1.7330 - val_VH_attention_linear_output_loss: 1.7180 - val_VL_attention_linear_output_acc: 0.4955 - val_VH_attention_linear_output_acc: 0.5085\n",
      "Epoch 4591/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2956 - VL_attention_linear_output_loss: 1.6532 - VH_attention_linear_output_loss: 1.6423 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5232 - val_loss: 3.4467 - val_VL_attention_linear_output_loss: 1.7192 - val_VH_attention_linear_output_loss: 1.7275 - val_VL_attention_linear_output_acc: 0.5025 - val_VH_attention_linear_output_acc: 0.5043\n",
      "Epoch 4592/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2906 - VL_attention_linear_output_loss: 1.6437 - VH_attention_linear_output_loss: 1.6469 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5216 - val_loss: 3.4440 - val_VL_attention_linear_output_loss: 1.7236 - val_VH_attention_linear_output_loss: 1.7204 - val_VL_attention_linear_output_acc: 0.5015 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4593/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2948 - VL_attention_linear_output_loss: 1.6489 - VH_attention_linear_output_loss: 1.6458 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4678 - val_VL_attention_linear_output_loss: 1.7544 - val_VH_attention_linear_output_loss: 1.7135 - val_VL_attention_linear_output_acc: 0.4824 - val_VH_attention_linear_output_acc: 0.5094\n",
      "Epoch 4594/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3055 - VL_attention_linear_output_loss: 1.6622 - VH_attention_linear_output_loss: 1.6432 - VL_attention_linear_output_acc: 0.5065 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.4437 - val_VL_attention_linear_output_loss: 1.7241 - val_VH_attention_linear_output_loss: 1.7196 - val_VL_attention_linear_output_acc: 0.4951 - val_VH_attention_linear_output_acc: 0.5067\n",
      "Epoch 4595/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2982 - VL_attention_linear_output_loss: 1.6517 - VH_attention_linear_output_loss: 1.6466 - VL_attention_linear_output_acc: 0.5098 - VH_attention_linear_output_acc: 0.5221 - val_loss: 3.4844 - val_VL_attention_linear_output_loss: 1.7396 - val_VH_attention_linear_output_loss: 1.7449 - val_VL_attention_linear_output_acc: 0.5018 - val_VH_attention_linear_output_acc: 0.4941\n",
      "Epoch 4596/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2979 - VL_attention_linear_output_loss: 1.6443 - VH_attention_linear_output_loss: 1.6536 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5194 - val_loss: 3.4434 - val_VL_attention_linear_output_loss: 1.7140 - val_VH_attention_linear_output_loss: 1.7294 - val_VL_attention_linear_output_acc: 0.5022 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4597/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2883 - VL_attention_linear_output_loss: 1.6415 - VH_attention_linear_output_loss: 1.6468 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4565 - val_VL_attention_linear_output_loss: 1.7263 - val_VH_attention_linear_output_loss: 1.7302 - val_VL_attention_linear_output_acc: 0.5053 - val_VH_attention_linear_output_acc: 0.5045\n",
      "Epoch 4598/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2798 - VL_attention_linear_output_loss: 1.6422 - VH_attention_linear_output_loss: 1.6376 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5252 - val_loss: 3.4404 - val_VL_attention_linear_output_loss: 1.7224 - val_VH_attention_linear_output_loss: 1.7180 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5073\n",
      "Epoch 4599/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3185 - VL_attention_linear_output_loss: 1.6501 - VH_attention_linear_output_loss: 1.6684 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5141 - val_loss: 3.4357 - val_VL_attention_linear_output_loss: 1.7233 - val_VH_attention_linear_output_loss: 1.7123 - val_VL_attention_linear_output_acc: 0.4970 - val_VH_attention_linear_output_acc: 0.5087\n",
      "Epoch 4600/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2849 - VL_attention_linear_output_loss: 1.6496 - VH_attention_linear_output_loss: 1.6353 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5258 - val_loss: 3.4277 - val_VL_attention_linear_output_loss: 1.7141 - val_VH_attention_linear_output_loss: 1.7136 - val_VL_attention_linear_output_acc: 0.5044 - val_VH_attention_linear_output_acc: 0.5074\n",
      "Epoch 4601/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2723 - VL_attention_linear_output_loss: 1.6370 - VH_attention_linear_output_loss: 1.6354 - VL_attention_linear_output_acc: 0.5158 - VH_attention_linear_output_acc: 0.5261 - val_loss: 3.4398 - val_VL_attention_linear_output_loss: 1.7265 - val_VH_attention_linear_output_loss: 1.7134 - val_VL_attention_linear_output_acc: 0.4917 - val_VH_attention_linear_output_acc: 0.5074\n",
      "Epoch 4602/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2892 - VL_attention_linear_output_loss: 1.6507 - VH_attention_linear_output_loss: 1.6385 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5247 - val_loss: 3.4301 - val_VL_attention_linear_output_loss: 1.7178 - val_VH_attention_linear_output_loss: 1.7123 - val_VL_attention_linear_output_acc: 0.4975 - val_VH_attention_linear_output_acc: 0.5085\n",
      "Epoch 4603/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2969 - VL_attention_linear_output_loss: 1.6398 - VH_attention_linear_output_loss: 1.6571 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5178 - val_loss: 3.4232 - val_VL_attention_linear_output_loss: 1.7129 - val_VH_attention_linear_output_loss: 1.7103 - val_VL_attention_linear_output_acc: 0.5034 - val_VH_attention_linear_output_acc: 0.5099\n",
      "Epoch 4604/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2871 - VL_attention_linear_output_loss: 1.6424 - VH_attention_linear_output_loss: 1.6447 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4357 - val_VL_attention_linear_output_loss: 1.7186 - val_VH_attention_linear_output_loss: 1.7171 - val_VL_attention_linear_output_acc: 0.4955 - val_VH_attention_linear_output_acc: 0.5082\n",
      "Epoch 4605/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2841 - VL_attention_linear_output_loss: 1.6455 - VH_attention_linear_output_loss: 1.6386 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5248 - val_loss: 3.4473 - val_VL_attention_linear_output_loss: 1.7183 - val_VH_attention_linear_output_loss: 1.7290 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.5042\n",
      "Epoch 4606/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2881 - VL_attention_linear_output_loss: 1.6468 - VH_attention_linear_output_loss: 1.6413 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5243 - val_loss: 3.4465 - val_VL_attention_linear_output_loss: 1.7347 - val_VH_attention_linear_output_loss: 1.7118 - val_VL_attention_linear_output_acc: 0.5024 - val_VH_attention_linear_output_acc: 0.5072\n",
      "Epoch 4607/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2987 - VL_attention_linear_output_loss: 1.6500 - VH_attention_linear_output_loss: 1.6487 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5212 - val_loss: 3.4778 - val_VL_attention_linear_output_loss: 1.7214 - val_VH_attention_linear_output_loss: 1.7564 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.4993\n",
      "Epoch 4608/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2964 - VL_attention_linear_output_loss: 1.6450 - VH_attention_linear_output_loss: 1.6514 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5207 - val_loss: 3.4732 - val_VL_attention_linear_output_loss: 1.7187 - val_VH_attention_linear_output_loss: 1.7545 - val_VL_attention_linear_output_acc: 0.4991 - val_VH_attention_linear_output_acc: 0.4930\n",
      "Epoch 4609/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2913 - VL_attention_linear_output_loss: 1.6478 - VH_attention_linear_output_loss: 1.6436 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.4337 - val_VL_attention_linear_output_loss: 1.7174 - val_VH_attention_linear_output_loss: 1.7163 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5073\n",
      "Epoch 4610/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2903 - VL_attention_linear_output_loss: 1.6415 - VH_attention_linear_output_loss: 1.6488 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5206 - val_loss: 3.4328 - val_VL_attention_linear_output_loss: 1.7214 - val_VH_attention_linear_output_loss: 1.7114 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.5119\n",
      "Epoch 4611/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3018 - VL_attention_linear_output_loss: 1.6492 - VH_attention_linear_output_loss: 1.6526 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5198 - val_loss: 3.4345 - val_VL_attention_linear_output_loss: 1.7216 - val_VH_attention_linear_output_loss: 1.7129 - val_VL_attention_linear_output_acc: 0.5024 - val_VH_attention_linear_output_acc: 0.5087\n",
      "Epoch 4612/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2871 - VL_attention_linear_output_loss: 1.6470 - VH_attention_linear_output_loss: 1.6401 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5244 - val_loss: 3.4789 - val_VL_attention_linear_output_loss: 1.7713 - val_VH_attention_linear_output_loss: 1.7077 - val_VL_attention_linear_output_acc: 0.4676 - val_VH_attention_linear_output_acc: 0.5082\n",
      "Epoch 4613/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2789 - VL_attention_linear_output_loss: 1.6443 - VH_attention_linear_output_loss: 1.6347 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4417 - val_VL_attention_linear_output_loss: 1.7141 - val_VH_attention_linear_output_loss: 1.7276 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5022\n",
      "Epoch 4614/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2783 - VL_attention_linear_output_loss: 1.6376 - VH_attention_linear_output_loss: 1.6407 - VL_attention_linear_output_acc: 0.5146 - VH_attention_linear_output_acc: 0.5244 - val_loss: 3.4266 - val_VL_attention_linear_output_loss: 1.7131 - val_VH_attention_linear_output_loss: 1.7135 - val_VL_attention_linear_output_acc: 0.5027 - val_VH_attention_linear_output_acc: 0.5058\n",
      "Epoch 4615/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2859 - VL_attention_linear_output_loss: 1.6443 - VH_attention_linear_output_loss: 1.6416 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5236 - val_loss: 3.4546 - val_VL_attention_linear_output_loss: 1.7251 - val_VH_attention_linear_output_loss: 1.7294 - val_VL_attention_linear_output_acc: 0.5038 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 4616/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3012 - VL_attention_linear_output_loss: 1.6599 - VH_attention_linear_output_loss: 1.6413 - VL_attention_linear_output_acc: 0.5066 - VH_attention_linear_output_acc: 0.5231 - val_loss: 3.4598 - val_VL_attention_linear_output_loss: 1.7248 - val_VH_attention_linear_output_loss: 1.7350 - val_VL_attention_linear_output_acc: 0.4965 - val_VH_attention_linear_output_acc: 0.4983\n",
      "Epoch 4617/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2810 - VL_attention_linear_output_loss: 1.6386 - VH_attention_linear_output_loss: 1.6424 - VL_attention_linear_output_acc: 0.5146 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4376 - val_VL_attention_linear_output_loss: 1.7171 - val_VH_attention_linear_output_loss: 1.7204 - val_VL_attention_linear_output_acc: 0.4996 - val_VH_attention_linear_output_acc: 0.5071\n",
      "Epoch 4618/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2784 - VL_attention_linear_output_loss: 1.6412 - VH_attention_linear_output_loss: 1.6373 - VL_attention_linear_output_acc: 0.5144 - VH_attention_linear_output_acc: 0.5255 - val_loss: 3.4483 - val_VL_attention_linear_output_loss: 1.7230 - val_VH_attention_linear_output_loss: 1.7253 - val_VL_attention_linear_output_acc: 0.4955 - val_VH_attention_linear_output_acc: 0.5083\n",
      "Epoch 4619/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2730 - VL_attention_linear_output_loss: 1.6378 - VH_attention_linear_output_loss: 1.6352 - VL_attention_linear_output_acc: 0.5149 - VH_attention_linear_output_acc: 0.5263 - val_loss: 3.4561 - val_VL_attention_linear_output_loss: 1.7370 - val_VH_attention_linear_output_loss: 1.7191 - val_VL_attention_linear_output_acc: 0.4934 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4620/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3054 - VL_attention_linear_output_loss: 1.6608 - VH_attention_linear_output_loss: 1.6446 - VL_attention_linear_output_acc: 0.5076 - VH_attention_linear_output_acc: 0.5228 - val_loss: 3.4485 - val_VL_attention_linear_output_loss: 1.7326 - val_VH_attention_linear_output_loss: 1.7159 - val_VL_attention_linear_output_acc: 0.5028 - val_VH_attention_linear_output_acc: 0.5085\n",
      "Epoch 4621/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2847 - VL_attention_linear_output_loss: 1.6435 - VH_attention_linear_output_loss: 1.6411 - VL_attention_linear_output_acc: 0.5128 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4277 - val_VL_attention_linear_output_loss: 1.7152 - val_VH_attention_linear_output_loss: 1.7125 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.5083\n",
      "Epoch 4622/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2816 - VL_attention_linear_output_loss: 1.6438 - VH_attention_linear_output_loss: 1.6378 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5249 - val_loss: 3.4459 - val_VL_attention_linear_output_loss: 1.7300 - val_VH_attention_linear_output_loss: 1.7159 - val_VL_attention_linear_output_acc: 0.4968 - val_VH_attention_linear_output_acc: 0.5087\n",
      "Epoch 4623/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2797 - VL_attention_linear_output_loss: 1.6394 - VH_attention_linear_output_loss: 1.6403 - VL_attention_linear_output_acc: 0.5146 - VH_attention_linear_output_acc: 0.5243 - val_loss: 3.4821 - val_VL_attention_linear_output_loss: 1.7331 - val_VH_attention_linear_output_loss: 1.7490 - val_VL_attention_linear_output_acc: 0.4932 - val_VH_attention_linear_output_acc: 0.4928\n",
      "Epoch 4624/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2886 - VL_attention_linear_output_loss: 1.6464 - VH_attention_linear_output_loss: 1.6422 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5230 - val_loss: 3.4346 - val_VL_attention_linear_output_loss: 1.7197 - val_VH_attention_linear_output_loss: 1.7150 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.5074\n",
      "Epoch 4625/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2850 - VL_attention_linear_output_loss: 1.6481 - VH_attention_linear_output_loss: 1.6369 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5251 - val_loss: 3.4500 - val_VL_attention_linear_output_loss: 1.7289 - val_VH_attention_linear_output_loss: 1.7211 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.5034\n",
      "Epoch 4626/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2871 - VL_attention_linear_output_loss: 1.6450 - VH_attention_linear_output_loss: 1.6421 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5232 - val_loss: 3.4485 - val_VL_attention_linear_output_loss: 1.7183 - val_VH_attention_linear_output_loss: 1.7303 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4627/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3113 - VL_attention_linear_output_loss: 1.6532 - VH_attention_linear_output_loss: 1.6581 - VL_attention_linear_output_acc: 0.5095 - VH_attention_linear_output_acc: 0.5182 - val_loss: 3.4199 - val_VL_attention_linear_output_loss: 1.7133 - val_VH_attention_linear_output_loss: 1.7066 - val_VL_attention_linear_output_acc: 0.5029 - val_VH_attention_linear_output_acc: 0.5091\n",
      "Epoch 4628/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2825 - VL_attention_linear_output_loss: 1.6465 - VH_attention_linear_output_loss: 1.6360 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5256 - val_loss: 3.4386 - val_VL_attention_linear_output_loss: 1.7219 - val_VH_attention_linear_output_loss: 1.7167 - val_VL_attention_linear_output_acc: 0.5026 - val_VH_attention_linear_output_acc: 0.5056\n",
      "Epoch 4629/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2696 - VL_attention_linear_output_loss: 1.6355 - VH_attention_linear_output_loss: 1.6341 - VL_attention_linear_output_acc: 0.5163 - VH_attention_linear_output_acc: 0.5265 - val_loss: 3.4448 - val_VL_attention_linear_output_loss: 1.7261 - val_VH_attention_linear_output_loss: 1.7188 - val_VL_attention_linear_output_acc: 0.5048 - val_VH_attention_linear_output_acc: 0.5074\n",
      "Epoch 4630/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2853 - VL_attention_linear_output_loss: 1.6399 - VH_attention_linear_output_loss: 1.6454 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4407 - val_VL_attention_linear_output_loss: 1.7199 - val_VH_attention_linear_output_loss: 1.7207 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.5065\n",
      "Epoch 4631/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2806 - VL_attention_linear_output_loss: 1.6427 - VH_attention_linear_output_loss: 1.6379 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5250 - val_loss: 3.4691 - val_VL_attention_linear_output_loss: 1.7307 - val_VH_attention_linear_output_loss: 1.7384 - val_VL_attention_linear_output_acc: 0.4914 - val_VH_attention_linear_output_acc: 0.4993\n",
      "Epoch 4632/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2898 - VL_attention_linear_output_loss: 1.6481 - VH_attention_linear_output_loss: 1.6417 - VL_attention_linear_output_acc: 0.5109 - VH_attention_linear_output_acc: 0.5241 - val_loss: 3.4366 - val_VL_attention_linear_output_loss: 1.7236 - val_VH_attention_linear_output_loss: 1.7130 - val_VL_attention_linear_output_acc: 0.5018 - val_VH_attention_linear_output_acc: 0.5064\n",
      "Epoch 4633/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3028 - VL_attention_linear_output_loss: 1.6546 - VH_attention_linear_output_loss: 1.6482 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5214 - val_loss: 3.4823 - val_VL_attention_linear_output_loss: 1.7407 - val_VH_attention_linear_output_loss: 1.7416 - val_VL_attention_linear_output_acc: 0.4882 - val_VH_attention_linear_output_acc: 0.4983\n",
      "Epoch 4634/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3263 - VL_attention_linear_output_loss: 1.6709 - VH_attention_linear_output_loss: 1.6554 - VL_attention_linear_output_acc: 0.5029 - VH_attention_linear_output_acc: 0.5190 - val_loss: 3.4474 - val_VL_attention_linear_output_loss: 1.7192 - val_VH_attention_linear_output_loss: 1.7282 - val_VL_attention_linear_output_acc: 0.4995 - val_VH_attention_linear_output_acc: 0.5053\n",
      "Epoch 4635/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2810 - VL_attention_linear_output_loss: 1.6360 - VH_attention_linear_output_loss: 1.6449 - VL_attention_linear_output_acc: 0.5151 - VH_attention_linear_output_acc: 0.5222 - val_loss: 3.4360 - val_VL_attention_linear_output_loss: 1.7268 - val_VH_attention_linear_output_loss: 1.7092 - val_VL_attention_linear_output_acc: 0.4891 - val_VH_attention_linear_output_acc: 0.5091\n",
      "Epoch 4636/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2864 - VL_attention_linear_output_loss: 1.6491 - VH_attention_linear_output_loss: 1.6373 - VL_attention_linear_output_acc: 0.5102 - VH_attention_linear_output_acc: 0.5252 - val_loss: 3.4403 - val_VL_attention_linear_output_loss: 1.7240 - val_VH_attention_linear_output_loss: 1.7163 - val_VL_attention_linear_output_acc: 0.5056 - val_VH_attention_linear_output_acc: 0.5082\n",
      "Epoch 4637/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2756 - VL_attention_linear_output_loss: 1.6346 - VH_attention_linear_output_loss: 1.6409 - VL_attention_linear_output_acc: 0.5159 - VH_attention_linear_output_acc: 0.5242 - val_loss: 3.4365 - val_VL_attention_linear_output_loss: 1.7238 - val_VH_attention_linear_output_loss: 1.7128 - val_VL_attention_linear_output_acc: 0.5016 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4638/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2963 - VL_attention_linear_output_loss: 1.6425 - VH_attention_linear_output_loss: 1.6538 - VL_attention_linear_output_acc: 0.5128 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.4661 - val_VL_attention_linear_output_loss: 1.7550 - val_VH_attention_linear_output_loss: 1.7111 - val_VL_attention_linear_output_acc: 0.4821 - val_VH_attention_linear_output_acc: 0.5120\n",
      "Epoch 4639/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2897 - VL_attention_linear_output_loss: 1.6474 - VH_attention_linear_output_loss: 1.6423 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4416 - val_VL_attention_linear_output_loss: 1.7219 - val_VH_attention_linear_output_loss: 1.7197 - val_VL_attention_linear_output_acc: 0.4935 - val_VH_attention_linear_output_acc: 0.5065\n",
      "Epoch 4640/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2873 - VL_attention_linear_output_loss: 1.6459 - VH_attention_linear_output_loss: 1.6414 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5236 - val_loss: 3.4261 - val_VL_attention_linear_output_loss: 1.7181 - val_VH_attention_linear_output_loss: 1.7080 - val_VL_attention_linear_output_acc: 0.5001 - val_VH_attention_linear_output_acc: 0.5069\n",
      "Epoch 4641/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2896 - VL_attention_linear_output_loss: 1.6492 - VH_attention_linear_output_loss: 1.6404 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5242 - val_loss: 3.4470 - val_VL_attention_linear_output_loss: 1.7235 - val_VH_attention_linear_output_loss: 1.7235 - val_VL_attention_linear_output_acc: 0.4999 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4642/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2903 - VL_attention_linear_output_loss: 1.6409 - VH_attention_linear_output_loss: 1.6493 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5212 - val_loss: 3.4358 - val_VL_attention_linear_output_loss: 1.7159 - val_VH_attention_linear_output_loss: 1.7199 - val_VL_attention_linear_output_acc: 0.5012 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4643/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2865 - VL_attention_linear_output_loss: 1.6401 - VH_attention_linear_output_loss: 1.6465 - VL_attention_linear_output_acc: 0.5140 - VH_attention_linear_output_acc: 0.5215 - val_loss: 3.4239 - val_VL_attention_linear_output_loss: 1.7121 - val_VH_attention_linear_output_loss: 1.7119 - val_VL_attention_linear_output_acc: 0.5007 - val_VH_attention_linear_output_acc: 0.5096\n",
      "Epoch 4644/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2851 - VL_attention_linear_output_loss: 1.6392 - VH_attention_linear_output_loss: 1.6458 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5217 - val_loss: 3.4187 - val_VL_attention_linear_output_loss: 1.7092 - val_VH_attention_linear_output_loss: 1.7096 - val_VL_attention_linear_output_acc: 0.5054 - val_VH_attention_linear_output_acc: 0.5089\n",
      "Epoch 4645/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2811 - VL_attention_linear_output_loss: 1.6398 - VH_attention_linear_output_loss: 1.6413 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5239 - val_loss: 3.4401 - val_VL_attention_linear_output_loss: 1.7192 - val_VH_attention_linear_output_loss: 1.7209 - val_VL_attention_linear_output_acc: 0.5045 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4646/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2891 - VL_attention_linear_output_loss: 1.6503 - VH_attention_linear_output_loss: 1.6388 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5246 - val_loss: 3.4548 - val_VL_attention_linear_output_loss: 1.7304 - val_VH_attention_linear_output_loss: 1.7244 - val_VL_attention_linear_output_acc: 0.5017 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4647/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2779 - VL_attention_linear_output_loss: 1.6369 - VH_attention_linear_output_loss: 1.6410 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5242 - val_loss: 3.4442 - val_VL_attention_linear_output_loss: 1.7201 - val_VH_attention_linear_output_loss: 1.7240 - val_VL_attention_linear_output_acc: 0.5002 - val_VH_attention_linear_output_acc: 0.5064\n",
      "Epoch 4648/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2863 - VL_attention_linear_output_loss: 1.6438 - VH_attention_linear_output_loss: 1.6426 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4430 - val_VL_attention_linear_output_loss: 1.7258 - val_VH_attention_linear_output_loss: 1.7172 - val_VL_attention_linear_output_acc: 0.4998 - val_VH_attention_linear_output_acc: 0.5085\n",
      "Epoch 4649/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2913 - VL_attention_linear_output_loss: 1.6463 - VH_attention_linear_output_loss: 1.6450 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5224 - val_loss: 3.4379 - val_VL_attention_linear_output_loss: 1.7142 - val_VH_attention_linear_output_loss: 1.7237 - val_VL_attention_linear_output_acc: 0.4999 - val_VH_attention_linear_output_acc: 0.5044\n",
      "Epoch 4650/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2973 - VL_attention_linear_output_loss: 1.6481 - VH_attention_linear_output_loss: 1.6492 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5216 - val_loss: 3.4270 - val_VL_attention_linear_output_loss: 1.7150 - val_VH_attention_linear_output_loss: 1.7119 - val_VL_attention_linear_output_acc: 0.5012 - val_VH_attention_linear_output_acc: 0.5098\n",
      "Epoch 4651/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2898 - VL_attention_linear_output_loss: 1.6455 - VH_attention_linear_output_loss: 1.6443 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5229 - val_loss: 3.5016 - val_VL_attention_linear_output_loss: 1.7205 - val_VH_attention_linear_output_loss: 1.7810 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.4907\n",
      "Epoch 4652/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2853 - VL_attention_linear_output_loss: 1.6404 - VH_attention_linear_output_loss: 1.6449 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4310 - val_VL_attention_linear_output_loss: 1.7173 - val_VH_attention_linear_output_loss: 1.7137 - val_VL_attention_linear_output_acc: 0.4989 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4653/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2853 - VL_attention_linear_output_loss: 1.6473 - VH_attention_linear_output_loss: 1.6380 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5256 - val_loss: 3.4204 - val_VL_attention_linear_output_loss: 1.7090 - val_VH_attention_linear_output_loss: 1.7114 - val_VL_attention_linear_output_acc: 0.5055 - val_VH_attention_linear_output_acc: 0.5078\n",
      "Epoch 4654/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2808 - VL_attention_linear_output_loss: 1.6334 - VH_attention_linear_output_loss: 1.6474 - VL_attention_linear_output_acc: 0.5161 - VH_attention_linear_output_acc: 0.5217 - val_loss: 3.4336 - val_VL_attention_linear_output_loss: 1.7165 - val_VH_attention_linear_output_loss: 1.7171 - val_VL_attention_linear_output_acc: 0.5060 - val_VH_attention_linear_output_acc: 0.5087\n",
      "Epoch 4655/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2840 - VL_attention_linear_output_loss: 1.6400 - VH_attention_linear_output_loss: 1.6440 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4641 - val_VL_attention_linear_output_loss: 1.7213 - val_VH_attention_linear_output_loss: 1.7427 - val_VL_attention_linear_output_acc: 0.4932 - val_VH_attention_linear_output_acc: 0.4939\n",
      "Epoch 4656/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3016 - VL_attention_linear_output_loss: 1.6414 - VH_attention_linear_output_loss: 1.6601 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5176 - val_loss: 3.4333 - val_VL_attention_linear_output_loss: 1.7170 - val_VH_attention_linear_output_loss: 1.7163 - val_VL_attention_linear_output_acc: 0.4997 - val_VH_attention_linear_output_acc: 0.5067\n",
      "Epoch 4657/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2863 - VL_attention_linear_output_loss: 1.6443 - VH_attention_linear_output_loss: 1.6420 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5238 - val_loss: 3.4302 - val_VL_attention_linear_output_loss: 1.7167 - val_VH_attention_linear_output_loss: 1.7136 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5080\n",
      "Epoch 4658/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2809 - VL_attention_linear_output_loss: 1.6407 - VH_attention_linear_output_loss: 1.6402 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4316 - val_VL_attention_linear_output_loss: 1.7199 - val_VH_attention_linear_output_loss: 1.7116 - val_VL_attention_linear_output_acc: 0.4998 - val_VH_attention_linear_output_acc: 0.5072\n",
      "Epoch 4659/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2821 - VL_attention_linear_output_loss: 1.6436 - VH_attention_linear_output_loss: 1.6384 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5251 - val_loss: 3.4441 - val_VL_attention_linear_output_loss: 1.7147 - val_VH_attention_linear_output_loss: 1.7294 - val_VL_attention_linear_output_acc: 0.5026 - val_VH_attention_linear_output_acc: 0.5044\n",
      "Epoch 4660/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3084 - VL_attention_linear_output_loss: 1.6501 - VH_attention_linear_output_loss: 1.6583 - VL_attention_linear_output_acc: 0.5096 - VH_attention_linear_output_acc: 0.5174 - val_loss: 3.4387 - val_VL_attention_linear_output_loss: 1.7132 - val_VH_attention_linear_output_loss: 1.7255 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5059\n",
      "Epoch 4661/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2825 - VL_attention_linear_output_loss: 1.6412 - VH_attention_linear_output_loss: 1.6414 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5235 - val_loss: 3.4388 - val_VL_attention_linear_output_loss: 1.7238 - val_VH_attention_linear_output_loss: 1.7151 - val_VL_attention_linear_output_acc: 0.5001 - val_VH_attention_linear_output_acc: 0.5106\n",
      "Epoch 4662/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2917 - VL_attention_linear_output_loss: 1.6469 - VH_attention_linear_output_loss: 1.6448 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5224 - val_loss: 3.4988 - val_VL_attention_linear_output_loss: 1.7186 - val_VH_attention_linear_output_loss: 1.7802 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.4903\n",
      "Epoch 4663/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3116 - VL_attention_linear_output_loss: 1.6548 - VH_attention_linear_output_loss: 1.6568 - VL_attention_linear_output_acc: 0.5084 - VH_attention_linear_output_acc: 0.5186 - val_loss: 3.4300 - val_VL_attention_linear_output_loss: 1.7188 - val_VH_attention_linear_output_loss: 1.7112 - val_VL_attention_linear_output_acc: 0.4922 - val_VH_attention_linear_output_acc: 0.5091\n",
      "Epoch 4664/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2858 - VL_attention_linear_output_loss: 1.6387 - VH_attention_linear_output_loss: 1.6471 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5217 - val_loss: 3.4507 - val_VL_attention_linear_output_loss: 1.7146 - val_VH_attention_linear_output_loss: 1.7361 - val_VL_attention_linear_output_acc: 0.5019 - val_VH_attention_linear_output_acc: 0.5037\n",
      "Epoch 4665/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2880 - VL_attention_linear_output_loss: 1.6429 - VH_attention_linear_output_loss: 1.6452 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4329 - val_VL_attention_linear_output_loss: 1.7218 - val_VH_attention_linear_output_loss: 1.7111 - val_VL_attention_linear_output_acc: 0.5040 - val_VH_attention_linear_output_acc: 0.5108\n",
      "Epoch 4666/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2846 - VL_attention_linear_output_loss: 1.6440 - VH_attention_linear_output_loss: 1.6406 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5241 - val_loss: 3.4790 - val_VL_attention_linear_output_loss: 1.7465 - val_VH_attention_linear_output_loss: 1.7325 - val_VL_attention_linear_output_acc: 0.4935 - val_VH_attention_linear_output_acc: 0.5001\n",
      "Epoch 4667/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2835 - VL_attention_linear_output_loss: 1.6444 - VH_attention_linear_output_loss: 1.6391 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5243 - val_loss: 3.4363 - val_VL_attention_linear_output_loss: 1.7292 - val_VH_attention_linear_output_loss: 1.7071 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.5110\n",
      "Epoch 4668/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2930 - VL_attention_linear_output_loss: 1.6465 - VH_attention_linear_output_loss: 1.6466 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5221 - val_loss: 3.4400 - val_VL_attention_linear_output_loss: 1.7191 - val_VH_attention_linear_output_loss: 1.7210 - val_VL_attention_linear_output_acc: 0.5002 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4669/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2780 - VL_attention_linear_output_loss: 1.6424 - VH_attention_linear_output_loss: 1.6355 - VL_attention_linear_output_acc: 0.5128 - VH_attention_linear_output_acc: 0.5262 - val_loss: 3.4450 - val_VL_attention_linear_output_loss: 1.7282 - val_VH_attention_linear_output_loss: 1.7167 - val_VL_attention_linear_output_acc: 0.4961 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 4670/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2852 - VL_attention_linear_output_loss: 1.6473 - VH_attention_linear_output_loss: 1.6379 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5248 - val_loss: 3.4653 - val_VL_attention_linear_output_loss: 1.7421 - val_VH_attention_linear_output_loss: 1.7231 - val_VL_attention_linear_output_acc: 0.4768 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4671/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2893 - VL_attention_linear_output_loss: 1.6396 - VH_attention_linear_output_loss: 1.6497 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5208 - val_loss: 3.4824 - val_VL_attention_linear_output_loss: 1.7298 - val_VH_attention_linear_output_loss: 1.7527 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.4894\n",
      "Epoch 4672/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2790 - VL_attention_linear_output_loss: 1.6373 - VH_attention_linear_output_loss: 1.6418 - VL_attention_linear_output_acc: 0.5155 - VH_attention_linear_output_acc: 0.5238 - val_loss: 3.4624 - val_VL_attention_linear_output_loss: 1.7490 - val_VH_attention_linear_output_loss: 1.7134 - val_VL_attention_linear_output_acc: 0.4997 - val_VH_attention_linear_output_acc: 0.5092\n",
      "Epoch 4673/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2848 - VL_attention_linear_output_loss: 1.6469 - VH_attention_linear_output_loss: 1.6379 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5252 - val_loss: 3.4477 - val_VL_attention_linear_output_loss: 1.7356 - val_VH_attention_linear_output_loss: 1.7122 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.5091\n",
      "Epoch 4674/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2928 - VL_attention_linear_output_loss: 1.6438 - VH_attention_linear_output_loss: 1.6491 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5214 - val_loss: 3.4234 - val_VL_attention_linear_output_loss: 1.7140 - val_VH_attention_linear_output_loss: 1.7094 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.5136\n",
      "Epoch 4675/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2838 - VL_attention_linear_output_loss: 1.6364 - VH_attention_linear_output_loss: 1.6474 - VL_attention_linear_output_acc: 0.5148 - VH_attention_linear_output_acc: 0.5223 - val_loss: 3.4318 - val_VL_attention_linear_output_loss: 1.7168 - val_VH_attention_linear_output_loss: 1.7150 - val_VL_attention_linear_output_acc: 0.5007 - val_VH_attention_linear_output_acc: 0.5095\n",
      "Epoch 4676/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2880 - VL_attention_linear_output_loss: 1.6418 - VH_attention_linear_output_loss: 1.6462 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4682 - val_VL_attention_linear_output_loss: 1.7412 - val_VH_attention_linear_output_loss: 1.7270 - val_VL_attention_linear_output_acc: 0.4781 - val_VH_attention_linear_output_acc: 0.5003\n",
      "Epoch 4677/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2791 - VL_attention_linear_output_loss: 1.6395 - VH_attention_linear_output_loss: 1.6396 - VL_attention_linear_output_acc: 0.5140 - VH_attention_linear_output_acc: 0.5247 - val_loss: 3.4237 - val_VL_attention_linear_output_loss: 1.7102 - val_VH_attention_linear_output_loss: 1.7135 - val_VL_attention_linear_output_acc: 0.5053 - val_VH_attention_linear_output_acc: 0.5035\n",
      "Epoch 4678/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2931 - VL_attention_linear_output_loss: 1.6494 - VH_attention_linear_output_loss: 1.6437 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.4722 - val_VL_attention_linear_output_loss: 1.7267 - val_VH_attention_linear_output_loss: 1.7455 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.4976\n",
      "Epoch 4679/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2865 - VL_attention_linear_output_loss: 1.6476 - VH_attention_linear_output_loss: 1.6389 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5248 - val_loss: 3.4630 - val_VL_attention_linear_output_loss: 1.7381 - val_VH_attention_linear_output_loss: 1.7249 - val_VL_attention_linear_output_acc: 0.4932 - val_VH_attention_linear_output_acc: 0.5067\n",
      "Epoch 4680/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3061 - VL_attention_linear_output_loss: 1.6623 - VH_attention_linear_output_loss: 1.6439 - VL_attention_linear_output_acc: 0.5053 - VH_attention_linear_output_acc: 0.5230 - val_loss: 3.4399 - val_VL_attention_linear_output_loss: 1.7186 - val_VH_attention_linear_output_loss: 1.7213 - val_VL_attention_linear_output_acc: 0.5019 - val_VH_attention_linear_output_acc: 0.5062\n",
      "Epoch 4681/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2827 - VL_attention_linear_output_loss: 1.6450 - VH_attention_linear_output_loss: 1.6376 - VL_attention_linear_output_acc: 0.5120 - VH_attention_linear_output_acc: 0.5249 - val_loss: 3.4347 - val_VL_attention_linear_output_loss: 1.7232 - val_VH_attention_linear_output_loss: 1.7115 - val_VL_attention_linear_output_acc: 0.4997 - val_VH_attention_linear_output_acc: 0.5115\n",
      "Epoch 4682/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2879 - VL_attention_linear_output_loss: 1.6516 - VH_attention_linear_output_loss: 1.6362 - VL_attention_linear_output_acc: 0.5092 - VH_attention_linear_output_acc: 0.5257 - val_loss: 3.4243 - val_VL_attention_linear_output_loss: 1.7123 - val_VH_attention_linear_output_loss: 1.7120 - val_VL_attention_linear_output_acc: 0.5001 - val_VH_attention_linear_output_acc: 0.5075\n",
      "Epoch 4683/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2759 - VL_attention_linear_output_loss: 1.6363 - VH_attention_linear_output_loss: 1.6395 - VL_attention_linear_output_acc: 0.5147 - VH_attention_linear_output_acc: 0.5244 - val_loss: 3.4452 - val_VL_attention_linear_output_loss: 1.7121 - val_VH_attention_linear_output_loss: 1.7331 - val_VL_attention_linear_output_acc: 0.5044 - val_VH_attention_linear_output_acc: 0.5001\n",
      "Epoch 4684/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2925 - VL_attention_linear_output_loss: 1.6476 - VH_attention_linear_output_loss: 1.6449 - VL_attention_linear_output_acc: 0.5109 - VH_attention_linear_output_acc: 0.5230 - val_loss: 3.4271 - val_VL_attention_linear_output_loss: 1.7174 - val_VH_attention_linear_output_loss: 1.7097 - val_VL_attention_linear_output_acc: 0.5026 - val_VH_attention_linear_output_acc: 0.5093\n",
      "Epoch 4685/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2851 - VL_attention_linear_output_loss: 1.6410 - VH_attention_linear_output_loss: 1.6441 - VL_attention_linear_output_acc: 0.5128 - VH_attention_linear_output_acc: 0.5228 - val_loss: 3.4274 - val_VL_attention_linear_output_loss: 1.7187 - val_VH_attention_linear_output_loss: 1.7087 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.5115\n",
      "Epoch 4686/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2843 - VL_attention_linear_output_loss: 1.6433 - VH_attention_linear_output_loss: 1.6410 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5239 - val_loss: 3.4335 - val_VL_attention_linear_output_loss: 1.7196 - val_VH_attention_linear_output_loss: 1.7138 - val_VL_attention_linear_output_acc: 0.4961 - val_VH_attention_linear_output_acc: 0.5092\n",
      "Epoch 4687/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2819 - VL_attention_linear_output_loss: 1.6453 - VH_attention_linear_output_loss: 1.6366 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5254 - val_loss: 3.4418 - val_VL_attention_linear_output_loss: 1.7226 - val_VH_attention_linear_output_loss: 1.7192 - val_VL_attention_linear_output_acc: 0.5011 - val_VH_attention_linear_output_acc: 0.5053\n",
      "Epoch 4688/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2883 - VL_attention_linear_output_loss: 1.6409 - VH_attention_linear_output_loss: 1.6474 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5209 - val_loss: 3.4301 - val_VL_attention_linear_output_loss: 1.7210 - val_VH_attention_linear_output_loss: 1.7091 - val_VL_attention_linear_output_acc: 0.5025 - val_VH_attention_linear_output_acc: 0.5093\n",
      "Epoch 4689/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2898 - VL_attention_linear_output_loss: 1.6456 - VH_attention_linear_output_loss: 1.6442 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5232 - val_loss: 3.4412 - val_VL_attention_linear_output_loss: 1.7239 - val_VH_attention_linear_output_loss: 1.7174 - val_VL_attention_linear_output_acc: 0.4942 - val_VH_attention_linear_output_acc: 0.5062\n",
      "Epoch 4690/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2899 - VL_attention_linear_output_loss: 1.6438 - VH_attention_linear_output_loss: 1.6461 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4282 - val_VL_attention_linear_output_loss: 1.7130 - val_VH_attention_linear_output_loss: 1.7152 - val_VL_attention_linear_output_acc: 0.5030 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4691/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2793 - VL_attention_linear_output_loss: 1.6405 - VH_attention_linear_output_loss: 1.6388 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5251 - val_loss: 3.4289 - val_VL_attention_linear_output_loss: 1.7119 - val_VH_attention_linear_output_loss: 1.7169 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4692/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2806 - VL_attention_linear_output_loss: 1.6363 - VH_attention_linear_output_loss: 1.6443 - VL_attention_linear_output_acc: 0.5146 - VH_attention_linear_output_acc: 0.5226 - val_loss: 3.4389 - val_VL_attention_linear_output_loss: 1.7188 - val_VH_attention_linear_output_loss: 1.7201 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.5067\n",
      "Epoch 4693/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2956 - VL_attention_linear_output_loss: 1.6478 - VH_attention_linear_output_loss: 1.6478 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5207 - val_loss: 3.4430 - val_VL_attention_linear_output_loss: 1.7224 - val_VH_attention_linear_output_loss: 1.7206 - val_VL_attention_linear_output_acc: 0.4930 - val_VH_attention_linear_output_acc: 0.5078\n",
      "Epoch 4694/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2664 - VL_attention_linear_output_loss: 1.6330 - VH_attention_linear_output_loss: 1.6334 - VL_attention_linear_output_acc: 0.5167 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4402 - val_VL_attention_linear_output_loss: 1.7256 - val_VH_attention_linear_output_loss: 1.7146 - val_VL_attention_linear_output_acc: 0.4924 - val_VH_attention_linear_output_acc: 0.5062\n",
      "Epoch 4695/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2738 - VL_attention_linear_output_loss: 1.6398 - VH_attention_linear_output_loss: 1.6341 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5261 - val_loss: 3.4286 - val_VL_attention_linear_output_loss: 1.7183 - val_VH_attention_linear_output_loss: 1.7103 - val_VL_attention_linear_output_acc: 0.5007 - val_VH_attention_linear_output_acc: 0.5103\n",
      "Epoch 4696/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2901 - VL_attention_linear_output_loss: 1.6548 - VH_attention_linear_output_loss: 1.6353 - VL_attention_linear_output_acc: 0.5086 - VH_attention_linear_output_acc: 0.5262 - val_loss: 3.4201 - val_VL_attention_linear_output_loss: 1.7135 - val_VH_attention_linear_output_loss: 1.7066 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.5126\n",
      "Epoch 4697/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2926 - VL_attention_linear_output_loss: 1.6507 - VH_attention_linear_output_loss: 1.6418 - VL_attention_linear_output_acc: 0.5088 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.4231 - val_VL_attention_linear_output_loss: 1.7124 - val_VH_attention_linear_output_loss: 1.7106 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.5102\n",
      "Epoch 4698/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2695 - VL_attention_linear_output_loss: 1.6338 - VH_attention_linear_output_loss: 1.6357 - VL_attention_linear_output_acc: 0.5153 - VH_attention_linear_output_acc: 0.5261 - val_loss: 3.4430 - val_VL_attention_linear_output_loss: 1.7292 - val_VH_attention_linear_output_loss: 1.7138 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.5085\n",
      "Epoch 4699/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2866 - VL_attention_linear_output_loss: 1.6399 - VH_attention_linear_output_loss: 1.6467 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5222 - val_loss: 3.4298 - val_VL_attention_linear_output_loss: 1.7206 - val_VH_attention_linear_output_loss: 1.7092 - val_VL_attention_linear_output_acc: 0.5006 - val_VH_attention_linear_output_acc: 0.5088\n",
      "Epoch 4700/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2810 - VL_attention_linear_output_loss: 1.6433 - VH_attention_linear_output_loss: 1.6377 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5250 - val_loss: 3.4514 - val_VL_attention_linear_output_loss: 1.7297 - val_VH_attention_linear_output_loss: 1.7217 - val_VL_attention_linear_output_acc: 0.4996 - val_VH_attention_linear_output_acc: 0.5092\n",
      "Epoch 4701/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2798 - VL_attention_linear_output_loss: 1.6419 - VH_attention_linear_output_loss: 1.6379 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5255 - val_loss: 3.4402 - val_VL_attention_linear_output_loss: 1.7156 - val_VH_attention_linear_output_loss: 1.7246 - val_VL_attention_linear_output_acc: 0.5017 - val_VH_attention_linear_output_acc: 0.5056\n",
      "Epoch 4702/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2905 - VL_attention_linear_output_loss: 1.6447 - VH_attention_linear_output_loss: 1.6458 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5224 - val_loss: 3.4407 - val_VL_attention_linear_output_loss: 1.7161 - val_VH_attention_linear_output_loss: 1.7245 - val_VL_attention_linear_output_acc: 0.5036 - val_VH_attention_linear_output_acc: 0.5036\n",
      "Epoch 4703/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2858 - VL_attention_linear_output_loss: 1.6392 - VH_attention_linear_output_loss: 1.6466 - VL_attention_linear_output_acc: 0.5136 - VH_attention_linear_output_acc: 0.5216 - val_loss: 3.4435 - val_VL_attention_linear_output_loss: 1.7177 - val_VH_attention_linear_output_loss: 1.7258 - val_VL_attention_linear_output_acc: 0.5034 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4704/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2777 - VL_attention_linear_output_loss: 1.6413 - VH_attention_linear_output_loss: 1.6364 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5260 - val_loss: 3.4373 - val_VL_attention_linear_output_loss: 1.7172 - val_VH_attention_linear_output_loss: 1.7201 - val_VL_attention_linear_output_acc: 0.5032 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 4705/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2748 - VL_attention_linear_output_loss: 1.6385 - VH_attention_linear_output_loss: 1.6363 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5262 - val_loss: 3.4838 - val_VL_attention_linear_output_loss: 1.7183 - val_VH_attention_linear_output_loss: 1.7655 - val_VL_attention_linear_output_acc: 0.4999 - val_VH_attention_linear_output_acc: 0.4930\n",
      "Epoch 4706/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3007 - VL_attention_linear_output_loss: 1.6520 - VH_attention_linear_output_loss: 1.6487 - VL_attention_linear_output_acc: 0.5091 - VH_attention_linear_output_acc: 0.5211 - val_loss: 3.4382 - val_VL_attention_linear_output_loss: 1.7139 - val_VH_attention_linear_output_loss: 1.7242 - val_VL_attention_linear_output_acc: 0.4998 - val_VH_attention_linear_output_acc: 0.5038\n",
      "Epoch 4707/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2778 - VL_attention_linear_output_loss: 1.6382 - VH_attention_linear_output_loss: 1.6396 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5251 - val_loss: 3.4567 - val_VL_attention_linear_output_loss: 1.7321 - val_VH_attention_linear_output_loss: 1.7246 - val_VL_attention_linear_output_acc: 0.4975 - val_VH_attention_linear_output_acc: 0.5029\n",
      "Epoch 4708/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2784 - VL_attention_linear_output_loss: 1.6444 - VH_attention_linear_output_loss: 1.6340 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5262 - val_loss: 3.4333 - val_VL_attention_linear_output_loss: 1.7232 - val_VH_attention_linear_output_loss: 1.7101 - val_VL_attention_linear_output_acc: 0.4965 - val_VH_attention_linear_output_acc: 0.5088\n",
      "Epoch 4709/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2893 - VL_attention_linear_output_loss: 1.6438 - VH_attention_linear_output_loss: 1.6455 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4237 - val_VL_attention_linear_output_loss: 1.7109 - val_VH_attention_linear_output_loss: 1.7129 - val_VL_attention_linear_output_acc: 0.5018 - val_VH_attention_linear_output_acc: 0.5106\n",
      "Epoch 4710/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2819 - VL_attention_linear_output_loss: 1.6379 - VH_attention_linear_output_loss: 1.6440 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5228 - val_loss: 3.4645 - val_VL_attention_linear_output_loss: 1.7204 - val_VH_attention_linear_output_loss: 1.7441 - val_VL_attention_linear_output_acc: 0.4988 - val_VH_attention_linear_output_acc: 0.4996\n",
      "Epoch 4711/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2852 - VL_attention_linear_output_loss: 1.6423 - VH_attention_linear_output_loss: 1.6430 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.4415 - val_VL_attention_linear_output_loss: 1.7223 - val_VH_attention_linear_output_loss: 1.7192 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4712/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2804 - VL_attention_linear_output_loss: 1.6426 - VH_attention_linear_output_loss: 1.6379 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5248 - val_loss: 3.4365 - val_VL_attention_linear_output_loss: 1.7173 - val_VH_attention_linear_output_loss: 1.7191 - val_VL_attention_linear_output_acc: 0.5007 - val_VH_attention_linear_output_acc: 0.5086\n",
      "Epoch 4713/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2871 - VL_attention_linear_output_loss: 1.6458 - VH_attention_linear_output_loss: 1.6413 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5239 - val_loss: 3.4570 - val_VL_attention_linear_output_loss: 1.7217 - val_VH_attention_linear_output_loss: 1.7352 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.4989\n",
      "Epoch 4714/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2939 - VL_attention_linear_output_loss: 1.6429 - VH_attention_linear_output_loss: 1.6510 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5210 - val_loss: 3.4815 - val_VL_attention_linear_output_loss: 1.7550 - val_VH_attention_linear_output_loss: 1.7265 - val_VL_attention_linear_output_acc: 0.4704 - val_VH_attention_linear_output_acc: 0.5059\n",
      "Epoch 4715/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3050 - VL_attention_linear_output_loss: 1.6466 - VH_attention_linear_output_loss: 1.6584 - VL_attention_linear_output_acc: 0.5109 - VH_attention_linear_output_acc: 0.5179 - val_loss: 3.4328 - val_VL_attention_linear_output_loss: 1.7195 - val_VH_attention_linear_output_loss: 1.7133 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.5099\n",
      "Epoch 4716/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2769 - VL_attention_linear_output_loss: 1.6340 - VH_attention_linear_output_loss: 1.6429 - VL_attention_linear_output_acc: 0.5159 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.4547 - val_VL_attention_linear_output_loss: 1.7303 - val_VH_attention_linear_output_loss: 1.7244 - val_VL_attention_linear_output_acc: 0.4859 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4717/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2845 - VL_attention_linear_output_loss: 1.6374 - VH_attention_linear_output_loss: 1.6471 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4376 - val_VL_attention_linear_output_loss: 1.7257 - val_VH_attention_linear_output_loss: 1.7119 - val_VL_attention_linear_output_acc: 0.4936 - val_VH_attention_linear_output_acc: 0.5078\n",
      "Epoch 4718/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2873 - VL_attention_linear_output_loss: 1.6434 - VH_attention_linear_output_loss: 1.6439 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5228 - val_loss: 3.4353 - val_VL_attention_linear_output_loss: 1.7184 - val_VH_attention_linear_output_loss: 1.7169 - val_VL_attention_linear_output_acc: 0.5004 - val_VH_attention_linear_output_acc: 0.5069\n",
      "Epoch 4719/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2727 - VL_attention_linear_output_loss: 1.6365 - VH_attention_linear_output_loss: 1.6362 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5259 - val_loss: 3.4204 - val_VL_attention_linear_output_loss: 1.7166 - val_VH_attention_linear_output_loss: 1.7038 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.5111\n",
      "Epoch 4720/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3048 - VL_attention_linear_output_loss: 1.6508 - VH_attention_linear_output_loss: 1.6540 - VL_attention_linear_output_acc: 0.5098 - VH_attention_linear_output_acc: 0.5195 - val_loss: 3.4238 - val_VL_attention_linear_output_loss: 1.7144 - val_VH_attention_linear_output_loss: 1.7094 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.5096\n",
      "Epoch 4721/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2709 - VL_attention_linear_output_loss: 1.6341 - VH_attention_linear_output_loss: 1.6367 - VL_attention_linear_output_acc: 0.5157 - VH_attention_linear_output_acc: 0.5255 - val_loss: 3.4308 - val_VL_attention_linear_output_loss: 1.7115 - val_VH_attention_linear_output_loss: 1.7194 - val_VL_attention_linear_output_acc: 0.4989 - val_VH_attention_linear_output_acc: 0.5083\n",
      "Epoch 4722/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2762 - VL_attention_linear_output_loss: 1.6381 - VH_attention_linear_output_loss: 1.6381 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5242 - val_loss: 3.4275 - val_VL_attention_linear_output_loss: 1.7140 - val_VH_attention_linear_output_loss: 1.7135 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5069\n",
      "Epoch 4723/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2770 - VL_attention_linear_output_loss: 1.6415 - VH_attention_linear_output_loss: 1.6355 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5260 - val_loss: 3.4601 - val_VL_attention_linear_output_loss: 1.7267 - val_VH_attention_linear_output_loss: 1.7334 - val_VL_attention_linear_output_acc: 0.4920 - val_VH_attention_linear_output_acc: 0.5022\n",
      "Epoch 4724/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2991 - VL_attention_linear_output_loss: 1.6465 - VH_attention_linear_output_loss: 1.6526 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5197 - val_loss: 3.4264 - val_VL_attention_linear_output_loss: 1.7178 - val_VH_attention_linear_output_loss: 1.7086 - val_VL_attention_linear_output_acc: 0.5012 - val_VH_attention_linear_output_acc: 0.5077\n",
      "Epoch 4725/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2798 - VL_attention_linear_output_loss: 1.6421 - VH_attention_linear_output_loss: 1.6377 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5249 - val_loss: 3.4163 - val_VL_attention_linear_output_loss: 1.7118 - val_VH_attention_linear_output_loss: 1.7045 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5123\n",
      "Epoch 4726/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2789 - VL_attention_linear_output_loss: 1.6435 - VH_attention_linear_output_loss: 1.6353 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5258 - val_loss: 3.4243 - val_VL_attention_linear_output_loss: 1.7150 - val_VH_attention_linear_output_loss: 1.7093 - val_VL_attention_linear_output_acc: 0.5016 - val_VH_attention_linear_output_acc: 0.5095\n",
      "Epoch 4727/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2796 - VL_attention_linear_output_loss: 1.6382 - VH_attention_linear_output_loss: 1.6414 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5237 - val_loss: 3.4477 - val_VL_attention_linear_output_loss: 1.7261 - val_VH_attention_linear_output_loss: 1.7216 - val_VL_attention_linear_output_acc: 0.4882 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4728/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2840 - VL_attention_linear_output_loss: 1.6415 - VH_attention_linear_output_loss: 1.6425 - VL_attention_linear_output_acc: 0.5118 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4184 - val_VL_attention_linear_output_loss: 1.7096 - val_VH_attention_linear_output_loss: 1.7088 - val_VL_attention_linear_output_acc: 0.5036 - val_VH_attention_linear_output_acc: 0.5088\n",
      "Epoch 4729/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2793 - VL_attention_linear_output_loss: 1.6417 - VH_attention_linear_output_loss: 1.6377 - VL_attention_linear_output_acc: 0.5132 - VH_attention_linear_output_acc: 0.5252 - val_loss: 3.4383 - val_VL_attention_linear_output_loss: 1.7225 - val_VH_attention_linear_output_loss: 1.7158 - val_VL_attention_linear_output_acc: 0.4984 - val_VH_attention_linear_output_acc: 0.5082\n",
      "Epoch 4730/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2676 - VL_attention_linear_output_loss: 1.6322 - VH_attention_linear_output_loss: 1.6354 - VL_attention_linear_output_acc: 0.5155 - VH_attention_linear_output_acc: 0.5262 - val_loss: 3.4235 - val_VL_attention_linear_output_loss: 1.7114 - val_VH_attention_linear_output_loss: 1.7121 - val_VL_attention_linear_output_acc: 0.5030 - val_VH_attention_linear_output_acc: 0.5086\n",
      "Epoch 4731/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2745 - VL_attention_linear_output_loss: 1.6354 - VH_attention_linear_output_loss: 1.6391 - VL_attention_linear_output_acc: 0.5148 - VH_attention_linear_output_acc: 0.5243 - val_loss: 3.4399 - val_VL_attention_linear_output_loss: 1.7220 - val_VH_attention_linear_output_loss: 1.7180 - val_VL_attention_linear_output_acc: 0.5015 - val_VH_attention_linear_output_acc: 0.5080\n",
      "Epoch 4732/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2871 - VL_attention_linear_output_loss: 1.6429 - VH_attention_linear_output_loss: 1.6442 - VL_attention_linear_output_acc: 0.5119 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4633 - val_VL_attention_linear_output_loss: 1.7549 - val_VH_attention_linear_output_loss: 1.7085 - val_VL_attention_linear_output_acc: 0.4787 - val_VH_attention_linear_output_acc: 0.5116\n",
      "Epoch 4733/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2765 - VL_attention_linear_output_loss: 1.6436 - VH_attention_linear_output_loss: 1.6329 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5267 - val_loss: 3.4270 - val_VL_attention_linear_output_loss: 1.7107 - val_VH_attention_linear_output_loss: 1.7163 - val_VL_attention_linear_output_acc: 0.5052 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4734/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2710 - VL_attention_linear_output_loss: 1.6363 - VH_attention_linear_output_loss: 1.6347 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5261 - val_loss: 3.4395 - val_VL_attention_linear_output_loss: 1.7227 - val_VH_attention_linear_output_loss: 1.7168 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.5067\n",
      "Epoch 4735/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2758 - VL_attention_linear_output_loss: 1.6423 - VH_attention_linear_output_loss: 1.6336 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5264 - val_loss: 3.4260 - val_VL_attention_linear_output_loss: 1.7132 - val_VH_attention_linear_output_loss: 1.7128 - val_VL_attention_linear_output_acc: 0.4995 - val_VH_attention_linear_output_acc: 0.5084\n",
      "Epoch 4736/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2756 - VL_attention_linear_output_loss: 1.6369 - VH_attention_linear_output_loss: 1.6388 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5239 - val_loss: 3.4323 - val_VL_attention_linear_output_loss: 1.7158 - val_VH_attention_linear_output_loss: 1.7164 - val_VL_attention_linear_output_acc: 0.5045 - val_VH_attention_linear_output_acc: 0.5111\n",
      "Epoch 4737/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2797 - VL_attention_linear_output_loss: 1.6366 - VH_attention_linear_output_loss: 1.6431 - VL_attention_linear_output_acc: 0.5149 - VH_attention_linear_output_acc: 0.5228 - val_loss: 3.4220 - val_VL_attention_linear_output_loss: 1.7113 - val_VH_attention_linear_output_loss: 1.7107 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.5095\n",
      "Epoch 4738/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2686 - VL_attention_linear_output_loss: 1.6358 - VH_attention_linear_output_loss: 1.6328 - VL_attention_linear_output_acc: 0.5147 - VH_attention_linear_output_acc: 0.5267 - val_loss: 3.4422 - val_VL_attention_linear_output_loss: 1.7179 - val_VH_attention_linear_output_loss: 1.7242 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5019\n",
      "Epoch 4739/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2877 - VL_attention_linear_output_loss: 1.6438 - VH_attention_linear_output_loss: 1.6439 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4336 - val_VL_attention_linear_output_loss: 1.7198 - val_VH_attention_linear_output_loss: 1.7138 - val_VL_attention_linear_output_acc: 0.4912 - val_VH_attention_linear_output_acc: 0.5100\n",
      "Epoch 4740/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2778 - VL_attention_linear_output_loss: 1.6442 - VH_attention_linear_output_loss: 1.6337 - VL_attention_linear_output_acc: 0.5109 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4318 - val_VL_attention_linear_output_loss: 1.7228 - val_VH_attention_linear_output_loss: 1.7090 - val_VL_attention_linear_output_acc: 0.5029 - val_VH_attention_linear_output_acc: 0.5123\n",
      "Epoch 4741/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2751 - VL_attention_linear_output_loss: 1.6356 - VH_attention_linear_output_loss: 1.6395 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5246 - val_loss: 3.4708 - val_VL_attention_linear_output_loss: 1.7147 - val_VH_attention_linear_output_loss: 1.7560 - val_VL_attention_linear_output_acc: 0.5058 - val_VH_attention_linear_output_acc: 0.5005\n",
      "Epoch 4742/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2818 - VL_attention_linear_output_loss: 1.6412 - VH_attention_linear_output_loss: 1.6405 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5239 - val_loss: 3.4298 - val_VL_attention_linear_output_loss: 1.7202 - val_VH_attention_linear_output_loss: 1.7096 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.5095\n",
      "Epoch 4743/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2988 - VL_attention_linear_output_loss: 1.6455 - VH_attention_linear_output_loss: 1.6533 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5192 - val_loss: 3.4411 - val_VL_attention_linear_output_loss: 1.7274 - val_VH_attention_linear_output_loss: 1.7137 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.5092\n",
      "Epoch 4744/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2730 - VL_attention_linear_output_loss: 1.6360 - VH_attention_linear_output_loss: 1.6370 - VL_attention_linear_output_acc: 0.5151 - VH_attention_linear_output_acc: 0.5252 - val_loss: 3.4312 - val_VL_attention_linear_output_loss: 1.7190 - val_VH_attention_linear_output_loss: 1.7121 - val_VL_attention_linear_output_acc: 0.4991 - val_VH_attention_linear_output_acc: 0.5083\n",
      "Epoch 4745/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2802 - VL_attention_linear_output_loss: 1.6421 - VH_attention_linear_output_loss: 1.6381 - VL_attention_linear_output_acc: 0.5119 - VH_attention_linear_output_acc: 0.5247 - val_loss: 3.4531 - val_VL_attention_linear_output_loss: 1.7357 - val_VH_attention_linear_output_loss: 1.7173 - val_VL_attention_linear_output_acc: 0.4908 - val_VH_attention_linear_output_acc: 0.5071\n",
      "Epoch 4746/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2847 - VL_attention_linear_output_loss: 1.6385 - VH_attention_linear_output_loss: 1.6462 - VL_attention_linear_output_acc: 0.5129 - VH_attention_linear_output_acc: 0.5215 - val_loss: 3.4278 - val_VL_attention_linear_output_loss: 1.7177 - val_VH_attention_linear_output_loss: 1.7101 - val_VL_attention_linear_output_acc: 0.5035 - val_VH_attention_linear_output_acc: 0.5108\n",
      "Epoch 4747/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2741 - VL_attention_linear_output_loss: 1.6337 - VH_attention_linear_output_loss: 1.6405 - VL_attention_linear_output_acc: 0.5151 - VH_attention_linear_output_acc: 0.5235 - val_loss: 3.4484 - val_VL_attention_linear_output_loss: 1.7255 - val_VH_attention_linear_output_loss: 1.7229 - val_VL_attention_linear_output_acc: 0.4901 - val_VH_attention_linear_output_acc: 0.5021\n",
      "Epoch 4748/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2771 - VL_attention_linear_output_loss: 1.6386 - VH_attention_linear_output_loss: 1.6385 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5249 - val_loss: 3.4264 - val_VL_attention_linear_output_loss: 1.7139 - val_VH_attention_linear_output_loss: 1.7124 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.5093\n",
      "Epoch 4749/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2861 - VL_attention_linear_output_loss: 1.6493 - VH_attention_linear_output_loss: 1.6368 - VL_attention_linear_output_acc: 0.5092 - VH_attention_linear_output_acc: 0.5253 - val_loss: 3.4318 - val_VL_attention_linear_output_loss: 1.7179 - val_VH_attention_linear_output_loss: 1.7140 - val_VL_attention_linear_output_acc: 0.5046 - val_VH_attention_linear_output_acc: 0.5065\n",
      "Epoch 4750/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2823 - VL_attention_linear_output_loss: 1.6394 - VH_attention_linear_output_loss: 1.6429 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.4298 - val_VL_attention_linear_output_loss: 1.7190 - val_VH_attention_linear_output_loss: 1.7108 - val_VL_attention_linear_output_acc: 0.5031 - val_VH_attention_linear_output_acc: 0.5091\n",
      "Epoch 4751/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2782 - VL_attention_linear_output_loss: 1.6356 - VH_attention_linear_output_loss: 1.6427 - VL_attention_linear_output_acc: 0.5156 - VH_attention_linear_output_acc: 0.5232 - val_loss: 3.4456 - val_VL_attention_linear_output_loss: 1.7154 - val_VH_attention_linear_output_loss: 1.7302 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.5009\n",
      "Epoch 4752/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2623 - VL_attention_linear_output_loss: 1.6288 - VH_attention_linear_output_loss: 1.6335 - VL_attention_linear_output_acc: 0.5170 - VH_attention_linear_output_acc: 0.5273 - val_loss: 3.4838 - val_VL_attention_linear_output_loss: 1.7692 - val_VH_attention_linear_output_loss: 1.7145 - val_VL_attention_linear_output_acc: 0.4665 - val_VH_attention_linear_output_acc: 0.5069\n",
      "Epoch 4753/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2738 - VL_attention_linear_output_loss: 1.6326 - VH_attention_linear_output_loss: 1.6411 - VL_attention_linear_output_acc: 0.5156 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4372 - val_VL_attention_linear_output_loss: 1.7171 - val_VH_attention_linear_output_loss: 1.7201 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4754/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2918 - VL_attention_linear_output_loss: 1.6491 - VH_attention_linear_output_loss: 1.6427 - VL_attention_linear_output_acc: 0.5087 - VH_attention_linear_output_acc: 0.5231 - val_loss: 3.4438 - val_VL_attention_linear_output_loss: 1.7173 - val_VH_attention_linear_output_loss: 1.7266 - val_VL_attention_linear_output_acc: 0.4983 - val_VH_attention_linear_output_acc: 0.5049\n",
      "Epoch 4755/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2856 - VL_attention_linear_output_loss: 1.6374 - VH_attention_linear_output_loss: 1.6482 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5211 - val_loss: 3.4810 - val_VL_attention_linear_output_loss: 1.7327 - val_VH_attention_linear_output_loss: 1.7484 - val_VL_attention_linear_output_acc: 0.4894 - val_VH_attention_linear_output_acc: 0.4999\n",
      "Epoch 4756/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2795 - VL_attention_linear_output_loss: 1.6363 - VH_attention_linear_output_loss: 1.6432 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5230 - val_loss: 3.4283 - val_VL_attention_linear_output_loss: 1.7132 - val_VH_attention_linear_output_loss: 1.7151 - val_VL_attention_linear_output_acc: 0.4965 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4757/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2869 - VL_attention_linear_output_loss: 1.6388 - VH_attention_linear_output_loss: 1.6481 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5214 - val_loss: 3.4722 - val_VL_attention_linear_output_loss: 1.7530 - val_VH_attention_linear_output_loss: 1.7192 - val_VL_attention_linear_output_acc: 0.4877 - val_VH_attention_linear_output_acc: 0.5065\n",
      "Epoch 4758/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2859 - VL_attention_linear_output_loss: 1.6516 - VH_attention_linear_output_loss: 1.6343 - VL_attention_linear_output_acc: 0.5085 - VH_attention_linear_output_acc: 0.5262 - val_loss: 3.4324 - val_VL_attention_linear_output_loss: 1.7121 - val_VH_attention_linear_output_loss: 1.7204 - val_VL_attention_linear_output_acc: 0.4988 - val_VH_attention_linear_output_acc: 0.5070\n",
      "Epoch 4759/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2662 - VL_attention_linear_output_loss: 1.6310 - VH_attention_linear_output_loss: 1.6352 - VL_attention_linear_output_acc: 0.5154 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4398 - val_VL_attention_linear_output_loss: 1.7144 - val_VH_attention_linear_output_loss: 1.7254 - val_VL_attention_linear_output_acc: 0.5031 - val_VH_attention_linear_output_acc: 0.5075\n",
      "Epoch 4760/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2774 - VL_attention_linear_output_loss: 1.6448 - VH_attention_linear_output_loss: 1.6326 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5273 - val_loss: 3.4332 - val_VL_attention_linear_output_loss: 1.7192 - val_VH_attention_linear_output_loss: 1.7140 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4761/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2617 - VL_attention_linear_output_loss: 1.6309 - VH_attention_linear_output_loss: 1.6308 - VL_attention_linear_output_acc: 0.5152 - VH_attention_linear_output_acc: 0.5273 - val_loss: 3.4211 - val_VL_attention_linear_output_loss: 1.7108 - val_VH_attention_linear_output_loss: 1.7103 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.5090\n",
      "Epoch 4762/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2936 - VL_attention_linear_output_loss: 1.6465 - VH_attention_linear_output_loss: 1.6471 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4496 - val_VL_attention_linear_output_loss: 1.7350 - val_VH_attention_linear_output_loss: 1.7145 - val_VL_attention_linear_output_acc: 0.4944 - val_VH_attention_linear_output_acc: 0.5094\n",
      "Epoch 4763/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2756 - VL_attention_linear_output_loss: 1.6376 - VH_attention_linear_output_loss: 1.6381 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5246 - val_loss: 3.4353 - val_VL_attention_linear_output_loss: 1.7110 - val_VH_attention_linear_output_loss: 1.7243 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.5089\n",
      "Epoch 4764/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2876 - VL_attention_linear_output_loss: 1.6357 - VH_attention_linear_output_loss: 1.6519 - VL_attention_linear_output_acc: 0.5151 - VH_attention_linear_output_acc: 0.5201 - val_loss: 3.4337 - val_VL_attention_linear_output_loss: 1.7101 - val_VH_attention_linear_output_loss: 1.7236 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.5058\n",
      "Epoch 4765/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2806 - VL_attention_linear_output_loss: 1.6413 - VH_attention_linear_output_loss: 1.6393 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5243 - val_loss: 3.4498 - val_VL_attention_linear_output_loss: 1.7300 - val_VH_attention_linear_output_loss: 1.7198 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4766/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2768 - VL_attention_linear_output_loss: 1.6430 - VH_attention_linear_output_loss: 1.6338 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5270 - val_loss: 3.4619 - val_VL_attention_linear_output_loss: 1.7285 - val_VH_attention_linear_output_loss: 1.7334 - val_VL_attention_linear_output_acc: 0.4985 - val_VH_attention_linear_output_acc: 0.4992\n",
      "Epoch 4767/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2820 - VL_attention_linear_output_loss: 1.6409 - VH_attention_linear_output_loss: 1.6411 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5238 - val_loss: 3.4375 - val_VL_attention_linear_output_loss: 1.7253 - val_VH_attention_linear_output_loss: 1.7122 - val_VL_attention_linear_output_acc: 0.5018 - val_VH_attention_linear_output_acc: 0.5090\n",
      "Epoch 4768/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2822 - VL_attention_linear_output_loss: 1.6440 - VH_attention_linear_output_loss: 1.6381 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5255 - val_loss: 3.4612 - val_VL_attention_linear_output_loss: 1.7350 - val_VH_attention_linear_output_loss: 1.7262 - val_VL_attention_linear_output_acc: 0.4952 - val_VH_attention_linear_output_acc: 0.5012\n",
      "Epoch 4769/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2847 - VL_attention_linear_output_loss: 1.6472 - VH_attention_linear_output_loss: 1.6375 - VL_attention_linear_output_acc: 0.5097 - VH_attention_linear_output_acc: 0.5250 - val_loss: 3.4349 - val_VL_attention_linear_output_loss: 1.7192 - val_VH_attention_linear_output_loss: 1.7156 - val_VL_attention_linear_output_acc: 0.5008 - val_VH_attention_linear_output_acc: 0.5106\n",
      "Epoch 4770/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2839 - VL_attention_linear_output_loss: 1.6364 - VH_attention_linear_output_loss: 1.6475 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5223 - val_loss: 3.4349 - val_VL_attention_linear_output_loss: 1.7187 - val_VH_attention_linear_output_loss: 1.7161 - val_VL_attention_linear_output_acc: 0.5033 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4771/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2816 - VL_attention_linear_output_loss: 1.6468 - VH_attention_linear_output_loss: 1.6349 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5260 - val_loss: 3.4561 - val_VL_attention_linear_output_loss: 1.7241 - val_VH_attention_linear_output_loss: 1.7320 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.5002\n",
      "Epoch 4772/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2801 - VL_attention_linear_output_loss: 1.6426 - VH_attention_linear_output_loss: 1.6375 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5252 - val_loss: 3.4263 - val_VL_attention_linear_output_loss: 1.7162 - val_VH_attention_linear_output_loss: 1.7101 - val_VL_attention_linear_output_acc: 0.4961 - val_VH_attention_linear_output_acc: 0.5084\n",
      "Epoch 4773/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2902 - VL_attention_linear_output_loss: 1.6473 - VH_attention_linear_output_loss: 1.6429 - VL_attention_linear_output_acc: 0.5092 - VH_attention_linear_output_acc: 0.5235 - val_loss: 3.4322 - val_VL_attention_linear_output_loss: 1.7201 - val_VH_attention_linear_output_loss: 1.7121 - val_VL_attention_linear_output_acc: 0.5026 - val_VH_attention_linear_output_acc: 0.5070\n",
      "Epoch 4774/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2777 - VL_attention_linear_output_loss: 1.6343 - VH_attention_linear_output_loss: 1.6434 - VL_attention_linear_output_acc: 0.5146 - VH_attention_linear_output_acc: 0.5228 - val_loss: 3.4299 - val_VL_attention_linear_output_loss: 1.7207 - val_VH_attention_linear_output_loss: 1.7092 - val_VL_attention_linear_output_acc: 0.4852 - val_VH_attention_linear_output_acc: 0.5116\n",
      "Epoch 4775/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2975 - VL_attention_linear_output_loss: 1.6522 - VH_attention_linear_output_loss: 1.6452 - VL_attention_linear_output_acc: 0.5081 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4356 - val_VL_attention_linear_output_loss: 1.7140 - val_VH_attention_linear_output_loss: 1.7216 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.5074\n",
      "Epoch 4776/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2785 - VL_attention_linear_output_loss: 1.6383 - VH_attention_linear_output_loss: 1.6402 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5241 - val_loss: 3.4382 - val_VL_attention_linear_output_loss: 1.7225 - val_VH_attention_linear_output_loss: 1.7157 - val_VL_attention_linear_output_acc: 0.5030 - val_VH_attention_linear_output_acc: 0.5074\n",
      "Epoch 4777/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2723 - VL_attention_linear_output_loss: 1.6321 - VH_attention_linear_output_loss: 1.6403 - VL_attention_linear_output_acc: 0.5151 - VH_attention_linear_output_acc: 0.5244 - val_loss: 3.4183 - val_VL_attention_linear_output_loss: 1.7109 - val_VH_attention_linear_output_loss: 1.7075 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.5107\n",
      "Epoch 4778/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2833 - VL_attention_linear_output_loss: 1.6373 - VH_attention_linear_output_loss: 1.6460 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5226 - val_loss: 3.4285 - val_VL_attention_linear_output_loss: 1.7186 - val_VH_attention_linear_output_loss: 1.7099 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.5113\n",
      "Epoch 4779/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2743 - VL_attention_linear_output_loss: 1.6406 - VH_attention_linear_output_loss: 1.6337 - VL_attention_linear_output_acc: 0.5128 - VH_attention_linear_output_acc: 0.5262 - val_loss: 3.4270 - val_VL_attention_linear_output_loss: 1.7158 - val_VH_attention_linear_output_loss: 1.7112 - val_VL_attention_linear_output_acc: 0.4974 - val_VH_attention_linear_output_acc: 0.5095\n",
      "Epoch 4780/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2844 - VL_attention_linear_output_loss: 1.6449 - VH_attention_linear_output_loss: 1.6395 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5241 - val_loss: 3.4428 - val_VL_attention_linear_output_loss: 1.7268 - val_VH_attention_linear_output_loss: 1.7160 - val_VL_attention_linear_output_acc: 0.4976 - val_VH_attention_linear_output_acc: 0.5068\n",
      "Epoch 4781/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2873 - VL_attention_linear_output_loss: 1.6432 - VH_attention_linear_output_loss: 1.6441 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5229 - val_loss: 3.4371 - val_VL_attention_linear_output_loss: 1.7228 - val_VH_attention_linear_output_loss: 1.7144 - val_VL_attention_linear_output_acc: 0.4981 - val_VH_attention_linear_output_acc: 0.5078\n",
      "Epoch 4782/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2774 - VL_attention_linear_output_loss: 1.6396 - VH_attention_linear_output_loss: 1.6378 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5252 - val_loss: 3.4914 - val_VL_attention_linear_output_loss: 1.7801 - val_VH_attention_linear_output_loss: 1.7112 - val_VL_attention_linear_output_acc: 0.4665 - val_VH_attention_linear_output_acc: 0.5101\n",
      "Epoch 4783/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2789 - VL_attention_linear_output_loss: 1.6438 - VH_attention_linear_output_loss: 1.6351 - VL_attention_linear_output_acc: 0.5103 - VH_attention_linear_output_acc: 0.5254 - val_loss: 3.4455 - val_VL_attention_linear_output_loss: 1.7376 - val_VH_attention_linear_output_loss: 1.7079 - val_VL_attention_linear_output_acc: 0.4884 - val_VH_attention_linear_output_acc: 0.5095\n",
      "Epoch 4784/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2813 - VL_attention_linear_output_loss: 1.6432 - VH_attention_linear_output_loss: 1.6380 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5251 - val_loss: 3.4318 - val_VL_attention_linear_output_loss: 1.7123 - val_VH_attention_linear_output_loss: 1.7194 - val_VL_attention_linear_output_acc: 0.5052 - val_VH_attention_linear_output_acc: 0.5069\n",
      "Epoch 4785/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2825 - VL_attention_linear_output_loss: 1.6410 - VH_attention_linear_output_loss: 1.6414 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5235 - val_loss: 3.4558 - val_VL_attention_linear_output_loss: 1.7412 - val_VH_attention_linear_output_loss: 1.7146 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.5100\n",
      "Epoch 4786/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2794 - VL_attention_linear_output_loss: 1.6330 - VH_attention_linear_output_loss: 1.6464 - VL_attention_linear_output_acc: 0.5148 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4513 - val_VL_attention_linear_output_loss: 1.7290 - val_VH_attention_linear_output_loss: 1.7223 - val_VL_attention_linear_output_acc: 0.4862 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4787/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2887 - VL_attention_linear_output_loss: 1.6519 - VH_attention_linear_output_loss: 1.6368 - VL_attention_linear_output_acc: 0.5072 - VH_attention_linear_output_acc: 0.5254 - val_loss: 3.4610 - val_VL_attention_linear_output_loss: 1.7403 - val_VH_attention_linear_output_loss: 1.7206 - val_VL_attention_linear_output_acc: 0.4879 - val_VH_attention_linear_output_acc: 0.5057\n",
      "Epoch 4788/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2660 - VL_attention_linear_output_loss: 1.6309 - VH_attention_linear_output_loss: 1.6351 - VL_attention_linear_output_acc: 0.5162 - VH_attention_linear_output_acc: 0.5260 - val_loss: 3.4813 - val_VL_attention_linear_output_loss: 1.7268 - val_VH_attention_linear_output_loss: 1.7545 - val_VL_attention_linear_output_acc: 0.4900 - val_VH_attention_linear_output_acc: 0.4984\n",
      "Epoch 4789/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2758 - VL_attention_linear_output_loss: 1.6316 - VH_attention_linear_output_loss: 1.6442 - VL_attention_linear_output_acc: 0.5152 - VH_attention_linear_output_acc: 0.5226 - val_loss: 3.4583 - val_VL_attention_linear_output_loss: 1.7174 - val_VH_attention_linear_output_loss: 1.7408 - val_VL_attention_linear_output_acc: 0.5012 - val_VH_attention_linear_output_acc: 0.5006\n",
      "Epoch 4790/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2736 - VL_attention_linear_output_loss: 1.6318 - VH_attention_linear_output_loss: 1.6418 - VL_attention_linear_output_acc: 0.5153 - VH_attention_linear_output_acc: 0.5232 - val_loss: 3.4223 - val_VL_attention_linear_output_loss: 1.7177 - val_VH_attention_linear_output_loss: 1.7045 - val_VL_attention_linear_output_acc: 0.4929 - val_VH_attention_linear_output_acc: 0.5135\n",
      "Epoch 4791/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2645 - VL_attention_linear_output_loss: 1.6356 - VH_attention_linear_output_loss: 1.6289 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5283 - val_loss: 3.4347 - val_VL_attention_linear_output_loss: 1.7176 - val_VH_attention_linear_output_loss: 1.7171 - val_VL_attention_linear_output_acc: 0.4948 - val_VH_attention_linear_output_acc: 0.5102\n",
      "Epoch 4792/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2766 - VL_attention_linear_output_loss: 1.6414 - VH_attention_linear_output_loss: 1.6352 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5256 - val_loss: 3.4337 - val_VL_attention_linear_output_loss: 1.7189 - val_VH_attention_linear_output_loss: 1.7147 - val_VL_attention_linear_output_acc: 0.4918 - val_VH_attention_linear_output_acc: 0.5074\n",
      "Epoch 4793/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3005 - VL_attention_linear_output_loss: 1.6511 - VH_attention_linear_output_loss: 1.6494 - VL_attention_linear_output_acc: 0.5082 - VH_attention_linear_output_acc: 0.5213 - val_loss: 3.4272 - val_VL_attention_linear_output_loss: 1.7187 - val_VH_attention_linear_output_loss: 1.7085 - val_VL_attention_linear_output_acc: 0.5006 - val_VH_attention_linear_output_acc: 0.5112\n",
      "Epoch 4794/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2597 - VL_attention_linear_output_loss: 1.6310 - VH_attention_linear_output_loss: 1.6287 - VL_attention_linear_output_acc: 0.5159 - VH_attention_linear_output_acc: 0.5283 - val_loss: 3.4372 - val_VL_attention_linear_output_loss: 1.7213 - val_VH_attention_linear_output_loss: 1.7159 - val_VL_attention_linear_output_acc: 0.4990 - val_VH_attention_linear_output_acc: 0.5102\n",
      "Epoch 4795/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2803 - VL_attention_linear_output_loss: 1.6388 - VH_attention_linear_output_loss: 1.6415 - VL_attention_linear_output_acc: 0.5119 - VH_attention_linear_output_acc: 0.5232 - val_loss: 3.4472 - val_VL_attention_linear_output_loss: 1.7190 - val_VH_attention_linear_output_loss: 1.7281 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.5060\n",
      "Epoch 4796/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2967 - VL_attention_linear_output_loss: 1.6429 - VH_attention_linear_output_loss: 1.6537 - VL_attention_linear_output_acc: 0.5104 - VH_attention_linear_output_acc: 0.5199 - val_loss: 3.4200 - val_VL_attention_linear_output_loss: 1.7118 - val_VH_attention_linear_output_loss: 1.7082 - val_VL_attention_linear_output_acc: 0.5044 - val_VH_attention_linear_output_acc: 0.5094\n",
      "Epoch 4797/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2584 - VL_attention_linear_output_loss: 1.6296 - VH_attention_linear_output_loss: 1.6288 - VL_attention_linear_output_acc: 0.5153 - VH_attention_linear_output_acc: 0.5276 - val_loss: 3.4205 - val_VL_attention_linear_output_loss: 1.7105 - val_VH_attention_linear_output_loss: 1.7100 - val_VL_attention_linear_output_acc: 0.5033 - val_VH_attention_linear_output_acc: 0.5145\n",
      "Epoch 4798/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2726 - VL_attention_linear_output_loss: 1.6420 - VH_attention_linear_output_loss: 1.6306 - VL_attention_linear_output_acc: 0.5120 - VH_attention_linear_output_acc: 0.5278 - val_loss: 3.4474 - val_VL_attention_linear_output_loss: 1.7358 - val_VH_attention_linear_output_loss: 1.7116 - val_VL_attention_linear_output_acc: 0.4872 - val_VH_attention_linear_output_acc: 0.5086\n",
      "Epoch 4799/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2802 - VL_attention_linear_output_loss: 1.6367 - VH_attention_linear_output_loss: 1.6435 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5226 - val_loss: 3.4162 - val_VL_attention_linear_output_loss: 1.7098 - val_VH_attention_linear_output_loss: 1.7065 - val_VL_attention_linear_output_acc: 0.4950 - val_VH_attention_linear_output_acc: 0.5111\n",
      "Epoch 4800/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2798 - VL_attention_linear_output_loss: 1.6408 - VH_attention_linear_output_loss: 1.6390 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5245 - val_loss: 3.4227 - val_VL_attention_linear_output_loss: 1.7145 - val_VH_attention_linear_output_loss: 1.7082 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.5101\n",
      "Epoch 4801/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2615 - VL_attention_linear_output_loss: 1.6290 - VH_attention_linear_output_loss: 1.6325 - VL_attention_linear_output_acc: 0.5159 - VH_attention_linear_output_acc: 0.5265 - val_loss: 3.4202 - val_VL_attention_linear_output_loss: 1.7051 - val_VH_attention_linear_output_loss: 1.7151 - val_VL_attention_linear_output_acc: 0.4995 - val_VH_attention_linear_output_acc: 0.5077\n",
      "Epoch 4802/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2663 - VL_attention_linear_output_loss: 1.6330 - VH_attention_linear_output_loss: 1.6333 - VL_attention_linear_output_acc: 0.5155 - VH_attention_linear_output_acc: 0.5264 - val_loss: 3.4373 - val_VL_attention_linear_output_loss: 1.7244 - val_VH_attention_linear_output_loss: 1.7129 - val_VL_attention_linear_output_acc: 0.4948 - val_VH_attention_linear_output_acc: 0.5083\n",
      "Epoch 4803/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2810 - VL_attention_linear_output_loss: 1.6392 - VH_attention_linear_output_loss: 1.6418 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5231 - val_loss: 3.4246 - val_VL_attention_linear_output_loss: 1.7055 - val_VH_attention_linear_output_loss: 1.7191 - val_VL_attention_linear_output_acc: 0.5082 - val_VH_attention_linear_output_acc: 0.5100\n",
      "Epoch 4804/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2663 - VL_attention_linear_output_loss: 1.6316 - VH_attention_linear_output_loss: 1.6347 - VL_attention_linear_output_acc: 0.5156 - VH_attention_linear_output_acc: 0.5264 - val_loss: 3.4416 - val_VL_attention_linear_output_loss: 1.7247 - val_VH_attention_linear_output_loss: 1.7169 - val_VL_attention_linear_output_acc: 0.4975 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4805/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2852 - VL_attention_linear_output_loss: 1.6438 - VH_attention_linear_output_loss: 1.6414 - VL_attention_linear_output_acc: 0.5108 - VH_attention_linear_output_acc: 0.5232 - val_loss: 3.4211 - val_VL_attention_linear_output_loss: 1.7144 - val_VH_attention_linear_output_loss: 1.7067 - val_VL_attention_linear_output_acc: 0.5050 - val_VH_attention_linear_output_acc: 0.5112\n",
      "Epoch 4806/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2791 - VL_attention_linear_output_loss: 1.6468 - VH_attention_linear_output_loss: 1.6323 - VL_attention_linear_output_acc: 0.5089 - VH_attention_linear_output_acc: 0.5264 - val_loss: 3.4361 - val_VL_attention_linear_output_loss: 1.7180 - val_VH_attention_linear_output_loss: 1.7182 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.5058\n",
      "Epoch 4807/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2691 - VL_attention_linear_output_loss: 1.6337 - VH_attention_linear_output_loss: 1.6355 - VL_attention_linear_output_acc: 0.5144 - VH_attention_linear_output_acc: 0.5259 - val_loss: 3.4282 - val_VL_attention_linear_output_loss: 1.7170 - val_VH_attention_linear_output_loss: 1.7112 - val_VL_attention_linear_output_acc: 0.5018 - val_VH_attention_linear_output_acc: 0.5080\n",
      "Epoch 4808/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2951 - VL_attention_linear_output_loss: 1.6505 - VH_attention_linear_output_loss: 1.6446 - VL_attention_linear_output_acc: 0.5079 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4359 - val_VL_attention_linear_output_loss: 1.7052 - val_VH_attention_linear_output_loss: 1.7306 - val_VL_attention_linear_output_acc: 0.5026 - val_VH_attention_linear_output_acc: 0.5026\n",
      "Epoch 4809/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2644 - VL_attention_linear_output_loss: 1.6292 - VH_attention_linear_output_loss: 1.6352 - VL_attention_linear_output_acc: 0.5165 - VH_attention_linear_output_acc: 0.5254 - val_loss: 3.4391 - val_VL_attention_linear_output_loss: 1.7185 - val_VH_attention_linear_output_loss: 1.7207 - val_VL_attention_linear_output_acc: 0.4972 - val_VH_attention_linear_output_acc: 0.5064\n",
      "Epoch 4810/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2704 - VL_attention_linear_output_loss: 1.6324 - VH_attention_linear_output_loss: 1.6380 - VL_attention_linear_output_acc: 0.5150 - VH_attention_linear_output_acc: 0.5246 - val_loss: 3.4407 - val_VL_attention_linear_output_loss: 1.7175 - val_VH_attention_linear_output_loss: 1.7232 - val_VL_attention_linear_output_acc: 0.4971 - val_VH_attention_linear_output_acc: 0.5086\n",
      "Epoch 4811/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2823 - VL_attention_linear_output_loss: 1.6371 - VH_attention_linear_output_loss: 1.6452 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5219 - val_loss: 3.4712 - val_VL_attention_linear_output_loss: 1.7239 - val_VH_attention_linear_output_loss: 1.7473 - val_VL_attention_linear_output_acc: 0.4971 - val_VH_attention_linear_output_acc: 0.4983\n",
      "Epoch 4812/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2942 - VL_attention_linear_output_loss: 1.6525 - VH_attention_linear_output_loss: 1.6417 - VL_attention_linear_output_acc: 0.5073 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4285 - val_VL_attention_linear_output_loss: 1.7203 - val_VH_attention_linear_output_loss: 1.7082 - val_VL_attention_linear_output_acc: 0.5042 - val_VH_attention_linear_output_acc: 0.5118\n",
      "Epoch 4813/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2846 - VL_attention_linear_output_loss: 1.6387 - VH_attention_linear_output_loss: 1.6459 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5221 - val_loss: 3.4222 - val_VL_attention_linear_output_loss: 1.7113 - val_VH_attention_linear_output_loss: 1.7109 - val_VL_attention_linear_output_acc: 0.4960 - val_VH_attention_linear_output_acc: 0.5096\n",
      "Epoch 4814/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2712 - VL_attention_linear_output_loss: 1.6273 - VH_attention_linear_output_loss: 1.6439 - VL_attention_linear_output_acc: 0.5166 - VH_attention_linear_output_acc: 0.5232 - val_loss: 3.4320 - val_VL_attention_linear_output_loss: 1.7162 - val_VH_attention_linear_output_loss: 1.7158 - val_VL_attention_linear_output_acc: 0.5045 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4815/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2666 - VL_attention_linear_output_loss: 1.6334 - VH_attention_linear_output_loss: 1.6332 - VL_attention_linear_output_acc: 0.5144 - VH_attention_linear_output_acc: 0.5269 - val_loss: 3.4338 - val_VL_attention_linear_output_loss: 1.7240 - val_VH_attention_linear_output_loss: 1.7098 - val_VL_attention_linear_output_acc: 0.4984 - val_VH_attention_linear_output_acc: 0.5104\n",
      "Epoch 4816/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2655 - VL_attention_linear_output_loss: 1.6337 - VH_attention_linear_output_loss: 1.6318 - VL_attention_linear_output_acc: 0.5158 - VH_attention_linear_output_acc: 0.5270 - val_loss: 3.4248 - val_VL_attention_linear_output_loss: 1.7148 - val_VH_attention_linear_output_loss: 1.7100 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.5108\n",
      "Epoch 4817/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2872 - VL_attention_linear_output_loss: 1.6464 - VH_attention_linear_output_loss: 1.6408 - VL_attention_linear_output_acc: 0.5089 - VH_attention_linear_output_acc: 0.5244 - val_loss: 3.4772 - val_VL_attention_linear_output_loss: 1.7668 - val_VH_attention_linear_output_loss: 1.7104 - val_VL_attention_linear_output_acc: 0.4643 - val_VH_attention_linear_output_acc: 0.5100\n",
      "Epoch 4818/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2803 - VL_attention_linear_output_loss: 1.6422 - VH_attention_linear_output_loss: 1.6382 - VL_attention_linear_output_acc: 0.5114 - VH_attention_linear_output_acc: 0.5249 - val_loss: 3.4274 - val_VL_attention_linear_output_loss: 1.7219 - val_VH_attention_linear_output_loss: 1.7055 - val_VL_attention_linear_output_acc: 0.4901 - val_VH_attention_linear_output_acc: 0.5101\n",
      "Epoch 4819/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2852 - VL_attention_linear_output_loss: 1.6432 - VH_attention_linear_output_loss: 1.6419 - VL_attention_linear_output_acc: 0.5115 - VH_attention_linear_output_acc: 0.5235 - val_loss: 3.4606 - val_VL_attention_linear_output_loss: 1.7473 - val_VH_attention_linear_output_loss: 1.7133 - val_VL_attention_linear_output_acc: 0.4855 - val_VH_attention_linear_output_acc: 0.5070\n",
      "Epoch 4820/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2745 - VL_attention_linear_output_loss: 1.6363 - VH_attention_linear_output_loss: 1.6381 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5246 - val_loss: 3.4340 - val_VL_attention_linear_output_loss: 1.7108 - val_VH_attention_linear_output_loss: 1.7231 - val_VL_attention_linear_output_acc: 0.5047 - val_VH_attention_linear_output_acc: 0.5070\n",
      "Epoch 4821/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2781 - VL_attention_linear_output_loss: 1.6364 - VH_attention_linear_output_loss: 1.6417 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4213 - val_VL_attention_linear_output_loss: 1.7150 - val_VH_attention_linear_output_loss: 1.7063 - val_VL_attention_linear_output_acc: 0.4938 - val_VH_attention_linear_output_acc: 0.5117\n",
      "Epoch 4822/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2941 - VL_attention_linear_output_loss: 1.6460 - VH_attention_linear_output_loss: 1.6481 - VL_attention_linear_output_acc: 0.5110 - VH_attention_linear_output_acc: 0.5210 - val_loss: 3.4904 - val_VL_attention_linear_output_loss: 1.7536 - val_VH_attention_linear_output_loss: 1.7369 - val_VL_attention_linear_output_acc: 0.4936 - val_VH_attention_linear_output_acc: 0.4959\n",
      "Epoch 4823/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2804 - VL_attention_linear_output_loss: 1.6419 - VH_attention_linear_output_loss: 1.6385 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5253 - val_loss: 3.4264 - val_VL_attention_linear_output_loss: 1.7164 - val_VH_attention_linear_output_loss: 1.7100 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.5102\n",
      "Epoch 4824/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2584 - VL_attention_linear_output_loss: 1.6297 - VH_attention_linear_output_loss: 1.6287 - VL_attention_linear_output_acc: 0.5162 - VH_attention_linear_output_acc: 0.5283 - val_loss: 3.4222 - val_VL_attention_linear_output_loss: 1.7138 - val_VH_attention_linear_output_loss: 1.7084 - val_VL_attention_linear_output_acc: 0.4966 - val_VH_attention_linear_output_acc: 0.5100\n",
      "Epoch 4825/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2783 - VL_attention_linear_output_loss: 1.6374 - VH_attention_linear_output_loss: 1.6409 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5242 - val_loss: 3.4546 - val_VL_attention_linear_output_loss: 1.7164 - val_VH_attention_linear_output_loss: 1.7382 - val_VL_attention_linear_output_acc: 0.5005 - val_VH_attention_linear_output_acc: 0.5017\n",
      "Epoch 4826/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2845 - VL_attention_linear_output_loss: 1.6368 - VH_attention_linear_output_loss: 1.6477 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5208 - val_loss: 3.4160 - val_VL_attention_linear_output_loss: 1.7105 - val_VH_attention_linear_output_loss: 1.7054 - val_VL_attention_linear_output_acc: 0.4985 - val_VH_attention_linear_output_acc: 0.5110\n",
      "Epoch 4827/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2669 - VL_attention_linear_output_loss: 1.6357 - VH_attention_linear_output_loss: 1.6312 - VL_attention_linear_output_acc: 0.5136 - VH_attention_linear_output_acc: 0.5270 - val_loss: 3.4576 - val_VL_attention_linear_output_loss: 1.7178 - val_VH_attention_linear_output_loss: 1.7398 - val_VL_attention_linear_output_acc: 0.5016 - val_VH_attention_linear_output_acc: 0.4995\n",
      "Epoch 4828/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2780 - VL_attention_linear_output_loss: 1.6421 - VH_attention_linear_output_loss: 1.6358 - VL_attention_linear_output_acc: 0.5116 - VH_attention_linear_output_acc: 0.5259 - val_loss: 3.4259 - val_VL_attention_linear_output_loss: 1.7089 - val_VH_attention_linear_output_loss: 1.7169 - val_VL_attention_linear_output_acc: 0.5004 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4829/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2742 - VL_attention_linear_output_loss: 1.6331 - VH_attention_linear_output_loss: 1.6411 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4366 - val_VL_attention_linear_output_loss: 1.7301 - val_VH_attention_linear_output_loss: 1.7065 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5090\n",
      "Epoch 4830/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2833 - VL_attention_linear_output_loss: 1.6438 - VH_attention_linear_output_loss: 1.6395 - VL_attention_linear_output_acc: 0.5109 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4373 - val_VL_attention_linear_output_loss: 1.7286 - val_VH_attention_linear_output_loss: 1.7086 - val_VL_attention_linear_output_acc: 0.4901 - val_VH_attention_linear_output_acc: 0.5105\n",
      "Epoch 4831/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2780 - VL_attention_linear_output_loss: 1.6424 - VH_attention_linear_output_loss: 1.6356 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5256 - val_loss: 3.4441 - val_VL_attention_linear_output_loss: 1.7184 - val_VH_attention_linear_output_loss: 1.7257 - val_VL_attention_linear_output_acc: 0.5049 - val_VH_attention_linear_output_acc: 0.5053\n",
      "Epoch 4832/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2745 - VL_attention_linear_output_loss: 1.6315 - VH_attention_linear_output_loss: 1.6430 - VL_attention_linear_output_acc: 0.5164 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.4283 - val_VL_attention_linear_output_loss: 1.7167 - val_VH_attention_linear_output_loss: 1.7115 - val_VL_attention_linear_output_acc: 0.4957 - val_VH_attention_linear_output_acc: 0.5090\n",
      "Epoch 4833/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2833 - VL_attention_linear_output_loss: 1.6345 - VH_attention_linear_output_loss: 1.6488 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5208 - val_loss: 3.4655 - val_VL_attention_linear_output_loss: 1.7436 - val_VH_attention_linear_output_loss: 1.7220 - val_VL_attention_linear_output_acc: 0.4922 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4834/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2834 - VL_attention_linear_output_loss: 1.6508 - VH_attention_linear_output_loss: 1.6326 - VL_attention_linear_output_acc: 0.5083 - VH_attention_linear_output_acc: 0.5267 - val_loss: 3.4281 - val_VL_attention_linear_output_loss: 1.7164 - val_VH_attention_linear_output_loss: 1.7118 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.5098\n",
      "Epoch 4835/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2671 - VL_attention_linear_output_loss: 1.6347 - VH_attention_linear_output_loss: 1.6324 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5268 - val_loss: 3.4184 - val_VL_attention_linear_output_loss: 1.7100 - val_VH_attention_linear_output_loss: 1.7084 - val_VL_attention_linear_output_acc: 0.4994 - val_VH_attention_linear_output_acc: 0.5096\n",
      "Epoch 4836/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2777 - VL_attention_linear_output_loss: 1.6334 - VH_attention_linear_output_loss: 1.6443 - VL_attention_linear_output_acc: 0.5150 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4439 - val_VL_attention_linear_output_loss: 1.7097 - val_VH_attention_linear_output_loss: 1.7343 - val_VL_attention_linear_output_acc: 0.5058 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4837/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2726 - VL_attention_linear_output_loss: 1.6343 - VH_attention_linear_output_loss: 1.6383 - VL_attention_linear_output_acc: 0.5144 - VH_attention_linear_output_acc: 0.5252 - val_loss: 3.4532 - val_VL_attention_linear_output_loss: 1.7392 - val_VH_attention_linear_output_loss: 1.7140 - val_VL_attention_linear_output_acc: 0.4966 - val_VH_attention_linear_output_acc: 0.5108\n",
      "Epoch 4838/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2800 - VL_attention_linear_output_loss: 1.6425 - VH_attention_linear_output_loss: 1.6375 - VL_attention_linear_output_acc: 0.5111 - VH_attention_linear_output_acc: 0.5256 - val_loss: 3.4337 - val_VL_attention_linear_output_loss: 1.7146 - val_VH_attention_linear_output_loss: 1.7190 - val_VL_attention_linear_output_acc: 0.5036 - val_VH_attention_linear_output_acc: 0.5058\n",
      "Epoch 4839/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2703 - VL_attention_linear_output_loss: 1.6348 - VH_attention_linear_output_loss: 1.6355 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5262 - val_loss: 3.4391 - val_VL_attention_linear_output_loss: 1.7132 - val_VH_attention_linear_output_loss: 1.7259 - val_VL_attention_linear_output_acc: 0.4954 - val_VH_attention_linear_output_acc: 0.5060\n",
      "Epoch 4840/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2826 - VL_attention_linear_output_loss: 1.6473 - VH_attention_linear_output_loss: 1.6353 - VL_attention_linear_output_acc: 0.5099 - VH_attention_linear_output_acc: 0.5260 - val_loss: 3.4293 - val_VL_attention_linear_output_loss: 1.7142 - val_VH_attention_linear_output_loss: 1.7151 - val_VL_attention_linear_output_acc: 0.4992 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4841/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2804 - VL_attention_linear_output_loss: 1.6348 - VH_attention_linear_output_loss: 1.6456 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4373 - val_VL_attention_linear_output_loss: 1.7166 - val_VH_attention_linear_output_loss: 1.7207 - val_VL_attention_linear_output_acc: 0.5012 - val_VH_attention_linear_output_acc: 0.5065\n",
      "Epoch 4842/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2830 - VL_attention_linear_output_loss: 1.6380 - VH_attention_linear_output_loss: 1.6449 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5224 - val_loss: 3.4431 - val_VL_attention_linear_output_loss: 1.7325 - val_VH_attention_linear_output_loss: 1.7106 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.5103\n",
      "Epoch 4843/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2652 - VL_attention_linear_output_loss: 1.6316 - VH_attention_linear_output_loss: 1.6335 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5263 - val_loss: 3.4360 - val_VL_attention_linear_output_loss: 1.7117 - val_VH_attention_linear_output_loss: 1.7243 - val_VL_attention_linear_output_acc: 0.5056 - val_VH_attention_linear_output_acc: 0.5073\n",
      "Epoch 4844/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2786 - VL_attention_linear_output_loss: 1.6390 - VH_attention_linear_output_loss: 1.6395 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4620 - val_VL_attention_linear_output_loss: 1.7162 - val_VH_attention_linear_output_loss: 1.7459 - val_VL_attention_linear_output_acc: 0.5020 - val_VH_attention_linear_output_acc: 0.5010\n",
      "Epoch 4845/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2653 - VL_attention_linear_output_loss: 1.6285 - VH_attention_linear_output_loss: 1.6368 - VL_attention_linear_output_acc: 0.5165 - VH_attention_linear_output_acc: 0.5258 - val_loss: 3.4225 - val_VL_attention_linear_output_loss: 1.7134 - val_VH_attention_linear_output_loss: 1.7091 - val_VL_attention_linear_output_acc: 0.4972 - val_VH_attention_linear_output_acc: 0.5094\n",
      "Epoch 4846/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2776 - VL_attention_linear_output_loss: 1.6336 - VH_attention_linear_output_loss: 1.6440 - VL_attention_linear_output_acc: 0.5154 - VH_attention_linear_output_acc: 0.5233 - val_loss: 3.4175 - val_VL_attention_linear_output_loss: 1.7101 - val_VH_attention_linear_output_loss: 1.7074 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.5114\n",
      "Epoch 4847/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2630 - VL_attention_linear_output_loss: 1.6297 - VH_attention_linear_output_loss: 1.6333 - VL_attention_linear_output_acc: 0.5160 - VH_attention_linear_output_acc: 0.5262 - val_loss: 3.4268 - val_VL_attention_linear_output_loss: 1.7117 - val_VH_attention_linear_output_loss: 1.7151 - val_VL_attention_linear_output_acc: 0.5028 - val_VH_attention_linear_output_acc: 0.5110\n",
      "Epoch 4848/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2642 - VL_attention_linear_output_loss: 1.6325 - VH_attention_linear_output_loss: 1.6318 - VL_attention_linear_output_acc: 0.5155 - VH_attention_linear_output_acc: 0.5277 - val_loss: 3.4472 - val_VL_attention_linear_output_loss: 1.7400 - val_VH_attention_linear_output_loss: 1.7072 - val_VL_attention_linear_output_acc: 0.4934 - val_VH_attention_linear_output_acc: 0.5123\n",
      "Epoch 4849/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2749 - VL_attention_linear_output_loss: 1.6371 - VH_attention_linear_output_loss: 1.6378 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5250 - val_loss: 3.4245 - val_VL_attention_linear_output_loss: 1.7156 - val_VH_attention_linear_output_loss: 1.7089 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5109\n",
      "Epoch 4850/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2661 - VL_attention_linear_output_loss: 1.6326 - VH_attention_linear_output_loss: 1.6335 - VL_attention_linear_output_acc: 0.5147 - VH_attention_linear_output_acc: 0.5257 - val_loss: 3.4237 - val_VL_attention_linear_output_loss: 1.7173 - val_VH_attention_linear_output_loss: 1.7065 - val_VL_attention_linear_output_acc: 0.5024 - val_VH_attention_linear_output_acc: 0.5112\n",
      "Epoch 4851/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2738 - VL_attention_linear_output_loss: 1.6357 - VH_attention_linear_output_loss: 1.6380 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5250 - val_loss: 3.4326 - val_VL_attention_linear_output_loss: 1.7229 - val_VH_attention_linear_output_loss: 1.7098 - val_VL_attention_linear_output_acc: 0.5002 - val_VH_attention_linear_output_acc: 0.5119\n",
      "Epoch 4852/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2774 - VL_attention_linear_output_loss: 1.6412 - VH_attention_linear_output_loss: 1.6361 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5259 - val_loss: 3.4322 - val_VL_attention_linear_output_loss: 1.7192 - val_VH_attention_linear_output_loss: 1.7130 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.5108\n",
      "Epoch 4853/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2764 - VL_attention_linear_output_loss: 1.6425 - VH_attention_linear_output_loss: 1.6339 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4252 - val_VL_attention_linear_output_loss: 1.7139 - val_VH_attention_linear_output_loss: 1.7113 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5082\n",
      "Epoch 4854/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2812 - VL_attention_linear_output_loss: 1.6338 - VH_attention_linear_output_loss: 1.6474 - VL_attention_linear_output_acc: 0.5146 - VH_attention_linear_output_acc: 0.5215 - val_loss: 3.4280 - val_VL_attention_linear_output_loss: 1.7229 - val_VH_attention_linear_output_loss: 1.7051 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.5122\n",
      "Epoch 4855/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2723 - VL_attention_linear_output_loss: 1.6477 - VH_attention_linear_output_loss: 1.6246 - VL_attention_linear_output_acc: 0.5086 - VH_attention_linear_output_acc: 0.5295 - val_loss: 3.4192 - val_VL_attention_linear_output_loss: 1.7110 - val_VH_attention_linear_output_loss: 1.7082 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.5091\n",
      "Epoch 4856/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2456 - VL_attention_linear_output_loss: 1.6229 - VH_attention_linear_output_loss: 1.6228 - VL_attention_linear_output_acc: 0.5182 - VH_attention_linear_output_acc: 0.5304 - val_loss: 3.4145 - val_VL_attention_linear_output_loss: 1.7081 - val_VH_attention_linear_output_loss: 1.7064 - val_VL_attention_linear_output_acc: 0.5035 - val_VH_attention_linear_output_acc: 0.5105\n",
      "Epoch 4857/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2507 - VL_attention_linear_output_loss: 1.6240 - VH_attention_linear_output_loss: 1.6267 - VL_attention_linear_output_acc: 0.5186 - VH_attention_linear_output_acc: 0.5291 - val_loss: 3.4402 - val_VL_attention_linear_output_loss: 1.7190 - val_VH_attention_linear_output_loss: 1.7212 - val_VL_attention_linear_output_acc: 0.4930 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4858/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2587 - VL_attention_linear_output_loss: 1.6267 - VH_attention_linear_output_loss: 1.6319 - VL_attention_linear_output_acc: 0.5169 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4423 - val_VL_attention_linear_output_loss: 1.7177 - val_VH_attention_linear_output_loss: 1.7246 - val_VL_attention_linear_output_acc: 0.4982 - val_VH_attention_linear_output_acc: 0.5073\n",
      "Epoch 4859/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2654 - VL_attention_linear_output_loss: 1.6354 - VH_attention_linear_output_loss: 1.6300 - VL_attention_linear_output_acc: 0.5140 - VH_attention_linear_output_acc: 0.5279 - val_loss: 3.4511 - val_VL_attention_linear_output_loss: 1.7245 - val_VH_attention_linear_output_loss: 1.7266 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.5077\n",
      "Epoch 4860/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2764 - VL_attention_linear_output_loss: 1.6302 - VH_attention_linear_output_loss: 1.6462 - VL_attention_linear_output_acc: 0.5150 - VH_attention_linear_output_acc: 0.5225 - val_loss: 3.4397 - val_VL_attention_linear_output_loss: 1.7235 - val_VH_attention_linear_output_loss: 1.7162 - val_VL_attention_linear_output_acc: 0.5000 - val_VH_attention_linear_output_acc: 0.5104\n",
      "Epoch 4861/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2741 - VL_attention_linear_output_loss: 1.6326 - VH_attention_linear_output_loss: 1.6415 - VL_attention_linear_output_acc: 0.5152 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4333 - val_VL_attention_linear_output_loss: 1.7190 - val_VH_attention_linear_output_loss: 1.7143 - val_VL_attention_linear_output_acc: 0.4978 - val_VH_attention_linear_output_acc: 0.5095\n",
      "Epoch 4862/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2693 - VL_attention_linear_output_loss: 1.6327 - VH_attention_linear_output_loss: 1.6366 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5256 - val_loss: 3.4316 - val_VL_attention_linear_output_loss: 1.7210 - val_VH_attention_linear_output_loss: 1.7106 - val_VL_attention_linear_output_acc: 0.4901 - val_VH_attention_linear_output_acc: 0.5094\n",
      "Epoch 4863/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2903 - VL_attention_linear_output_loss: 1.6497 - VH_attention_linear_output_loss: 1.6405 - VL_attention_linear_output_acc: 0.5091 - VH_attention_linear_output_acc: 0.5247 - val_loss: 3.4398 - val_VL_attention_linear_output_loss: 1.7095 - val_VH_attention_linear_output_loss: 1.7303 - val_VL_attention_linear_output_acc: 0.4997 - val_VH_attention_linear_output_acc: 0.5046\n",
      "Epoch 4864/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2636 - VL_attention_linear_output_loss: 1.6281 - VH_attention_linear_output_loss: 1.6355 - VL_attention_linear_output_acc: 0.5167 - VH_attention_linear_output_acc: 0.5261 - val_loss: 3.4376 - val_VL_attention_linear_output_loss: 1.7164 - val_VH_attention_linear_output_loss: 1.7213 - val_VL_attention_linear_output_acc: 0.5022 - val_VH_attention_linear_output_acc: 0.5070\n",
      "Epoch 4865/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2606 - VL_attention_linear_output_loss: 1.6263 - VH_attention_linear_output_loss: 1.6343 - VL_attention_linear_output_acc: 0.5169 - VH_attention_linear_output_acc: 0.5255 - val_loss: 3.4196 - val_VL_attention_linear_output_loss: 1.7089 - val_VH_attention_linear_output_loss: 1.7107 - val_VL_attention_linear_output_acc: 0.5037 - val_VH_attention_linear_output_acc: 0.5110\n",
      "Epoch 4866/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2663 - VL_attention_linear_output_loss: 1.6282 - VH_attention_linear_output_loss: 1.6381 - VL_attention_linear_output_acc: 0.5161 - VH_attention_linear_output_acc: 0.5248 - val_loss: 3.4331 - val_VL_attention_linear_output_loss: 1.7111 - val_VH_attention_linear_output_loss: 1.7221 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.5073\n",
      "Epoch 4867/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2733 - VL_attention_linear_output_loss: 1.6304 - VH_attention_linear_output_loss: 1.6429 - VL_attention_linear_output_acc: 0.5158 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4432 - val_VL_attention_linear_output_loss: 1.7168 - val_VH_attention_linear_output_loss: 1.7263 - val_VL_attention_linear_output_acc: 0.5017 - val_VH_attention_linear_output_acc: 0.5066\n",
      "Epoch 4868/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2903 - VL_attention_linear_output_loss: 1.6318 - VH_attention_linear_output_loss: 1.6585 - VL_attention_linear_output_acc: 0.5163 - VH_attention_linear_output_acc: 0.5177 - val_loss: 3.4171 - val_VL_attention_linear_output_loss: 1.7114 - val_VH_attention_linear_output_loss: 1.7057 - val_VL_attention_linear_output_acc: 0.5047 - val_VH_attention_linear_output_acc: 0.5119\n",
      "Epoch 4869/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2686 - VL_attention_linear_output_loss: 1.6349 - VH_attention_linear_output_loss: 1.6337 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4265 - val_VL_attention_linear_output_loss: 1.7136 - val_VH_attention_linear_output_loss: 1.7128 - val_VL_attention_linear_output_acc: 0.5055 - val_VH_attention_linear_output_acc: 0.5093\n",
      "Epoch 4870/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2767 - VL_attention_linear_output_loss: 1.6426 - VH_attention_linear_output_loss: 1.6341 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5260 - val_loss: 3.4217 - val_VL_attention_linear_output_loss: 1.7160 - val_VH_attention_linear_output_loss: 1.7057 - val_VL_attention_linear_output_acc: 0.5019 - val_VH_attention_linear_output_acc: 0.5110\n",
      "Epoch 4871/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2644 - VL_attention_linear_output_loss: 1.6325 - VH_attention_linear_output_loss: 1.6319 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5274 - val_loss: 3.4546 - val_VL_attention_linear_output_loss: 1.7215 - val_VH_attention_linear_output_loss: 1.7330 - val_VL_attention_linear_output_acc: 0.4941 - val_VH_attention_linear_output_acc: 0.5068\n",
      "Epoch 4872/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2709 - VL_attention_linear_output_loss: 1.6401 - VH_attention_linear_output_loss: 1.6308 - VL_attention_linear_output_acc: 0.5124 - VH_attention_linear_output_acc: 0.5278 - val_loss: 3.4240 - val_VL_attention_linear_output_loss: 1.7092 - val_VH_attention_linear_output_loss: 1.7148 - val_VL_attention_linear_output_acc: 0.5052 - val_VH_attention_linear_output_acc: 0.5108\n",
      "Epoch 4873/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2790 - VL_attention_linear_output_loss: 1.6380 - VH_attention_linear_output_loss: 1.6410 - VL_attention_linear_output_acc: 0.5140 - VH_attention_linear_output_acc: 0.5243 - val_loss: 3.4217 - val_VL_attention_linear_output_loss: 1.7120 - val_VH_attention_linear_output_loss: 1.7098 - val_VL_attention_linear_output_acc: 0.5069 - val_VH_attention_linear_output_acc: 0.5105\n",
      "Epoch 4874/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2819 - VL_attention_linear_output_loss: 1.6426 - VH_attention_linear_output_loss: 1.6393 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5250 - val_loss: 3.4222 - val_VL_attention_linear_output_loss: 1.7130 - val_VH_attention_linear_output_loss: 1.7092 - val_VL_attention_linear_output_acc: 0.5026 - val_VH_attention_linear_output_acc: 0.5107\n",
      "Epoch 4875/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2712 - VL_attention_linear_output_loss: 1.6322 - VH_attention_linear_output_loss: 1.6389 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5250 - val_loss: 3.4254 - val_VL_attention_linear_output_loss: 1.7125 - val_VH_attention_linear_output_loss: 1.7129 - val_VL_attention_linear_output_acc: 0.4992 - val_VH_attention_linear_output_acc: 0.5089\n",
      "Epoch 4876/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2728 - VL_attention_linear_output_loss: 1.6349 - VH_attention_linear_output_loss: 1.6379 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5246 - val_loss: 3.4207 - val_VL_attention_linear_output_loss: 1.7126 - val_VH_attention_linear_output_loss: 1.7081 - val_VL_attention_linear_output_acc: 0.5002 - val_VH_attention_linear_output_acc: 0.5102\n",
      "Epoch 4877/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2617 - VL_attention_linear_output_loss: 1.6260 - VH_attention_linear_output_loss: 1.6357 - VL_attention_linear_output_acc: 0.5174 - VH_attention_linear_output_acc: 0.5261 - val_loss: 3.4222 - val_VL_attention_linear_output_loss: 1.7103 - val_VH_attention_linear_output_loss: 1.7119 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.5092\n",
      "Epoch 4878/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2874 - VL_attention_linear_output_loss: 1.6459 - VH_attention_linear_output_loss: 1.6416 - VL_attention_linear_output_acc: 0.5105 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4446 - val_VL_attention_linear_output_loss: 1.7148 - val_VH_attention_linear_output_loss: 1.7299 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5041\n",
      "Epoch 4879/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2828 - VL_attention_linear_output_loss: 1.6372 - VH_attention_linear_output_loss: 1.6456 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5220 - val_loss: 3.4497 - val_VL_attention_linear_output_loss: 1.7248 - val_VH_attention_linear_output_loss: 1.7249 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.5051\n",
      "Epoch 4880/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2694 - VL_attention_linear_output_loss: 1.6350 - VH_attention_linear_output_loss: 1.6344 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5259 - val_loss: 3.4237 - val_VL_attention_linear_output_loss: 1.7147 - val_VH_attention_linear_output_loss: 1.7090 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.5126\n",
      "Epoch 4881/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2739 - VL_attention_linear_output_loss: 1.6407 - VH_attention_linear_output_loss: 1.6331 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5265 - val_loss: 3.4386 - val_VL_attention_linear_output_loss: 1.7308 - val_VH_attention_linear_output_loss: 1.7079 - val_VL_attention_linear_output_acc: 0.4864 - val_VH_attention_linear_output_acc: 0.5110\n",
      "Epoch 4882/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2688 - VL_attention_linear_output_loss: 1.6352 - VH_attention_linear_output_loss: 1.6336 - VL_attention_linear_output_acc: 0.5132 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4243 - val_VL_attention_linear_output_loss: 1.7117 - val_VH_attention_linear_output_loss: 1.7127 - val_VL_attention_linear_output_acc: 0.4966 - val_VH_attention_linear_output_acc: 0.5102\n",
      "Epoch 4883/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.3038 - VL_attention_linear_output_loss: 1.6365 - VH_attention_linear_output_loss: 1.6673 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5146 - val_loss: 3.4304 - val_VL_attention_linear_output_loss: 1.7210 - val_VH_attention_linear_output_loss: 1.7094 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.5094\n",
      "Epoch 4884/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2768 - VL_attention_linear_output_loss: 1.6450 - VH_attention_linear_output_loss: 1.6318 - VL_attention_linear_output_acc: 0.5101 - VH_attention_linear_output_acc: 0.5270 - val_loss: 3.4283 - val_VL_attention_linear_output_loss: 1.7130 - val_VH_attention_linear_output_loss: 1.7153 - val_VL_attention_linear_output_acc: 0.4953 - val_VH_attention_linear_output_acc: 0.5058\n",
      "Epoch 4885/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2675 - VL_attention_linear_output_loss: 1.6348 - VH_attention_linear_output_loss: 1.6327 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5269 - val_loss: 3.4646 - val_VL_attention_linear_output_loss: 1.7178 - val_VH_attention_linear_output_loss: 1.7468 - val_VL_attention_linear_output_acc: 0.4973 - val_VH_attention_linear_output_acc: 0.5024\n",
      "Epoch 4886/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2752 - VL_attention_linear_output_loss: 1.6386 - VH_attention_linear_output_loss: 1.6366 - VL_attention_linear_output_acc: 0.5120 - VH_attention_linear_output_acc: 0.5253 - val_loss: 3.4451 - val_VL_attention_linear_output_loss: 1.7243 - val_VH_attention_linear_output_loss: 1.7208 - val_VL_attention_linear_output_acc: 0.4975 - val_VH_attention_linear_output_acc: 0.5081\n",
      "Epoch 4887/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2727 - VL_attention_linear_output_loss: 1.6391 - VH_attention_linear_output_loss: 1.6337 - VL_attention_linear_output_acc: 0.5127 - VH_attention_linear_output_acc: 0.5269 - val_loss: 3.4292 - val_VL_attention_linear_output_loss: 1.7251 - val_VH_attention_linear_output_loss: 1.7041 - val_VL_attention_linear_output_acc: 0.4987 - val_VH_attention_linear_output_acc: 0.5108\n",
      "Epoch 4888/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2712 - VL_attention_linear_output_loss: 1.6369 - VH_attention_linear_output_loss: 1.6343 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5261 - val_loss: 3.4504 - val_VL_attention_linear_output_loss: 1.7191 - val_VH_attention_linear_output_loss: 1.7313 - val_VL_attention_linear_output_acc: 0.5002 - val_VH_attention_linear_output_acc: 0.5018\n",
      "Epoch 4889/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2737 - VL_attention_linear_output_loss: 1.6336 - VH_attention_linear_output_loss: 1.6402 - VL_attention_linear_output_acc: 0.5150 - VH_attention_linear_output_acc: 0.5250 - val_loss: 3.5472 - val_VL_attention_linear_output_loss: 1.7849 - val_VH_attention_linear_output_loss: 1.7624 - val_VL_attention_linear_output_acc: 0.4815 - val_VH_attention_linear_output_acc: 0.4976\n",
      "Epoch 4890/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2706 - VL_attention_linear_output_loss: 1.6374 - VH_attention_linear_output_loss: 1.6332 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5268 - val_loss: 3.4180 - val_VL_attention_linear_output_loss: 1.7074 - val_VH_attention_linear_output_loss: 1.7106 - val_VL_attention_linear_output_acc: 0.4997 - val_VH_attention_linear_output_acc: 0.5086\n",
      "Epoch 4891/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2562 - VL_attention_linear_output_loss: 1.6264 - VH_attention_linear_output_loss: 1.6299 - VL_attention_linear_output_acc: 0.5173 - VH_attention_linear_output_acc: 0.5280 - val_loss: 3.4277 - val_VL_attention_linear_output_loss: 1.7072 - val_VH_attention_linear_output_loss: 1.7204 - val_VL_attention_linear_output_acc: 0.5062 - val_VH_attention_linear_output_acc: 0.5079\n",
      "Epoch 4892/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2762 - VL_attention_linear_output_loss: 1.6291 - VH_attention_linear_output_loss: 1.6471 - VL_attention_linear_output_acc: 0.5156 - VH_attention_linear_output_acc: 0.5216 - val_loss: 3.5197 - val_VL_attention_linear_output_loss: 1.7535 - val_VH_attention_linear_output_loss: 1.7662 - val_VL_attention_linear_output_acc: 0.4744 - val_VH_attention_linear_output_acc: 0.4877\n",
      "Epoch 4893/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2676 - VL_attention_linear_output_loss: 1.6370 - VH_attention_linear_output_loss: 1.6305 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5273 - val_loss: 3.4179 - val_VL_attention_linear_output_loss: 1.7096 - val_VH_attention_linear_output_loss: 1.7083 - val_VL_attention_linear_output_acc: 0.5009 - val_VH_attention_linear_output_acc: 0.5099\n",
      "Epoch 4894/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2627 - VL_attention_linear_output_loss: 1.6305 - VH_attention_linear_output_loss: 1.6322 - VL_attention_linear_output_acc: 0.5157 - VH_attention_linear_output_acc: 0.5274 - val_loss: 3.4229 - val_VL_attention_linear_output_loss: 1.7120 - val_VH_attention_linear_output_loss: 1.7110 - val_VL_attention_linear_output_acc: 0.5012 - val_VH_attention_linear_output_acc: 0.5120\n",
      "Epoch 4895/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2612 - VL_attention_linear_output_loss: 1.6297 - VH_attention_linear_output_loss: 1.6315 - VL_attention_linear_output_acc: 0.5164 - VH_attention_linear_output_acc: 0.5273 - val_loss: 3.4527 - val_VL_attention_linear_output_loss: 1.7222 - val_VH_attention_linear_output_loss: 1.7305 - val_VL_attention_linear_output_acc: 0.5006 - val_VH_attention_linear_output_acc: 0.5026\n",
      "Epoch 4896/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2769 - VL_attention_linear_output_loss: 1.6361 - VH_attention_linear_output_loss: 1.6408 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5241 - val_loss: 3.4896 - val_VL_attention_linear_output_loss: 1.7815 - val_VH_attention_linear_output_loss: 1.7081 - val_VL_attention_linear_output_acc: 0.4678 - val_VH_attention_linear_output_acc: 0.5109\n",
      "Epoch 4897/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2654 - VL_attention_linear_output_loss: 1.6357 - VH_attention_linear_output_loss: 1.6297 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5279 - val_loss: 3.4370 - val_VL_attention_linear_output_loss: 1.7114 - val_VH_attention_linear_output_loss: 1.7256 - val_VL_attention_linear_output_acc: 0.4962 - val_VH_attention_linear_output_acc: 0.5071\n",
      "Epoch 4898/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2695 - VL_attention_linear_output_loss: 1.6366 - VH_attention_linear_output_loss: 1.6329 - VL_attention_linear_output_acc: 0.5132 - VH_attention_linear_output_acc: 0.5263 - val_loss: 3.4306 - val_VL_attention_linear_output_loss: 1.7183 - val_VH_attention_linear_output_loss: 1.7123 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.5097\n",
      "Epoch 4899/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2690 - VL_attention_linear_output_loss: 1.6339 - VH_attention_linear_output_loss: 1.6351 - VL_attention_linear_output_acc: 0.5140 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4196 - val_VL_attention_linear_output_loss: 1.7109 - val_VH_attention_linear_output_loss: 1.7087 - val_VL_attention_linear_output_acc: 0.5063 - val_VH_attention_linear_output_acc: 0.5118\n",
      "Epoch 4900/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2726 - VL_attention_linear_output_loss: 1.6386 - VH_attention_linear_output_loss: 1.6340 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5262 - val_loss: 3.4237 - val_VL_attention_linear_output_loss: 1.7171 - val_VH_attention_linear_output_loss: 1.7066 - val_VL_attention_linear_output_acc: 0.5044 - val_VH_attention_linear_output_acc: 0.5118\n",
      "Epoch 4901/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2625 - VL_attention_linear_output_loss: 1.6282 - VH_attention_linear_output_loss: 1.6343 - VL_attention_linear_output_acc: 0.5158 - VH_attention_linear_output_acc: 0.5260 - val_loss: 3.4201 - val_VL_attention_linear_output_loss: 1.7102 - val_VH_attention_linear_output_loss: 1.7099 - val_VL_attention_linear_output_acc: 0.5058 - val_VH_attention_linear_output_acc: 0.5108\n",
      "Epoch 4902/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2647 - VL_attention_linear_output_loss: 1.6297 - VH_attention_linear_output_loss: 1.6350 - VL_attention_linear_output_acc: 0.5157 - VH_attention_linear_output_acc: 0.5263 - val_loss: 3.4751 - val_VL_attention_linear_output_loss: 1.7362 - val_VH_attention_linear_output_loss: 1.7389 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.4968\n",
      "Epoch 4903/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2745 - VL_attention_linear_output_loss: 1.6369 - VH_attention_linear_output_loss: 1.6376 - VL_attention_linear_output_acc: 0.5125 - VH_attention_linear_output_acc: 0.5250 - val_loss: 3.4626 - val_VL_attention_linear_output_loss: 1.7287 - val_VH_attention_linear_output_loss: 1.7339 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.5021\n",
      "Epoch 4904/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2694 - VL_attention_linear_output_loss: 1.6405 - VH_attention_linear_output_loss: 1.6289 - VL_attention_linear_output_acc: 0.5122 - VH_attention_linear_output_acc: 0.5284 - val_loss: 3.4278 - val_VL_attention_linear_output_loss: 1.7186 - val_VH_attention_linear_output_loss: 1.7092 - val_VL_attention_linear_output_acc: 0.5028 - val_VH_attention_linear_output_acc: 0.5090\n",
      "Epoch 4905/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2728 - VL_attention_linear_output_loss: 1.6361 - VH_attention_linear_output_loss: 1.6368 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5253 - val_loss: 3.4412 - val_VL_attention_linear_output_loss: 1.7172 - val_VH_attention_linear_output_loss: 1.7240 - val_VL_attention_linear_output_acc: 0.4961 - val_VH_attention_linear_output_acc: 0.5039\n",
      "Epoch 4906/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2732 - VL_attention_linear_output_loss: 1.6316 - VH_attention_linear_output_loss: 1.6416 - VL_attention_linear_output_acc: 0.5159 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4259 - val_VL_attention_linear_output_loss: 1.7147 - val_VH_attention_linear_output_loss: 1.7112 - val_VL_attention_linear_output_acc: 0.4986 - val_VH_attention_linear_output_acc: 0.5095\n",
      "Epoch 4907/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2751 - VL_attention_linear_output_loss: 1.6342 - VH_attention_linear_output_loss: 1.6409 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5240 - val_loss: 3.4684 - val_VL_attention_linear_output_loss: 1.7161 - val_VH_attention_linear_output_loss: 1.7523 - val_VL_attention_linear_output_acc: 0.5014 - val_VH_attention_linear_output_acc: 0.4904\n",
      "Epoch 4908/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2718 - VL_attention_linear_output_loss: 1.6330 - VH_attention_linear_output_loss: 1.6388 - VL_attention_linear_output_acc: 0.5153 - VH_attention_linear_output_acc: 0.5248 - val_loss: 3.4787 - val_VL_attention_linear_output_loss: 1.7685 - val_VH_attention_linear_output_loss: 1.7102 - val_VL_attention_linear_output_acc: 0.4863 - val_VH_attention_linear_output_acc: 0.5072\n",
      "Epoch 4909/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2699 - VL_attention_linear_output_loss: 1.6404 - VH_attention_linear_output_loss: 1.6295 - VL_attention_linear_output_acc: 0.5121 - VH_attention_linear_output_acc: 0.5284 - val_loss: 3.4223 - val_VL_attention_linear_output_loss: 1.7141 - val_VH_attention_linear_output_loss: 1.7082 - val_VL_attention_linear_output_acc: 0.4980 - val_VH_attention_linear_output_acc: 0.5135\n",
      "Epoch 4910/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2608 - VL_attention_linear_output_loss: 1.6256 - VH_attention_linear_output_loss: 1.6351 - VL_attention_linear_output_acc: 0.5177 - VH_attention_linear_output_acc: 0.5256 - val_loss: 3.4285 - val_VL_attention_linear_output_loss: 1.7219 - val_VH_attention_linear_output_loss: 1.7066 - val_VL_attention_linear_output_acc: 0.5053 - val_VH_attention_linear_output_acc: 0.5116\n",
      "Epoch 4911/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2666 - VL_attention_linear_output_loss: 1.6353 - VH_attention_linear_output_loss: 1.6313 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5274 - val_loss: 3.4370 - val_VL_attention_linear_output_loss: 1.7316 - val_VH_attention_linear_output_loss: 1.7054 - val_VL_attention_linear_output_acc: 0.4895 - val_VH_attention_linear_output_acc: 0.5129\n",
      "Epoch 4912/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2762 - VL_attention_linear_output_loss: 1.6370 - VH_attention_linear_output_loss: 1.6393 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5247 - val_loss: 3.4356 - val_VL_attention_linear_output_loss: 1.7203 - val_VH_attention_linear_output_loss: 1.7153 - val_VL_attention_linear_output_acc: 0.5007 - val_VH_attention_linear_output_acc: 0.5096\n",
      "Epoch 4913/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2703 - VL_attention_linear_output_loss: 1.6366 - VH_attention_linear_output_loss: 1.6338 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5264 - val_loss: 3.4295 - val_VL_attention_linear_output_loss: 1.7201 - val_VH_attention_linear_output_loss: 1.7095 - val_VL_attention_linear_output_acc: 0.5030 - val_VH_attention_linear_output_acc: 0.5102\n",
      "Epoch 4914/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2711 - VL_attention_linear_output_loss: 1.6301 - VH_attention_linear_output_loss: 1.6410 - VL_attention_linear_output_acc: 0.5169 - VH_attention_linear_output_acc: 0.5241 - val_loss: 3.4249 - val_VL_attention_linear_output_loss: 1.7198 - val_VH_attention_linear_output_loss: 1.7051 - val_VL_attention_linear_output_acc: 0.5020 - val_VH_attention_linear_output_acc: 0.5110\n",
      "Epoch 4915/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2562 - VL_attention_linear_output_loss: 1.6282 - VH_attention_linear_output_loss: 1.6280 - VL_attention_linear_output_acc: 0.5168 - VH_attention_linear_output_acc: 0.5281 - val_loss: 3.4172 - val_VL_attention_linear_output_loss: 1.7124 - val_VH_attention_linear_output_loss: 1.7048 - val_VL_attention_linear_output_acc: 0.5035 - val_VH_attention_linear_output_acc: 0.5125\n",
      "Epoch 4916/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2758 - VL_attention_linear_output_loss: 1.6418 - VH_attention_linear_output_loss: 1.6341 - VL_attention_linear_output_acc: 0.5117 - VH_attention_linear_output_acc: 0.5262 - val_loss: 3.4207 - val_VL_attention_linear_output_loss: 1.7120 - val_VH_attention_linear_output_loss: 1.7087 - val_VL_attention_linear_output_acc: 0.4991 - val_VH_attention_linear_output_acc: 0.5118\n",
      "Epoch 4917/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2740 - VL_attention_linear_output_loss: 1.6381 - VH_attention_linear_output_loss: 1.6359 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5259 - val_loss: 3.4369 - val_VL_attention_linear_output_loss: 1.7238 - val_VH_attention_linear_output_loss: 1.7131 - val_VL_attention_linear_output_acc: 0.4975 - val_VH_attention_linear_output_acc: 0.5102\n",
      "Epoch 4918/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2629 - VL_attention_linear_output_loss: 1.6302 - VH_attention_linear_output_loss: 1.6327 - VL_attention_linear_output_acc: 0.5148 - VH_attention_linear_output_acc: 0.5272 - val_loss: 3.4235 - val_VL_attention_linear_output_loss: 1.7131 - val_VH_attention_linear_output_loss: 1.7103 - val_VL_attention_linear_output_acc: 0.5064 - val_VH_attention_linear_output_acc: 0.5071\n",
      "Epoch 4919/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2719 - VL_attention_linear_output_loss: 1.6380 - VH_attention_linear_output_loss: 1.6339 - VL_attention_linear_output_acc: 0.5138 - VH_attention_linear_output_acc: 0.5261 - val_loss: 3.4199 - val_VL_attention_linear_output_loss: 1.7125 - val_VH_attention_linear_output_loss: 1.7074 - val_VL_attention_linear_output_acc: 0.5035 - val_VH_attention_linear_output_acc: 0.5115\n",
      "Epoch 4920/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2587 - VL_attention_linear_output_loss: 1.6298 - VH_attention_linear_output_loss: 1.6289 - VL_attention_linear_output_acc: 0.5163 - VH_attention_linear_output_acc: 0.5279 - val_loss: 3.4286 - val_VL_attention_linear_output_loss: 1.7193 - val_VH_attention_linear_output_loss: 1.7093 - val_VL_attention_linear_output_acc: 0.4967 - val_VH_attention_linear_output_acc: 0.5144\n",
      "Epoch 4921/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2749 - VL_attention_linear_output_loss: 1.6374 - VH_attention_linear_output_loss: 1.6375 - VL_attention_linear_output_acc: 0.5123 - VH_attention_linear_output_acc: 0.5250 - val_loss: 3.4337 - val_VL_attention_linear_output_loss: 1.7234 - val_VH_attention_linear_output_loss: 1.7103 - val_VL_attention_linear_output_acc: 0.5028 - val_VH_attention_linear_output_acc: 0.5087\n",
      "Epoch 4922/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2670 - VL_attention_linear_output_loss: 1.6271 - VH_attention_linear_output_loss: 1.6399 - VL_attention_linear_output_acc: 0.5175 - VH_attention_linear_output_acc: 0.5247 - val_loss: 3.4711 - val_VL_attention_linear_output_loss: 1.7145 - val_VH_attention_linear_output_loss: 1.7566 - val_VL_attention_linear_output_acc: 0.4992 - val_VH_attention_linear_output_acc: 0.4994\n",
      "Epoch 4923/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2889 - VL_attention_linear_output_loss: 1.6445 - VH_attention_linear_output_loss: 1.6443 - VL_attention_linear_output_acc: 0.5106 - VH_attention_linear_output_acc: 0.5231 - val_loss: 3.4240 - val_VL_attention_linear_output_loss: 1.7165 - val_VH_attention_linear_output_loss: 1.7074 - val_VL_attention_linear_output_acc: 0.4993 - val_VH_attention_linear_output_acc: 0.5112\n",
      "Epoch 4924/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2551 - VL_attention_linear_output_loss: 1.6277 - VH_attention_linear_output_loss: 1.6274 - VL_attention_linear_output_acc: 0.5173 - VH_attention_linear_output_acc: 0.5293 - val_loss: 3.4137 - val_VL_attention_linear_output_loss: 1.7100 - val_VH_attention_linear_output_loss: 1.7037 - val_VL_attention_linear_output_acc: 0.5032 - val_VH_attention_linear_output_acc: 0.5112\n",
      "Epoch 4925/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2692 - VL_attention_linear_output_loss: 1.6395 - VH_attention_linear_output_loss: 1.6297 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5279 - val_loss: 3.4259 - val_VL_attention_linear_output_loss: 1.7230 - val_VH_attention_linear_output_loss: 1.7029 - val_VL_attention_linear_output_acc: 0.5041 - val_VH_attention_linear_output_acc: 0.5111\n",
      "Epoch 4926/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2521 - VL_attention_linear_output_loss: 1.6241 - VH_attention_linear_output_loss: 1.6281 - VL_attention_linear_output_acc: 0.5180 - VH_attention_linear_output_acc: 0.5287 - val_loss: 3.4179 - val_VL_attention_linear_output_loss: 1.7129 - val_VH_attention_linear_output_loss: 1.7050 - val_VL_attention_linear_output_acc: 0.4992 - val_VH_attention_linear_output_acc: 0.5115\n",
      "Epoch 4927/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2638 - VL_attention_linear_output_loss: 1.6292 - VH_attention_linear_output_loss: 1.6346 - VL_attention_linear_output_acc: 0.5161 - VH_attention_linear_output_acc: 0.5259 - val_loss: 3.4597 - val_VL_attention_linear_output_loss: 1.7286 - val_VH_attention_linear_output_loss: 1.7311 - val_VL_attention_linear_output_acc: 0.4893 - val_VH_attention_linear_output_acc: 0.5043\n",
      "Epoch 4928/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2761 - VL_attention_linear_output_loss: 1.6432 - VH_attention_linear_output_loss: 1.6329 - VL_attention_linear_output_acc: 0.5112 - VH_attention_linear_output_acc: 0.5271 - val_loss: 3.4249 - val_VL_attention_linear_output_loss: 1.7167 - val_VH_attention_linear_output_loss: 1.7082 - val_VL_attention_linear_output_acc: 0.5063 - val_VH_attention_linear_output_acc: 0.5132\n",
      "Epoch 4929/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2526 - VL_attention_linear_output_loss: 1.6294 - VH_attention_linear_output_loss: 1.6232 - VL_attention_linear_output_acc: 0.5162 - VH_attention_linear_output_acc: 0.5305 - val_loss: 3.4810 - val_VL_attention_linear_output_loss: 1.7167 - val_VH_attention_linear_output_loss: 1.7643 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.4880\n",
      "Epoch 4930/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2575 - VL_attention_linear_output_loss: 1.6305 - VH_attention_linear_output_loss: 1.6271 - VL_attention_linear_output_acc: 0.5163 - VH_attention_linear_output_acc: 0.5292 - val_loss: 3.4275 - val_VL_attention_linear_output_loss: 1.7215 - val_VH_attention_linear_output_loss: 1.7061 - val_VL_attention_linear_output_acc: 0.4969 - val_VH_attention_linear_output_acc: 0.5119\n",
      "Epoch 4931/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2626 - VL_attention_linear_output_loss: 1.6326 - VH_attention_linear_output_loss: 1.6300 - VL_attention_linear_output_acc: 0.5148 - VH_attention_linear_output_acc: 0.5280 - val_loss: 3.4346 - val_VL_attention_linear_output_loss: 1.7119 - val_VH_attention_linear_output_loss: 1.7227 - val_VL_attention_linear_output_acc: 0.5015 - val_VH_attention_linear_output_acc: 0.5042\n",
      "Epoch 4932/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2618 - VL_attention_linear_output_loss: 1.6283 - VH_attention_linear_output_loss: 1.6335 - VL_attention_linear_output_acc: 0.5168 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4516 - val_VL_attention_linear_output_loss: 1.7315 - val_VH_attention_linear_output_loss: 1.7201 - val_VL_attention_linear_output_acc: 0.4915 - val_VH_attention_linear_output_acc: 0.5073\n",
      "Epoch 4933/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2856 - VL_attention_linear_output_loss: 1.6378 - VH_attention_linear_output_loss: 1.6478 - VL_attention_linear_output_acc: 0.5133 - VH_attention_linear_output_acc: 0.5216 - val_loss: 3.4200 - val_VL_attention_linear_output_loss: 1.7087 - val_VH_attention_linear_output_loss: 1.7113 - val_VL_attention_linear_output_acc: 0.5016 - val_VH_attention_linear_output_acc: 0.5105\n",
      "Epoch 4934/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2584 - VL_attention_linear_output_loss: 1.6288 - VH_attention_linear_output_loss: 1.6295 - VL_attention_linear_output_acc: 0.5153 - VH_attention_linear_output_acc: 0.5283 - val_loss: 3.4180 - val_VL_attention_linear_output_loss: 1.7117 - val_VH_attention_linear_output_loss: 1.7063 - val_VL_attention_linear_output_acc: 0.5010 - val_VH_attention_linear_output_acc: 0.5110\n",
      "Epoch 4935/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2520 - VL_attention_linear_output_loss: 1.6283 - VH_attention_linear_output_loss: 1.6237 - VL_attention_linear_output_acc: 0.5167 - VH_attention_linear_output_acc: 0.5302 - val_loss: 3.4240 - val_VL_attention_linear_output_loss: 1.7119 - val_VH_attention_linear_output_loss: 1.7121 - val_VL_attention_linear_output_acc: 0.5067 - val_VH_attention_linear_output_acc: 0.5083\n",
      "Epoch 4936/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2662 - VL_attention_linear_output_loss: 1.6282 - VH_attention_linear_output_loss: 1.6381 - VL_attention_linear_output_acc: 0.5164 - VH_attention_linear_output_acc: 0.5258 - val_loss: 3.4155 - val_VL_attention_linear_output_loss: 1.7087 - val_VH_attention_linear_output_loss: 1.7068 - val_VL_attention_linear_output_acc: 0.5041 - val_VH_attention_linear_output_acc: 0.5099\n",
      "Epoch 4937/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2976 - VL_attention_linear_output_loss: 1.6541 - VH_attention_linear_output_loss: 1.6435 - VL_attention_linear_output_acc: 0.5076 - VH_attention_linear_output_acc: 0.5235 - val_loss: 3.4491 - val_VL_attention_linear_output_loss: 1.7426 - val_VH_attention_linear_output_loss: 1.7065 - val_VL_attention_linear_output_acc: 0.4802 - val_VH_attention_linear_output_acc: 0.5137\n",
      "Epoch 4938/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2713 - VL_attention_linear_output_loss: 1.6358 - VH_attention_linear_output_loss: 1.6355 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5254 - val_loss: 3.4278 - val_VL_attention_linear_output_loss: 1.7140 - val_VH_attention_linear_output_loss: 1.7138 - val_VL_attention_linear_output_acc: 0.5011 - val_VH_attention_linear_output_acc: 0.5124\n",
      "Epoch 4939/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2570 - VL_attention_linear_output_loss: 1.6270 - VH_attention_linear_output_loss: 1.6300 - VL_attention_linear_output_acc: 0.5170 - VH_attention_linear_output_acc: 0.5275 - val_loss: 3.4295 - val_VL_attention_linear_output_loss: 1.7186 - val_VH_attention_linear_output_loss: 1.7109 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.5112\n",
      "Epoch 4940/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2554 - VL_attention_linear_output_loss: 1.6280 - VH_attention_linear_output_loss: 1.6274 - VL_attention_linear_output_acc: 0.5179 - VH_attention_linear_output_acc: 0.5291 - val_loss: 3.4229 - val_VL_attention_linear_output_loss: 1.7146 - val_VH_attention_linear_output_loss: 1.7083 - val_VL_attention_linear_output_acc: 0.5069 - val_VH_attention_linear_output_acc: 0.5115\n",
      "Epoch 4941/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2585 - VL_attention_linear_output_loss: 1.6336 - VH_attention_linear_output_loss: 1.6249 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5297 - val_loss: 3.4727 - val_VL_attention_linear_output_loss: 1.7555 - val_VH_attention_linear_output_loss: 1.7172 - val_VL_attention_linear_output_acc: 0.4896 - val_VH_attention_linear_output_acc: 0.5052\n",
      "Epoch 4942/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2755 - VL_attention_linear_output_loss: 1.6422 - VH_attention_linear_output_loss: 1.6333 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5271 - val_loss: 3.4254 - val_VL_attention_linear_output_loss: 1.7122 - val_VH_attention_linear_output_loss: 1.7131 - val_VL_attention_linear_output_acc: 0.5056 - val_VH_attention_linear_output_acc: 0.5091\n",
      "Epoch 4943/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2626 - VL_attention_linear_output_loss: 1.6348 - VH_attention_linear_output_loss: 1.6278 - VL_attention_linear_output_acc: 0.5135 - VH_attention_linear_output_acc: 0.5282 - val_loss: 3.4427 - val_VL_attention_linear_output_loss: 1.7216 - val_VH_attention_linear_output_loss: 1.7210 - val_VL_attention_linear_output_acc: 0.5047 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4944/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2681 - VL_attention_linear_output_loss: 1.6302 - VH_attention_linear_output_loss: 1.6379 - VL_attention_linear_output_acc: 0.5162 - VH_attention_linear_output_acc: 0.5246 - val_loss: 3.4255 - val_VL_attention_linear_output_loss: 1.7134 - val_VH_attention_linear_output_loss: 1.7121 - val_VL_attention_linear_output_acc: 0.5053 - val_VH_attention_linear_output_acc: 0.5113\n",
      "Epoch 4945/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2698 - VL_attention_linear_output_loss: 1.6306 - VH_attention_linear_output_loss: 1.6392 - VL_attention_linear_output_acc: 0.5158 - VH_attention_linear_output_acc: 0.5252 - val_loss: 3.4317 - val_VL_attention_linear_output_loss: 1.7168 - val_VH_attention_linear_output_loss: 1.7148 - val_VL_attention_linear_output_acc: 0.5003 - val_VH_attention_linear_output_acc: 0.5102\n",
      "Epoch 4946/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2629 - VL_attention_linear_output_loss: 1.6280 - VH_attention_linear_output_loss: 1.6349 - VL_attention_linear_output_acc: 0.5165 - VH_attention_linear_output_acc: 0.5260 - val_loss: 3.4278 - val_VL_attention_linear_output_loss: 1.7135 - val_VH_attention_linear_output_loss: 1.7143 - val_VL_attention_linear_output_acc: 0.5016 - val_VH_attention_linear_output_acc: 0.5074\n",
      "Epoch 4947/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2658 - VL_attention_linear_output_loss: 1.6383 - VH_attention_linear_output_loss: 1.6275 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5288 - val_loss: 3.4622 - val_VL_attention_linear_output_loss: 1.7474 - val_VH_attention_linear_output_loss: 1.7149 - val_VL_attention_linear_output_acc: 0.4927 - val_VH_attention_linear_output_acc: 0.5094\n",
      "Epoch 4948/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2638 - VL_attention_linear_output_loss: 1.6344 - VH_attention_linear_output_loss: 1.6294 - VL_attention_linear_output_acc: 0.5146 - VH_attention_linear_output_acc: 0.5280 - val_loss: 3.4202 - val_VL_attention_linear_output_loss: 1.7123 - val_VH_attention_linear_output_loss: 1.7080 - val_VL_attention_linear_output_acc: 0.4991 - val_VH_attention_linear_output_acc: 0.5109\n",
      "Epoch 4949/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2889 - VL_attention_linear_output_loss: 1.6307 - VH_attention_linear_output_loss: 1.6582 - VL_attention_linear_output_acc: 0.5155 - VH_attention_linear_output_acc: 0.5185 - val_loss: 3.4089 - val_VL_attention_linear_output_loss: 1.7065 - val_VH_attention_linear_output_loss: 1.7024 - val_VL_attention_linear_output_acc: 0.5045 - val_VH_attention_linear_output_acc: 0.5107\n",
      "Epoch 4950/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2587 - VL_attention_linear_output_loss: 1.6295 - VH_attention_linear_output_loss: 1.6291 - VL_attention_linear_output_acc: 0.5168 - VH_attention_linear_output_acc: 0.5281 - val_loss: 3.4247 - val_VL_attention_linear_output_loss: 1.7220 - val_VH_attention_linear_output_loss: 1.7027 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5128\n",
      "Epoch 4951/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2718 - VL_attention_linear_output_loss: 1.6462 - VH_attention_linear_output_loss: 1.6257 - VL_attention_linear_output_acc: 0.5100 - VH_attention_linear_output_acc: 0.5297 - val_loss: 3.4166 - val_VL_attention_linear_output_loss: 1.7164 - val_VH_attention_linear_output_loss: 1.7002 - val_VL_attention_linear_output_acc: 0.5011 - val_VH_attention_linear_output_acc: 0.5131\n",
      "Epoch 4952/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2568 - VL_attention_linear_output_loss: 1.6317 - VH_attention_linear_output_loss: 1.6252 - VL_attention_linear_output_acc: 0.5153 - VH_attention_linear_output_acc: 0.5298 - val_loss: 3.4164 - val_VL_attention_linear_output_loss: 1.7080 - val_VH_attention_linear_output_loss: 1.7085 - val_VL_attention_linear_output_acc: 0.5077 - val_VH_attention_linear_output_acc: 0.5091\n",
      "Epoch 4953/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2628 - VL_attention_linear_output_loss: 1.6333 - VH_attention_linear_output_loss: 1.6296 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5281 - val_loss: 3.4297 - val_VL_attention_linear_output_loss: 1.7195 - val_VH_attention_linear_output_loss: 1.7102 - val_VL_attention_linear_output_acc: 0.5020 - val_VH_attention_linear_output_acc: 0.5101\n",
      "Epoch 4954/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2713 - VL_attention_linear_output_loss: 1.6374 - VH_attention_linear_output_loss: 1.6340 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5267 - val_loss: 3.4414 - val_VL_attention_linear_output_loss: 1.7301 - val_VH_attention_linear_output_loss: 1.7112 - val_VL_attention_linear_output_acc: 0.4977 - val_VH_attention_linear_output_acc: 0.5128\n",
      "Epoch 4955/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2667 - VL_attention_linear_output_loss: 1.6362 - VH_attention_linear_output_loss: 1.6306 - VL_attention_linear_output_acc: 0.5150 - VH_attention_linear_output_acc: 0.5276 - val_loss: 3.4105 - val_VL_attention_linear_output_loss: 1.7054 - val_VH_attention_linear_output_loss: 1.7052 - val_VL_attention_linear_output_acc: 0.5055 - val_VH_attention_linear_output_acc: 0.5136\n",
      "Epoch 4956/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2716 - VL_attention_linear_output_loss: 1.6333 - VH_attention_linear_output_loss: 1.6383 - VL_attention_linear_output_acc: 0.5140 - VH_attention_linear_output_acc: 0.5251 - val_loss: 3.4211 - val_VL_attention_linear_output_loss: 1.7161 - val_VH_attention_linear_output_loss: 1.7050 - val_VL_attention_linear_output_acc: 0.4959 - val_VH_attention_linear_output_acc: 0.5108\n",
      "Epoch 4957/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2595 - VL_attention_linear_output_loss: 1.6315 - VH_attention_linear_output_loss: 1.6280 - VL_attention_linear_output_acc: 0.5148 - VH_attention_linear_output_acc: 0.5283 - val_loss: 3.4195 - val_VL_attention_linear_output_loss: 1.7111 - val_VH_attention_linear_output_loss: 1.7084 - val_VL_attention_linear_output_acc: 0.5020 - val_VH_attention_linear_output_acc: 0.5125\n",
      "Epoch 4958/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2703 - VL_attention_linear_output_loss: 1.6362 - VH_attention_linear_output_loss: 1.6341 - VL_attention_linear_output_acc: 0.5145 - VH_attention_linear_output_acc: 0.5261 - val_loss: 3.4349 - val_VL_attention_linear_output_loss: 1.7089 - val_VH_attention_linear_output_loss: 1.7261 - val_VL_attention_linear_output_acc: 0.5016 - val_VH_attention_linear_output_acc: 0.5069\n",
      "Epoch 4959/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2729 - VL_attention_linear_output_loss: 1.6369 - VH_attention_linear_output_loss: 1.6360 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5250 - val_loss: 3.4357 - val_VL_attention_linear_output_loss: 1.7234 - val_VH_attention_linear_output_loss: 1.7122 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5101\n",
      "Epoch 4960/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2606 - VL_attention_linear_output_loss: 1.6280 - VH_attention_linear_output_loss: 1.6326 - VL_attention_linear_output_acc: 0.5174 - VH_attention_linear_output_acc: 0.5272 - val_loss: 3.4392 - val_VL_attention_linear_output_loss: 1.7231 - val_VH_attention_linear_output_loss: 1.7160 - val_VL_attention_linear_output_acc: 0.5013 - val_VH_attention_linear_output_acc: 0.5051\n",
      "Epoch 4961/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2674 - VL_attention_linear_output_loss: 1.6323 - VH_attention_linear_output_loss: 1.6351 - VL_attention_linear_output_acc: 0.5151 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4292 - val_VL_attention_linear_output_loss: 1.7226 - val_VH_attention_linear_output_loss: 1.7066 - val_VL_attention_linear_output_acc: 0.4931 - val_VH_attention_linear_output_acc: 0.5127\n",
      "Epoch 4962/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2691 - VL_attention_linear_output_loss: 1.6401 - VH_attention_linear_output_loss: 1.6290 - VL_attention_linear_output_acc: 0.5126 - VH_attention_linear_output_acc: 0.5282 - val_loss: 3.4357 - val_VL_attention_linear_output_loss: 1.7311 - val_VH_attention_linear_output_loss: 1.7046 - val_VL_attention_linear_output_acc: 0.4922 - val_VH_attention_linear_output_acc: 0.5112\n",
      "Epoch 4963/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2573 - VL_attention_linear_output_loss: 1.6311 - VH_attention_linear_output_loss: 1.6261 - VL_attention_linear_output_acc: 0.5159 - VH_attention_linear_output_acc: 0.5298 - val_loss: 3.4253 - val_VL_attention_linear_output_loss: 1.7165 - val_VH_attention_linear_output_loss: 1.7088 - val_VL_attention_linear_output_acc: 0.5029 - val_VH_attention_linear_output_acc: 0.5106\n",
      "Epoch 4964/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2561 - VL_attention_linear_output_loss: 1.6276 - VH_attention_linear_output_loss: 1.6285 - VL_attention_linear_output_acc: 0.5161 - VH_attention_linear_output_acc: 0.5285 - val_loss: 3.4312 - val_VL_attention_linear_output_loss: 1.7126 - val_VH_attention_linear_output_loss: 1.7186 - val_VL_attention_linear_output_acc: 0.5023 - val_VH_attention_linear_output_acc: 0.5093\n",
      "Epoch 4965/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2733 - VL_attention_linear_output_loss: 1.6309 - VH_attention_linear_output_loss: 1.6424 - VL_attention_linear_output_acc: 0.5153 - VH_attention_linear_output_acc: 0.5237 - val_loss: 3.4187 - val_VL_attention_linear_output_loss: 1.7146 - val_VH_attention_linear_output_loss: 1.7042 - val_VL_attention_linear_output_acc: 0.5055 - val_VH_attention_linear_output_acc: 0.5125\n",
      "Epoch 4966/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2675 - VL_attention_linear_output_loss: 1.6389 - VH_attention_linear_output_loss: 1.6287 - VL_attention_linear_output_acc: 0.5130 - VH_attention_linear_output_acc: 0.5289 - val_loss: 3.4173 - val_VL_attention_linear_output_loss: 1.7076 - val_VH_attention_linear_output_loss: 1.7097 - val_VL_attention_linear_output_acc: 0.5024 - val_VH_attention_linear_output_acc: 0.5101\n",
      "Epoch 4967/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2682 - VL_attention_linear_output_loss: 1.6320 - VH_attention_linear_output_loss: 1.6361 - VL_attention_linear_output_acc: 0.5158 - VH_attention_linear_output_acc: 0.5256 - val_loss: 3.4279 - val_VL_attention_linear_output_loss: 1.7151 - val_VH_attention_linear_output_loss: 1.7128 - val_VL_attention_linear_output_acc: 0.4983 - val_VH_attention_linear_output_acc: 0.5047\n",
      "Epoch 4968/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2790 - VL_attention_linear_output_loss: 1.6317 - VH_attention_linear_output_loss: 1.6472 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5227 - val_loss: 3.4185 - val_VL_attention_linear_output_loss: 1.7123 - val_VH_attention_linear_output_loss: 1.7062 - val_VL_attention_linear_output_acc: 0.5067 - val_VH_attention_linear_output_acc: 0.5100\n",
      "Epoch 4969/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2533 - VL_attention_linear_output_loss: 1.6283 - VH_attention_linear_output_loss: 1.6250 - VL_attention_linear_output_acc: 0.5172 - VH_attention_linear_output_acc: 0.5300 - val_loss: 3.4210 - val_VL_attention_linear_output_loss: 1.7148 - val_VH_attention_linear_output_loss: 1.7062 - val_VL_attention_linear_output_acc: 0.4983 - val_VH_attention_linear_output_acc: 0.5135\n",
      "Epoch 4970/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2712 - VL_attention_linear_output_loss: 1.6354 - VH_attention_linear_output_loss: 1.6357 - VL_attention_linear_output_acc: 0.5142 - VH_attention_linear_output_acc: 0.5264 - val_loss: 3.4498 - val_VL_attention_linear_output_loss: 1.7408 - val_VH_attention_linear_output_loss: 1.7090 - val_VL_attention_linear_output_acc: 0.4817 - val_VH_attention_linear_output_acc: 0.5096\n",
      "Epoch 4971/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2634 - VL_attention_linear_output_loss: 1.6294 - VH_attention_linear_output_loss: 1.6339 - VL_attention_linear_output_acc: 0.5158 - VH_attention_linear_output_acc: 0.5266 - val_loss: 3.4495 - val_VL_attention_linear_output_loss: 1.7074 - val_VH_attention_linear_output_loss: 1.7421 - val_VL_attention_linear_output_acc: 0.4988 - val_VH_attention_linear_output_acc: 0.5028\n",
      "Epoch 4972/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2627 - VL_attention_linear_output_loss: 1.6340 - VH_attention_linear_output_loss: 1.6288 - VL_attention_linear_output_acc: 0.5131 - VH_attention_linear_output_acc: 0.5290 - val_loss: 3.4133 - val_VL_attention_linear_output_loss: 1.7117 - val_VH_attention_linear_output_loss: 1.7016 - val_VL_attention_linear_output_acc: 0.5068 - val_VH_attention_linear_output_acc: 0.5126\n",
      "Epoch 4973/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2573 - VL_attention_linear_output_loss: 1.6248 - VH_attention_linear_output_loss: 1.6325 - VL_attention_linear_output_acc: 0.5184 - VH_attention_linear_output_acc: 0.5270 - val_loss: 3.4212 - val_VL_attention_linear_output_loss: 1.7131 - val_VH_attention_linear_output_loss: 1.7081 - val_VL_attention_linear_output_acc: 0.5085 - val_VH_attention_linear_output_acc: 0.5092\n",
      "Epoch 4974/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2732 - VL_attention_linear_output_loss: 1.6356 - VH_attention_linear_output_loss: 1.6376 - VL_attention_linear_output_acc: 0.5137 - VH_attention_linear_output_acc: 0.5255 - val_loss: 3.4320 - val_VL_attention_linear_output_loss: 1.7093 - val_VH_attention_linear_output_loss: 1.7226 - val_VL_attention_linear_output_acc: 0.5027 - val_VH_attention_linear_output_acc: 0.5051\n",
      "Epoch 4975/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2783 - VL_attention_linear_output_loss: 1.6390 - VH_attention_linear_output_loss: 1.6393 - VL_attention_linear_output_acc: 0.5128 - VH_attention_linear_output_acc: 0.5247 - val_loss: 3.4171 - val_VL_attention_linear_output_loss: 1.7060 - val_VH_attention_linear_output_loss: 1.7111 - val_VL_attention_linear_output_acc: 0.5021 - val_VH_attention_linear_output_acc: 0.5087\n",
      "Epoch 4976/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2611 - VL_attention_linear_output_loss: 1.6343 - VH_attention_linear_output_loss: 1.6269 - VL_attention_linear_output_acc: 0.5143 - VH_attention_linear_output_acc: 0.5291 - val_loss: 3.4168 - val_VL_attention_linear_output_loss: 1.7094 - val_VH_attention_linear_output_loss: 1.7074 - val_VL_attention_linear_output_acc: 0.5036 - val_VH_attention_linear_output_acc: 0.5095\n",
      "Epoch 4977/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2743 - VL_attention_linear_output_loss: 1.6295 - VH_attention_linear_output_loss: 1.6448 - VL_attention_linear_output_acc: 0.5158 - VH_attention_linear_output_acc: 0.5234 - val_loss: 3.4106 - val_VL_attention_linear_output_loss: 1.7036 - val_VH_attention_linear_output_loss: 1.7070 - val_VL_attention_linear_output_acc: 0.5063 - val_VH_attention_linear_output_acc: 0.5124\n",
      "Epoch 4978/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2669 - VL_attention_linear_output_loss: 1.6401 - VH_attention_linear_output_loss: 1.6268 - VL_attention_linear_output_acc: 0.5113 - VH_attention_linear_output_acc: 0.5291 - val_loss: 3.4172 - val_VL_attention_linear_output_loss: 1.7160 - val_VH_attention_linear_output_loss: 1.7012 - val_VL_attention_linear_output_acc: 0.4988 - val_VH_attention_linear_output_acc: 0.5141\n",
      "Epoch 4979/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2707 - VL_attention_linear_output_loss: 1.6298 - VH_attention_linear_output_loss: 1.6409 - VL_attention_linear_output_acc: 0.5159 - VH_attention_linear_output_acc: 0.5243 - val_loss: 3.4223 - val_VL_attention_linear_output_loss: 1.7119 - val_VH_attention_linear_output_loss: 1.7104 - val_VL_attention_linear_output_acc: 0.4958 - val_VH_attention_linear_output_acc: 0.5130\n",
      "Epoch 4980/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2550 - VL_attention_linear_output_loss: 1.6298 - VH_attention_linear_output_loss: 1.6252 - VL_attention_linear_output_acc: 0.5170 - VH_attention_linear_output_acc: 0.5297 - val_loss: 3.4314 - val_VL_attention_linear_output_loss: 1.7109 - val_VH_attention_linear_output_loss: 1.7205 - val_VL_attention_linear_output_acc: 0.5077 - val_VH_attention_linear_output_acc: 0.5054\n",
      "Epoch 4981/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2667 - VL_attention_linear_output_loss: 1.6315 - VH_attention_linear_output_loss: 1.6351 - VL_attention_linear_output_acc: 0.5167 - VH_attention_linear_output_acc: 0.5256 - val_loss: 3.4087 - val_VL_attention_linear_output_loss: 1.7075 - val_VH_attention_linear_output_loss: 1.7012 - val_VL_attention_linear_output_acc: 0.5040 - val_VH_attention_linear_output_acc: 0.5130\n",
      "Epoch 4982/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2725 - VL_attention_linear_output_loss: 1.6377 - VH_attention_linear_output_loss: 1.6348 - VL_attention_linear_output_acc: 0.5141 - VH_attention_linear_output_acc: 0.5260 - val_loss: 3.4325 - val_VL_attention_linear_output_loss: 1.7140 - val_VH_attention_linear_output_loss: 1.7185 - val_VL_attention_linear_output_acc: 0.4999 - val_VH_attention_linear_output_acc: 0.5096\n",
      "Epoch 4983/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2584 - VL_attention_linear_output_loss: 1.6313 - VH_attention_linear_output_loss: 1.6270 - VL_attention_linear_output_acc: 0.5155 - VH_attention_linear_output_acc: 0.5287 - val_loss: 3.4089 - val_VL_attention_linear_output_loss: 1.7057 - val_VH_attention_linear_output_loss: 1.7032 - val_VL_attention_linear_output_acc: 0.5050 - val_VH_attention_linear_output_acc: 0.5147\n",
      "Epoch 4984/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2772 - VL_attention_linear_output_loss: 1.6403 - VH_attention_linear_output_loss: 1.6369 - VL_attention_linear_output_acc: 0.5134 - VH_attention_linear_output_acc: 0.5253 - val_loss: 3.4254 - val_VL_attention_linear_output_loss: 1.7134 - val_VH_attention_linear_output_loss: 1.7120 - val_VL_attention_linear_output_acc: 0.5019 - val_VH_attention_linear_output_acc: 0.5113\n",
      "Epoch 4985/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2663 - VL_attention_linear_output_loss: 1.6312 - VH_attention_linear_output_loss: 1.6352 - VL_attention_linear_output_acc: 0.5156 - VH_attention_linear_output_acc: 0.5261 - val_loss: 3.4385 - val_VL_attention_linear_output_loss: 1.7101 - val_VH_attention_linear_output_loss: 1.7284 - val_VL_attention_linear_output_acc: 0.4991 - val_VH_attention_linear_output_acc: 0.4991\n",
      "Epoch 4986/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2514 - VL_attention_linear_output_loss: 1.6262 - VH_attention_linear_output_loss: 1.6252 - VL_attention_linear_output_acc: 0.5171 - VH_attention_linear_output_acc: 0.5298 - val_loss: 3.4139 - val_VL_attention_linear_output_loss: 1.7083 - val_VH_attention_linear_output_loss: 1.7056 - val_VL_attention_linear_output_acc: 0.5062 - val_VH_attention_linear_output_acc: 0.5126\n",
      "Epoch 4987/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2663 - VL_attention_linear_output_loss: 1.6356 - VH_attention_linear_output_loss: 1.6306 - VL_attention_linear_output_acc: 0.5139 - VH_attention_linear_output_acc: 0.5271 - val_loss: 3.4200 - val_VL_attention_linear_output_loss: 1.7118 - val_VH_attention_linear_output_loss: 1.7082 - val_VL_attention_linear_output_acc: 0.5022 - val_VH_attention_linear_output_acc: 0.5089\n",
      "Epoch 4988/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2570 - VL_attention_linear_output_loss: 1.6237 - VH_attention_linear_output_loss: 1.6333 - VL_attention_linear_output_acc: 0.5187 - VH_attention_linear_output_acc: 0.5270 - val_loss: 3.4272 - val_VL_attention_linear_output_loss: 1.7110 - val_VH_attention_linear_output_loss: 1.7163 - val_VL_attention_linear_output_acc: 0.5068 - val_VH_attention_linear_output_acc: 0.5128\n",
      "Epoch 4989/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2660 - VL_attention_linear_output_loss: 1.6327 - VH_attention_linear_output_loss: 1.6333 - VL_attention_linear_output_acc: 0.5155 - VH_attention_linear_output_acc: 0.5272 - val_loss: 3.4220 - val_VL_attention_linear_output_loss: 1.7117 - val_VH_attention_linear_output_loss: 1.7103 - val_VL_attention_linear_output_acc: 0.5001 - val_VH_attention_linear_output_acc: 0.5124\n",
      "Epoch 4990/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2706 - VL_attention_linear_output_loss: 1.6325 - VH_attention_linear_output_loss: 1.6380 - VL_attention_linear_output_acc: 0.5155 - VH_attention_linear_output_acc: 0.5255 - val_loss: 3.4414 - val_VL_attention_linear_output_loss: 1.7196 - val_VH_attention_linear_output_loss: 1.7218 - val_VL_attention_linear_output_acc: 0.5053 - val_VH_attention_linear_output_acc: 0.5050\n",
      "Epoch 4991/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2592 - VL_attention_linear_output_loss: 1.6257 - VH_attention_linear_output_loss: 1.6335 - VL_attention_linear_output_acc: 0.5177 - VH_attention_linear_output_acc: 0.5268 - val_loss: 3.4279 - val_VL_attention_linear_output_loss: 1.7211 - val_VH_attention_linear_output_loss: 1.7069 - val_VL_attention_linear_output_acc: 0.5072 - val_VH_attention_linear_output_acc: 0.5142\n",
      "Epoch 4992/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2583 - VL_attention_linear_output_loss: 1.6298 - VH_attention_linear_output_loss: 1.6286 - VL_attention_linear_output_acc: 0.5157 - VH_attention_linear_output_acc: 0.5287 - val_loss: 3.4445 - val_VL_attention_linear_output_loss: 1.7163 - val_VH_attention_linear_output_loss: 1.7283 - val_VL_attention_linear_output_acc: 0.5043 - val_VH_attention_linear_output_acc: 0.5071\n",
      "Epoch 4993/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2701 - VL_attention_linear_output_loss: 1.6431 - VH_attention_linear_output_loss: 1.6270 - VL_attention_linear_output_acc: 0.5107 - VH_attention_linear_output_acc: 0.5292 - val_loss: 3.4190 - val_VL_attention_linear_output_loss: 1.7179 - val_VH_attention_linear_output_loss: 1.7011 - val_VL_attention_linear_output_acc: 0.4981 - val_VH_attention_linear_output_acc: 0.5133\n",
      "Epoch 4994/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2610 - VL_attention_linear_output_loss: 1.6229 - VH_attention_linear_output_loss: 1.6381 - VL_attention_linear_output_acc: 0.5188 - VH_attention_linear_output_acc: 0.5248 - val_loss: 3.4178 - val_VL_attention_linear_output_loss: 1.7106 - val_VH_attention_linear_output_loss: 1.7072 - val_VL_attention_linear_output_acc: 0.5049 - val_VH_attention_linear_output_acc: 0.5124\n",
      "Epoch 4995/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2484 - VL_attention_linear_output_loss: 1.6225 - VH_attention_linear_output_loss: 1.6260 - VL_attention_linear_output_acc: 0.5196 - VH_attention_linear_output_acc: 0.5294 - val_loss: 3.4195 - val_VL_attention_linear_output_loss: 1.7060 - val_VH_attention_linear_output_loss: 1.7135 - val_VL_attention_linear_output_acc: 0.5070 - val_VH_attention_linear_output_acc: 0.5087\n",
      "Epoch 4996/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2620 - VL_attention_linear_output_loss: 1.6259 - VH_attention_linear_output_loss: 1.6361 - VL_attention_linear_output_acc: 0.5165 - VH_attention_linear_output_acc: 0.5257 - val_loss: 3.4761 - val_VL_attention_linear_output_loss: 1.7078 - val_VH_attention_linear_output_loss: 1.7683 - val_VL_attention_linear_output_acc: 0.5040 - val_VH_attention_linear_output_acc: 0.4991\n",
      "Epoch 4997/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2755 - VL_attention_linear_output_loss: 1.6344 - VH_attention_linear_output_loss: 1.6411 - VL_attention_linear_output_acc: 0.5151 - VH_attention_linear_output_acc: 0.5243 - val_loss: 3.4368 - val_VL_attention_linear_output_loss: 1.7140 - val_VH_attention_linear_output_loss: 1.7227 - val_VL_attention_linear_output_acc: 0.5064 - val_VH_attention_linear_output_acc: 0.5076\n",
      "Epoch 4998/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2459 - VL_attention_linear_output_loss: 1.6212 - VH_attention_linear_output_loss: 1.6247 - VL_attention_linear_output_acc: 0.5194 - VH_attention_linear_output_acc: 0.5297 - val_loss: 3.4120 - val_VL_attention_linear_output_loss: 1.7059 - val_VH_attention_linear_output_loss: 1.7061 - val_VL_attention_linear_output_acc: 0.5054 - val_VH_attention_linear_output_acc: 0.5127\n",
      "Epoch 4999/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2479 - VL_attention_linear_output_loss: 1.6217 - VH_attention_linear_output_loss: 1.6262 - VL_attention_linear_output_acc: 0.5190 - VH_attention_linear_output_acc: 0.5296 - val_loss: 3.4236 - val_VL_attention_linear_output_loss: 1.7068 - val_VH_attention_linear_output_loss: 1.7168 - val_VL_attention_linear_output_acc: 0.5088 - val_VH_attention_linear_output_acc: 0.5109\n",
      "Epoch 5000/5000\n",
      "4144/4144 [==============================] - 9s 2ms/step - loss: 3.2616 - VL_attention_linear_output_loss: 1.6233 - VH_attention_linear_output_loss: 1.6383 - VL_attention_linear_output_acc: 0.5182 - VH_attention_linear_output_acc: 0.5248 - val_loss: 3.4334 - val_VL_attention_linear_output_loss: 1.7089 - val_VH_attention_linear_output_loss: 1.7245 - val_VL_attention_linear_output_acc: 0.5046 - val_VH_attention_linear_output_acc: 0.5056\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit([VL_encoded_shuffled, VH_encoded_shuffled], [VL_encoded_shuffled, VH_encoded_shuffled],\n",
    "                          epochs=5000, batch_size=32, validation_split=0.2,\n",
    "                          callbacks=[keras.callbacks.ModelCheckpoint(weight_path, save_best_only=True),\n",
    "                                     keras.callbacks.TensorBoard(log_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(autoencoder.history.history['val_loss'], label='Validation loss')\n",
    "plt.plot(autoencoder.history.history['loss'], label='Training loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "code = encoder.predict([VL_encoded, VH_encoded])\n",
    "\n",
    "le = LabelEncoder().fit(animals_mask)\n",
    "labels = le.transform(animals_mask)\n",
    "\n",
    "unique_labels = np.unique(labels)\n",
    "len(unique_labels)\n",
    "\n",
    "c=sns.color_palette(n_colors=25)\n",
    "\n",
    "f,ax = plt.subplots(figsize=(12,12))\n",
    "for x in range(unique_labels.size):\n",
    "    mask_labels = labels == unique_labels[x]\n",
    "    ax.scatter(code[mask_labels,0], code[mask_labels,1], marker='.', c=c[x],label=le.classes_[x], s=100)\n",
    "ax.legend()\n",
    "leg = ax.get_legend()\n",
    "for i, x in enumerate(leg.legendHandles):\n",
    "    x.set_color(c[i])\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in antibody objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gil/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b54a6534fb4d2cac368a1da8e6b5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to load 0 objects in list\n",
      "Loading in antibody objects\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7dca443e5b4f838b595d47a9876817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to load 0 objects in list\n",
      "Loading in antibody objects\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a1486a2e314e3eb85c2c693098fbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=900), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to load 0 objects in list\n",
      "Loading in antibody objects\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089f2f564ada464e8870a36d310e3164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=900), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to load 0 objects in list\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tm D - Mean</th>\n",
       "      <th>Tm D - Std. Error</th>\n",
       "      <th>Tm2 - Mean</th>\n",
       "      <th>Tm2 - Std. Error</th>\n",
       "      <th>Latent1</th>\n",
       "      <th>Latent2</th>\n",
       "      <th>Latent3</th>\n",
       "      <th>Latent4</th>\n",
       "      <th>Latent5</th>\n",
       "      <th>Latent6</th>\n",
       "      <th>...</th>\n",
       "      <th>Latent41</th>\n",
       "      <th>Latent42</th>\n",
       "      <th>Latent43</th>\n",
       "      <th>Latent44</th>\n",
       "      <th>Latent45</th>\n",
       "      <th>Latent46</th>\n",
       "      <th>Latent47</th>\n",
       "      <th>Latent48</th>\n",
       "      <th>Latent49</th>\n",
       "      <th>Latent50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P2</th>\n",
       "      <td>64.473820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.051418</td>\n",
       "      <td>0.021670</td>\n",
       "      <td>0.181966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>0.149049</td>\n",
       "      <td>0.031167</td>\n",
       "      <td>-0.085060</td>\n",
       "      <td>-0.122417</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>-0.032724</td>\n",
       "      <td>-0.067047</td>\n",
       "      <td>0.089651</td>\n",
       "      <td>0.107890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P3</th>\n",
       "      <td>73.982970</td>\n",
       "      <td>0.130358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048295</td>\n",
       "      <td>-0.029499</td>\n",
       "      <td>0.012616</td>\n",
       "      <td>0.045318</td>\n",
       "      <td>0.045699</td>\n",
       "      <td>0.210421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>0.181902</td>\n",
       "      <td>0.091613</td>\n",
       "      <td>-0.067408</td>\n",
       "      <td>-0.161802</td>\n",
       "      <td>0.053480</td>\n",
       "      <td>-0.074275</td>\n",
       "      <td>-0.041463</td>\n",
       "      <td>0.110604</td>\n",
       "      <td>0.061388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P4</th>\n",
       "      <td>64.326010</td>\n",
       "      <td>0.060344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.212363</td>\n",
       "      <td>-0.034255</td>\n",
       "      <td>0.121332</td>\n",
       "      <td>-0.017056</td>\n",
       "      <td>0.090313</td>\n",
       "      <td>0.109553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055115</td>\n",
       "      <td>-0.119031</td>\n",
       "      <td>-0.413384</td>\n",
       "      <td>-0.187159</td>\n",
       "      <td>-0.031011</td>\n",
       "      <td>-0.118497</td>\n",
       "      <td>0.125994</td>\n",
       "      <td>-0.103432</td>\n",
       "      <td>-0.050610</td>\n",
       "      <td>0.157095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P6</th>\n",
       "      <td>74.192370</td>\n",
       "      <td>0.036953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.089274</td>\n",
       "      <td>-0.078399</td>\n",
       "      <td>-0.021633</td>\n",
       "      <td>-0.020640</td>\n",
       "      <td>-0.035128</td>\n",
       "      <td>-0.030462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006228</td>\n",
       "      <td>-0.086683</td>\n",
       "      <td>-0.087677</td>\n",
       "      <td>0.124390</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>-0.131636</td>\n",
       "      <td>0.191119</td>\n",
       "      <td>-0.047083</td>\n",
       "      <td>-0.061675</td>\n",
       "      <td>-0.055586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9</th>\n",
       "      <td>72.899025</td>\n",
       "      <td>0.085337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.232276</td>\n",
       "      <td>0.012704</td>\n",
       "      <td>0.013416</td>\n",
       "      <td>-0.142749</td>\n",
       "      <td>0.097472</td>\n",
       "      <td>0.099610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029664</td>\n",
       "      <td>-0.143968</td>\n",
       "      <td>-0.455162</td>\n",
       "      <td>-0.001830</td>\n",
       "      <td>0.037824</td>\n",
       "      <td>-0.108287</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>-0.026382</td>\n",
       "      <td>-0.040677</td>\n",
       "      <td>0.037382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tm D - Mean  Tm D - Std. Error  Tm2 - Mean  Tm2 - Std. Error   Latent1  \\\n",
       "P2    64.473820           0.000000         NaN               NaN  0.003523   \n",
       "P3    73.982970           0.130358         NaN               NaN  0.048295   \n",
       "P4    64.326010           0.060344         NaN               NaN -0.212363   \n",
       "P6    74.192370           0.036953         NaN               NaN -0.089274   \n",
       "P9    72.899025           0.085337         NaN               NaN -0.232276   \n",
       "\n",
       "     Latent2   Latent3   Latent4   Latent5   Latent6    ...     Latent41  \\\n",
       "P2 -0.005681  0.005243  0.051418  0.021670  0.181966    ...     0.042600   \n",
       "P3 -0.029499  0.012616  0.045318  0.045699  0.210421    ...     0.007334   \n",
       "P4 -0.034255  0.121332 -0.017056  0.090313  0.109553    ...     0.055115   \n",
       "P6 -0.078399 -0.021633 -0.020640 -0.035128 -0.030462    ...    -0.006228   \n",
       "P9  0.012704  0.013416 -0.142749  0.097472  0.099610    ...     0.029664   \n",
       "\n",
       "    Latent42  Latent43  Latent44  Latent45  Latent46  Latent47  Latent48  \\\n",
       "P2  0.149049  0.031167 -0.085060 -0.122417  0.007230 -0.032724 -0.067047   \n",
       "P3  0.181902  0.091613 -0.067408 -0.161802  0.053480 -0.074275 -0.041463   \n",
       "P4 -0.119031 -0.413384 -0.187159 -0.031011 -0.118497  0.125994 -0.103432   \n",
       "P6 -0.086683 -0.087677  0.124390  0.009179 -0.131636  0.191119 -0.047083   \n",
       "P9 -0.143968 -0.455162 -0.001830  0.037824 -0.108287  0.086458 -0.026382   \n",
       "\n",
       "    Latent49  Latent50  \n",
       "P2  0.089651  0.107890  \n",
       "P3  0.110604  0.061388  \n",
       "P4 -0.050610  0.157095  \n",
       "P6 -0.061675 -0.055586  \n",
       "P9 -0.040677  0.037382  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from abpytools import FabCollection, ChainCollection\n",
    "import pandas as pd\n",
    "\n",
    "combinations = pd.read_csv('/home/gil/PhD/UCB/precollection/random_pairs.txt', index_col=0, delimiter=', ')\n",
    "\n",
    "heavy_chains = ChainCollection.load_from_json(path='/home/gil/PhD/UCB/CombinationData/AbFiles/heavy_chains.json')\n",
    "light_chains = ChainCollection.load_from_json(path='/home/gil/PhD/UCB/CombinationData/AbFiles/light_chains.json')\n",
    "\n",
    "heavy_chains_list=[]\n",
    "light_chains_list=[]\n",
    "\n",
    "for heavy, light in  combinations['Random Pairs'].str.split('-'):\n",
    "    heavy_chains_list.append(heavy_chains.get_object(heavy))\n",
    "    light_chains_list.append(light_chains.get_object(light))    \n",
    "    \n",
    "fab_collection = FabCollection(None, heavy_chains_list, light_chains_list,\n",
    "                               names=['P' + str(x) for x in combinations.index.tolist()])\n",
    "\n",
    "data = pd.read_csv('/home/gil/PhD/UCB/Data/Tm/Processed Data/AllTmData.csv', index_col=0)\n",
    "data.index = ['P' + str(x) for x in data.index]\n",
    "\n",
    "VL_data = [''.join(x).replace('-','') for x in fab_collection.numbering_table()['Light'].values]\n",
    "VH_data = [''.join(x).replace('-','') for x in fab_collection.numbering_table()['Heavy'].values]\n",
    "\n",
    "VH_data_encoded = AminoAcidEncoder(max_length=VH_LENGTH).transform(VH_data)\n",
    "VL_data_encoded = AminoAcidEncoder(max_length=VL_LENGTH).transform(VL_data)\n",
    "\n",
    "code_1 = encoder.predict([VL_data_encoded, VH_data_encoded])\n",
    "\n",
    "latent_data = pd.DataFrame(code_1, columns=[f\"Latent{x}\" for x in range(1, 51)], index=fab_collection.names)\n",
    "\n",
    "data = pd.read_csv('/home/gil/PhD/UCB/Data/Tm/Processed Data/AllTmData.csv', index_col=0)\n",
    "data.index = ['P' + str(x) for x in data.index]\n",
    "\n",
    "data.dropna(axis=0, inplace=True, subset=[data.columns[0]])\n",
    "\n",
    "data = data.join(latent_data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gil/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X = data[[x for x in data.columns if 'Latent' in x]].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_variance = [np.var(X[:, x] / abs(np.mean(X[:,x]))) for x in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f74cc17e470>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ax = plt.figure().gca()\n",
    "ax.xaxis.set_major_locator(MaxNLocator(nbins=11))\n",
    "\n",
    "ax.plot(range(1, 51), [norm_variance[x]/sum(norm_variance) for x in np.argsort(norm_variance)[::-1]])\n",
    "ax.plot(range(1, 51), np.cumsum([norm_variance[x]/sum(norm_variance) for x in np.argsort(norm_variance)[::-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 41,  2,  6, 20, 48, 47, 38,  3, 49, 13, 22, 43, 30, 31,  1,  8,\n",
       "        9, 18, 45, 21, 28, 32, 36, 10, 46, 15, 27, 14, 17, 23, 44, 42, 39,\n",
       "       29,  4, 35,  7,  0, 24,  5, 37, 12, 26, 34, 25, 11, 19, 33, 16])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(norm_variance)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f74cc0ccdd8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,40], X[:,41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:, np.argsort(norm_variance)[::-1]][:, :2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
